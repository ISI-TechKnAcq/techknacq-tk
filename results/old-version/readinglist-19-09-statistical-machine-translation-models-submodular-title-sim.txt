Before Submodular: 
56
acl-P08-2040 - {'url': 'https://aclweb.org/anthology/P08-2040', 'book': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2008, 'score': 0.5261784134372253, 'abstract': ['Boxing Chen, Min Zhang, Aiti Aw and Haizhou Li', 'Institute for Infocomm Research 21 Heng Mui Keng Terrace, 119613, Singapore {bxchen, mzhang, aaiti, hli}@i2r.a-star.edu.sg', 'Word and n-gram posterior probabilities estimated on N-best hypotheses have been used to improve the performance of statistical machine translation (SMT) in a rescoring framework.', 'In this paper, we extend the idea to estimate the posterior probabilities on N-best hypotheses for translation phrase-pairs, target language n-grams, and source word re-orderings.', 'The SMT system is self-enhanced with the posterior knowledge learned from N-best hypotheses in a re-decoding framework.', 'Experiments on NIST Chinese-to-English task show performance improvements for all the strategies.', 'Moreover, the combination of the three strategies achieves further improvements and outperforms the baseline by 0.67 BLEU score on NIST-2003 set, and 0.64 on NIST-2005 set, respectively.'], 'authors': ['Boxing Chen', 'Min Zhang', 'Aiti Aw', 'Haizhou Li'], 'id': 'acl-P08-2040', 'type': 'unknown', 'title': 'Exploiting N-best Hypotheses for SMT Self-Enhancement'}
acl-P00-1056 - {'url': 'https://aclweb.org/anthology/P00-1056', 'book': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2000, 'score': 0.767028756136451, 'abstract': ['In this paper, we present and compare various single-word based alignment models for statistical machine translation.', 'We discuss the five IBM alignment models, the Hidden-Markov alignment model, smoothing techniques and various modifications.', 'We present different methods to combine alignments.', 'As evaluation criterion we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment.', 'We show that models with a first-order dependence and a fertility model lead to significantly better results than the simple models IBM-1 or IBM-2, which are not able to go beyond zero-order dependencies.'], 'authors': ['Franz Josef Och', 'Hermann Ney'], 'id': 'acl-P00-1056', 'type': 'unknown', 'title': 'Improved Statistical Alignment Models'}
acl-P14-2095 - {'url': 'https://aclweb.org/anthology/P14-2095', 'book': 'ACL', 'year': 2014, 'score': 0.44787132327976686, 'abstract': ['Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 579?585, Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational Linguistics Cross-lingual Model Transfer Using Feature Representation Projection Mikhail Kozhevnikov MMCI, University of Saarland Saarbr?ucken, Germany mkozhevn@mmci.uni-saarland.de Ivan Titov ILLC, University of Amsterdam Amsterdam, Netherlands titov@uva.nl', 'Abstract', 'We propose a novel approach to cross-lingual model transfer based on feature representation projection.', 'First, a compact feature representation relevant for the task in question is constructed for either language independently and then the mapping between the two representations is determined using parallel data.', 'The target instance can then be mapped into the source-side feature representation using the derived mapping and handled directly by the source-side model.', 'This approach displays competitive performance on model transfer for semantic role labeling when compared to direct model transfer and annotation projection and suggests interesting directions for further research.'], 'authors': ['Mikhail Kozhevnikov', 'Ivan Titov'], 'id': 'acl-P14-2095', 'type': 'unknown', 'title': 'Cross-lingual Model Transfer Using Feature Representation Projection'}
acl-W09-2413 - {'url': 'https://aclweb.org/anthology/W09-2413', 'book': 'Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW-2009)', 'year': 2009, 'score': 0.4206817456456919, 'abstract': ['Els Lefever1,2 and Veronique Hoste', 'LT3, Language and Translation Technology Team, University College Ghent', 'Groot-Brittannielaan 45, 9000 Gent, Belgium Department of Applied Mathematics and Computer Science, Ghent University Krijgslaan 281 (S9), 9000 Gent, Belgium', '(Els.Lefever, Veronique.Hoste}@hogent.be', 'We propose a multilingual unsupervised Word Sense Disambiguation (WSD) task for a sample of English nouns.', 'Instead of providing manually sense-tagged examples for each sense of a polysemous noun, our sense inventory is built up on the basis of the Europarl parallel corpus.', 'The multilingual setup involves the translations of a given English polyse-mous noun in five supported languages, viz. Dutch, French, German, Spanish and Italian.', 'The task targets the following goals: (a) the manual creation of a multilingual sense inventory for a lexical sample of English nouns and (b) the evaluation of systems on their ability to disambiguate new occurrences of the selected polysemous nouns.', 'For the creation of the hand-tagged gold standard, all translations of a given polysemous English noun are retrieved in the five languages and clustered by meaning.', 'Systems can participate in 5 bilingual evaluation subtasks (English - Dutch, English - German, etc.)'], 'authors': ['Els Lefever', 'Véronique Hoste'], 'id': 'acl-W09-2413', 'type': 'unknown', 'title': 'SemEval-2010 Task 3: Cross-lingual Word Sense Disambiguation'}
acl-P08-2038 - {'url': 'https://aclweb.org/anthology/P08-2038', 'book': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2008, 'score': 0.6368380145476898, 'abstract': ['In this paper, we propose a linguistically annotated reordering model for BTG-based statistical machine translation.', 'The model incorporates linguistic knowledge to predict orders for both syntactic and non-syntactic phrases.', 'The linguistic knowledge is automatically learned from source-side parse trees through an annotation algorithm.', 'We empirically demonstrate that the proposed model leads to a significant improvement of 1.55% in the BLEU score over the baseline reordering model on the NIST MT-05 Chinese-to-English translation task.'], 'authors': ['Deyi Xiong', 'Min Zhang', 'Aiti Aw', 'Haizhou Li'], 'id': 'acl-P08-2038', 'type': 'unknown', 'title': 'A Linguistically Annotated Reordering Model for BTG-based Statistical Machine Translation'}
acl-J10-3009 - {'url': 'https://aclweb.org/anthology/J10-3009', 'book': 'Computational Linguistics', 'year': 2010, 'score': 0.5665052485545983, 'abstract': ['Linguistic knowledge plays an important role in phrase movement in statistical machine translation.', 'To efficiently incorporate linguistic knowledge into phrase reordering, we propose a new approach: Linguistically Annotated Reordering (LAR).', 'In LAR, we build hard hierarchical skeletons and inject soft linguistic knowledge from source parse trees to nodes ofhard skeletons during translation.', 'The experimental results on large-scale training data show that LAR is comparable to boundary word-based reordering (BWR) (Xiong, Liu, and Lin 2006), which is a very competitive lexicalized reordering approach.', 'When combined with BWR, LAR provides complementary information for phrase reordering, which collectively improves the BLEU score significantly.', 'To further understand the contribution oflinguistic knowledge in LAR to phrase reordering, we introduce a syntax-based analysis method to automatically detect constituent movement in both reference and system translations, and summarize syntactic reordering patterns that are captured by reordering models.', 'With the proposed analysis method, we conduct a comparative analysis that not only provides the insight into how linguistic knowledge affects phrase movement but also reveals new challenges in phrase reordering.'], 'authors': ['Deyi Xiong', 'Min Zhang', 'Aiti Aw', 'Haizhou Li'], 'id': 'acl-J10-3009', 'type': 'unknown', 'title': 'Linguistically Annotated Reordering: Evaluation and Analysis'}
acl-C94-2175 - {'url': 'https://aclweb.org/anthology/C94-2175', 'book': 'International Conference on Computational Linguistics', 'year': 1994, 'score': 0.5927511131437411, 'abstract': ['This paper describes a unified framework for bilingual text matching by combining existing handwritten bilingual dictionaries and statistical techniques.', 'The process of bilingual text matching consists of two major steps: sentence alignment and structural matching of bilingual sentences.', 'Statistical techniques are applied to estimate word correspondences not included in bilingual dictionaries.', 'Estimated word correspondences are useful for improving both sentence alignment and structural matching.'], 'authors': ['Takehito Utsuro', 'Hiroshi Ikeda', 'Masaya Yamane', 'Yuji Matsumoto', 'Makoto Nagao'], 'id': 'acl-C94-2175', 'type': 'unknown', 'title': 'Bilingual Text, Matching Using Bilingual Dictionary and Statistics'}
acl-W04-1121 - {'url': 'https://aclweb.org/anthology/W04-1121', 'book': 'Workshop on Automatic Alignment and Extraction of Bilingual Domain Ontology for Medical Domain Web Search', 'year': 2004, 'score': 0.5317585015077735, 'abstract': ['Large amounts of bilingual resource on the Internet provide us with the probability of building a large scale of bilingual corpus.', 'The irregular characteristics of the real texts, especially without the strictly aligned paragraph boundaries, bring a challenge to alignment technology.', 'The traditional alignment methods have some difficulties in competency for doing this.', 'This paper describes a new method for aligning real bilingual texts using sentence pair location information.', 'The model was motivated by the observation that the location of a sentence pair with certain length is distributed in the whole text similarly.', 'It uses (1:1) sentence beads instead of high frequency words as the candidate anchors.', 'The method was developed and evaluated through many different test data.', 'The results show that it can achieve good aligned performance and be robust and language independent.', 'It can resolve the alignment problem on real bilingual text.'], 'authors': ['Weigang Li', 'Ting Liu', 'Zhen Wang', 'Sheng Li'], 'id': 'acl-W04-1121', 'type': 'unknown', 'title': 'Aligning Bilingual Corpora Using Sentences Location Information'}
acl-J13-3001 - {'url': 'https://aclweb.org/anthology/J13-3001', 'book': 'Computational Linguistics', 'year': 2013, 'score': 0.6501073523435825, 'abstract': ['Paraphrases are sentences or phrases that convey the same meaning using different wording.', 'Although the logical definition of paraphrases requires strict semantic equivalence, linguistics accepts a broader, approximate, equivalence?thereby allowing far more examples of ?quasi-paraphrase.?', 'But approximate equivalence is hard to define.', 'Thus, the phenomenon of paraphrases, as understood in linguistics, is difficult to characterize.', 'In this article, we list a set of 25 operations that generate quasi-paraphrases.', 'We then empirically validate the scope and accuracy of this list by manually analyzing random samples of two publicly available paraphrase corpora.', 'We provide the distribution of naturally occurring quasi-paraphrases in English text.'], 'authors': ['Rahul Bhagat', 'Eduard Hovy'], 'id': 'acl-J13-3001', 'type': 'unknown', 'title': 'Squibs: What is a Paraphrase?'}
acl-C10-4001 - {'url': 'https://aclweb.org/anthology/C10-4001', 'book': 'COLING – Tutorial Notes', 'year': 2010, 'score': 0.5877299308358976, 'abstract': ['Shiqi Zhao Haifeng Wang', 'Baidu, Inc. Baidu, Inc.'], 'authors': ['Shiqi Zhao', 'Haifeng Wang'], 'id': 'acl-C10-4001', 'type': 'unknown', 'title': 'Paraphrases and Applications'}
acl-W11-2103 - {'url': 'https://aclweb.org/anthology/W11-2103', 'book': 'Proceedings of the Sixth Workshop on Statistical Machine Translation', 'year': 2011, 'score': 0.7275698227756415, 'abstract': ['Chris Callison-Burch Philipp Koehn', 'Center for Language and Speech Processing School of Informatics', 'Johns Hopkins University University of Edinburgh', 'Informatics Institute University of Amsterdam', 'Center for Language and Speech Processing Johns Hopkins University', 'This paper presents the results of the WMT11 shared tasks, which included a translation task, a system combination task, and a task for machine translation evaluation metrics.', 'We conducted a large-scale manual evaluation of 148 machine translation systems and 41 system combination entries.', 'We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 21 evaluation metrics.', 'This year featured a Haitian Creole to English task translating SMS messages sent to an emergency response service in the aftermath of the Haitian earthquake.', "We also conducted a pilot 'tunable metrics' task to test whether optimizing a fixed system to different metrics would result in perceptibly different translation quality."], 'authors': ['Chris Callison-Burch', 'Philipp Koehn', 'Christof Monz', 'Omar F. Zaidan'], 'id': 'acl-W11-2103', 'type': 'unknown', 'title': 'Findings of the 2011 Workshop on Statistical Machine Translation'}
acl-W10-1703 - {'url': 'https://aclweb.org/anthology/W10-1703', 'book': 'Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR', 'year': 2010, 'score': 0.6678447745451398, 'abstract': ['Chris Callison-Burch Philipp Koehn Christof Monz', 'Johns Hopkins University University of Edinburgh University of Amsterdam ccb@cs.jhu.edu pkoehn@inf.ed.ac.uk c.monz@uva.nl', 'Kay Peterson and Mark Przybocki Omar F. Zaidan', 'This paper presents the results of the WMT10 and MetricsMATR10 shared tasks, which included a translation task, a system combination task, and an evaluation task.', 'We conducted a large-scale manual evaluation of 104 machine translation systems and 41 system combination entries.', 'We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 26 metrics.', "This year we also investigated increasing the number of human judgments by hiring non-expert annotators through Amazon's Mechanical Turk."], 'authors': ['Chris Callison-Burch', 'Philipp Koehn', 'Christof Monz', 'Kay Peterson', 'Mark A. Przybocki', 'Omar F. Zaidan'], 'id': 'acl-W10-1703', 'type': 'unknown', 'title': 'Findings of the 2010 Joint Workshop on Statistical Machine Translation and Metrics for Machine Translation'}
acl-P12-2007 - {'url': 'https://aclweb.org/anthology/P12-2007', 'book': 'ACL', 'year': 2012, 'score': 0.7662520728002502, 'abstract': ["This paper presents an extension of Chiang's hierarchical phrase-based (HPB) model, called Head-Driven HPB (HD-HPB), which incorporates head information in translation rules to better capture syntax-driven information, as well as improved reordering between any two neighboring non-terminals at any stage of a derivation to explore a larger reordering search space.", "Experiments on Chinese-English translation on four NIST MT test sets show that the HD-HPB model significantly outperforms Chiang's model with average gains of 1.91 points absolute in BLEU."], 'authors': ['Junhui Li', 'Zhaopeng Tu', 'Guodong Zhou', 'Josef van Genabith'], 'id': 'acl-P12-2007', 'type': 'unknown', 'title': 'Head-Driven Hierarchical Phrase-based Translation'}
acl-P09-1063 - {'url': 'https://aclweb.org/anthology/P09-1063', 'book': 'ACL-IJCNLP', 'year': 2009, 'score': 0.7290738296043581, 'abstract': ['Yang Liu and Yajuan Lii and Qun Liu', 'Key Laboratory of Intelligent Information Processing Institute of Computing Technology Chinese Academy of Sciences P.O.', 'Box 2704, Beijing 100190, China (yliu,lvyajuan,liuqun}@ict.ac.cn', 'Current tree-to-tree models suffer from parsing errors as they usually use only 1-best parses for rule extraction and decoding.', 'We instead propose a forest-based tree-to-tree model that uses packed forests.', 'The model is based on a probabilistic synchronous tree substitution grammar (STSG), which can be learned from aligned forest pairs automatically.', 'The decoder finds ways of decomposing trees in the source forest into elementary trees using the source projection of STSG while building target forest in parallel.', 'Comparable to the state-of-the-art phrase-based system Moses, using packed forests in tree-to-tree translation results in a significant absolute improvement of 3.6 BLEU points over using 1-best trees.'], 'authors': ['Yang Liu', 'Yajuan Lü', 'Qun Liu'], 'id': 'acl-P09-1063', 'type': 'unknown', 'title': 'Improving Tree-to-Tree Translation with Packed Forests'}
acl-C04-1032 - {'url': 'https://aclweb.org/anthology/C04-1032', 'book': 'International Conference on Computational Linguistics', 'year': 2004, 'score': 0.720495037846413, 'abstract': ['In this paper, we address the word alignment problem for statistical machine translation.', 'We aim at creating a symmetric word alignment allowing for reliable one-to-many and many-to-one word relationships.', 'We perform the iterative alignment training in the source-to-target and the target-to-source direction with the well-known IBM and HMM alignment models.', 'Using these models, we robustly estimate the local costs of aligning a source word and a target word in each sentence pair.', 'Then, we use efficient graph algorithms to determine the symmetric alignment with minimal total costs (i. e. maximal alignment probability).', 'We evaluate the automatic alignments created in this way on the German–English Verb-mobil task and the French–English Canadian Hansards task.', 'We show statistically significant improvements of the alignment quality compared to the best results reported so far.', 'On the Verbmobil task, we achieve an improvement of more than 1% absolute over the baseline error rate of 4.7%.'], 'authors': ['Evgeny Matusov', 'Richard Zens', 'Hermann Ney'], 'id': 'acl-C04-1032', 'type': 'unknown', 'title': 'Symmetric Word Alignments for Statistical Machine Translation'}
acl-C04-1045 - {'url': 'https://aclweb.org/anthology/C04-1045', 'book': 'International Conference on Computational Linguistics', 'year': 2004, 'score': 0.6975033529905635, 'abstract': ['In this paper, we present an approach to include morpho-syntactic dependencies into the training of the statistical alignment models.', 'Existing statistical translation systems usually treat different derivations of the same base form as they were independent of each other.', 'We propose a method which explicitly takes into account such interdependencies during the EM training of the statistical alignment models.', 'The evaluation is done by comparing the obtained Viterbi alignments with a manually annotated reference alignment.', 'The improvements of the alignment quality compared to the, to our knowledge, best system are reported on the German-English Verbmobil corpus.'], 'authors': ['Hermann Ney', 'Maja Popović'], 'id': 'acl-C04-1045', 'type': 'unknown', 'title': 'Improving Word Alignment Quality Using Morpho-Syntactic Information'}
acl-W12-3147 - {'url': 'https://aclweb.org/anthology/W12-3147', 'book': 'Proceedings of the Seventh Workshop on Statistical Machine Translation', 'year': 2012, 'score': 0.62039405477476, 'abstract': ['This paper describes the development of French?English and English?French statistical machine translation systems for the 2012 WMT shared task evaluation.', 'We developed phrase-based systems based on the Moses decoder, trained on the provided data only.', 'Additionally, new features this year included improved language and translation model adaptation using the cross-entropy score for the corpus selection.'], 'authors': ['Christophe Servan', 'Patrik Lambert', 'Anthony Rousseau', 'Holger Schwenk', 'Loïc Barrault'], 'id': 'acl-W12-3147', 'type': 'unknown', 'title': 'LIUM’s SMT Machine Translation Systems for WMT 2012'}
acl-I08-1042 - {'url': 'https://aclweb.org/anthology/I08-1042', 'book': 'Proceedings of the Third International Joint Conference on Natural Language Processing', 'year': 2008, 'score': 0.7490549476435829, 'abstract': ['Jesus Gimenez and Lluis Märquez', 'Combining different metrics into a single measure of quality seems the most direct and natural way to improve over the quality of individual metrics.', 'Recently, several approaches have been suggested (Kulesza and Shieber, 2004; Liu and Gildea, 2007; Albrecht and Hwa, 2007a).', 'Although based on different assumptions, these approaches share the common characteristic of being parametric.', 'Their models involve a number of parameters whose weight must be adjusted.', 'As an alternative, in this work, we study the behaviour of non-parametric schemes, in which metrics are combined without having to adjust their relative importance.', 'Besides, rather than limiting to the lexical dimension, we work on a wide set of metrics operating at different linguistic levels (e.g., lexical, syntactic and semantic).', 'Experimental results show that non-parametric methods are a valid means of putting different quality dimensions together, thus tracing a possible path towards heterogeneous automatic MT evaluation.'], 'authors': ['Jesús Giménez', 'Lluís Màrquez'], 'id': 'acl-I08-1042', 'type': 'unknown', 'title': 'Heterogeneous Automatic MT Evaluation Through Non-Parametric Metric Combinations'}
acl-W12-3107 - {'url': 'https://aclweb.org/anthology/W12-3107', 'book': 'Proceedings of the Seventh Workshop on Statistical Machine Translation', 'year': 2012, 'score': 0.7397981177652936, 'abstract': ["This paper describes Stanford University's submission to the Shared Evaluation Task of WMT 2012.", 'Our proposed metric (SPEDE) computes probabilistic edit distance as predictions of translation quality.', 'We learn weighted edit distance in a probabilistic finite state machine (pFSM) model, where state transitions correspond to edit operations.', 'While standard edit distance models cannot capture long-distance word swapping or cross alignments, we rectify these shortcomings using a novel pushdown automaton extension of the pFSM model.', 'Our models are trained in a regression framework, and can easily incorporate a rich set of linguistic features.', 'Evaluated on two different prediction tasks across a diverse set of datasets, our methods achieve state-of-the-art correlation with human judgments.'], 'authors': ['Mengqiu Wang', 'Christopher Manning'], 'id': 'acl-W12-3107', 'type': 'unknown', 'title': 'SPEDE: Probabilistic Edit Distance Metrics for MT Evaluation'}
acl-W11-2158 - {'url': 'https://aclweb.org/anthology/W11-2158', 'book': 'Proceedings of the Sixth Workshop on Statistical Machine Translation', 'year': 2011, 'score': 0.6155744999697585, 'abstract': ["LIUM's SMT Machine Translation Systems for WMT 2011", 'Holger Schwenk, Patrik Lambert, Loïc Barrault, Christophe Servan, Haithem Afli, Sadaf Abdul-Rauf and Kashif Shah', 'LIUM, University of Le Mans 72085 Le Mans cedex 9, FRANCE FirstName.LastName@lium.univ-lemans.fr', 'Abstract 2 Resources Used', 'This paper describes the development of French-English and English-French statistical machine translation systems for the 2011 WMT shared task evaluation.', 'Our main systems were standard phrase-based statistical systems based on the Moses decoder, trained on the provided data only, but we also performed initial experiments with hierarchical systems.', 'Additional, new features this year include improved translation model adaptation using monolingual data, a continuous space language model and the treatment of unknown words.'], 'authors': ['Holger Schwenk', 'Patrik Lambert', 'Loïc Barrault', 'Christophe Servan', 'Sadaf Abdul-Rauf', 'Haithem Afli', 'Kashif Shah'], 'id': 'acl-W11-2158', 'type': 'unknown', 'title': 'LIUM’s SMT Machine Translation Systems for WMT 2011'}
acl-W10-1716 - {'url': 'https://aclweb.org/anthology/W10-1716', 'book': 'Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR', 'year': 2010, 'score': 0.6131327846717648, 'abstract': ['Patrik Lambert, Sadaf Abdul-Rauf and Holger Schwenk', 'LIUM, University of Le Mans 72085 Le Mans cedex 9, FRANCE FirstName.LastName@lium.univ-lemans.fr', 'This paper describes the development of French-English and English-French machine translation systems for the 2010 WMT shared task evaluation.', 'These systems were standard phrase-based statistical systems based on the Moses decoder, trained on the provided data only.', 'Most of our efforts were devoted to the choice and extraction of bilingual data used for training.', 'We filtered out some bilingual corpora and pruned the phrase table.', 'We also investigated the impact of adding two types of additional bilingual texts, extracted automatically from the available monolingual data.', 'We first collected bilingual data by performing automatic translations of monolingual texts.', 'The second type of bilingual text was harvested from comparable corpora with Information Retrieval techniques.'], 'authors': ['Patrik Lambert', 'Sadaf Abdul-Rauf', 'Holger Schwenk'], 'id': 'acl-W10-1716', 'type': 'unknown', 'title': 'LIUM SMT Machine Translation System for WMT 2010'}
acl-H93-1001 - {'url': 'https://aclweb.org/anthology/H93-1001', 'book': 'Human Language Technology Conference', 'year': 1993, 'score': 0.6896844984773962, 'abstract': ['For five years, 1988-1992, the Defense Advanced Projects Agency sponsored a series of meetings called the DARPA Speech and Natural Language Workshops.', 'These workshops provided a forum where researchers in speech and natural language, particularly as relating to the DARPA programs in spoken and written language understanding, could exchange information about recent research and technical progress.', 'Participants included researchers funded under the DARPA programs, other researchers who voluntarily participated in these programs or in related evaluations, government researchers and consumers of these research results, and invited attendees from inside and outside the US.', 'Proceedings of these workshops were published by Morgan Kaufmann.'], 'authors': ['Madeleine Bates'], 'id': 'acl-H93-1001', 'type': 'unknown', 'title': 'Overview of the ARPA Human Language Technology Workshop'}
acl-W00-1429 - {'url': 'https://aclweb.org/anthology/W00-1429', 'book': 'International Conference on Natural Language Generation', 'year': 2000, 'score': 0.5257659543297751, 'abstract': ['We describe the knowledge acquisition (KA) techniques used to build the STOP system, especially sorting and think-aloud protocols.', 'That is, we describe the ways in which we interacted with domain experts to determine appropriate user categories, schemas, detailed content rules, and so forth for STOP.', 'Informal evaluations of these techniques suggest that they had some benefit, but perhaps were most successful as a source of insight and hypotheses, and should ideally have been supplemented by other techniques when deciding on the specific rules and knowledge incorporated into STOP.'], 'authors': ['Ehud Reiter', 'Roma Robertson', 'Liesl Osman'], 'id': 'acl-W00-1429', 'type': 'unknown', 'title': 'Knowledge Acquisition for Natural Language Generation'}
acl-P01-1057 - {'url': 'https://aclweb.org/anthology/P01-1057', 'book': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2001, 'score': 0.519462531022038, 'abstract': ['The STOP system, which generates personalised smoking-cessation letters, was evaluated by a randomised controlled clinical trial.', 'We believe this is the largest and perhaps most rigorous task effectiveness evaluation ever performed on an NLG system.', 'The detailed results of the clinical trial have been presented elsewhere, in the medical literature.', 'In this paper we discuss the clinical trial itself: its structure and cost, what we did and did not learn from it (especially considering that the trial showed that STOP was not effective), and how it compares to other NLG evaluation techniques.'], 'authors': ['Ehud Reiter', 'Roma Robertson', 'A. Scott Lennox', 'Liesl Osman'], 'id': 'acl-P01-1057', 'type': 'unknown', 'title': 'Using a Randomised Controlled Clinical Trial to Evaluate an NLG System'}
acl-C08-2019 - {'url': 'https://aclweb.org/anthology/C08-2019', 'book': 'COLING – Posters', 'year': 2008, 'score': 0.1716554896314715, 'abstract': ['We report on work in progress on using very simple statistics in an unsupervised fashion to re-rank search engine results when review-oriented queries are issued; the goal is to bring opinionated or subjective results to the top of the results list.', 'We find that our proposed technique performs comparably to methods that rely on sophisticated pre-encoded linguistic knowledge, and that both substantially improve the initial results produced by the Yahoo!', 'search engine.'], 'authors': ['Bo Pang', 'Lillian Lee'], 'id': 'acl-C08-2019', 'type': 'unknown', 'title': 'Using Very Simple Statistics for Review Search: An Exploration'}
acl-P12-2018 - {'url': 'https://aclweb.org/anthology/P12-2018', 'book': 'ACL', 'year': 2012, 'score': 0.1673894466436222, 'abstract': ['Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset.', 'We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets.', 'Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level.'], 'authors': ['Sida Wang', 'Christopher Manning'], 'id': 'acl-P12-2018', 'type': 'unknown', 'title': 'Baselines and Bigrams: Simple, Good Sentiment and Topic Classification'}
acl-W12-3212 - {'url': 'https://aclweb.org/anthology/W12-3212', 'book': 'Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries', 'year': 2012, 'score': 0.6676956381545492, 'abstract': ['We describe how paperXML, a logical document structure markup for scholarly articles, is generated on the basis of OCR tool outputs.', 'PaperXML has been initially developed for the ACL Anthology Searchbench.', 'The main purpose was to robustly provide uniform access to sentences in ACL Anthology papers from the past 46 years, ranging from scanned, typewriter-written conference and workshop proceedings papers, up to recent high-quality typeset, born-digital journal articles, with varying layouts.', 'PaperXML markup includes information on page and paragraph breaks, section headings, footnotes, tables, captions, boldface and italics character styles as well as bibliographic and publication meta-data.', 'The role of paperXML in the ACL Contributed Task Rediscovering 50 Years of Discoveries is to serve as fall-back source (1) for older, scanned papers (mostly published before the year 2000), for which born-digital PDF sources are not available, (2) for born-digital PDF papers on which the PDFExtract method failed, (3) for document parts where PDFExtract does not output useful markup such as currently for tables.', "We sketch transformation of paperXML into the ACL Contributed Task's TEI P5 XML."], 'authors': ['Ulrich Schäfer', 'Benjamin Weitz'], 'id': 'acl-W12-3212', 'type': 'unknown', 'title': 'Combining OCR Outputs for Logical Document Structure Markup. Technical Background to the ACL 2012 Contributed Task'}
acl-W06-1613 - {'url': 'https://aclweb.org/anthology/W06-1613', 'book': 'Conference on Empirical Methods in Natural Language Processing', 'year': 2006, 'score': 0.6095497865399048, 'abstract': ['Citation function is defined as the author’s reason for citing a given paper (e.g. acknowledgement of the use of the cited method).', 'The automatic recognition of the rhetorical function of citations in scientific text has many applications, from improvement of impact factor calculations to text summarisation and more informative citation indexers.', 'We show that our annotation scheme for citation function is reliable, and present a supervised machine learning framework to automatically classify citation function, using both shallow and linguistically-inspired features.', 'We find, amongst other things, a strong relationship between citation function and sentiment classification.'], 'authors': ['Simone Teufel', 'Advaith Siddharthan', 'Dan Tidhar'], 'id': 'acl-W06-1613', 'type': 'unknown', 'title': 'Automatic Classification of Citation Function'}
acl-H93-1047 - {'url': 'https://aclweb.org/anthology/H93-1047', 'book': 'Human Language Technology Conference', 'year': 1993, 'score': 0.5671820190796741, 'abstract': ['In this paper we describe a new technique for parsing free text: a transformational grammar/ is automatically learned that is capable of accurately parsing text into binary-branching syntactic trees with nonterminals unlabelled.', 'The algorithm works by beginning in a very naive state of knowledge about phrase structure.', 'By repeatedly comparing the results of bracketing in the current state to proper bracketing provided in the training corpus, the system learns a set of simple structural transformations that can be applied to reduce error.', 'After describing the algorithm, we present results and compare these results to other recent results in automatic grammar induction.'], 'authors': ['Eric Brill'], 'id': 'acl-H93-1047', 'type': 'unknown', 'title': 'Automatic Grammar Induction and Parsing Free Text: A Transformation-Based Approach'}
acl-C00-1074 - {'url': 'https://aclweb.org/anthology/C00-1074', 'book': 'International Conference on Computational Linguistics', 'year': 2000, 'score': 0.5018102050885659, 'abstract': ['A hybrid system for tagging part of speech is described that consists of a neuro tagger and a rule-based corrector.', 'The neuro tagger is an initial-state annotator that uses different lengths of contexts based on longest context priority.', 'its inputs are weighted by information gains that are obtained by information maximization.', 'The rule-based corrector is constructed by a set of transformation rules to make up for the shortcomings of the neuro tagger.', 'Computer experiments show that almost 20% of the errors made by the neuro tagger are corrected by these transformation rules, so that the hybrid system can reach an accuracy of 95.5% counting only flue ambiguous words and 99.1% counting all words when a small Thai corpus with 22,311 ambiguous words is used for training.', 'This accuracy is far higher than that using an 11MM and is also higher than that using a rule-based model.'], 'authors': ['Qing Ma', 'Masaki Murata', 'Kiyotaka Uchimoto', 'Hitoshi Isahara'], 'id': 'acl-C00-1074', 'type': 'unknown', 'title': 'Hybrid Neuro and Rule-Based Part of Speech Taggers'}
acl-P14-2010 - {'url': 'https://aclweb.org/anthology/P14-2010', 'book': 'ACL', 'year': 2014, 'score': 0.9969348779647177, 'abstract': ['aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa References'], 'authors': ['Swapnil Hingmire', 'Sutanu Chakraborti'], 'id': 'acl-P14-2010', 'type': 'unknown', 'title': 'Sprinkling Topics for Weakly Supervised Text Classification'}
acl-P14-2015 - {'url': 'https://aclweb.org/anthology/P14-2015', 'book': 'ACL', 'year': 2014, 'score': 0.992911134267781, 'abstract': ['aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa aa aa aa aa aaaa aaa aaa aaa aaa aaa aaas aaaa aaa aaa aaa aaaa aaaa aaaa aaaaa aaaaa a aaaa a a a aaa a a a aaaa aa aaaa aaa aaaa aaaa References'], 'authors': ['Zvi Ben-Ami', 'Ronen Feldman', 'Binyamin Rosenfeld'], 'id': 'acl-P14-2015', 'type': 'unknown', 'title': "Entities' Sentiment Relevance"}
acl-C10-3013 - {'url': 'https://aclweb.org/anthology/C10-3013', 'book': 'COLING – Demos', 'year': 2010, 'score': 0.5370970028311163, 'abstract': ['Dorothée Beermann Pavel Mihaylov', 'Norwegian University of Science and Technology Ontotext', 'The system presented is a web application designed to aid linguistic research with data collection and online publishing.', 'It is a service mainly for linguists and language experts working with language description of less-documented and less-resourced languages.', 'When the central concern is in-depth linguistic analysis, maintaining and administering software can be a burden.', 'Cloud computing offers an alternative.', 'At present mainly used for archiving, we extend linguistic web applications to allow creation, search and storage of interlinear annotated texts.', 'By combining a conceptually appealing online glosser with an SQL database and a wiki, we make the online publication of linguistic data an easy task also for non-computationally oriented researchers.'], 'authors': ['Dorothee Beermann', 'Pavel Mihaylov'], 'id': 'acl-C10-3013', 'type': 'unknown', 'title': 'Cloud Computing for Linguists'}
acl-P02-1022 - {'url': 'https://aclweb.org/anthology/P02-1022', 'book': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2002, 'score': 0.5053581577856099, 'abstract': ['In this paper we present GATE, a framework and graphical development environment which enables users to develop and deploy language engineering components and resources in a robust fashion.', 'The GATE architecture has enabled us not only to develop a number of successful applications for various language processing tasks (such as Information Extraction), but also to build and annotate corpora and carry out evaluations on the applications generated.', 'The framework can be used to develop applications and resources in multiple languages, based on its thorough Unicode support.'], 'authors': ['Hamish Cunningham', 'Diana Maynard', 'Kalina Bontcheva', 'Valentin Tablan'], 'id': 'acl-P02-1022', 'type': 'unknown', 'title': 'GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications'}
acl-W02-0112 - {'url': 'https://aclweb.org/anthology/W02-0112', 'book': 'Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics', 'year': 2002, 'score': 0.6840342841769208, 'abstract': ['The paper gives a review of teaching Computational Linguistics (CL) at the University of Tartu.', 'The current curriculum foresees the possibility of studying CL as an independent 4-year subject in the Faculty of Philosophy on the bachelor stage.', 'In connection with the higher education reform in Estonia, new curricula will be introduced from the next study year where the 3-year bachelor stage will be followed by a 2 year master’s stage.', 'It will then be possible to study CL proceeding from two paths: in the Faculty of Philosophy, and additionally also in the Faculty of Mathematics and Computer Science.', 'This way two types of specialists will be trained who will hopefully be able to complement each other in teamwork.'], 'authors': ['Mare Koit', 'Tiit Roosmaa', 'Haldur Õim'], 'id': 'acl-W02-0112', 'type': 'unknown', 'title': 'Teaching Computational Linguistics at the University of Tartu: Experience, Perspectives and Challenges'}
acl-W02-0106 - {'url': 'https://aclweb.org/anthology/W02-0106', 'book': 'Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics', 'year': 2002, 'score': 0.6798698036644222, 'abstract': ['The Language Technologies Institute (LTI) of the School of Computer Science at Carnegie Mellon University is one of the largest programs of its kind.', 'We present here the initial design and subsequent evolution of our MS and PhD programs in Language Technologies.', 'The motivations for the design and evolution are also presented.'], 'authors': ['Robert E. Frederking', 'Eric H. Nyberg', 'Teruko Mitamura', 'Jaime G. Carbonnell'], 'id': 'acl-W02-0106', 'type': 'unknown', 'title': 'Design and Evolution of a Language Technologies Curriculum'}
acl-A97-1056 - {'url': 'https://aclweb.org/anthology/A97-1056', 'book': 'Applied Natural Language Processing Conference', 'year': 1997, 'score': 0.3537152848989457, 'abstract': ['Statistical models of word–sense disambiguation are often based on a small number of contextual features or on a model that is assumed to characterize the interactions among a set of features.', 'Model selection is presented as an alternative to these approaches, where a sequential search of possible models is conducted in order to find the model that best characterizes the interactions among features.', 'This paper expands existing model selection methodology and presents the first comparative study of model selection search strategies and evaluation criteria when applied to the problem of building probabilistic classifiers for word–sense disambiguation.'], 'authors': ['Ted Pedersen', 'Rebecca F. Bruce', 'Janyce Wiebe'], 'id': 'acl-A97-1056', 'type': 'unknown', 'title': 'Sequential Model Selection for Word Sense Disambiguation'}
acl-J14-3004 - {'url': 'https://aclweb.org/anthology/J14-3004', 'book': 'CL', 'year': 2014, 'score': 0.6796828956026063, 'abstract': ['Feature-Frequency?Adaptive On-line Training for Fast and Accurate Natural Language Processing Xu Sun?', 'Peking University Wenjie Li??', 'Hong Kong Polytechnic University Houfeng Wang?', 'Peking University Qin Lu?', 'Hong Kong Polytechnic University Training speed and accuracy are two major concerns of large-scale natural language processing systems.', 'Typically, we need to make a tradeoff between speed and accuracy.', 'It is trivial to improve the training speed via sacrificing accuracy or to improve the accuracy via sacrificing speed.', 'Nevertheless, it is nontrivial to improve the training speed and the accuracy at the same time, which is the target of this work.', 'To reach this target, we present a new training method, feature-frequency?adaptive on-line training, for fast and accurate training of natural language processing systems.', 'It is based on the core idea that higher frequency features should have a learning rate that decays faster.'], 'authors': ['Xu Sun', 'Wenjie Li', 'Houfeng Wang', 'Qin Lu'], 'id': 'acl-J14-3004', 'type': 'unknown', 'title': 'Feature-Frequency–Adaptive On-line Training for Fast and Accurate Natural Language Processing'}
acl-P09-1054 - {'url': 'https://aclweb.org/anthology/P09-1054', 'book': 'ACL-IJCNLP', 'year': 2009, 'score': 0.5636729215407645, 'abstract': ['Stochastic Gradient Descent Training for Ll-regularized Log-linear Models with Cumulative Penalty', 'Yoshimasa Tsuruoka"^ Jun\'ichi Tsujii^* Sophia Ananiadou"^', 't School of Computer Science, University of Manchester, UK', 'Stochastic gradient descent (SGD) uses approximate gradients estimated from subsets of the training data and updates the parameters in an online fashion.', 'This learning framework is attractive because it often requires much less training time in practice than batch training algorithms.', 'However, L1-regularization, which is becoming popular in natural language processing because of its ability to produce compact models, cannot be efficiently applied in SGD training, due to the large dimensions of feature vectors and the fluctuations of approximate gradients.', 'We present a simple method to solve these problems by penalizing the weights according to cumulative values for L1 penalty.', 'We evaluate the effectiveness of our method in three applications: text chunking, named entity recognition, and part-of-speech tagging.', 'Experimental results demonstrate that our method can produce compact and accurate models much more quickly than a state-of-the-art quasiNewton method for L1-regularized loglinear models.'], 'authors': ['Yoshimasa Tsuruoka', "Jun'ichi Tsujii", 'Sophia Ananiadou'], 'id': 'acl-P09-1054', 'type': 'unknown', 'title': 'Stochastic Gradient Descent Training for L1-regularized Log-linear Models with Cumulative Penalty'}
acl-W96-0210 - {'url': 'https://aclweb.org/anthology/W96-0210', 'book': 'Conference on Empirical Methods in Natural Language Processing', 'year': 1996, 'score': 0.3205780000583197, 'abstract': ['This paper describes measures for evaluating the three determinants of how well a probabilistic classifier performs on a given test set.', 'These determinants are the appropriateness, for the test set, of the results of (1) feature selection, (2) formulation of the parametric form of the model, and (3) parameter estimation.', 'These are part of any model formulation procedure, even if not broken out as separate steps, so the tradeoffs explored in this paper are relevant to a wide variety of methods.', 'The measures are demonstrated in a large experiment, in which they are used to analyze the results of roughly 300 classifiers that perform word-sense disambiguation.'], 'authors': ['Rebecca F. Bruce', 'Janyce Wiebe', 'Ted Pedersen'], 'id': 'acl-W96-0210', 'type': 'unknown', 'title': 'The Measure of a Model'}
acl-J99-2002 - {'url': 'https://aclweb.org/anthology/J99-2002', 'book': 'Computational Linguistics', 'year': 1999, 'score': 0.26524946213472506, 'abstract': ['at Asheville In this paper, we describe a framework for developing probabilistic classifiers in natural language processing.', 'Our focus is on formulating models that capture the most important interdependencies among features, to avoid overfitting the data while also characterizing the data well.', 'The class of probability models and the associated inference techniques described here were developed in mathematical statistics, and are widely used in artificial intelligence and applied statistics.', 'Our goal is to make this model selection framework accessible to researchers in NLP, and provide pointers to available software and important references.', 'In addition, we describe how the quality of the three determinants of classifier performance (the features, the form of the model, and the parameter estimates) can be separately evaluated.', 'We also demonstrate the classification performance of these models in a large-scale experiment involving the disambiguation of 34 words taken from the HECTOR word sense corpus (Hanks 1996).', 'In 10-fold cross-validations, the model search procedure performs significantly better than naive Bayes on 6 of the words without being significantly worse on any of them.'], 'authors': ['Rebecca F. Bruce', 'Janyce Wiebe'], 'id': 'acl-J99-2002', 'type': 'unknown', 'title': 'Decomposable Modeling in Natural Language Processing'}
acl-P09-2060 - {'url': 'https://aclweb.org/anthology/P09-2060', 'book': 'ACL-IJCNLP: Short Papers', 'year': 2009, 'score': 0.37934743680956795, 'abstract': ["We investigate the use of Fisher's exact significance test for pruning the translation table of a hierarchical phrase-based statistical machine translation system.", "In addition to the significance values computed by Fisher's exact test, we introduce compositional properties to classify phrase pairs of same significance values.", 'We also examine the impact of using significance values as a feature in translation models.', 'Experimental results show that 1% to 2% BLEU improvements can be achieved along with substantial model size reduction in an Iraqi/English two-way translation task.'], 'authors': ['Mei Yang', 'Jing Zheng'], 'id': 'acl-P09-2060', 'type': 'unknown', 'title': 'Toward Smaller, Faster, and Better Hierarchical Phrase-based SMT'}
acl-C10-1056 - {'url': 'https://aclweb.org/anthology/C10-1056', 'book': 'COLING', 'year': 2010, 'score': 0.3184529170048533, 'abstract': ['Fei Huang and Bing Xiang', 'IBM T. J. Watson Research Center', 'This paper proposes a new approach to phrase rescoring for statistical machine translation (SMT).', 'A set of novel features capturing the translingual equivalence between a source and a target phrase pair are introduced.', 'These features are combined with linear regression model and neural network to predict the quality score of the phrase translation pair.', "These phrase scores are used to dis-criminatively rescore the baseline MT system's phrase library: boost good phrase translations while prune bad ones.", 'This approach not only significantly improves machine translation quality, but also reduces the model size by a considerable margin.'], 'authors': ['Fei Huang', 'Bing Xiang'], 'id': 'acl-C10-1056', 'type': 'unknown', 'title': 'Feature-Rich Discriminative Phrase Rescoring for SMT'}
acl-D12-1088 - {'url': 'https://aclweb.org/anthology/D12-1088', 'book': 'EMNLP', 'year': 2012, 'score': 0.3114890936388646, 'abstract': ['Phrase-based machine translation models have shown to yield better translations than Word-based models, since phrase pairs encode the contextual information that is needed for a more accurate translation.', 'However, many phrase pairs do not encode any relevant context, which means that the translation event encoded in that phrase pair is led by smaller translation events that are independent from each other, and can be found on smaller phrase pairs, with little or no loss in translation accuracy.', 'In this work, we propose a relative entropy model for translation models, that measures how likely a phrase pair encodes a translation event that is derivable using smaller translation events with similar probabilities.', 'This model is then applied to phrase table pruning.', 'Tests show that considerable amounts of phrase pairs can be excluded, without much impact on the translation quality.', 'In fact, we show that better translations can be obtained using our pruned models, due to the compression of the search space during decoding.'], 'authors': ['Wang Ling', 'João Graça', 'Isabel Trancoso', 'Alan Black'], 'id': 'acl-D12-1088', 'type': 'unknown', 'title': 'Entropy-based Pruning for Phrase-based Machine Translation'}
acl-I05-1051 - {'url': 'https://aclweb.org/anthology/I05-1051', 'book': 'Second International Joint Conference on Natural Language Processing: Full Papers', 'year': 2005, 'score': 0.3088836790750615, 'abstract': ["Hendra Setiawan', Haizhou Li,Min Zhang, and Beng Chin Ooi", 'Institute for Infocomm Research, 21 Heng Mui Keng Terrace, Singapore 119613 {stuhs, hli, mzhang}@i2r.a-star.edu.sg School of Computing, National University of Singapore, Singapore 117543 {hendrase, ooibc}@comp.nus.edu.sg', 'Abstract.', 'The merit of phrase-based statistical machine translation is often reduced by the complexity to construct it.', 'In this paper, we address some issues in phrase-based statistical machine translation, namely: the size of the phrase translation table, the use of underlying translation model probability and the length of the phrase unit.', 'We present Level-Of-Detail (LOD) approach, an agglomerative approach for learning phrase-level alignment.', 'Our experiments show that LOD approach significantly improves the performance of the word-based approach.', 'LOD demonstrates a clear advantage that the phrase translation table grows only sub-linearly over the maximum phrase length, while having a performance comparable to those of other phrase-based approaches.'], 'authors': ['Hendra Setiawan', 'Haizhou Li', 'Min Zhang', 'Beng Chin Ooi'], 'id': 'acl-I05-1051', 'type': 'unknown', 'title': 'Phrase-Based Statistical Machine Translation: A Level of Detail Approach'}
acl-W02-0715 - {'url': 'https://aclweb.org/anthology/W02-0715', 'book': 'Workshop on Speech-To-Speech Translation: Algorithms and Systems', 'year': 2002, 'score': 0.28448395218006456, 'abstract': ['by-one.', 'The actual plotted broken line is averaged over 10 random trials.', 'Figure 9 shows the relationship between iteration and the system’s TOEIC score.', 'In this figure, the horizontal axis represents the iteration, and the vertical axis TOEIC score.', 'The broken line and the solid line are plotted using the same denotation as that in Figure 8.', 'In Figure 8, the solid line always lies on a lower position than the broken line.', 'In Figure 9, from iteration 1 to around iteration 200, the broken line does not deviate from the actual system’s TOEIC score, which is 548.', 'Considering these results, the test set optimized for TDMT is shown to be applicable for evaluating ATR-MATRIX.'], 'authors': ['Fumiaki Sugaya', 'Keiji Yasuda', 'Toshiyuki Takezawa', 'Seiichi Yamamoto'], 'id': 'acl-W02-0715', 'type': 'unknown', 'title': 'Quality-Sensitive Test Set Selection for a Speech Translation System'}
acl-A92-1028 - {'url': 'https://aclweb.org/anthology/A92-1028', 'book': 'Applied Natural Language Processing Conference', 'year': 1992, 'score': 0.7238661008796474, 'abstract': ['A method of anaphoral resolution of zero pronouns in Japanese language texts using the verbal semantic attributes is suggested.', 'This method focuses attention on the semantic attributes of verbs and examines the context from the relationship between the semantic attributes of verbs governing zero pronouns and the semantic attributes of verbs governing their referents.', 'The semantic attributes of verbs are created using 2 different viewpoints: dynamic characteristics of verbs and the relationship of verbs to cases.', 'By using this method, it is shown that, in the case of translating newspaper articles, the major portion (93%) of anaphoral resolution of zero pronouns necessary for machine translation can be achieved by using only linguistic knowledge.', 'Factors to be given special attention when incorporating this method into a machine translation system are examined, together with suggested conditions for the detection of zero pronouns and methods for their conversion.', 'This study considers four factors that are important when implementing this method in a Japanese to English machine translation system: the difference in conception between Japanese and English expressions, the difference in case frame patterns between Japanese and English, restrictions by voice and restriction by translation structure.', 'Implementation of the proposed method with due consideration of these points leads to a viable method for anaphoral resolution of zero pronouns in a practical machine translation system.'], 'authors': ['Hiromi Nakaiwa', 'Satoru Ikehara'], 'id': 'acl-A92-1028', 'type': 'unknown', 'title': 'Zero Pronoun Resolution in a Machine Translation System by Using Japanese to English Verbal Semantic Attributes'}
acl-C96-2146 - {'url': 'https://aclweb.org/anthology/C96-2146', 'book': 'International Conference on Computational Linguistics', 'year': 1996, 'score': 0.6614859634739717, 'abstract': ['This paper describes a method for analyzing Japanese double-subject construction having an adjective predicate based on the valency structure.', 'A simple sentence usually has only one subjective case in most languages.', 'However, many Japanese adjectives (and some verbs) can dominate two surface subjective cases within a simple sentence.', 'Such sentence structure is called the double-subject construction.', 'This paper classifies the Japanese double-subject construction into four types and describes problems arising when analyzing these types using ordinary Japanese construction approaches.', 'This paper proposes a method for analyzing a Japanese double-subject construction having an adjective predicate in order to overcome the problems described.', 'By applying this method to Japanese sentence analysis in Japanese-to-English machine translation systems, translation accuracy can be improved because this method can analyze correctly the double-subject construction.'], 'authors': ['Masahiro Oku'], 'id': 'acl-C96-2146', 'type': 'unknown', 'title': 'Analyzing Japanese Double-Subject Construction Having an Adjective Predicate'}
acl-C04-1014 - {'url': 'https://aclweb.org/anthology/C04-1014', 'book': 'International Conference on Computational Linguistics', 'year': 2004, 'score': 0.6569717581749753, 'abstract': ['Ngram models are simple in language modeling and have been successfully used in speech recognition and other tasks.', 'However, they can only capture the short distance context dependency within an n-words window where currently the largest practical n for a natural language is three while much of the context dependency in a natural language occurs beyond a three words window.', 'In order to incorporate this kind of long distance context dependency in the ngram model of our Mandarin speech recognition system, this paper proposes a novel MI-Ngram modeling approach.', 'This new MI-Ngram model consists of two components: a normal ngram model and a novel MI model.', 'The ngram model captures the short distance context dependency within an n-words window while the MI model captures the context dependency between the word pairs over a long distance by using the concept of mutual information.', 'That is, the MI-Ngram model incorporates the word occurrences beyond the scope of the normal ngram model.', 'It is found that MI-Ngram modeling has much better performance than the normal word ngram modeling.', 'Experimentation shows that about 20% of errors can be corrected by using a MI-Trigram model compared with the pure word trigram model.'], 'authors': ['Guodong Zhou'], 'id': 'acl-C04-1014', 'type': 'unknown', 'title': 'Modeling of Long Distance Context Dependency'}
acl-D09-1078 - {'url': 'https://aclweb.org/anthology/D09-1078', 'book': 'EMNLP', 'year': 2009, 'score': 0.6362706169150789, 'abstract': ['Robert C. Moore Chris Quirk', 'The recent availability of large corpora for training N-gram language models has shown the utility of models of higher order than just trigrams.', 'In this paper, we investigate methods to control the increase in model size resulting from applying standard methods at higher orders.', 'We introduce significance-based N-gram selection, which not only reduces model size, but also improves perplexity for several smoothing methods, including Katz backoff and absolute discounting.', 'We also show that, when combined with a new smoothing method and a novel variant of weighted-difference pruning, our selection method performs better in the trade-off between model size and perplexity than the best pruning method we found for modified Kneser-Ney smoothing.'], 'authors': ['Robert C. Moore', 'Chris Quirk'], 'id': 'acl-D09-1078', 'type': 'unknown', 'title': 'Less is More: Significance-Based N-gram Selection for Smaller, Better Language Models'}
acl-P09-2008 - {'url': 'https://aclweb.org/anthology/P09-2008', 'book': 'ACL-IJCNLP: Short Papers', 'year': 2009, 'score': 0.2753588349223253, 'abstract': ["Han-Cheol Cho} Do-Gil Lee,§ Jung-Tae Lee,§ Pontus Stenetorp} Jun'ichi TsujiiWid Hae-Chang Rim§", 't Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan §Dept.', 'of Computer & Radio Communications Engineering, Korea University, Seoul, Korea {hccho,pontus,tsujii}@is.s.u-tokyo.ac.jp, {dglee,jtlee,rim}@nlp.korea.ac.kr', 'Most NLP applications work under the assumption that a user input is error-free; thus, word segmentation (WS) for written languages that use word boundary markers (WBMs), such as spaces, has been regarded as a trivial issue.', 'However, noisy real-world texts, such as blogs, e-mails, and SMS, may contain spacing errors that require correction before further processing may take place.', 'For the Korean language, many researchers have adopted a traditional WS approach, which eliminates all spaces in the user input and reinserts proper word boundaries.', 'Unfortunately, such an approach often exacerbates the word spacing quality for user input, which has few or no spacing errors; such is the case, because a perfect WS model does not exist.', 'In this paper, we propose a novel WS method that takes into consideration the initial word spacing information of the user input.', 'Our method generates a better output than the original user input, even if the user input has few spacing errors.', 'Moreover, the proposed method significantly outperforms a state-of-the-art Korean WS model when the user input initially contains less than 10% spacing errors, and performs comparably for cases containing more spacing errors.'], 'authors': ['Han-Cheol Cho', 'Do-Gil Lee', 'Jung-Tae Lee', 'Pontus Stenetorp', "Jun'ichi Tsujii", 'Hae-Chang Rim'], 'id': 'acl-P09-2008', 'type': 'unknown', 'title': 'A Novel Word Segmentation Approach for Written Languages with Word Boundary Markers'}
acl-P07-2020 - {'url': 'https://aclweb.org/anthology/P07-2020', 'book': '45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions', 'year': 2007, 'score': 0.23119178840532434, 'abstract': ['Ensemble Document Clustering Using Weighted Hypergraph Generated by NMF', 'Hiroyuki Shinnou, Minoru Sasaki', 'In this paper, we propose a new ensemble document clustering method.', 'The novelty of our method is the use of Non-negative Matrix Factorization (NMF) in the generation phase and a weighted hypergraph in the integration phase.', 'In our experiment, we compared our method with some clustering methods.', 'Our method achieved the best results.'], 'authors': ['Hiroyuki Shinnou', 'Minoru Sasaki'], 'id': 'acl-P07-2020', 'type': 'unknown', 'title': 'Ensemble document clustering using weighted hypergraph generated by NMF'}
acl-P09-1018 - {'url': 'https://aclweb.org/anthology/P09-1018', 'book': 'ACL-IJCNLP', 'year': 2009, 'score': 0.5256681349989019, 'abstract': ['Hua Wu and Haifeng Wang', 'Toshiba (China) Research and Development Center 5/F., Tower W2, Oriental Plaza, Beijing, 100738, China {wuhua, wanghaifeng}@rdc.toshiba.com.cn', 'This paper revisits the pivot language approach for machine translation.', 'First, we investigate three different methods for pivot translation.', 'Then we employ a hybrid method combining RBMT and SMT systems to fill up the data gap for pivot translation, where the source-pivot and pivot-target corpora are independent.', 'Experimental results on spoken language translation show that this hybrid method significantly improves the translation quality, which outperforms the method using a source-target corpus of the same size.', 'In addition, we propose a system combination approach to select better translations from those produced by various pivot translation methods.', 'This method regards system combination as a translation evaluation problem and formalizes it with a regression learning model.', 'Experimental results indicate that our method achieves consistent and significant improvement over individual translation outputs.'], 'authors': ['Hua Wu', 'Haifeng Wang'], 'id': 'acl-P09-1018', 'type': 'unknown', 'title': 'Revisiting Pivot Language Approach for Machine Translation'}
acl-D14-1174 - {'url': 'https://aclweb.org/anthology/D14-1174', 'book': 'EMNLP', 'year': 2014, 'score': 0.5239626365947524, 'abstract': ['Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1665?1675, October 25-29, 2014, Doha, Qatar.', 'Abstract To overcome the scarceness of bilingual corpora for some language pairs in machine translation, pivot-based SMT uses pivot language as a "bridge" to generate source-target translation from source-pivot and pivot-target translation.', 'One of the key issues is to estimate the probabilities for the generated phrase pairs.', 'In this paper, we present a novel approach to calculate the translation probability by pivoting the co-occurrence count of source-pivot and pivot-target phrase pairs.', 'Experimental results on Europarl data and web data show that our method leads to significant improvements over the baseline systems.'], 'authors': ['Xiaoning Zhu', 'Zhongjun He', 'Hua Wu', 'Conghui Zhu', 'Haifeng Wang', 'Tiejun Zhao'], 'id': 'acl-D14-1174', 'type': 'unknown', 'title': 'Improving Pivot-Based Statistical Machine Translation by Pivoting the Co-occurrence Count of Phrase Pairs'}
acl-W07-0724 - {'url': 'https://aclweb.org/anthology/W07-0724', 'book': 'Workshop on Statistical Machine Translation', 'year': 2007, 'score': 0.5167615615075047, 'abstract': ["NRC's PORTAGE system for WMT 2007", 'Nicola Ueffing, Michel Simard, Samuel Larkin Howard Johnson', 'Interactive Language Technologies Group Interactive Information Group', 'National Research Council Canada', 'Gatineau, Quebec, Canada firstname.lastname@nrc.gc.ca', 'National Research Council Canada Ottawa, Ontario, Canada Howard.Johnson@nrc.gc.ca', 'We present the PORTAGE statistical machine translation system which participated in the shared task of the ACL 2007 Second Workshop on Statistical Machine Translation.', 'The focus of this description is on improvements which were incorporated into the system over the last year.', 'These include adapted language models, phrase table pruning, an IBMl-based decoder feature, and rescor-ing with posterior probabilities.'], 'authors': ['Nicola Ueffing', 'Michel Simard', 'Samuel Larkin', 'Howard Johnson'], 'id': 'acl-W07-0724', 'type': 'unknown', 'title': "NRC's PORTAGE System for WMT 2007"}
acl-D07-1030 - {'url': 'https://aclweb.org/anthology/D07-1030', 'book': '2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)', 'year': 2007, 'score': 0.5141486557633063, 'abstract': ['Xiaoguang Hu, Haifeng Wang, Hua Wu', 'Toshiba (China) Research and Development Center 5/F., Tower W2, Oriental Plaza No.1, East Chang An Ave., Dong Cheng District Beijing, 100738, China', '{huxiaoguang, wanghaifeng, wuhua}@rdc.toshiba.com.cn', 'This paper proposes a method using the existing Rule-based Machine Translation (RBMT) system as a black box to produce synthetic bilingual corpus, which will be used as training data for the Statistical Machine Translation (SMT) system.', 'We use the existing RBMT system to translate the monolingual corpus into synthetic bilingual corpus.', 'With the synthetic bilingual corpus, we can build an SMT system even if there is no real bilingual corpus.', 'In our experiments using BLEU as a metric, the system achieves a relative improvement of 11.7% over the best RBMT system that is used to produce the synthetic bilingual corpora.', 'We also interpolate the model trained on a real bilingual corpus and the models trained on the synthetic bilingual corpora.', 'The interpolated model achieves an absolute improvement of 0.0245 BLEU score (13.1% relative) as compared with the individual model trained on the real bilingual corpus.'], 'authors': ['Xiaoguang Hu', 'Haifeng Wang', 'Hua Wu'], 'id': 'acl-D07-1030', 'type': 'unknown', 'title': 'Using RBMT Systems to Produce Bilingual Corpus for SMT'}
Lambda = 0 -> No penalty
bound: 0.0
find mmr max: 8.766674955461314
len: 1 55
bound: 8.766674955461314
find mmr max: 15.545544081040203
len: 2 54
bound: 15.545544081040203
find mmr max: 21.243251295732
len: 3 53
bound: 21.243251295732
find mmr max: 26.155416091752745
len: 4 52
bound: 26.155416091752745
find mmr max: 30.13596022712404
len: 5 51
bound: 30.13596022712404
find mmr max: 33.75908932163567
len: 6 50
bound: 33.75908932163567
find mmr max: 37.22093135047125
len: 7 49
bound: 37.22093135047125
find mmr max: 40.06324742706998
len: 8 48
bound: 40.06324742706998
find mmr max: 42.49313571433506
len: 9 47
bound: 42.49313571433506
find mmr max: 44.64686685690346
len: 10 46
bound: 44.64686685690346
find mmr max: 46.48390013329195
len: 11 45
bound: 46.48390013329195
find mmr max: 48.27758012101036
len: 12 44
bound: 48.27758012101036
find mmr max: 49.61362536770358
len: 13 43
bound: 49.61362536770358
find mmr max: 50.944125682277196
len: 14 42
bound: 50.944125682277196
find mmr max: 52.26507717160767
len: 15 41
bound: 52.26507717160767
find mmr max: 53.17864687069676
len: 16 40
bound: 53.17864687069676
find mmr max: 53.86244463147444
len: 17 39
bound: 53.86244463147444
find mmr max: 54.502337722981274
len: 18 38
bound: 54.502337722981274
find mmr max: 55.04098292515416
len: 19 37
bound: 55.04098292515416
find mmr max: 55.48257197580276
len: 20 36
bound: 55.48257197580276
find mmr max: 55.86987953547976
len: 21 35
bound: 55.86987953547976
find mmr max: 56.10679141612064
len: 22 34
bound: 56.10679141612064
find mmr max: 56.213466520644516
len: 23 33
bound: 56.213466520644516
find mmr max: 56.25996607006307
len: 24 32
bound: 56.25996607006307
find mmr max: 56.25723310681402
len: 24 31
bound: 56.25996607006307
find mmr max: 56.242795621870485
len: 24 30
bound: 56.25996607006307
find mmr max: 56.16500715015918
len: 24 29
bound: 56.25996607006307
find mmr max: 56.11177915618145
len: 24 28
bound: 56.25996607006307
find mmr max: 56.08588841410737
len: 24 27
bound: 56.25996607006307
find mmr max: 56.06663533740323
len: 24 26
bound: 56.25996607006307
find mmr max: 56.060477757359415
len: 24 25
bound: 56.25996607006307
find mmr max: 56.01335952261047
len: 24 24
bound: 56.25996607006307
find mmr max: 55.973484332951436
len: 24 23
bound: 56.25996607006307
find mmr max: 55.941049022702195
len: 24 22
bound: 56.25996607006307
find mmr max: 55.92148064572578
len: 24 21
bound: 56.25996607006307
find mmr max: 55.86965253900933
len: 24 20
bound: 56.25996607006307
find mmr max: 55.86612268581729
len: 24 19
bound: 56.25996607006307
find mmr max: 55.85985162160812
len: 24 18
bound: 56.25996607006307
find mmr max: 55.83207384383034
len: 24 17
bound: 56.25996607006307
find mmr max: 55.78824202454304
len: 24 16
bound: 56.25996607006307
find mmr max: 55.71392598024864
len: 24 15
bound: 56.25996607006307
find mmr max: 55.701459550251954
len: 24 14
bound: 56.25996607006307
find mmr max: 55.693008637158954
len: 24 13
bound: 56.25996607006307
find mmr max: 55.69072487001199
len: 24 12
bound: 56.25996607006307
find mmr max: 55.6822280877692
len: 24 11
bound: 56.25996607006307
find mmr max: 55.671986928191316
len: 24 10
bound: 56.25996607006307
find mmr max: 55.6224117984135
len: 24 9
bound: 56.25996607006307
find mmr max: 55.622309250429474
len: 24 8
bound: 56.25996607006307
find mmr max: 55.58723155144653
len: 24 7
bound: 56.25996607006307
find mmr max: 55.547074605726536
len: 24 6
bound: 56.25996607006307
find mmr max: 55.475988826361004
len: 24 5
bound: 56.25996607006307
find mmr max: 55.458220152088444
len: 24 4
bound: 56.25996607006307
find mmr max: 55.43961966845212
len: 24 3
bound: 56.25996607006307
find mmr max: 55.413330871217426
len: 24 2
bound: 56.25996607006307
find mmr max: 55.38463658998401
len: 24 1
bound: 56.25996607006307
find mmr max: 55.11071399616459
len: 24 0
24
acl-W10-1703
acl-W10-1716
acl-P09-1018
acl-P08-2038
acl-D07-1030
acl-C04-1032
acl-W02-0106
acl-P02-1022
acl-C10-1056
acl-W02-0715
acl-D14-1174
acl-J14-3004
acl-D09-1078
acl-C94-2175
acl-W06-1613
acl-A97-1056
acl-P01-1057
acl-W02-0112
acl-W12-3107
acl-P12-2007
acl-C04-1045
acl-P12-2018
acl-C04-1014
acl-P09-1054
Lambda = 0.5 -> less penalty
bound: 0.0
find mmr max: 8.766674955461314
len: 1 55
bound: 8.766674955461314
find mmr max: 15.058879817647917
len: 2 54
bound: 15.058879817647917
find mmr max: 19.92214018470902
len: 3 53
bound: 19.92214018470902
find mmr max: 23.757593498497787
len: 4 52
bound: 23.757593498497787
find mmr max: 27.199471522987718
len: 5 51
bound: 27.199471522987718
find mmr max: 30.36546150973632
len: 6 50
bound: 30.36546150973632
find mmr max: 32.7213083549701
len: 7 49
bound: 32.7213083549701
find mmr max: 34.67511238948413
len: 8 48
bound: 34.67511238948413
find mmr max: 36.24133984210002
len: 9 47
bound: 36.24133984210002
find mmr max: 37.50292006613284
len: 10 46
bound: 37.50292006613284
find mmr max: 38.47513433550634
len: 11 45
bound: 38.47513433550634
find mmr max: 39.41990405278196
len: 12 44
bound: 39.41990405278196
find mmr max: 40.220652733331875
len: 13 43
bound: 40.220652733331875
find mmr max: 40.74526404031241
len: 14 42
bound: 40.74526404031241
find mmr max: 41.26713000069657
len: 15 41
bound: 41.26713000069657
find mmr max: 41.44120765665227
len: 16 40
bound: 41.44120765665227
find mmr max: 41.51919159857814
len: 17 39
bound: 41.51919159857814
find mmr max: 41.510543377277514
len: 17 38
bound: 41.51919159857814
find mmr max: 41.4303923387467
len: 17 37
bound: 41.51919159857814
find mmr max: 41.40151736885963
len: 17 36
bound: 41.51919159857814
find mmr max: 41.29930570174484
len: 17 35
bound: 41.51919159857814
find mmr max: 41.200191755541134
len: 17 34
bound: 41.51919159857814
find mmr max: 41.19125180657055
len: 17 33
bound: 41.51919159857814
find mmr max: 41.17766001942365
len: 17 32
bound: 41.51919159857814
find mmr max: 41.16043126571719
len: 17 31
bound: 41.51919159857814
find mmr max: 41.14287382375743
len: 17 30
bound: 41.51919159857814
find mmr max: 41.12283079045821
len: 17 29
bound: 41.51919159857814
find mmr max: 41.10217088690022
len: 17 28
bound: 41.51919159857814
find mmr max: 41.027755353613685
len: 17 27
bound: 41.51919159857814
find mmr max: 40.98623122580101
len: 17 26
bound: 41.51919159857814
find mmr max: 40.97764213109416
len: 17 25
bound: 41.51919159857814
find mmr max: 40.96547381083362
len: 17 24
bound: 41.51919159857814
find mmr max: 40.952678885464294
len: 17 23
bound: 41.51919159857814
find mmr max: 40.923782792253434
len: 17 22
bound: 41.51919159857814
find mmr max: 40.76211222186183
len: 17 21
bound: 41.51919159857814
find mmr max: 40.75845915712162
len: 17 20
bound: 41.51919159857814
find mmr max: 40.751599976912765
len: 17 19
bound: 41.51919159857814
find mmr max: 40.74344528403975
len: 17 18
bound: 41.51919159857814
find mmr max: 40.72935959619546
len: 17 17
bound: 41.51919159857814
find mmr max: 40.69386860166465
len: 17 16
bound: 41.51919159857814
find mmr max: 40.6704996583388
len: 17 15
bound: 41.51919159857814
find mmr max: 40.6684884952183
len: 17 14
bound: 41.51919159857814
find mmr max: 40.63506432036803
len: 17 13
bound: 41.51919159857814
find mmr max: 40.54607932912565
len: 17 12
bound: 41.51919159857814
find mmr max: 40.52264265605055
len: 17 11
bound: 41.51919159857814
find mmr max: 40.48413340718845
len: 17 10
bound: 41.51919159857814
find mmr max: 40.45281927834874
len: 17 9
bound: 41.51919159857814
find mmr max: 40.45245990355903
len: 17 8
bound: 41.51919159857814
find mmr max: 40.39535660851851
len: 17 7
bound: 41.51919159857814
find mmr max: 40.37718738480603
len: 17 6
bound: 41.51919159857814
find mmr max: 40.28867796378269
len: 17 5
bound: 41.51919159857814
find mmr max: 40.21981010141633
len: 17 4
bound: 41.51919159857814
find mmr max: 40.13511427564651
len: 17 3
bound: 41.51919159857814
find mmr max: 40.10733649786872
len: 17 2
bound: 41.51919159857814
find mmr max: 39.85249804833063
len: 17 1
bound: 41.51919159857814
find mmr max: 39.75178338397543
len: 17 0
17
acl-W10-1703
acl-W10-1716
acl-P09-1018
acl-P08-2038
acl-D07-1030
acl-W02-0106
acl-A97-1056
acl-P02-1022
acl-D14-1174
acl-J14-3004
acl-C04-1045
acl-W06-1613
acl-P09-2060
acl-W12-3107
acl-P01-1057
acl-P14-2015
acl-P09-1054
Lambda = 1.0 -> same degree penalty
bound: 0.0
find mmr max: 8.766674955461314
len: 1 55
bound: 8.766674955461314
find mmr max: 14.572215554255628
len: 2 54
bound: 14.572215554255628
find mmr max: 18.69848430332808
len: 3 53
bound: 18.69848430332808
find mmr max: 22.105648847615612
len: 4 52
bound: 22.105648847615612
find mmr max: 25.510309276102088
len: 5 51
bound: 25.510309276102088
find mmr max: 27.762343850812776
len: 6 50
bound: 27.762343850812776
find mmr max: 29.553197261431578
len: 7 49
bound: 29.553197261431578
find mmr max: 31.075679603268732
len: 8 48
bound: 31.075679603268732
find mmr max: 32.07708681052135
len: 9 47
bound: 32.07708681052135
find mmr max: 32.77229491658016
len: 10 46
bound: 32.77229491658016
find mmr max: 33.08168498017544
len: 11 45
bound: 33.08168498017544
find mmr max: 33.319442793344344
len: 12 44
bound: 33.319442793344344
find mmr max: 33.53878767115003
len: 13 43
bound: 33.53878767115003
find mmr max: 33.75161361148125
len: 14 42
bound: 33.75161361148125
find mmr max: 33.935450726340505
len: 15 41
bound: 33.935450726340505
find mmr max: 34.109528382296205
len: 16 40
bound: 34.109528382296205
find mmr max: 34.26756928680719
len: 17 39
bound: 34.26756928680719
find mmr max: 34.202811798761985
len: 17 38
bound: 34.26756928680719
find mmr max: 34.0956189387374
len: 17 37
bound: 34.26756928680719
find mmr max: 34.09270373039336
len: 17 36
bound: 34.26756928680719
find mmr max: 34.002060221416635
len: 17 35
bound: 34.26756928680719
find mmr max: 33.971571123043844
len: 17 34
bound: 34.26756928680719
find mmr max: 33.77510670820287
len: 17 33
bound: 34.26756928680719
find mmr max: 33.558409895742116
len: 17 32
bound: 34.26756928680719
find mmr max: 33.53575578533548
len: 17 31
bound: 34.26756928680719
find mmr max: 33.35640652102635
len: 17 30
bound: 34.26756928680719
find mmr max: 33.34466313291635
len: 17 29
bound: 34.26756928680719
find mmr max: 33.25063155555836
len: 17 28
bound: 34.26756928680719
find mmr max: 33.2249754312973
len: 17 27
bound: 34.26756928680719
find mmr max: 33.17803929034559
len: 17 26
bound: 34.26756928680719
find mmr max: 33.16277128080808
len: 17 25
bound: 34.26756928680719
find mmr max: 33.13846485552877
len: 17 24
bound: 34.26756928680719
find mmr max: 33.04615780041994
len: 17 23
bound: 34.26756928680719
find mmr max: 33.0325430405107
len: 17 22
bound: 34.26756928680719
find mmr max: 32.97021580471717
len: 17 21
bound: 34.26756928680719
find mmr max: 32.92523646742809
len: 17 20
bound: 34.26756928680719
find mmr max: 32.898593638853
len: 17 19
bound: 34.26756928680719
find mmr max: 32.89688916758611
len: 17 18
bound: 34.26756928680719
find mmr max: 32.83507160843942
len: 17 17
bound: 34.26756928680719
find mmr max: 32.82035126539593
len: 17 16
bound: 34.26756928680719
find mmr max: 32.78977109808705
len: 17 15
bound: 34.26756928680719
find mmr max: 32.73200830581459
len: 17 14
bound: 34.26756928680719
find mmr max: 32.71197353674019
len: 17 13
bound: 34.26756928680719
find mmr max: 32.68287172061944
len: 17 12
bound: 34.26756928680719
find mmr max: 32.59404884927024
len: 17 11
bound: 34.26756928680719
find mmr max: 32.45928786370513
len: 17 10
bound: 34.26756928680719
find mmr max: 32.349449309356245
len: 17 9
bound: 34.26756928680719
find mmr max: 32.273204319121035
len: 17 8
bound: 34.26756928680719
find mmr max: 32.23605040671343
len: 17 7
bound: 34.26756928680719
find mmr max: 32.208272628935646
len: 17 6
bound: 34.26756928680719
find mmr max: 32.14037791740611
len: 17 5
bound: 34.26756928680719
find mmr max: 32.078302985529774
len: 17 4
bound: 34.26756928680719
find mmr max: 32.0497267654992
len: 17 3
bound: 34.26756928680719
find mmr max: 31.97013834269091
len: 17 2
bound: 34.26756928680719
find mmr max: 31.845751808593484
len: 17 1
bound: 34.26756928680719
find mmr max: 31.569488813934836
len: 17 0
17
acl-W10-1703
acl-W10-1716
acl-P08-2038
acl-D07-1030
acl-W02-0106
acl-J14-3004
acl-A97-1056
acl-D14-1174
acl-H93-1047
acl-C08-2019
acl-C04-1014
acl-J13-3001
acl-I08-1042
acl-P09-2060
acl-C96-2146
acl-P14-2015
acl-C04-1045
Lambda = 2.0 -> double degree penalty
bound: 0.0
find mmr max: 8.766674955461314
len: 1 55
bound: 8.766674955461314
find mmr max: 13.789414821900042
len: 2 54
bound: 13.789414821900042
find mmr max: 17.113229040843937
len: 3 53
bound: 17.113229040843937
find mmr max: 19.715234270375973
len: 4 52
bound: 19.715234270375973
find mmr max: 21.799526143515898
len: 5 51
bound: 21.799526143515898
find mmr max: 23.874925737908402
len: 6 50
bound: 23.874925737908402
find mmr max: 25.174995753322595
len: 7 49
bound: 25.174995753322595
find mmr max: 25.796355757231975
len: 8 48
bound: 25.796355757231975
find mmr max: 26.275309003403812
len: 9 47
bound: 26.275309003403812
find mmr max: 26.621772525986678
len: 10 46
bound: 26.621772525986678
find mmr max: 26.88804244606537
len: 11 45
bound: 26.88804244606537
find mmr max: 27.06212010202107
len: 12 44
bound: 27.06212010202107
find mmr max: 27.231519731936793
len: 13 43
bound: 27.231519731936793
find mmr max: 27.292693242183486
len: 14 42
bound: 27.292693242183486
find mmr max: 27.181007775717433
len: 14 41
bound: 27.292693242183486
find mmr max: 27.018215306207985
len: 14 40
bound: 27.292693242183486
find mmr max: 26.873507667887214
len: 14 39
bound: 27.292693242183486
find mmr max: 26.839456778289517
len: 14 38
bound: 27.292693242183486
find mmr max: 26.774666482733785
len: 14 37
bound: 27.292693242183486
find mmr max: 26.66290837185621
len: 14 36
bound: 27.292693242183486
find mmr max: 26.338120203638617
len: 14 35
bound: 27.292693242183486
find mmr max: 26.258999365830988
len: 14 34
bound: 27.292693242183486
find mmr max: 26.205543756042584
len: 14 33
bound: 27.292693242183486
find mmr max: 26.08007681586542
len: 14 32
bound: 27.292693242183486
find mmr max: 25.97972798916748
len: 14 31
bound: 27.292693242183486
find mmr max: 25.97961570530281
len: 14 30
bound: 27.292693242183486
find mmr max: 25.912020820938476
len: 14 29
bound: 27.292693242183486
find mmr max: 25.88597067875717
len: 14 28
bound: 27.292693242183486
find mmr max: 25.88301460650066
len: 14 27
bound: 27.292693242183486
find mmr max: 25.87941149375547
len: 14 26
bound: 27.292693242183486
find mmr max: 25.803394900013874
len: 14 25
bound: 27.292693242183486
find mmr max: 25.752545951553923
len: 14 24
bound: 27.292693242183486
find mmr max: 25.723054642191915
len: 14 23
bound: 27.292693242183486
find mmr max: 25.625789260808094
len: 14 22
bound: 27.292693242183486
find mmr max: 25.47654520480953
len: 14 21
bound: 27.292693242183486
find mmr max: 25.309773134286832
len: 14 20
bound: 27.292693242183486
find mmr max: 25.17777475255081
len: 14 19
bound: 27.292693242183486
find mmr max: 25.02351338262584
len: 14 18
bound: 27.292693242183486
find mmr max: 24.960994403221243
len: 14 17
bound: 27.292693242183486
find mmr max: 24.954581826504796
len: 14 16
bound: 27.292693242183486
find mmr max: 24.69315559899113
len: 14 15
bound: 27.292693242183486
find mmr max: 24.683361169309823
len: 14 14
bound: 27.292693242183486
find mmr max: 24.654224798093917
len: 14 13
bound: 27.292693242183486
find mmr max: 24.556531090760494
len: 14 12
bound: 27.292693242183486
find mmr max: 24.418911365168995
len: 14 11
bound: 27.292693242183486
find mmr max: 24.403604393937428
len: 14 10
bound: 27.292693242183486
find mmr max: 24.393901804685562
len: 14 9
bound: 27.292693242183486
find mmr max: 24.389787828470205
len: 14 8
bound: 27.292693242183486
find mmr max: 24.378096661811274
len: 14 7
bound: 27.292693242183486
find mmr max: 24.310675907819817
len: 14 6
bound: 27.292693242183486
find mmr max: 23.81103034825398
len: 14 5
bound: 27.292693242183486
find mmr max: 23.760997549530135
len: 14 4
bound: 27.292693242183486
find mmr max: 23.728047623667898
len: 14 3
bound: 27.292693242183486
find mmr max: 22.881034755387304
len: 14 2
bound: 27.292693242183486
find mmr max: 22.743122607389015
len: 14 1
bound: 27.292693242183486
find mmr max: 22.7121151245334
len: 14 0
14
acl-W10-1703
acl-W11-2158
acl-J14-3004
acl-A97-1056
acl-P01-1057
acl-I05-1051
acl-C94-2175
acl-I08-1042
acl-P09-2060
acl-C04-1014
acl-C10-3013
acl-P14-2015
acl-P07-2020
acl-J13-3001
#Lambda = 4.0 -> as the paper chosen
bound: 0.0
find mmr max: 8.766674955461314
len: 1 55
bound: 8.766674955461314
find mmr max: 13.059832199693483
len: 2 54
bound: 13.059832199693483
find mmr max: 15.504818477439938
len: 3 53
bound: 15.504818477439938
find mmr max: 17.172536481424117
len: 4 52
bound: 17.172536481424117
find mmr max: 18.59571085500525
len: 5 51
bound: 18.59571085500525
find mmr max: 19.925459716510773
len: 6 50
bound: 19.925459716510773
find mmr max: 20.546819720420153
len: 7 49
bound: 20.546819720420153
find mmr max: 20.762193614754043
len: 8 48
bound: 20.762193614754043
find mmr max: 20.946030729613298
len: 9 47
bound: 20.946030729613298
find mmr max: 21.120108385568997
len: 10 46
bound: 21.120108385568997
find mmr max: 21.289508015484717
len: 11 45
bound: 21.289508015484717
find mmr max: 21.21298243682374
len: 11 44
bound: 21.289508015484717
find mmr max: 20.799689510836362
len: 11 43
bound: 21.289508015484717
find mmr max: 20.63026887338538
len: 11 42
bound: 21.289508015484717
find mmr max: 20.38160241566799
len: 11 41
bound: 21.289508015484717
find mmr max: 20.210192024325824
len: 11 40
bound: 21.289508015484717
find mmr max: 20.195647536530934
len: 11 39
bound: 21.289508015484717
find mmr max: 20.159721360687293
len: 11 38
bound: 21.289508015484717
find mmr max: 20.124352595442744
len: 11 37
bound: 21.289508015484717
find mmr max: 20.115621475479998
len: 11 36
bound: 21.289508015484717
find mmr max: 20.056383847201815
len: 11 35
bound: 21.289508015484717
find mmr max: 20.05353385116416
len: 11 34
bound: 21.289508015484717
find mmr max: 19.969693645114035
len: 11 33
bound: 21.289508015484717
find mmr max: 19.858894969115653
len: 11 32
bound: 21.289508015484717
find mmr max: 19.85376137460338
len: 11 31
bound: 21.289508015484717
find mmr max: 19.847940794119037
len: 11 30
bound: 21.289508015484717
find mmr max: 19.742662836348728
len: 11 29
bound: 21.289508015484717
find mmr max: 19.673166814395962
len: 11 28
bound: 21.289508015484717
find mmr max: 19.390628283881632
len: 11 27
bound: 21.289508015484717
find mmr max: 19.389333859006918
len: 11 26
bound: 21.289508015484717
find mmr max: 19.358364216511063
len: 11 25
bound: 21.289508015484717
find mmr max: 19.21613800484812
len: 11 24
bound: 21.289508015484717
find mmr max: 19.06574198215116
len: 11 23
bound: 21.289508015484717
find mmr max: 19.01028671792051
len: 11 22
bound: 21.289508015484717
find mmr max: 18.925081146829086
len: 11 21
bound: 21.289508015484717
find mmr max: 18.870182380229977
len: 11 20
bound: 21.289508015484717
find mmr max: 18.858669289592818
len: 11 19
bound: 21.289508015484717
find mmr max: 18.846132711839886
len: 11 18
bound: 21.289508015484717
find mmr max: 18.597400905636402
len: 11 17
bound: 21.289508015484717
find mmr max: 18.45392819708262
len: 11 16
bound: 21.289508015484717
find mmr max: 18.449172898782095
len: 11 15
bound: 21.289508015484717
find mmr max: 18.273277554490015
len: 11 14
bound: 21.289508015484717
find mmr max: 18.245499776712244
len: 11 13
bound: 21.289508015484717
find mmr max: 18.01179656625142
len: 11 12
bound: 21.289508015484717
find mmr max: 17.900636548725707
len: 11 11
bound: 21.289508015484717
find mmr max: 17.889194309560068
len: 11 10
bound: 21.289508015484717
find mmr max: 17.83075720066326
len: 11 9
bound: 21.289508015484717
find mmr max: 17.693438366678222
len: 11 8
bound: 21.289508015484717
find mmr max: 17.635717282727008
len: 11 7
bound: 21.289508015484717
find mmr max: 17.400769238950716
len: 11 6
bound: 21.289508015484717
find mmr max: 16.93922585902
len: 11 5
bound: 21.289508015484717
find mmr max: 16.12041574181831
len: 11 4
bound: 21.289508015484717
find mmr max: 15.621025874294627
len: 11 3
bound: 21.289508015484717
find mmr max: 15.434096972053933
len: 11 2
bound: 21.289508015484717
find mmr max: 14.801616854434258
len: 11 1
bound: 21.289508015484717
find mmr max: 14.64708549959741
len: 11 0
11
acl-W10-1703
acl-D07-1030
acl-J14-3004
acl-W96-0210
acl-P09-2008
acl-P12-2007
acl-I08-1042
acl-P00-1056
acl-C96-2146
acl-P14-2015
acl-P07-2020
