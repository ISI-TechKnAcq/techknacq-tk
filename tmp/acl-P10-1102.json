{
  "info": {
    "authors": [
      "Kornel Laskowski"
    ],
    "book": "ACL",
    "id": "acl-P10-1102",
    "title": "Modeling Norms of Turn-Taking in Multi-Party Conversation",
    "url": "https://aclweb.org/anthology/P10-1102",
    "year": 2010
  },
  "references": [
    "acl-W04-2319"
  ],
  "sections": [
    {
      "text": [
        "Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation.",
        "While most aspects of conversational speech have benefited from a wide availability of analytic, computationally tractable techniques, only qualitative assessments are available for characterizing multi-party turn-taking.",
        "The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches.",
        "Experiments show that direct multi-participant models do not generalize to held out data, and likely never will, for practical reasons.",
        "In contrast, the Extended-Degree-of-Overlap model represents a suitable candidate for future work in this area, and is shown to successfully predict the distribution of speech in time and across participants in previously unseen conversations."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation.",
        "Whereas sociolinguists might argue that multiparty settings provide for the most natural form of conversation, and that dialogue and monologue are merely degenerate cases (Jaffe and Feldstein, 1970), computational approaches have found it most expedient to leverage past successes; these often involved at most one speaker.",
        "Consequently, even in multi-party settings, automatic systems generally continue to treat participants independently, fusing information across participants relatively late in processing.",
        "This state of affairs has resulted in the near-exclusion from computational consideration and from semantic analysis of a phenomenon which occurs at the lowest level of speech exchange, namely the relative timing of the deployment of speech in arbitrary multi-party groups.",
        "This phenomenon, the implicit taking of turns at talk (Sacks et al., 1974), is important because unless participants adhere to its general rules, a conversation would simply not take place.",
        "It is therefore somewhat surprising that while most other aspects of speech enjoy a large base of computational methodologies for their study, there are few quantitative techniques for assessing the flow of turn-taking in general multi-party conversation.",
        "The current work attempts to address this problem by proposing a simple framework, which, at least conceptually, borrows quite heavily from the standard language modeling paradigm.",
        "First, itde-fines the perplexity of a vector-valued Markov process whose multi-participant states are a concatenation of the binary states of individual speakers.",
        "Second, it presents some obvious evidence regarding the unsuitability of models defined directly over this space, under various assumptions of independence, for the inference of conversation-independent norms of turn-taking.",
        "Finally, it demonstrates that the extended-degree-of-overlap model of (Laskowski and Schultz, 2007), which models participants in an alternate space, achieves by far the best likelihood estimates for previously unseen conversations.",
        "This appears to be because the model can learn across conversations, regardless of the number of their participants.",
        "Experimental results show that it yields relative perplexity reductions of approximately 75% when compared to the ubiquitous single-participant model which ignores interlocutors, indicating that it can learn and generalize aspects of interaction which direct multi-participant models, and merely single-participant models, cannot.",
        "Analysis and experiments are performed using the ICSI Meeting Corpus (Janin et al., 2003; Shriberg et al., 2004).",
        "The corpus consists of 75 meetings, held by various research groups at ICSI, which would have occurred even if they had not been recorded.",
        "This is important for studying naturally occurring interaction, since any form of intervention (including occurrence staging solely for the purpose of obtaining a record) may have an unknown but consistent impact on the emergence of turn-taking behaviors.",
        "Each meeting was attended by 3 to 9 participants, providing a wide variety of possible interaction types."
      ]
    },
    {
      "heading": "3. Conceptual Framework 3.1 Definitions",
      "text": [
        "Turn-taking is a generally observed phenomenon in conversation (Sacks et al., 1974; Goodwin, 1981; Schegloff, 2007); one party talks while the others listen.",
        "Its description and analysis is an important problem, treated frequently as a subdomain of linguistic pragmatics (Levinson, 1983).",
        "In spite of this, linguists tend to disagree about what precisely constitutes a turn (Sacks et al., 1974; Edelsky, 1981; Goodwin, 1981; Traum and Heeman, 1997), or even a turn boundary.",
        "For example, a \"yeah\" produced by a listener to indicate attentiveness, referred to as a backchannel (Yngve, 1970), is often considered to not implement a turn (nor to delineate an ongoing turn of an interlocutor), as it bears no propositional content and does not \"take the floor\" from the current speaker.",
        "To avoid being tied to any particular sociolinguistic theory, the current work equates \"turn\" with any contiguous interval of speech uttered by the same participant.",
        "Such intervals are commonly referred to as talk spurts (Norwine and Murphy, 1938).",
        "Because Norwine and Murphy's original definition is somewhat ambiguous and non-trivial to operationalize, this work relies on that proposed by (Shriberg et al., 2001), in which spurts are \"defined as speech regions uninterrupted by pauses longer than 500 ms\" (italics in the original).",
        "Here, a threshold of 300 ms is used instead, as recently proposed in NIST's Rich Transcription Meeting Recognition evaluations (NIST, 2002).",
        "The resulting definition of talk spurt, it is important to note, is in quite common use but frequently under different names.",
        "An oft-cited example is the inter-pausal unit of (Koiso et al., 1998), where the threshold is 100 ms.",
        "A consequence of this choice is that any model of turn-taking behavior inferred will effectively be a model of the distribution of speech, in time and across participants.",
        "If the parameters of such a model are maximum likelihood (ML) estimates, then that model will best account for what is most likely, or most \"normal\"; it will constitute a norm.",
        "Finally, an important aspect of this work is that it analyzes turn-taking behavior as independent of the words spoken (and of the ways in which those words are spoken).",
        "As a result, strictly speaking, what is modeled is not the distribution of speech in time and across participants but of binary speech activity in time and across participants.",
        "Despite this seemingly dramatic simplification, it will be seen that important aspects of turn-taking are sufficiently rare to be problematic for modeling.",
        "Modeling them jointly alongside lexical information, in multi-party scenarios, is likely to remain intractable for the foreseeable future.",
        "The notation used here, as in (Laskowski and Schultz, 2007), is a trivial extension of that proposed in (Rabiner, 1989) to vector-valued Markov processes.",
        "At any instant t, each of K participants to a conversation is in a state drawn from * = {S0, S1} = {□, ■}, where Si = ■ indicates speech (or, more precisely, \"intra-talk-spurt instants\") and So = □ indicates non-speech (or \"inter-talk-spurt instants\").",
        "The joint state of all participants at time t is described using the K-length column vector",
        "An entire conversation, from the point of view of this work, can be represented as the matrix",
        "g *KxT .",
        "Q is known as the (discrete) vocal interaction (Dabbs and Ruback, 1987) record.",
        "T is the total number of frames in the conversation, sampled at Ts = 100 ms intervals.",
        "This is approximately the duration of the shortest lexical productions in the ICSI Meeting Corpus.",
        "Given this definition of Q, a model 0 is sought to account for it.",
        "Only time-independent models, whose parameters do not change over the course of the conversation, are considered in this work.",
        "For simplicity, the state qo = So = [□, □]*, in which no participant is speaking (* indicates matrix transpose, to avoid confusion with conversation duration T) is first prepended to Q. Po = P ( q0 ) therefore represents the unconditional probability of all participants being silent just prior to the start of any conversation.",
        "Then where in the second line the history is truncated to yield a standard first-order Markov form.",
        "Each of the T factors in Equation 3 is independent of the instant t, as per the notation in (Rabiner, 1989).",
        "In particular, each factor is a function only of the state Si in which the conversation was at time t – 1 and the state Sj in which the conversation is at time t, and not of the instants t – 1 or t. It may be expressed as the scalar aij which forms the ith row and jth column entry of the matrix {aij } = 0.",
        "In language modeling practice, one finds the likelihood P ( w I 0 ), of a word sequence w of length Ilw y under a model 0, to be an inconvenient measure for comparison.",
        "Instead, the negative log-likelihood (NLL) and perplexity (PPL), defined as",
        "recording of a conversation, rather than the beginning of the conversation itself; this detail is without consequence.",
        "are often preferred (Jelinek, 1999).",
        "They are ubiquitously used to compare the complexity of different word sequences (or corpora) w and w' under the same model 0, or the performance on a single word sequence (or corpus) w under competing models 0 and 0'.",
        "Here, a similar metric is proposed, to be used for the same purposes, for the record Q.",
        "are defined as measures of turn-taking perplexity.",
        "As can be seen in Equation 8, the negative log-likelihood is normalized by the number K of participants and the number T of frames in Q; the latter renders the measure useful for making duration-independent comparisons.",
        "The normalization by K does not per se suggest that turn-taking in conversations with different K is necessarily similar; it merely provides similar bounds on the magnitudes of these metrics."
      ]
    },
    {
      "heading": "4. Direct Estimation of ©",
      "text": [
        "Direct application of bigram modeling techniques, defined over the states {S}, is treated as a baseline.",
        "In contrast to multi-party conversation, dialogue has been extensively modeled in the ways described in this paper.",
        "Beginning with (Brady, 1969), Markov modeling techniques over the joint speech activity of two interlocutors have been explored by both the sociolinguist and the psycholinguist community (Jaffe and Feldstein, 1970; Dabbs and Ruback, 1987).",
        "The same models have also appeared in dialogue systems (Raux, 2008).",
        "Most recently, they have been augmented with duration models in a study of the Switchboard corpus (Grothendieck et al., 2009).",
        "In the general case beyond dialogue, such models have found less traction.",
        "This is partly due to the exponential growth in the number of states as K increases, and partly due to difficulties in interpretation.",
        "The only model for arbitrary K that the author is familiar with is the GroupTalk model (Dabbs and Ruback, 1987), which is unsuitable for the purposes here as it does not scale (with K,",
        "Figure 1 : Perplexity (along y-axis) in time (along x-axis, in minutes) for meeting Bmr024 under a conditionally dependent global oracle model, two \"matched-half models (A+B), and two \"mismatched-half ' models (B+A).",
        "the number of participants) without losing track of speakers when two or more participants speak simultaneously (known as overlap).",
        "In a particular conversation with K participants, the state space of an ergodic process contains 2K states, and the number of free parameters in a model 0 which treats participant behavior as conditionally dependent (CD), henceforth 0CD, scales as 2K • (2K – l) .It should be immediately obvious that many of the 2K states are likely to not occur within a conversation of duration T, leading to misestimation of the desired probabilities.",
        "To demonstrate this, three perplexity trajectories for a snippet of meeting Bmr024 are shown in Figure 1, in the interval beginning 5 minutes into the meeting and ending 20 minutes later.",
        "(The meeting is actually just over 50 minutes long but only a snippet is shown to better appreciate small time-scale variation.)",
        "The depicted perplexities are not unweighted averages over the whole meeting of duration T as in Equation 8, but over a 60-second Hamming window centered on each t.",
        "The first trajectory, the dashed black line, is obtained when the entire meeting is used to estimate 0CD, and is then scored by that same model (an \"oracle\" condition).",
        "Significant perplexity variation is observed throughout the depicted snippet.",
        "The second trajectory, the continuous black line, is that obtained when the meeting is split into two equal-duration halves, one consisting of all instants prior to the midpoint and the other of all instants following it.",
        "These halves are hereafter referred to as A and B, respectively (the interval in Figure 1 falls entirely within the A half).",
        "Two separate models 0^D and 0BD are each trained on only one of the two halves, and then applied to those same halves.",
        "As can be seen at the scale employed, the matched A+B model, demonstrating the effect of training data ablation, deviates from the global oracle model only in the intervals [7, ll] seconds and [15,18] seconds; otherwise it appears that more training data, from later in the conversation, does not affect model performance.",
        "Finally, the third trajectory, the continuous gray line, is obtained when the two halves A and B of the meeting are scored using the mismatched models 0BD and 0^D, respectively (this condition is henceforth referred to as the B+A condition).",
        "It can be seen that even when probabilities are estimated from the same participants, in exactly the same conversation, a direct conditionally dependent model exposed to over 25 minutes of a conversation cannot predict the turn-taking patterns observed later.",
        "A potential reason for the gross misestimation of 0CD under mismatched conditions is the size of the state space {S}.",
        "The number of parameters in the model can be reduced by assuming that participants behave independently at instant t, but are conditioned on their joint behavior at t – 1.",
        "The likelihood of Q under the resulting conditionally independent model 0CI has the form where each factor is time-independent, with 0 < i < 2K and 0 < n < 2.",
        "The complete model {0CI} = {{a<CIn}} consists of K matrices of size 2K x 2 each.",
        "It therefore contains only K 2K free parameters, a significant reduction over the conditionally dependent model 0CD.",
        "Panel (a) of Figure 2 shows the performance of this model on the same conversational snippet as in Figure 1.",
        "The oracle, dashed black line of the latter is reproduced as a reference.",
        "The continuous black and gray lines show the smoothed perplexity for the matched (A+B) and the mismatched (B+A) conditions, respectively.",
        "In the matched condition, the CI model reproduces the oracle trajectory with relatively high fidelity, suggesting that participants' behavior may in fact be assumed to be conditionally independent in the sense discussed.",
        "Furthermore, the failures of the CI model under mismatched conditions are less severe in magnitude than those of the CD model.",
        "A j",
        "l\\",
        "Ii",
        "1",
        "--oracle -",
        "- A+B",
        "- B+A",
        "Panel (b) of Figure 2 demonstrates the trivial fact that a conditionally independent model 0^, tying the statistics of all K participants into a single model, is useless.",
        "This is of course because it cannot predict the next state of a generic participant for which the index k in qt-1 has been lost.",
        "A further reduction in the complexity of 0 can be achieved by assuming that participants are mutually independent (MI), leading to the participant-specific 0jfI model:",
        "The factors are time-independent, where 0 < m < 2 and 0 < n < 2.",
        "This model {0MI} = {{afmmn}} consists of K matrices of size 2 x 2 each, with only K • 2 free parameters.",
        "Panel (c) of Figure 2 shows that the MI model yields mismatched performance which is a much better approximation to its performance under matched conditions.",
        "However, its matched performance is worse than that of CD and CI models.",
        "When a single MI model is trained instead for all participants, as shown in panel (d), both of these effects are exaggerated.",
        "In fact, the performance of 0MnIy in matched and mismatched conditions is almost identical.",
        "The consistently higher perplexity is obtained, as mentioned, by smoothing over 60-second windows, and therefore underestimates poor performance at specific instants (which occur frequently).",
        "Figure 2: Perplexity (along y-axis) in time (along x-axis, in minutes) for meeting Bmr024 under a conditionally dependent global oracle model, and various matched (A+B) and mismatched (B+A) model pairs with relaxed dependence assumptions.",
        "Legend as in Figure 1."
      ]
    },
    {
      "heading": "5. Limitations and Desiderata",
      "text": [
        "As the analyses in Section 4 reveal, direct estimation can be useful under oracle conditions, namely when all of a conversation has been observed and the task is to find intervals where multi-participant behavior deviates significantly from its conversation-specific norm.",
        "The assumption of conditional independence among participants was argued to lead to negligible degradation in the detectability of these intervals.",
        "However, the assumption of mutual independence consistently leads to higher surprise by the model.",
        "In the more interesting setting in which only a part of a conversation has been seen and the task is to limit the perplexity of what is still to come, direct estimation exhibits relatively large failures under both conditionally dependent and conditionally independent participant assumptions.",
        "This appears to be due to the size of the state space, which scales as 2K with the number K of participants.",
        "In the case of general K, more conversational data may be sought, from exactly the same group of participants, but that approach appears likely to be insufficient, and, for practical reasons, impossible.",
        "One would instead like to be able to use other conversations, also exhibiting participant interaction, to limit the perplexity of speech occurrence in the conversation under study.",
        "1",
        "*",
        "V k",
        "W",
        "y",
        "V",
        "Unfortunately, there are two reasons why direct estimation cannot be tractably deployed across conversations.",
        "The first is that the direct models considered here, with the exception of 0^^^, are K-specific.",
        "In particular, the number and the identity of conditioning states are both functions of K, for 0CD and {0^}; the models may also consist of K distinct submodels, as for {0kCI} and {0MI}.",
        "No techniques for computing the turn-taking perplexity in conversations with K participants, using models trained on conversations with K' = K, are currently available.",
        "The second reason is that these models, again with the exception of , are R-specific, independently of K-specificity.",
        "By this it is meant that the models are sensitive to participant index permutation.",
        "Had a participant at index k in Q been assigned to another index k'=k, an alternate representation of the conversation, namely Q' = Rkk' • Q, would have been obtained.",
        "(Here, Rkk' is a matrix rotation operator obtained by exchanging columns k and k' of the K x K identity matrix I.)",
        "Since index assignment is entirely arbitrary, useful direct models cannot be inferred from other conversations, even when their K' K, unless K is small.",
        "The prospect of naively permuting every training conversation prior to parameter inference has complexity K !.",
        "Until R-specificity is comprehensively addressed, the only model from among those discussed so far, which exhibits no K-dependence, is 0^^^, namely that which treats participants identically and independently.",
        "This model can be used to score the perplexity of anyconversation, and facilitates the comparison of the distribution of speech activity across conversations.",
        "Unfortunately, since the model captures only durational aspects of one-participant speech and non-speech intervals, it does not in any way encode a norm of turn-taking, an inherently interactive and hence multi-participant phenomenon.",
        "It therefore cannot be said to rank conversations according to their deviation from turn-taking norms.",
        "In addition to the concerns above, a fundamental limitation of the analyzed direct models, whether for conversation-specific or conversation-independent use, is that they are theoretically cumbersome if not vacuous.",
        "Given a solution to the problem of R-specificity, the parameters {aCD} may be robustly inferred, and the models may be applied to yield useful estimates of turn-taking perplexity.",
        "However, they cannot be said to directly validate or dispute the vast qualitative observations of sociolinguistics, and of conversation analysis in particular.",
        "To produce Figures 1 and 2, a small fraction of probability mass was reserved for unseen bigram transitions (as opposed to backing off to unigram probabilities).",
        "Furthermore, transitions into never-observed states were assigned uniform probabilities.",
        "This policy is simplistic, and there is significant scope for more detailed back-off and interpolation.",
        "However, such techniques infer values for underestimated probabilities from shorter truncations of the conditioning history.",
        "As K-specificity and R-specificity suggest, what appears to be needed here are back-off and interpolation across states.",
        "For example, in a conversation of K = 5 participants, estimates of the likelihood of the state qt = [□■■■□]*, which might have been unobserved in any training material, can be assumed to be related to those of qt = [□□■■□]* and",
        "Rq't', for arbitrary R."
      ]
    },
    {
      "heading": "6. The Extended-Degree-of-Overlap Model",
      "text": [
        "The limitations of direct models appear to be addressable by a form proposed by Laskowski and Schultz in (2006) and (2007).",
        "That form, the Extended-Degree-of-Overlap (EDO) model, was used to provide prior probabilities P ( Q I 0 ) of the speech states of multiple meeting participants simultaneously, for use in speech activity detection.",
        "The model was trained on utterances (rather than talk spurts) from a different corpus than that used here, and the authors did not explore the turn-taking perplexities of their data sets.",
        "Several of the equations in (Laskowski and Schultz, 2007) are reproduced here for comparison.",
        "The EDO model yields time-independent transition probabilities which assume conditional inter-participant dependence (cf.",
        "Equation 3), where n» = 11 S» M and nj = || Sj ||, with 11S M yielding the number of participants in ■ in the multi-participant state S. In other words, n» and nj are the numbers of participants simultaneously speaking in states S» and Sj, respectively.",
        "The elements of the binary product S = S1 • S2 are given by and Oj is therefore the number of same participants speaking in S» and Sj.□ , otherwise ,",
        "The discussion of the role of a»j in Equation 16 is deferred to the end of this section.",
        "The EDO model mitigates R-specificity because it models each bigram (qt-1, qt) = (S», Sj) as the modified bigram (n», [oj, nj]), involving three scalars each of which is a sum – a commutative (and therefore rotation-invariant) operation.",
        "Because it sums across only those participants which are in the ■ state, completely ignoring their □-state interlocutors, it can also mitigate K-specificity if one additionally redefines as in (Laskowski and Schultz, 2007).",
        "Kmaxrepresents the maximum model-licensed degree of overlap, or the maximum number of participants allowed to be simultaneously speaking.",
        "The EDO model therefore represents a viable conversation-independent, K-independent, and R-independent model of turn-taking for the purposes in the current work.",
        "The factor a»j in Equation 16 provides a deterministic mapping from the conversation-independent space (n», [oj ,nj]) to the conversation-specific space {aj}.",
        "The mapping is deterministic because the model assumes that all participants are identical.",
        "This places the EDO model at a disadvantage with respect to the CD and CI models, as well as to {0MI}, which allow each participant to be modeled differently."
      ]
    },
    {
      "heading": "7. Experiments",
      "text": [
        "This section describes the performance of the discussed models on the entire ICSI Meeting Corpus.",
        "First to be explored is the prediction of yet-unobserved behavior in conversation-specific settings.",
        "For each meeting, models are trained on portions of that meeting only, and then used to score other portions of the same meeting.",
        "This is repeated over all meetings, and comprises the mismatched condition of Section 4; for contrast, the matched condition is also evaluated.",
        "Each meeting is divided into two halves, in two different ways.",
        "The first way is the A/B split of Section 4, representing the first and second halves of each meeting; as has been shown, turn-taking patterns may vary substantially from A to B.",
        "The second split (C/D) places every even-numbered frame in one set and every odd-numbered frame in the other.",
        "This yields a much easier setting, of two halves which are on average maximally similar but still temporally disjoint.",
        "The perplexities (of Equation 9) in these experiments are shown in the second, fourth, sixth and eighth columns of Table 1, under \"all\".",
        "In the matched A+B and C+D conditions, the conditionally dependent model 0CD provides topline ML performance.",
        "Perplexities decrease as model complexities fall for direct models, as expected.",
        "However, in the more interesting mismatched B+A condition, the EDO model performs the best.",
        "This shows that its ability to generalize to unseen data is higher than that of direct models.",
        "However, in the easier mismatched D+C condition, it is outperformed by the CI model due to behavior differences among participants, which the EDO model",
        "small groups and large groups, represented in their study by K = 5 and K = 10, and noted that there is a smooth transition between the two extremes; this provides some scope for interpolating small-and large-group models, and the EDO framework makes this possible.",
        "Table 1: Perplexities for conversation-specific turn-taking models on the entire ICSI Meeting Corpus.",
        "Both \"all\" frames and the subset (\"sub\") for which qt-1 = qt are shown, for matched (A+B and C+D) and mismatched (B+A and D+C) conditions on splits A/B and C/D.",
        "does not capture.",
        "The numbers under the \"all\" columns in Table 1 were computed using all of each meeting's frames.",
        "For contrast, in the \"sub\" columns, perplexities are computed over only those frames for which qt-1 = qt.",
        "This is a useful subset because, for the majority of time in conversations, one person simply continues to talk while all others remain silent.",
        "Excluding qt-1 = qt bigrams (leading to 0.32M frames from 2.39M frames in \"all\") offers a glimpse of expected performance differences were duration modeling to be included in the models.",
        "Perplexities are much higher in these intervals, but the same general trend as for \"all\" is observed.",
        "The training of conversation-independent models, given a corpus of K-heterogeneous meetings, is achieved by iterating over all meetings and testing each using models trained on all of the other meetings.",
        "As discussed in the preceding section, is the only one among the direct models which can be used for this purpose.",
        "It also models exclusively single-participant behavior, ignoring the interactive setting provided by other participants.",
        "As shown in Table 2, when all time is scored the EDO model with Kmax = 4 is the best model (in Section 7.1, Kmax = K since the model was trained on the same meeting to which it was applied).",
        "Its perplexity gap to the oracle model is only a quarter of the gap exhibited by .",
        "The relative performance of EDO models is even better when only those instants t are considered for which qt-1 = qt.",
        "There, the perplexity gap to the oracle model is smaller than that of",
        "Table 2: Perplexities for conversation-independent turn-taking models on the entire ICSI Meeting Corpus; the oracle 0CD topline is included in the first row.",
        "Both \"all\" frames and the subset (\"sub\") for which qt-1 = qt are shown; relative increases over the topline (less unity, representing no perplexity) are shown in columns 4 and 5.",
        "The value of Kmax (cf. Equations 18, 19, and 20) is shown in parentheses in the first column.",
        "0EDO by 78%."
      ]
    },
    {
      "heading": "8. Discussion",
      "text": [
        "The model perplexities as reported above may be somewhat different if the \"talk spurt\" were replaced by a more sociolinguistically motivated definition of \"turn\", but the ranking of models and their relative performance differences are likely to remain quite similar.",
        "On the one hand, many intertalk-spurt gaps might find themselves to be within-turn, leading to more ■ entries in the record Q than observed in the current work.",
        "This would increase the apparent frequency and duration of intervals of overlap.",
        "On the other hand, alternative definitions of turn may exclude some speech activity, such as that implementing backchannels.",
        "Since backchannels are often produced in overlap with the foreground speaker, their removal may eliminate some overlap from Q.",
        "(However, as noted in (Shriberg et al., 2001), overlap rates in multi-party conversation remain high even after the exclusion of backchannels.)",
        "Both inter-talk-spurt gap inclusion and backchannel exclusion are likely to yield systematic differences, and therefore to be exploitable by the investigated models in similar ways.",
        "Model",
        "Hard split A/B (first/second halves)",
        "Easy split C/D (odd/even frames)",
        "A+B",
        "B+A",
        "C+D",
        "D+C",
        "\"all\" \"sub\"",
        "\"all\" \"sub\"",
        "\"all\" \"sub\"",
        "\"all\" \"sub\"",
        "0MI",
        "1.0905 1.6444",
        "1.0915 1.6576 1.0978 1.7236 1.1046 1.8047",
        "1.1225 1.8395 1.1156 1.7809 1.1086 1.7950 1.1047 1.8059",
        "1.0915 1.6555",
        "1.0925 1.6695 1.0991 1.7381 1.1046 1.8050",
        "1.0991 1.7403 1.0956 1.7028",
        "1.0992 1.7398 1.1046 1.8052",
        "0EDO",
        "1.0977 1.7257",
        "1.0985 1.7323",
        "1.0977 1.7268",
        "1.0982 1.7313",
        "Model",
        "PPL",
        "APPL (%)",
        "\"all\"",
        "\"sub\"",
        "\"all\"",
        "\"sub\"",
        "0CD",
        "1.0921",
        "1.6616",
        " – ",
        " – ",
        "0MI",
        "1.1051",
        "1.8170",
        "14.1",
        "23.5",
        "0EDO (6)",
        "1.0992",
        "1.7405",
        "7.7",
        "11.9",
        "0EDO (5)",
        "1.0968",
        "1.7127",
        "5.1",
        "7.7",
        "0EDO (4)",
        "1.0953",
        "1.6947",
        "3.5",
        "5.0",
        "0EDO (3)",
        "1.1082",
        "1.8502",
        "17.5",
        "28.5",
        "The results presented may also be perturbed by modifying the way in which a (manually produced) talk spurt segmentation, with high-precision boundary time-stamps, is discretized to yield Q .",
        "Two parameters have controlled the discretization in this work: (1) the frame step Ts = 100 ms; and (2) the proportion p of Ts for which a participant must be speaking within a frame in order for that frame to be considered ■ rather than □.",
        "p = 0.5 was chosen since this posits approximately as much more speech (than in the high-precision segmentation) as it eliminates.",
        "Higher values of p would lead to more ■, leading to more overlap than observed in this work.",
        "Meanwhile, at constant p, choosing a Ts value larger than 100 ms would occasionally miss the shortest talk spurts, but it would allow the models, which are all 1st-order Markovian, to learn temporally more distant dependencies.",
        "The trade-offs between these choices are currently under investigation.",
        "From an operational, modeling perspective, it is important to recognize that the choices of the definition for \"turn\", and of the way in which segmentations are discretized, are essentially arbitrary.",
        "The investigated modeling alternatives, and the EDO model in particular, require only that the multi-participant vocal interaction record Q be binary-valued.",
        "This general applicability has been demonstrated in past work, in which the EDO model was trained on utterances for use in speech activity detection (Laskowski and Schultz, 2007), as well as in (Laskowski and Burger, 2007) where it was trained separately on talk spurts and laugh bouts, in the same data, to highlight the differences between speech and laughter deployment.",
        "Finally, it should be remembered that the EDO model is both time-independent and participant-independent.",
        "This makes it suitable for comparison of conversational genres, in much the same way as are general language models of words.",
        "Accordingly, as for language models, density estimation in future turn-taking models may be improved by considering variability across participants and in time.",
        "Participant dependence is likely to be related to speakers' social characteristics and conversational roles, while time dependence may reflect opening and closing functions, topic boundaries, and periodic turn exchange failures.",
        "In the meantime, event types such as the latter may be detectable as EDO perplexity departures, potentially recommending the model's use for localizing conversational \"hot spots\" (Wrede and Shriberg, 2003).",
        "The EDO model, and turn-taking models in general, may also find use in diagnosing turn-taking naturalness in spoken dialogue systems."
      ]
    },
    {
      "heading": "9. Conclusions",
      "text": [
        "This paper has presented a framework for quantifying the turn-taking perplexity in multi-party conversations.",
        "To begin with, it explored the consequences of modeling participants jointly by concatenating their binary speech/non-speech states into a single multi-participant vector-valued state.",
        "Analysis revealed that such models are particularly poor at generalization, even to subsequent portions of the same conversation.",
        "This is due to the size of their state space, which is factorial in the number of participants.",
        "Furthermore, because such models are both specific to the number of participants and to the order in which participant states are concatenated together, it is generally intractable to train them on material from other conversations.",
        "The only such model which may be trained on other conversations is that which completely ignores interlocutor interaction.",
        "In contrast, the Extended-Degree-of-Overlap (EDO) construction of (Laskowski and Schultz, 2007) may be trained on other conversations, regardless of their number of participants, and usefully applied to approximate the turn-taking perplexity of an oracle model.",
        "This is achieved because it models entry into and egress out of specific degrees of overlap, and completely ignores the number of participants actually present or their modeled arrangement.",
        "In this sense, the EDO model can be said to implement the qualitative findings of conversation analysis.",
        "In predicting the distribution of speech in time and across participants, it reduces the unseen data perplexity of a model which ignores interaction by 75% relative to an oracle model."
      ]
    }
  ]
}
