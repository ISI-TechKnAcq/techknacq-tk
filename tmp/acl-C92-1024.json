{
  "info": {
    "authors": [
      "Mark Hepple"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C92-1024",
    "title": "Chart Parsing Lambek Grammars: Modal Extensions and Incrementality",
    "url": "https://aclweb.org/anthology/C92-1024",
    "year": 1992
  },
  "references": [
    "acl-C90-2030",
    "acl-C90-2041",
    "acl-E91-1035",
    "acl-P89-1033",
    "acl-P91-1011"
  ],
  "sections": [
    {
      "heading": "CHART PARSING LAMBEK GRAMMARS: MODAL EXTENSIONS AND INCREMENTALITY",
      "text": []
    },
    {
      "heading": "Abstract",
      "text": [
        "This paper' describes a method for chart parsing Lam-bek grammars.",
        "The method is of particular interest in two regards.",
        "Firstly, it allows efficient processing of grammars which use necessity operators, an extension proposed for handling locality phenomena.",
        "Secondly, the method is easily adapted to allow incremental processing of Lambek grammars, a possibility that has hitherto been unavailable."
      ]
    },
    {
      "heading": "Introduction",
      "text": [
        "Categorial Grammars (CGs) consist of two components: (i) a lexicon, which assigns syntactic types (plus an associated meaning) to words, (ii) a calculus which determines the set of admitted type combinations.",
        "The set of types (T) is defined recursively in terms of a set of basic types (Ts) and a set of operators ({ \\ ,/} for standard bidirectional CG), as the smallest set such that (i) To C T, (ii) if x,y E T, then x \\ y, x/y E T.2 Intuitively, lexical types specify subcategorisation requirements of words, and requirements on constituent order.",
        "We here address a particular flexible CG, the (product-free) Lambek calculus (L: Lambek, 1958).",
        "The rules below provide a natural deduction formulation of L (Morrill et al.",
        "1990; Barry et al.",
        "1991), where dots above a type represent a proof of that type.",
        "Proofs proceed from a number of initial assumptions, consisting of individual types, some of which may be \"discharged\" as the proof is constructed.",
        "Each type in a proof is associated with a lambda expression, corresponding to its meaning.",
        "The elimination rule /E states that proofs of A/B and B may be combined to construct a proof of A.",
        "The introduction rule /1 indicates that we may discharge an assumption B within a proof of A to construct a proof of A/B (square brackets indicating the assumption's discharge).",
        "There is a side condition on the introduction rules, reflecting the ordering significance of the directional slashes.",
        "For /I (reap.",
        "\\I), the assumption discharged must be the rightmost (reap.",
        "leftmost) undischarged assumption in the proof.",
        "Elimination and introduction inferences correspond semantically to steps of functional application and abstraction, respectively.",
        "Each proof demonstrates the possibility of combining the types of its undischarged assumptions, in their given order, to yield the type at the bottom of the proof.",
        "The following proof of \"simple forward compo-sition\" illustrates the approach.",
        "Following Prawitz (1965), a normal form (NF) for proofs can be defined using the following meaning preserving contraction rule and its mirror image dual with \\ in place of /, which, under a version of the Curry-Howard correspondence between proofs and lambda terms, are analogous to the fl-contraction rule ((as.P)Q to P[Q/x]) for lambda expressions.",
        "Under this system, every L proof has an equivalent 'fl-NF' proof.",
        "Such fl-NF proofs have a straightforward structural characterisation, that their main branch (the unique path from the proof's end-type to an assumption, that includes no types forming the argument for an elimination step) consists of a sequence of (> 0) eliminations followed by a sequence of (> 0) introductions.",
        "The main approach for parsing L has been sequent calculus theorem proving.3 Used naively, this approach is inefficient due to 'spurious ambiguity', i.e. the existence of multiple equivalent proofs for combinations, KOnig (1989) and Ilepple (1990a) develop a solution to this problem based on defining a NF for Sequent proofs.",
        "These NF systems as yet cover only the basic calculus, and do not extend to various additions proposed to overcome the basic system's shortcomings as a grammatical framework.",
        "Some importance has been attached to the properties of flexible CGs in respect of incremental proct%sing.",
        "These grammars typically allow sentences to be given analyses which are either fully or primarily left-branching, in which many sentence-initial substrings are interpretable constituents, providing for processing in which the interpretation of a sentence is generated 'on-line' as the sentence in presented.",
        "incrementality is characteristic of human sentence processing, and might also allow more efficient machine processing of language, by allowing early filtering of semantically implausible analyses.",
        "It is notable, however, that us methods have yet been proposed for incremental parsing of Lambek grammars.",
        "In what follows, 1 describe a chart method for L and then show how it may be modified to allow both inclusion of an operator ❑, used for handling locality constraints, and also to allow incremental parsing of L."
      ]
    },
    {
      "heading": "Chart Parsing Lambek Grammars",
      "text": [
        "Standard chart methods are inadequate for L because proving that some combination of types is possible may involve `hypothetical reasoning', i.e. using additional assumptions over and above just the types that are being combined.",
        "For example, the above proof of a/b, b/c a/c requires an additional assumption c, subsequently discharged.",
        "Standard chart parsing involves ordering the edges for lexical categories along a single dimension, and then adding edges for constituents that span wider substretches of this dimension as constituents are combined.",
        "The problem for L is that there is no place in this set up for additional hypothetical elements.",
        "Placing edges for them anywhere on the single dimension of a normal chart would simply be incorrect.",
        "Kiinig (1990, 1991), in the only previous chart method for L, handles this problem by placing hypo• thetical elements on separate, independently ordered `minicharts', which are created (`emitted') in response to the presence of edges that bear `higher order' functor types (i.e. seeking arguments having functional types), which may require 'hypothetical reasoning' in the derivation of their argument.",
        "Minicharts may `at-tach' themselves into other charts (including other minicharts) at points where combinations are possible, so that `chains of attachment' may arise.",
        "SODS!"
      ]
    },
    {
      "heading": "3 Space limits preclude discussion of recent proof net work.",
      "text": [
        "fairly complicated bookkeeping is required to keep track of what has combined with what as a basis for ensuring correct `discharge.'",
        "of hypothetical elements.",
        "This information is encoded into edges by replacing the simple indices (or vertices) of standard charts with 'complex indices'.",
        "Unfortunately, the complexity of this method precludes a proper exposition here.",
        "However, some differences between KOnig's method and the method to be proposed will be mentioned at the end of the next section."
      ]
    },
    {
      "heading": "A New Chart Approach",
      "text": [
        "I next present a new chart parsing method for L. Its most striking difference to the standard approach is that there is typically more than one ordering governing the association of edges in a chart.",
        "These orderings intersect and overlap, making a chart a `multidimensional object'.",
        "A second difference is that the basic unit we adopt for specifying the orderings of the chart is primitive intervals, rather than point-like vertices, where the relative order of the primitive intervals that make up an ordering must be explicitly defined.",
        "The alma of edges is specified extensionally as the concatenated sum of sonic number of primitive intervals.",
        "The method is perhaps most easily explained by example.",
        "To parse the combination x/y, y/z, x, we require a three element ordering ordaring(a.b.c ) (a h and c being primitive intervals).",
        "The three types give three edges, each having Ulm; fields: (i) the edge's span (here a primitive interval), (ii) its type (iii) the type's 'meaning' (here a unique constant).",
        "La, a/y, fb, yia, t21 Lc, a, tail Edges are combined under the following chart rules, corresponding to our elimination rules: if X/Y, A] and fj, Y, Ii] and isa_aahord(X-i) then IA.",
        "], X, (All)] Y, 13] and [j X\\Y, Al said ita_nabord (I j) than fi.",
        ", X, (AO] The rules allow two edges with appropriate types to combine provided that the concatenation of their spans is a substring of some defined ordering (a test made by the predicate iga_nubord).",
        "Given these rules, our chart will expand to include the following two edges.",
        "The presence of an edge with type x that spans the full width of the single defined ordering shows that x/y, y/z, x can be derived.",
        "fb.c, y, (t2 t3)] La.b.c, a, (ti t3))] Acres DE COLING-92, NANti,.s, 23-28 AoM 1992 I.",
        "3 5 PROC.",
        "OF COLING-92, NAN I FS, AUG. 23-28, 1992 essit(CH,T,J): if T = WYM31/F1....\\13n/Fm).",
        "then (add_edges: [i1,131,v1].",
        "Cin,Bn,vnl , Cjm,Fmona] , , add_condition: if ordering(P.H.Q.R) and non_empty(Q) then ordering(il...in.Q.jm..,j1) add_condition: if [(i1...in.X.ja...j1),Y,S] and isa_subord(H.K) then CIS, (Y\\B1/11....\\Bn/Fm), (vmOvne....w10v10S)]) else if T X\\(Y\\B1/F1....\\Bn/Fm), then (add_edges: Ci1,B1,v1], , Cin,Bn,vn] , [ps,Faione] , , [ji,F1,wi] add_condition:",
        "Our next example x/(y \\p/q), y/z \\p, z/q x requires 'hypothetical reasoning' in its derivation, which is made possible by the presence of the higher-order functor x/(y \\p/q).",
        "In the natural deduction approach, deriving the functor's argument y \\p/q might involve introduction inference steps which discharge additional assumptions p and q occurring peripherally within the relevant subproof.",
        "To chart parse the same example, we require firstly the following three edges and require a three element ordering:",
        "As in Konig's approach, an 'emit' step is performed on the edge which bears a higher-order type, giving various additions to the chart needed to allow for hypothetical reasoning.",
        "Firstly, this gives two new edges, which are assigned new primitive intervals: Cd, p, vi] Ca, q, v2] Some new orderings must be defined to allow these edges to combine.",
        "Since the higher-order functor is forward directional, possible arguments for it must occupy non-empty intervals H such that isa_subord( a .H) .",
        "Hypothetical reasoning with the two new edges is useful only in so far as it contributes to deriving edges that occupy these spans.",
        "Hence, the required new orderings are (d.11.",
        "e) such that iaa_aubord(a.B).",
        "Such new orderings are most conveniently created by including the following condition on orderings.",
        "if ordering(P .",
        "a .",
        "Q .11) and non_empty(Q) then ordering(d .Q . )",
        "In general, such conditions may fire after the emit step that creates the condition, when other new orderings are created that include the emitting edge's span.",
        "The above condition causes new orderings (d.b.•) and (d.b.",
        "c.e) to be defined, allowing combinations that yield the following edges: Cd.b, y/z, (t2 v1)] Cc.e, z, (t3 v2)] Cd.b.c.e, Y.",
        "((t2 v1)(t3 v2))] The final thing created by the emit process is the following condition on edges (where LOB represents lambda abstraction over A in B): if Cd .0. a , y, S] and iaa_subord(a.",
        "0) then [0, y \\p/q, v2evilOS] This condition has the effect that whenever an edge of a certain form is added to the chart, another edge of a related form is also added.",
        "The condition completes the process of hypothetical reasoning, by syntactically and semantically abstracting over the hypothetical elements (`discharging' them) to derive the function required as argument by the higher order functor.",
        "Note that, since the intervals d and a are unique to the two edges created in the emit process, any edge spanning an interval (d .",
        "O. e) must have involved these two edges in its derivation.",
        "The condition 'fires' on the above edge spanning (d.b.c.",
        "e) to give the first of the following edges, which by combination gives the second.",
        "This final edge demonstrates the derivability of original goal combination.",
        "Cb.e, y\\p/q, v20v10((t2 v1)(t3 v2))].",
        "Ca.b.c, x, (t1 v20v10((t2 v1)(t3 v2)))].",
        "We have now seen all the basic ingredients required for handling hypothetical reasoning in the new approach.",
        "Figure 1. shows a general (if still somewhat informal) statement of the emit procedure which is called on every edge added to the chart, but which only has an effect when an edge bears a higher-order type.",
        "The specific consequences depend on the functor's directionality.",
        "The notation (Y \\ Bi/Fi • \\ Bn/Fm) stands for a functional type requiring n backward directional arguments Bi and m forward directional arguments Fl.",
        "....Fm in any order.'",
        "In each case, the procedure simply adds an edge for each required hypothetical element, a condition on orders (to create all required new orderings), and a condition on edges, which fires to produce an edge for the result of hypothetical reasoning, should it succeed.",
        "Note that edges produced by such conditions are there only to be argument to some higher order functor, and allowing them combine with other edges as fancier would be unnecessary work.",
        "I assume that such edges are marked, and that some mechanism operates to block such combinations,5 A slightly modified emit procedure is required to allow for deriving overall combinations that have a functional result type.",
        "I will not give a full statement of this procedure, but merely illustrate it.",
        "For example, in proving a combination r y \\ p/q, where an ordering Q had been defined for the edges of the types I', emitting the result type y \\ p/q would give only a single new ordering (not a condition on orderings), a condition on edges, and two new edges for the hypothetical elements as follows: ordering(a.Q.b) if Ca.Q.b, y, Sl then [Q. y\\p/q, v2e(viCS)] [a, p, [b, q, v2] That completes description of the new chart method for L. A few final comments.",
        "Although the method has been described for proving type combinations, it can also be used for parsing word strings, since lexical ambiguity presents no problems.",
        "Note that defining a new ordering may enable certain combinations of edges already present in the chart that were not previously allowed.",
        "However, simply checking for all edge combinations that the new ordering allows will result in many previous combinations being redone, since new orderings always share some suborderings with previously defined orderings.",
        "One way to avoid this problem is to only check for combinations allowed by substrings of the new ordering that were not previously suborderings.",
        "Concerning the soundness of this method, note that chart derivations can be easily translated into (correct) natural deduction proofs, given a knowledge of 'This notation is rather clumsy in that it appears to suggest the presence of at least one forward and one backward directional orpiment and also a relative ordering of these arguments, when neither of these implications is intended.",
        "A similar point can be made about abstractions in the schematic semantics insavne ....•10v1.113, whose order and number will in fact mirror that of the corresponding syntactic arguments.",
        "A more satisfactory statement of the emit procedure could be made recursively, but this would take up too much space.",
        "5 An alternative would be not entering such edges at all, but instead have a condition on edges that creates an edge for the result of combining the emitting higher-order functor with its implicitly derived argument, directly.",
        "which edges gave rise to which others, i.e. with binary edge combinations corresponding to elimination inferences, and with the creation of an edge by a condition on edges corresponding to some sequence of introduction inferences.",
        "In fact, chart derivations all translate to 13-NF proofs, i.e. with introductions always made after any eliminations on the main branch of any subproof.",
        "This observation provides at least an informal indication of the completeness of the method, since the mechanisms described should allow for chart derivations corresponding to all possible /3-NI, proofs of a given combination, which (as we noted earlier) are fully representative.",
        "Another issue is whether the method is minimal in the sense of allowing only a single chart derivation for each reading of a combination.",
        "This is not so, given that distinct but equivalent 1.1-NF proofs of a combination are possible, due to a second source of equivalence for proofs analogous to ry-equivalence of lambda expressions (i.e. that f As.",
        "f x).",
        "For example, the combination a/(b/c), b/c a has two /3-NP proofs, one involving 'unnecessary' hypothetical reasoning.",
        "However, having equivalent edges represented on the chart, and the undesirable consequences for subsequence derivations, can be avoided by a simple identity check on edge addition, provided that the meaning terms of edges produced by conditions on edges are subject to ry-normalisation.",
        "I will finish with some comparisons of the method to that of lainig (1990, 1991).",
        "The importance of Klinig's method as precursor for the new method cannot be overstated.",
        "However, the new approach is, I believe, conceptually much simpler than Kiinig's.",
        "This is largely due to the use of 'conditions on edges' in the new approach to handle discharge of hypothetical de-ments, which allows edges to be much simpler objects than in Kiinig's approach, where edges instead have to encode the potentially complex information required to allow proper discharge in their 'complex indices'.",
        "The complex nature of Kiinig's edges considerably obscures the nature of parsing as being simply reasoning about sequences of types, and also makes it difficult to see how the rnethod might be adapted to allow for extensions of L involving additional operators, even ones that have straightforward sequent rules.",
        "A second difference of the new method is that orderings that govern the association of edges are explicitly defined.",
        "There is a sense in which the multiple intersecting orderings of the new approach can be seen to express the dimensions of the search space addressed in sequent calculus theorem proving, although.",
        "collapsing together the parts of that search space that have common structure.",
        "In Kiiirrig's method, although the elements that belong together in a minichart are relatively ordered, the attachment of one minichart to another is allowed wherever relevant edges can combine (although subject to some constraints preventing infinite looping).",
        "This means that elements may be combined that would not be in sequent calculus theorem proving or in the new chart method.",
        "The consequences of this difference for the relative complexity of the two chart methods is at present unknown."
      ]
    },
    {
      "heading": "Parsing Modal Extensions",
      "text": [
        "Various extensions of the basic Lambek calculus have been proposed to overcome some of its limitations as a grammatical approach.",
        "Morrill (1989, 1990) suggests a unary operator 0, for handling locality constraints on binding and reflexivisation.",
        "This has the following inference rules, which make it behave somewhat like necessity in the modal logic S4: OA A where every undischarged – OE – 01 assumption is a 0-type A OA I will try to briefly suggest how 0 may help in handling locality constraints.",
        "Boundaries arise where lexical functors seek a modal argument, i.e. are of the form x/Ily, the presence of the 0 making the argument phrase potentially a bounded domain.",
        "In addition, all lexical types are of the form Ox, i.e. have a single [3 as their outermost operator, which allows them to appear embedded within modal domains (c.f.",
        "the 01 rule's requirement of 0-ed assumptions).",
        "For example, a lexical NP might be Onp, a transitive verb 0(s\\np/np), and a sentence-complement verb like believes type 0(s \\ np/Os).",
        "In a standard flexible CG treatment, extraction is handled by functional abstraction over the position of the missing (i.e. extracted) element.",
        "The type of the abstracted element is determined by the type of the higher order lexical type that requires this abstraction, e.g. the relative pronoun type rel/(s/np) abstracts over np.",
        "Note that this relative pronoun type cannot extract out of an embedded modal domain, because it abstracts over a bare (i.e. non-modal) np, whose presence would block Oi rule's use in deriving the overall modal constituent.",
        "However, a relative pronoun rel/(s/0np), which abstracts over a modal type Onp, can extract out of an embedded modal domain.",
        "Including this operator presents considerable problems for efficient processing.",
        "Firstly, it excludes the use of the NF systems devised for the calculus (KOnig, 1989; Hepple, 1990a).",
        "As noted above, spurious ambiguity makes ordinary (i.e. non-normal form) sequent theorem proving of L inefficient.",
        "This problem is greatly increased by inclusion of 0, largely due to non-determinism for use of the OE rule.'",
        "'Consider a sequent S = Oxt,C1x2 Oxn xo, where the related sequent xi,x2 ,,,,, xn xo is a theorem.",
        "Non-determinism for use of means that there are n!",
        "different paths of inference from S to S', so that there are at least n!",
        "proofs of S for each proof of 5'.",
        "In fact, interaction of (OL1 with other inference rules means that there is typically many more proofs than this.",
        "The new chart method is fairly easily adapted to allow for 0, avoiding the non-determinism problem of the sequent system, so that parsing examples with 0 is typically only slightly slower than parsing related examples without any Os.",
        "Firstly, it is crucial that we can always identify the parent edge(s) for some edge (i.e. the immediate edge(s) from which it is derived), and thereby an edge's more distant ancestors.",
        "I ignore here the precise details of how this is done.",
        "The following chart rule serves in place of the DE rule: if DI, A] then Ci, For the combination x/0y, 0(y/z), Oz x, we would require the following ordering and first three edges.",
        "The next three edges then result from the operation of chart rules:",
        "To allow completion, we must extend the emit procedure to also take action in cases where the type of an added edge seeks a modal argument.",
        "For the case at hand, the emit procedure would create a condition on edges as follows: if [H, y, and isa_aubord(a.H) and check_modal_hiatory(CH, y, S]) then CH, []y, S] The procedure check_modal_history used by this condition checks the edge's 'history' to see if it has appropriate ancestors to license the 0-introduction step.",
        "Recall that the 01 rule requires that the undischarged assumptions of the proof to which it applies are all 0 types.",
        "The corresponding requirement for the chart system is that the edge must have ancestors with El-types that together span the full width of the edge's span H (i.e. there must be a subset of the edge's ancestor edges that have 0-types, and whose spans concatenate to give H).",
        "The edge ((b. t) .",
        "y, (t2 t3)] satisfies this requirement, and so the condition will fire, allowing the parse to proceed to successful completion, as follows:",
        "More complicated cases arise when an emitted functor seeks an argument type that is both functional and modal.",
        "As suggested above, a satisfactory statement of the emit process is best given recursively, but there is not sufficient space here.",
        "Hopefully, an example will adequately illustrate the method.",
        "Consider what is required in emitting an edge Ca, w/ ( (x \\ y)/z), t 1], whose type seeks an argument (0(x\\y)/z, i.e. a function to a modal form of a further functional type.",
        "As before, emitting creates two new edges and a single condition on orderings: [1, y, vi] [j, z, v2] if ordering(P.a.Q.R) and non_empty(Q) then ordering(i.Q.j) However, recursive decomposition of the type ((:3(x \\y)/z) gives rise to three separate conditions on edges (which reflect the three aspects of the description of this type as a 'function to a modal form of a further functional type'):",
        "These three conditions 'chain' together to create edges with the type required by the emitted functor.",
        "Of course in practice, the three conditions could be collapsed into a single condition, and such a move seems sensible from the viewpoint of efficiency."
      ]
    },
    {
      "heading": "Incremental Parsing",
      "text": [
        "Despite considerable interest in the theoretical possibility of incremental processing using the Lambek calculus, no incremental parsing methods have as yet been proposed.",
        "Indeed, most Lambek parsing work has been based around sequent theorem proving, which might be viewed as antithetical to incremental processing since it fundamentally involves reasoning about complete sequences of types.",
        "In fact it is fairly easy to modify the chart method to allow some extent of incremental processing, i.e. so that scanning left-to-right through an input string (or type sequence), the chart will contain edges assigning types to substrings that would not otherwise receive types during parsing, including some for initial substrings of the input.",
        "The modification of the chart method involves allowing an additional extent of hypothetical reasoning over that so far allowed, so that edges for hypothetical types are added not only for higher-order functors, but also for first-order functors.",
        "This is allowe by a new procedure emits, described below.",
        "emits is called on every edge added to the chart, but only has an effect if the edge's type is functional, creating a new edge for a hypothetical type corresponding to the function's first argument, as well as a condition on orderings and one on edges.",
        "The condition on orderings creates new orderings allowing the hypothetical edge to combine with its 'emittor', and the result of that combination to be combined with further edges.",
        "(The requirement J \\= i.1( prevents the condition incorrectly reapplying to its own output.)",
        "Note that the new edge's interval is peripheral in the new orderings that are defined since it is only in peripheral position that the new hypothesis can be discharged (hence, we have (G.H.i) in the condition of the first case rather than (G.H.i.J)).",
        "Such discharge is made by the new condition on edges.",
        "emit*([H,T,_]): it T = x/Y then add_edge: [i, Y, v] add_condition: if ordering(G.H.J) then ordering(G.H.i) add_condition: if [(Q.i),Z,S] and non_empty(Q) then [Q,Z/Y,vOS] else if T = K\\Y then add_edge: Y, v] add_ condition : if ordering(G.H.3) and G \\= K.1 then ordering(i.H.3) add_condition: if [(i.Q),Z,S] and non_empty(Q) then [Q,Z\\Y,v0S] Let us look at some examples (where we limit our attention to just edges relevant to the discussion).",
        "Consider parsing the type sequence (x/y, y/z, z).",
        "Since the method should not depend on the parser knowing the length of the input sequence in advance, an ordering will be defined with each scanning step that covers just the material so far scanned, and which extends the ordering of the previous scanning step by one.",
        "After scanning the first two types of the input, the chart will include at least the following two edges and ordering: ordering(a.b) [a, x/y, ti] [b, y/z, t2] Applying emit* to the second edge (ignoring the first edge here) yields the following edge and conditions: [i, z, v] if ordering(G.b.J) and J \\ i.K then ordering(G.b.i) if Cal .i.",
        "),T,S] and non_empty(Q) then [Q,T/z,vOS] The condition on orderings will fire on the ordering (a.b) to produce a new ordering (a. b .",
        "i), which permits the first two of the following edges to be built, the third being generated from the second by the condition on edges.",
        "The type x/z this edge assigns to the initial substring (x/y, y/z) of the input (corresponding to the composition of the two functions) would not have been created during parsing with other Lambek parsing methods.",
        "[(b.i), y, (t2 v)] [(a.b.i), x, (ti (t2 v))] [(a.b), x/z, vc(ti (t2 v))] and J \\= i.K As a second example, consider the stage of having scanned the first two types of the input sequence (y, x \\ y/z, z).",
        "Scanning yields the following ordering and the first two edges.",
        "Applying emits to the second edge yields the third edge, and two conditions: ordering(a.b) Ca, 'ay, ti] [b, t2] [l., z, sr] if ordering (G b J) and J .K then ordering (0 b i) ii [(q.i).r,s] and non_smpty(q) then RI, T/m,v05] The ordering condition gives the following new ordering, allowing creation of the subsequent new edges.",
        "As before, the last edge assigns a type to the combination of the first two input types which would not otherwise be expected during parsing.",
        "ordering (a .",
        "b .",
        "i) Ub.",
        "i), \\y, (t2 v)7 [(a.b.1), x, ((t2 v) ti)] [(a.b), x/z, v0((t2 v) ti)] Although the method allows for a considerable degree of incrementality, some conceivable incremental constituents will not be created that would be in parsing with alternative categorial frameworks.",
        "For example, rules of type raising and composition in Combinatory Categorial Grammar (Steedman, 1987; Szabolcai, 1987) would allow incremental combination of types vp/s, np vp/(s\\np), not allowed by the present approach.",
        "The modified chart method instead allows for the construction of incremental constituents in a manner that most closely relates to the notion of dependency constituency argued for by Barry 1.c Pickering (1990) (see also Hepple, 1991), although since the modified parser is still a complete parser for L it cannot be viewed as implementing a notion of dependency constituency.7 Finally, it should be noted that the additional hypothetical reasoning allowed by emits and combinations involving additional 'incremental constituents' result in many 'spurious' analyses, so that the incremental chart method is in general slower than the non-incremental chart method."
      ]
    },
    {
      "heading": "Conclusion",
      "text": [
        "I have presented a chart parsing method for the Lambek calculus, which I would argue has several advantages over that of Konig (1990, 1991).",
        "Firstly, I believe that it is considerably conceptually clearer than Konig's method, and more straightforwardly reflects intuitions about the nature of hypothetical reasoning 'However, some version of a chart parser that used only the kind of hypothetical reasoning allowed by the snits procedure, and not that of the suit procedure, might well implement a notion of dependency constituency.",
        "in proving L combinations.",
        "Secondly, the relatively straightforward nature of the system with respect to reasoning about sequences of types should, I believe, make it easier to adapt the method to allow for additional type-forming operators over those already provided in the (product-free) Lambek calculus, particularly where operators have fairly straightforward Sequent rules.",
        "We have seen how the method can be extended to allow for Morrill's Doperator.",
        "We have also seen how the method may be modified to allow incremental parsing of Lambek grammars."
      ]
    }
  ]
}
