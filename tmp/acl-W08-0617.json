{
  "info": {
    "authors": [
      "Deyu Zhou",
      "Yulan He"
    ],
    "book": "Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing",
    "id": "acl-W08-0617",
    "title": "Extracting Protein-Protein Interaction based on Discriminative Training of the Hidden Vector State Model",
    "url": "https://aclweb.org/anthology/W08-0617",
    "year": 2008
  },
  "references": [
    "acl-W02-1002"
  ],
  "sections": [
    {
      "text": [
        "Extracting Protein-Protein Interaction based on Discriminative Training of",
        "the Hidden Vector State Model",
        "Deyu Zhou and Yulan He",
        "1 Introduction",
        "The knowledge about gene clusters and protein interactions is important for biological researchers to unveil the mechanism of life.",
        "However, large quantity of the knowledge often hides in the literature, such as journal articles, reports, books and so on.",
        "Many approaches focusing on extracting information from unstructured text, such as pattern matching, shallow and deep parsing, have been proposed especially for extracting protein-protein interactions (Zhou and He, 2008).",
        "A semantic parser based on the Hidden Vector State (HVS) model for extracting protein-protein interactions is presented in (Zhou et al., 2008).",
        "The HVS model is an extension of the basic discrete Markov model in which context is encoded as a stack-oriented state vector.",
        "Maximum Likelihood estimation (MLE) is used to derive the parameters of the HVS model.",
        "In this paper, we propose a discriminative approach based on parse error measure to train the HVS model.",
        "To adjust the HVS model to achieve minimum parse error rate, the generalized probabilistic descent (GPD) algorithm (Kuo et al., 2002) is used.",
        "Experiments have been conducted on the GENIA corpus.",
        "The results demonstrate modest improvements when the discriminatively trained HVS model outperforms its MLE trained counterpart by 2.5% in F-measure on the GENIA corpus."
      ]
    },
    {
      "heading": "2. Methodologies",
      "text": [
        "The Hidden Vector State (HVS) model (He and Young, 2005) is a discrete Hidden Markov Model (HMM) in which each HMM state represents the state of a push-down automaton with a finite stack size.",
        "Normally, MLE is used for generative probability model training in which only the correct model needs to be updated during training.",
        "It is believed that improvement can be achieved by training the generative model based on a discriminative optimization criteria (Klein and Manning, 2002) in which the training procedure is designed to maximize the conditional probability of the parses given the sentences in the training corpus.",
        "That is, not only the likelihood for the correct model should be increased but also the likelihood for the incorrect models should be decreased.",
        "Assuming the most likely semantic parse tree",
        "C = Cj and there are altogether M semantic parse hypotheses for a particular sentence W, a parse error measure (Juang et al., 1993; Chou et al., 1993; Chen and Soong, 1994) can be defined as",
        "where r is a positive number and is used to select competing semantic parses.",
        "When rj = 1, the competing semantic parse term is the average of all the competing semantic parse scores.",
        "When rj – to, the competing semantic parse term becomes max P(W, Ci) which is the score for the top competing semantic parse.",
        "By varying the value of j , we can take all the competing semantic parses into consideration.",
        "d(W) > 0 implies classification error and d(W) < 0 implies correct decision.",
        "The sigmoid function can be used to normalize d(W) in a smooth zero-one range and the loss function is thus defined as (Juang et al., 1993):",
        "Here, 7 is a constant which controls the slope of the sigmoid function.",
        "The update formula is given by:",
        "where ek is the step size.",
        "Using the definition of £(Wi, Xk) and after working out the mathematics, we get the update formu-lae5,6, 7,",
        "where I(Ci,n, c') denotes the number of times the operation of popping up n semantic tags at the current vector state c' in the Ci parse tree, I (Ci, c[1],c[2..D}) denotes the number of times the operation of pushing the semantic tag c[1] at the current vector state c[2..D] in the Ci parse tree and I(Ci, w, c) denotes the number of times of emitting the word w at the state c in the parse tree Ci."
      ]
    },
    {
      "heading": "3. Experimental Setup and Results",
      "text": [
        "GENIA (Kim et al., 2003) is a collection of 2000 research abstracts selected from the search results of MEDLINE database using keywords (MESH terms) \"human, blood cells and transcription factors\".",
        "All these abstracts were then split into sentences and those containing more than two protein names and at least one interaction keyword were kept.",
        "Altogether 3533 sentences were left and 2500 sentences were sampled to build our data set.",
        "The results using MLE and discriminative training are listed in Table 1.",
        "Discriminative training improves on the MLE by relatively 2.5% where N and I are set to 5 and 200 individually.",
        "Here N denotes the number of semantic parse hypotheses and I denotes the the number of sentences in the training data.",
        "Measurement",
        "GENIA",
        "MLE",
        "Discriminative",
        "Recall",
        "61.78%",
        "64.59%",
        "Precision",
        "61.16%",
        "61.51%",
        "F-measure",
        "61.47%",
        "63.01%"
      ]
    }
  ]
}
