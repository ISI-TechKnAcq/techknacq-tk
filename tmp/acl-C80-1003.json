{
  "info": {
    "authors": [
      "Toru Hitaka",
      "Sho Yoshida"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C80-1003",
    "title": "A Syntax Parser Based on the Case Dependency Grammar and Its Efficiency",
    "url": "https://aclweb.org/anthology/C80-1003",
    "year": 1980
  },
  "references": [],
  "sections": [
    {
      "heading": "A SYNTAX PARSER BASED ON THE CASE DEPENDENCY GRAMMAR AND ITS EFFICIENCY",
      "text": [
        "Toru Hitaka and Sho Yoshida Department of Electronics, Kyushu University, Fukuoka, Japan SUMMARY Augumented transition network grammars (ATNGs) or augumented context-free grammars are generally used in natural language processing systems.",
        "The advantages of ATNGs may be summarized as 1) efficiency of representation, 2) perspicuity, 3) generative power, and the disadvantage of ATNGs is that it is difficult to get an efficient parsing algorithm becuase of the flexibility of their complicated additional functions.",
        "In this paper, the syntax of Japanese sentences , based on case dependency relations are stated first, and then we give an bottom-up and breadth-first parsing algorithm which parses input sentence using time 0(n3) and memory space 0(n2), where n is the length of input sentence.",
        "Moreover, it is shown that this parser requires time 0(n2), whenever each B-phrase in input sentence is unambiguous in its grammatical structure.",
        "Therefore, the efficiency of this parser is nearly equal to the Earley's parser which is the most efficient parsing method for general context-free grammars."
      ]
    },
    {
      "heading": "1. FUNDAMENTALS OF JAPANESE SENTENCE",
      "text": [
        "The Japanese sentence is ordinarily written in kana (phonetic) letters and kanji (ideographic) characters without leaving a space between words.",
        "From the viewpoint of machine processing, however, it is necessary to express clearly the units composing the sentence in such a way as to leave a space between every word as in English.",
        "We have no standard way of spacing the units though the need for this has been demanded for a long time.",
        "We give some examples in Figure 1.",
        "The first sentence in the figure is of ordinary written form.",
        "The second indicates a way of spacing (i.e. putting a space between every word).",
        "The third indicates another way of spacing (i.e. putting a space between every B-phrase).",
        "Nowadays, many other spacing methods have been tried in several institutes in Japan.",
        "In this paper, input sentences are given in colloquial style in which a spacing symbol is placed between two successive B-phrases.",
        "In Japanese sentences, BUNSETSUs(Bphrase) are the minimal morphological units of case dependency, and the syntax of Japanese sentences consists of (1) the syntax of B-phrase as a string of words, and (2) the syntax of a sentence as a string of B-phrases.",
        "A B-phrase usually pronounced without pausing consists of two.",
        "parts -- main part [or equally an independent part in the conventional school grammatical term] and an annex part which is post positioned.",
        "We denote the connection of two parts in a B-phrase by a dot if necessary.",
        "A main part, which is a conceptual word [or equally an independent word] (e.g. noun, verb, adjective or adverb) provides mainly the information of the concept.",
        "On the other hand, an annex part, a possibly null string of suffix words (e.g. auxiliary verbs or particles) provides the information concerning the kakariuke relation and/or the supplementary information (e.g. the speaker's attitude towards the contents of the sentence, tense, etc.)",
        "A word w has it's spelling W, part of speech H and inflexion K. We call (W,H,K) the word structure of w. Suppose that a string b of length n be a B-phrase.",
        "Then, there exist an independent word wo and suffix words wl, W2, *** sal, and",
        "where (Wi,Hi,Ki) is the word structure of wi Cont(Hk,Kk,Hk+l) means a word whose part of speech and inflexion are Hk, Kk respectively can be followed by a word whose part of speech is Hk+lin",
        "B-phrases and Termi(119,,K0 means a word whose part of speech and inflexion are Hit, KR, respectively can be a rightmost subword of B-phrases.",
        "(1),(2) are called the rules of B-phrase structure, and",
        "is called B-phrase structure of b.",
        "If (3) satisfies the condition (1), wowiw2 – wR, is called to be a left partial B-phrase.",
        "The kakariuke relation is the dependency relation between two B-phrases in a sentence.",
        "A B-phrase has the syntactic functions of governor and dependent.",
        "The function of governor is mainly represented by the independent word of B-phrase.",
        "The function of dependent is mainly represented by the string of particles which is the rightmost substring of B-phrase and by the word in front of it (right-most non-particle word).",
        "Every particle has the syntactic and partially semantic dependent function with its own degree of power.",
        "The particle whose power of dependent function is strongest of all particles appearing in the string of particles is called the representative particle.",
        "Therefore, the syntactic function of dependent of a B-phrase is mainly represented by the representative particle and by the rightmost non-particle word.",
        "Let (W0,1-10,K0),(Wi,Hi,Ki),(W1,H,,Kj) be the word structures of independent word, rightmost non-particle word and representative particle of a B-phrase, respectively.",
        "Then, <W0,H0>, <Wi,Hi, Hj>d are called the information of governor and the information of dependent of the B-phrase respectively, and the pair (<W„1-0>a,<Wi,Hi,Hj>d) is called dependency information of the B-phrase.",
        "There are many types of dependency relation such as agent, patient, instrument, location, time, etc.",
        "Let C be the set of all types of dependency relation.",
        "The set of all possible dependency relations from a B-phrase bl to a B-phrase b2 is founded on the information of dependent of b1 and the information of governor of b2.",
        "Therefore, there is a function 6 which computes the set of all possible dependency relations 6(a,6) between a B-phrase of dependency information a and another B-phrase of dependency information S. The function 6 is realized by the dependency dictionary retrieved with the key of two dependency informations.",
        "The order of B-phrase is relatively free in a simple sentence, except for one constraint that the predicative B-phrase governing the whole sentence must be in the sentence's final position.",
        "Japanese is a post positional in this sense.",
        "The pattern of the dependency relations in a sentence has some structural property which is called the rules of dependency structure, and the dependency relations in a sentence are called the dependency structure of a sentence.",
        "The dependency structure of a sentence is shown in figure 2, where arrows indicate dependency relations of various types.",
        "The rules of dependency structure consist of following three conditions.",
        "i Each B-phrase except one at the sentence final is a dependent of exactly one B-phrase appearing after it.",
        "ii A dependency relation between any two B-phrases does not cross with another dependency relations in a sentence.",
        "iii No two dependency relations depending on the same governor are the same.",
        "Let N be the number of B-phrases in a input sentence, and all B-phrases are numbered descendingly from right to left (see figure 2).",
        "We shall fix an input sentence, throughout this chapter.",
        "Let DI(i) be the set of all dependency informations of i-th B-phrase.",
        "Definition: A dependency file DF of a sentence is a finite set of 5-tuples.",
        "Definition: If a subset of DF satisfies following conditions 1) to 5), it is called a dependency structure from the 11-th B-phrase to the m-th B-phrase (NN2>mN1) and denoted by DS(1,m) or DS1(k,m).",
        "1) If (i,j,ai,aj,c)E DS(k,m), then RNi>jm.",
        "2) For arbitrary i(9,Ni>m), there exists unique j,ai,aj,c such that (i,j,ai,aj,c) E DS(Z,m).",
        "(Uniqueness of Dependent) 3) ,If (i,j,ai,aj,c) DS(9,,m) and (j,k,aj,ak,e) r DS(R,,m), then aj (Uniqueness of B-phrase structure) 4), If (i,j,ai,al,c) DS(k,m), (1 ,j,ai!",
        ",a ,c )6 bS(R,m) and i>i'>j, then j'j.",
        "(Nest Structure of Dependency)",
        "5) If (i,j,cti,ct•,c) E DS(32,m), (ii,j,aif ,ai,c1) e ng(9,,m) and i then c (Inhibition of Duplication of a Case) The set of all dependency structures from k-th B-phrase to m-th B-phrase is denoted by :pk,m).",
        "Any DS(N,1)E 7(N,1) is called a dependency structure of the input sentence.",
        "The dependency information of j-th B-phrase is unique in DS(k,m), since 2) and 3) hold.",
        "Let iDIDS(k.m) and jGDS(R,m) be the dependency information of the j-th B-phrase in DS(k,m) and thset of all the dependency relations that the j-th B-phrase governs in DS(Z,m), respectively.",
        "Definition: If the k-th B-phrase (kNkNm) in DS(k,m) has the following property, k(the k-th B-phrase) is called a joint of DS(k,m): For any (it raj sai ,C) EDS ( .k,m) , kNi or jk.",
        "Let jo(=k) >j1 >j1 > ...> jp(=m) be the descending sequence of all the joints of DS(k,m) (see figure 2).",
        "Then, the jk-th B-phrase is called the k-th joint of DS(k,m).",
        "There is a dependency relation from k-th joint (dependent) to k+l-th joint(governor) in DS(k,m).",
        "Let J.DS(9,,m) be a set of all the joints of DS(k,m).",
        "DS(k,m/i,j) a subset of DS(k,m), is defined as follows:",
        "Lemma 1.",
        "For any positive integer R, j, m (NNJA.i>jNm), the following propositions hold.",
        "(i) DS(k,m/i,3)E 7(i,3), if j is a joint of DS(k,m).",
        "(ii) DS(k,j)U DS(j,m)E:7(k,m), if and only if jpIDS(k,j) =jDIDS(j,m).",
        "(iii) {(2+1,j,a,B,c)}uDS(k,74)E7(t+1, m) if and only if (k+1,j,a,3,c) EDIF,13=30IDS(\"m\" j J.DS(2,,m) and c*jGDS(k,m).",
        "(iv) If (jk,jk+1,ak,ak+1,c)E DS(j ,m) (k=0,1,2,•••), then jk is the k-th joint of DS(jo,m).",
        "Syntax analysis of a Japanese sentence is defined as giving B-phrase structures and dependency structure of the sentence."
      ]
    },
    {
      "heading": "2. THE PARSING ALGORITHM AND ITS EFFICIENCY",
      "text": [
        "In this chapter, we shall give a parsing method which will parse an input sentence using time 0(n3) and space 0(n3), where n is the length of input sentence.",
        "Moreover, if the dependency information of each B-phrase is unambiguous, the time variation is quadratic.",
        "The essence of the parsing algorithm is the construction of B-phrase parse list BL and dependency parse list DL which are constructed essentially by a \"dynamic programming\" method.",
        "The parsing algorithm consists of four minor algorithms that are the construction of BL, the obtaining of B-phrase structure, the construction of DL and the obtaining of dependency structure.",
        "B-PHRASE PARSE LIST Let b be a string of n length and b(i) denote the i-th character from the left end of it.",
        "b=b(1)(2) b(n).",
        "The B-phrase parse list of b consists of n minor lists BL(1), BL(2), , BL(n).",
        "Form of items in BL(j) (i, WS, DI) where, 1Li<j4n, WS is a word structure and DI is a dependency information.",
        "F-7 Semantics of (i, WS, DI)EBL(j) (i, WS, DI)E BL(j), if and only if there exists a sequence of words wo, w1, , wk satisfying following two conditions:",
        "1) b(1)b(2) •• b(i)=w0W1 wk-1, b(i+l)b(i+2) b(3)=wk, and WS is the word structure of wk.",
        "2) The string of word wows ••• wk is a left parcial B-phrase of dependency information DI.",
        "ALGORITHM FOR THE CONSTRUCTION OF BL Input.",
        "An input string b=b(1)(2) ...b(n).",
        "Output.",
        "The B-phrase parse list BL(1), BL(2), , BL(n).",
        "Method.",
        "Step 1: Find all the independent word which are the leftmost subwords of b, using independent word dictionary and for each independent word w=b(1)b(2) b(j), add (0,(W,H,K),a) to BL(j) where, (W,H,K) is the word structure of w and a= (<W,H>g, <W,H,->d).",
        "Then, set the control word i to 1 and repeat Step 2 until i=n.",
        "Step 2: Obtain all the suffix words which are the leftmost subwords of B(i+l)B(i+2) b(n) and for each suffix word w=b(i+l)b(i+2) b(k) of word structure (W1,111,10), and for each item (j, <W,H,K>,a) BL(i), add (i,(W',H',K'), (W,H1)0a) to BL(k) if",
        "C(H,K,KI).",
        "(W,H')0a is a dependency information defined as follows.",
        "i If H' is a auxiliary verb, then (W',H')oa (<a>gl<141',H1,->a) where, <u>, is the information of governor of a. ii Let <W\",H\",11\" > be the information of dependent of a.",
        "When H' is a particle, (w,,H,)00, def a (< >g,<W,H\",1.11>d) if the power of dependency function of H' is stronger than that of H\" , and else def a.",
        "There exists upper limit in the length of words and there exists upper limit in the number of dependency informations of all left partial B-phrase of a(1)a(2) a(i).",
        "Therefore, there exists upper limit for the necessary size of memory space of BL(i) and the theorem 1 follows.",
        "Theorem 1.",
        "Algorithm for the construction of BL requires 0(n) memory space and 0(n) elementary operations.",
        "We shall now describe how to find a B-phrase structure of specified dependency information from BL.",
        "The method is given as follows."
      ]
    },
    {
      "heading": "ALGORITHM FOR OBTAINING A B-PHRASE STRUCTURE OF AN INPUT STRING",
      "text": [
        "Input.",
        "The specified dependency information a and BL.",
        "Output.",
        "A B-phrase structure of dependency information a or the error signal \"error\".",
        "Method.",
        "STEP 1: Search any item (i,(W,H,K),a) in BL(n) such as Termi (H,H).",
        "If there is no such item, then emit \"error\" and halt.",
        "Otherwise, output the word structure (W,H,K), set the register R to (i,(W,H,K),a) and repeat the step 2 until i =O.",
        "STEP 2: Let R be (i,(W,H,K),a).",
        "Search any item (i',(W',H',K'),a') in BL(i) such as C(H',K',H) and (W,H)00i=a.",
        "There exist at least one element which satisfies above conditions.",
        "'Output the word structure (W',H',K') and It is easy to know theorem 2 holds.",
        "Theorem 2.",
        "A B-phrase structure of specified dependency information is output by the above algorithm, if and only if the input string has at least one B-phrase structure of specified dependency information and it takes constant memory space and 0(n) elementary operations to operate the above algorithm.",
        "The set of all the dependency informations DI of input string b is obtained from BL(n), since DI={a I (i, (W,H,K) ,a)EBL(n) , C(H,K) }.",
        "DEPENDENCY PARSE LIST DL Let s be a input sentence of N B-phrases.",
        "The set of all the dependency informations DI(i) of the i-th B-phrase is obtained by operating the algorithm of construction of BL on the string of the i-th B-phrase.",
        "The dependency parse list DL of s consists of N-1 minor lists DL(2), DL(3), ,DL(N).",
        "Form of items in DL(i).",
        "(a1,j1apc,P) (ai,j,aj,$,P) I where, aiE DI(i), ajE DI(j), c e C, P S and $ is a specially introduced symbol.",
        "Semantics of (ai,j,al,c,P)EDL(i).",
        "(ai,j,apc,P)E DL/i), if and only if there is a dependency structure DS(i,l) of s, where",
        "(ai,j,aj,$,P)E DL(i), if and only if there is a dependency structure DS(i,l) of s, where ai=j-DIDS(i,1), aj=iDIDS(i,l), j is a joint of DS(i,l) except 0-th or 1st joint, jGDS(i,l) =P."
      ]
    },
    {
      "heading": "ALGORITHM FOR THE CONSTRUCTION OF DL",
      "text": [
        "Input.",
        "The sequence of the sets of all dependency informations DI(1), DI(2), ,DI(N).",
        "Output.",
        "Dependency list DL(2), DL(3), ,DL(N).",
        "Method.",
        "STEP 1 (Construction of DL(2)): For each a2E DI(2), ale DI(1) and ce C such that cE6(a2,a1), add (a2,1,a1,c,{c}) to DL(2), set i to 2 and repeat the STEP 2 and the STEP 3 until i =N.",
        "STEP 2 (Registration of items of the form (ai+,,j,apc,P)): For any (ai,j,aj,c,P)E DL(i) and ai+/E DI(i-1-1), compute cS(ai+1,ai) and add every (ai+1,i,ai,c1,{c1}) to DL(i+l) such that c'e (5(a1+1,ai).",
        "And, for any (ai,j,aj,A,P)E DL(i) where A E u{$} and ai+IE DI(i+1), compute 6(ai.1-1,0tj) and add every ,j faj,c' ,P {c'})",
        "and P. Go to Step 3.",
        "STEP 3 (Registration of items of the form (04i+1,j,aj,$,P)): For any (ai+1,j,a•,c,P) E Dt(i+1) and (ai,k,ak, A,P') E DI(j), add (ai+1,k,ak,$,16') to DL(i+1).",
        "Then, set i to i+1 and go to STEP 2.",
        "Theorem 3.",
        "If there exist no ambiguity in the dependency information of B-phrases of input sentence, then the step 3 in the above algorithm can be replaced to the following step 3'.",
        "STEP 3': For each (aKi.0,j,ai,A,P) EDL(Ki+2), add (ai+i,j,aj,$,P) to DL(i+1), where def K max{kl (a. k a c P) 1+1 1+1/ kr / E DL (1+1)1.",
        "Then, set ito i+1 and go to STEP 2.",
        "The efficiency of each step of above algorithm is as follows.",
        "The memory size of DL(i) is 0(N).",
        "The step 1, the step 2 and the step 3 take constant, 0(N) and 0(N2) elementary operations, respectively.",
        "The step 3' takes 0(N) elementary operations since it takes 0(N) elementary operations to compute Ki+1.",
        "Therefore, the theorem 4 holds.",
        "Theorem 4.",
        "The algorithm for the construction of DL requires 0(N2) memory space and 0(N3) elementary operations.",
        "Moreover, if there exist no ambiguity in the dependency information of each B-phrases, the algorithm requires 0(N2) elementary operations by replacing the step 3 with the step 3'.",
        "We shall now describe how to find a dependency structure of input sentence from DL.",
        "To begin with, we shall explain items of partial dependency structure list PDSL.",
        "Form of items in PDSL (ifj,4,1,0) where, >j a#E DI(i) U{#}, a#E DI(j) VW, P# is a subset of C or Ciand # is specially introduced symbol.",
        "1) If alt=a0##), then iDIDS(i,j)=ai.",
        "2) If at-,..ai(t#), then iDIDS(i/j)--=aj• 3) If Pi=P(0), then jGDS(i,j)=P.",
        "Therefore, (N,1,#,#,#) means to be a dependency structure of the input sentence."
      ]
    },
    {
      "heading": "ALGORITHM FOR OBTAINING A DEPENDENCY STRUCTURE FROM DL",
      "text": [
        "Input.",
        "DL.",
        "Output.",
        "A dependency structure of input sentence or the signal \"error\".",
        "Method.",
        "STEP 1: If DL(N) is empty, emit the message \"error\", else, initialize PDSL to {(N,1,#,#,#)} and repeat step 2 until PDSL becomes empty.",
        "STEP 2: Take an item freely out of PDSL and delete it from PDSL.",
        "According to the form of the item, execute 1) or 2) or 3).",
        "1) If the item is (N,1,#,#,#) of the form and (aN,j,aj,c,P)E DL(N), then output (N,j,aN,ai,c), add (N-1,j, #,ai,P/{c}) to PDSL N-1 tj and add (j,1,aj,#,#) to PDSL if j 1.",
        "2) If the item is (i,l,ai,#,#) of the form and (j,ai,aj,c,P)E DL(i), then output (i,j,ai,a•,c), add (i-1,j, #,a•,P/{c}) to PDSL i i-1 #j and add (j,1,ap#,#) to PDSL if j 1.",
        "3) If the item is (i,j,a!,aj,P) of the form, where i",
        "a#=a or #, and (ai,j, a c P)E DL(i), then output (i,j,ai,",
        "c) and add (i-1,j,#,apP/{c}) to PDSL if i-1+ j.",
        "When there is not such item in DL(i), search a pair of items (ai,k,ak,c,P')E DL(i) and (ak,j, ai,A,P)EDL(k), then output (i,k,ai,ak, 0, add (i-1,k,#,ak,P7{c}) to PDSL if i-ltk and add (k,j,ak,aj,P) to PDSL.",
        "PDSL needs 0(N) memory space and STEP 1, STEP 2 take constant, 0(N) elementary operations, respectively.",
        "Theorem 5.",
        "Algorithm for obtaining a dependency structure from DL requires 0(N) memory space and 0(N2) elementary operations."
      ]
    },
    {
      "heading": "PARSING ALGORITHM",
      "text": [
        "Input.",
        "A Japanese sentence in colloquial style.",
        "Output.",
        "A dependency structure DS(N, 1) of the input sentence and a B-phrase structure of the j-th B-phrase, whose dependency information is iDIDS(N,1), for every j(j=1,2, ,N).",
        "Method.",
        "STEP 1: Construct NB-phrase parse lists of all B-phrases of the input sentence and get the sets of dependency informations DI(1), DI(2),",
        "Let no .be the length of j-th B-phrase (3=1,2, ,N), and N,n denote the number of B-phrases and the length of input sentence, respectively.",
        "Then, n1+n2+ ••• +nN =n N z n By theorem 1, theorem 2, theorem 4 and theorem 5, next theorem holds.",
        "Theorem 6.",
        "The parsing algorithm requires 0(n2) memory space and 0(n3) elementary operations.",
        "Moreover, if the dependency information of each B-phrase is unambiguous, it requires 0(n2) elementary operations."
      ]
    },
    {
      "heading": "3. CONCLUSION",
      "text": [
        "Syntax of Japanese sentences is stated and a efficient parsing algorithm is given.",
        "A Japanese sentence in colloquial style is parsed by the parsing algorithm, using time 0(n3) and memory space 0(n2), where n is the length of input sentence.",
        "Moreover, it is parsed using time 0(n2) whenever dependency information of every B-phrase is unambiguous."
      ]
    },
    {
      "heading": "REFERENCES",
      "text": []
    }
  ]
}
