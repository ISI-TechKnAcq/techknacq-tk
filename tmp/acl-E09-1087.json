{
  "info": {
    "authors": [
      "Drahomíra Johanka Spoustová",
      "Jan Hajič",
      "Jan Raab",
      "Miroslav Spousta"
    ],
    "book": "EACL",
    "id": "acl-E09-1087",
    "title": "Semi-Supervised Training for the Averaged Perceptron POS Tagger",
    "url": "https://aclweb.org/anthology/E09-1087",
    "year": 2009
  },
  "references": [
    "acl-A00-1031",
    "acl-J01-2002",
    "acl-J93-2004",
    "acl-N03-1033",
    "acl-P07-1096",
    "acl-P08-1076",
    "acl-P98-1029",
    "acl-P98-1080",
    "acl-W02-1001",
    "acl-W07-1709",
    "acl-W96-0213"
  ],
  "sections": [
    {
      "text": [
        "Semi-supervised Training for the Averaged Perceptron POS Tagger",
        "Drahomfra \"johanka\" Spoustova Jan Hajic Jan Raab Miroslav Spousta",
        "Institute of Formal and Applied Linguistics",
        "Faculty of Mathematics and Physics, Charles University Prague, Czech Republic",
        "{johanka,hajic,raab,spousta}@ ufal.mff.cuni.cz",
        "This paper describes POS tagging experiments with semi-supervised training as an extension to the (supervised) averaged perceptron algorithm, first introduced for this task by (Collins, 2002).",
        "Experiments with an iterative training on standard-sized supervised (manually annotated) dataset (10 tokens) combined with a relatively modest (in the order of 10 tokens) unsupervised (plain) data in a bagging-like fashion showed significant improvement of the POS classification task on typologically different languages, yielding better than state-of-the-art results for English and Czech (4.12 % and 4.86 % relative error reduction, respectively; absolute accuracies being 97.44 % and 95.89 %)."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Since 2002, we have seen a renewed interest in improving POS tagging results for English, and an inflow of results (initial or improved) for many other languages.",
        "For English, after a relatively big jump achieved by (Collins, 2002), we have seen two significant improvements: (Toutanova et al., 2003) and (Shen et al., 2007) pushed the results by a significant amount each time.",
        "Even though an improvement in POS tagging might be a questionable enterprise (given that its effects on other tasks, such as parsing or other NLP problems are less than clear – at least for English), it is still an interesting problem.",
        "Moreover, the \"ideal\" situation of having a single algorithm (and its implementation) for many (if not all) languages has not been reached yet.",
        "We have chosen Collins' perceptron algorithm because of its simplicity, short training times, and an apparent room for improvement with (substantially) growing data sizes (see Figure 1).",
        "However, it is clear that there is usually little chance to get (substantially) more manually annotated data.",
        "Thus, we have been examining the effect of adding a large monolingual corpus to Collins' perceptron, appropriately extended, for two typologically different languages: English and Czech.",
        "It is clear however that the features (feature templates) that the taggers use are still language-dependent.",
        "One of the goals is also to have a fast implementation for tagging large amounts of data quickly.",
        "We have experimented with various classifier combination methods, such as those described in (Brill and Wu, 1998) or (van Halteren et al., 2001), and got improved results, as expected.",
        "However, we view this only as a side effect (yet, a positive one) – our goal was to stay on the turf of single taggers, which are both the common ground for competing on tagger accuracy today and also significantly faster at runtime.",
        "Nevertheless, we have found that it is advantageous to use them to (pre-)tag the large amounts of plain text data during the training phase.",
        "Apart from feeding the perceptron by various mixtures of manually tagged (\"supervised\") and auto-tagged (\"unsupervised\") data, we have also used various feature templates extensively; for example, we use lexicalization (with the added twist of lemmatization, useful especially for Czech, an inflectionally rich language), \"manual\" tag classification into large classes (again, useful especially for Czech to avoid the huge, still-to-be-overcome data sparseness for such a language), and sub-lexical features mainly targeted at OOV words.",
        "Inspired i.a.",
        "by (Toutanova et al., 2003) and (Hajic and Vidova-Hladka, 1998), we also use \"lookahead\" features (however, we still remain in the left-to-right HMM world - in this respect our solution is closer to the older work of (Hajic and Vidova-Hladka, 1998) than to (Toutanova et al., 2003), who uses bidirectional dependencies to include the right-hand side disambiguated tags, which we cannot.)",
        "To summarize, we can describe our system as follows: it is based on (Votrubec, 2006)'s implementation of (Collins, 2002), which has been fed at each iteration by a different dataset consisting of the supervised and unsupervised part: precisely, by a concatenation of the manually tagged training data (WSJ portion of the PTB 3 for English, morphologically disambiguated data from PDT 2.0 for Czech) and a chunk of automatically tagged unsupervised data.",
        "The \"parameters\" of the training process (feature templates, the size of the unsupervised chunks added to the trainer at each iteration, number of iterations, the combination of taggers that should be used in the auto-tagging of the unsupervised chunk, etc.)",
        "have been determined empirically in a number of experiments on a development data set.",
        "We should also note that as a result of these development-data-based optimizations, no feature pruning has been employed (see Section 4 for details); adding (even lexical) features from the auto-tagged data did not give significant accuracy improvements (and only made the training very slow).",
        "The final taggers have surpassed the current state-of-the-art taggers by significant margins (we have achieved 4.12 % relative error reduction for English and 4.86 % for Czech over the best previously published results, single or combined), using a single tagger.",
        "However, the best English tagger combining some of the previous state-of-the-art ones is still \"optically\" better (yet not significantly – see Section 6)."
      ]
    },
    {
      "heading": "2. The perceptron algorithm",
      "text": [
        "We have used the Morce tagger (Votrubec, 2006) as a main component in our experiments.",
        "It is a reimplementation of the averaged perceptron described in (Collins, 2002), which uses such features that it behaves like an HMM tagger and thus the standard Viterbi decoding is possible.",
        "Collins' GEN(x) set (a set of possible tags at any given position) is generated, in our case, using a morphological analyzer for the given language (essentially, a dictionary that returns all possible tagsfor an input word form).",
        "The transition and output scores for the candidate tags are based on a large number of binary-valued features and their weights, which are determined during iterative training by the averaged perceptron algorithm.",
        "The binary features describe the tag being predicted and its context.",
        "They can be derived from any information we already have about the text at the point of decision (respecting the HMM-based overall setting).",
        "Every feature can be true or false in a given context, so we can consider the true features at the current position to be the description of a tag and its context.",
        "For every feature, the perceptron keeps its weight coefficient, which is (in its basic version) an integer number, (possibly) changed at every training sentence.",
        "After its final update, this integer value is stored with the feature to be later retrieved and used at runtime.",
        "Then, the task of the perceptron algorithm is to sum up all the coefficients of true features in a given context.",
        "The result is passed to the Viterbi algorithm as a transition and output weight for the current state.",
        "We can express it as where w(C, T) is the transition weight for tag T in context C, n is the number of features, a is the weight coefficient of the ith feature and 0j(C, T) is the evaluation of the ith feature for context C and tag T. In the averaged perceptron, the values of every coefficient are added up at each update, which happens (possibly) at each training sentence, and their arithmetic average is used in-stead.",
        "This trick makes the algorithm more resistant to weight oscillations during training (or, more precisely, at the end of it) and as a result, it substantially improves its performance.",
        "OOV words.",
        "The supervised training described in (Collins, 2002) uses manually annotated data for the estimation of the weight coefficients a.",
        "The training algorithm is very simple – only integer numbers (counts and their sums for the averaging) are updated for each feature at each sentence with imperfect match(es) found against the gold standard.",
        "Therefore, it can be relatively quickly retrained and thus many different feature sets and other training parameters, such as the number of iterations, feature thresholds etc.",
        "can be considered and tested.",
        "As a result of this tuning, our (fully supervised) version of the Morce tagger gives the best accuracy among all single taggers for Czech and also very good results for English, being beaten only by the tagger (Shen et al., 2007) (by 0.10 % absolute) and (not significantly) by (Toutanova et al., 2003)."
      ]
    },
    {
      "heading": "3. The data",
      "text": [
        "For English, we use the same data division of Penn Treebank (PTB) parsed section (Marcus et al., 1994) as all of (Collins, 2002), (Toutanova et al., 2003) , (Gimenez and Marquez, 2004) and (Shen et al., 2007) do; for details, see Table 1.",
        "For Czech, we use the current standard Prague Dependency Treebank (PDT 2.0) data sets (Hajic et al., 2006); for details, see Table 2.",
        "For English, we have processed the North American News Text corpus (Graff, 1995) (without the",
        "data set",
        "tokens",
        "sentences",
        "train (0-18)",
        "912,344",
        "38,220",
        "dev-test (19-21)",
        "131,768",
        "5,528",
        "eval-test (22-24)",
        "129,654",
        "5,463",
        "data set",
        "tokens",
        "sentences",
        "train",
        "1,539,241",
        "91,049",
        "dev-test",
        "201,651",
        "11,880",
        "eval-test",
        "219,765",
        "13,136",
        "WSJ section) with the Stanford segmenter and to-kenizer (Toutanova et al., 2003).",
        "For Czech, we have used the SYN2005 part of Czech National Corpus (CNC, 2005) (with the original segmentation and tokenization).",
        "For English, we perform a very simple morphological analysis, which reduces the full PTB tagset to a small list of tags for each token on input.",
        "The resulting list is larger than such a list derived solely from the PTB/WSJ, but much smaller than a full list of tags found in the PTB/WSJ.",
        "The English morphological analyzer is thus (empirically) optimized for precision while keeping as high recall as possible (it still overgenerates).",
        "It consists of a small dictionary of exceptions and a small set of general rules, thus covering also a lot of OOV to-kens.",
        "For Czech, the separate morphological analyzer (Hajic, 2004) usually precedes the tagger.",
        "We use the version from April 2006 (the same as (Spous-tova et al., 2007), who reported the best previous result on Czech tagging)."
      ]
    },
    {
      "heading": "4. The perceptron feature sets",
      "text": [
        "The averaged perceptron's accuracy is determined (to a large extent) by the set of features used.",
        "A feature set is based on feature templates, i.e. general patterns, which are filled in with concrete values from the training data.",
        "Czech and English are morphosyntactically very different languages, therefore each of them needs a different set of feature templates.",
        "We have empirically tested hundreds of feature templates on both languages, taken over from previous works for direct comparison, inspired by them, or based on a combination of previous experience, error analysis and linguistic intuition.",
        "In the following sections, we present the best performing set of feature templates as determined on the development data set using only the supervised training setting; our feature templates have thus not been influenced nor extended by the unsupervised data.",
        "The best feature set for English consists of 30 feature templates.",
        "All templates predict the current tag as a whole.",
        "A detailed description of the English feature templates can be found in Table 3.",
        "A total of 1,953,463 features has been extracted from the supervised training data using the templates from Table 3.",
        "The best feature set for Czech consists of 63 feature templates.",
        "26 of them predict current tag as a whole, whereas the rest predicts only some parts of the current tag separately (e.g., detailed POS, gender, case) to avoid data sparseness.",
        "Such a feature is true, in an identical context, for several different tags belonging to the same class (e.g., sharing a locative case).",
        "The individual grammatical categories used for such classing have been chosen on both linguistic grounds (POS, detailed finegrained POS) and also such categories have been used which contribute most to the elimination of the tagger errors (based on an extensive error analysis of previous results, the detailed description of which can be found in (Votrubec, 2006)).",
        "Several features can look ahead (to the right of the current position) - apart from the obvious word form, which is unambiguous, we have used (in case of ambiguity) a random tag and lemma of the first position to the right from the current position which might be occupied with a verb (based on dictionary and the associated morphological guesser restrictions).",
        "A total of 8,440,467 features has been extracted from the supervised training data set.",
        "A detailed description is included in the distribution downloadable from the Morce website.",
        "Context predicting whole tag",
        "Tags",
        "Previous tag",
        "Previous two tags",
        "First letter of previous tag",
        "Word forms",
        "Current word form Previous word form Previous two word forms Following word form Following two word forms Last but one word form",
        "Current word affixes",
        "Prefixes of length 1-9 Suffixes of length 1-9",
        "Current word features",
        "Contains number",
        "Contains dash",
        "Contains upper case letter"
      ]
    },
    {
      "heading": "5. The (un)supervised training setup",
      "text": [
        "We have extended the averaged perceptron setup in the following way: the training algorithm is fed, in each iteration, by a concatenation of the supervised data (the manually tagged corpus) and the automatically pre-tagged unsupervised data, different for each iteration (in this order).",
        "In other words, the training algorithm proper does not change at all: it is the data and their selection (including the selection of the way they are automatically tagged) that makes all the difference.",
        "The following \"parameters\" of the (unsuper-vised part of the) data selection had to be determined experimentally:",
        "• the tagging process for tagging the selected data",
        "• the selection mechanism (sequential or random with/without replacement)",
        "• the size to use for each iteration",
        "• and the use and order of concatenation with the manually tagged data.",
        "We have experimented with various settings to arrive at the best performing configuration, described below.",
        "In each subsection, we compare the result of our ,,winning\" configuration with results of the experiments which have the selected attributes omitted or changed; everything is measured on the development data set.",
        "In order to simulate the labeled training events, we have tagged the unsupervised data simply by a combination of the best available taggers.",
        "For practical reasons (to avoid prohibitive training times), we have tagged all the data in advance, i.e. no re-tagging is performed between iterations.",
        "The setup for the combination is as follows (the idea is simplified from (Spoustova et al., 2007) where it has been used in a more complex setting):"
      ]
    },
    {
      "heading": "1.. run N different taggers independently;",
      "text": [
        "2. join the results on each position in the data from the previous step – each token thus ends up with between 1 and N tags, a union of the tags output by the taggers at that position;"
      ]
    },
    {
      "heading": "3.. do final disambiguation (by a single tag-",
      "text": [
        "ger).",
        "Table 4 illustrates why it is advantageous to go through this (still) complicated setup against a single-tagger bootstrapping mechanism, which always uses the same tagger for tagging the unsupervised data.",
        "For both English and Czech, the selection of taggers, the best combination and the best overall setup has been optimized on the development data set.",
        "A bit surprisingly, the final setup is very similar for both languages (two taggers to tag the data in Step 1, and a third one to finish it up).",
        "For English, we use three state-of-the-art taggers: the taggers of (Toutanova et al., 2003) and (Shen et al., 2007) in Step 1, and the SVM tagger (Gimenez and Marquez, 2004) in Step 3.",
        "We run the taggers with the parameters which were shown to be the best in the corresponding papers.",
        "The SVM tagger needed to be adapted to accept the (reduced) list of possible tags.",
        "For Czech, we use the Feature-based tagger (Hajic, 2004) and the Morce tagger (with the new feature set as described in section 4) in Step 1, and an HMM tagger (Krbec, 2005) in Step 3.",
        "This combination outperforms the results in (Spoustova et al., 2007) by a small margin.",
        "We have found that it is better to feed the training with different chunks of the unsupervised data at each iteration.",
        "We have then experimented with three methods of unsupervised data selection, i.e. generating the unsupervised data chunks for each training iteration from the ,,pool\" of sentences.",
        "These methods are: simple sequential chopping, randomized data selection with replacement and randomized selection without replacement.",
        "Table 5 demonstrates that there is practically no difference in the results.",
        "Thus, we use the sequential chopping mechanism, mainly for its simplicity.",
        "Tagger",
        "Accuracy",
        "Morce",
        "97.21",
        "Shen",
        "97.33",
        "Combination",
        "97.44",
        "We have experimented with various sizes of the unsupervised parts (from 500k tokens to 5M) and also with various numbers of iterations.",
        "The best results (on the development data set) have been achieved with the unsupervised chunks containing approx.",
        "4 million tokens for English and 1 million tokens for Czech.",
        "Each training process consists of (at most) 100 iterations (Czech) or 50 iterations (English); therefore, for the 50 (100) iterations we needed only about 200,000,000 (100,000,000) tokens of raw texts.",
        "The best development data set results have been (with the current setup) achieved on the 44th (English) and 33th (Czech) iteration.",
        "The development data set has been also used to determine the best way to \"merge\" the manually labeled data (the PTB/WSJ and the PDT 2.0 training data) and the unsupervised parts of the data.",
        "Given the properties of the perceptron algorithm, it is not too surprising that the best solution is to put (the full size of) the manually labeled data first, followed by the (four) million-token chunk of the automatically tagged data (different data in each chunk but of the same size for each iteration).",
        "It corresponds to the situation when the trainer is periodically \"returned to the right track\" by giving it the gold standard data time to time.",
        "Figure 2 (English) and especially Figure 3 (Czech) demonstrate the perceptron behavior in cases where the supervised data precede the unsupervised data only in selected iterations.",
        "A subset of these development results is also present in",
        "Table 6.",
        "5.4 The morphological analyzers and the perceptron feature templates",
        "The whole experiment can be performed with the original perceptron feature set described in (Collins, 2002) instead of the feature set described in this article.",
        "The results are compared in Table 7 (for English only).",
        "Also, for English it is not necessary to use our morphological analyzer described in section 3.3 (other variants are to use the list of tags derived solely from the WSJ training data or to give each token the full list of tags found in WSJ).",
        "It is practically impossible to perform the unsupervised training with the full list of tags (it would take several years instead of several days with the default setup), thus we compare only the results with morphological analyzer to the results with the list of tags derived from the training data, see Table 8.",
        "It can be expected (some approximated experiments were performed) that the results with the full list of tags would be very similar to the results with the morphological analyzer, i.e. the morphological analyzer is used mainly for technical reasons.",
        "Our expectations are based mainly (but not on the GEN(x) only) on the supervised training results, where the performance of the taggers using the morphological analyzer output and using the full list of tags are nearly the same, see Table 9.",
        "Method of data selection",
        "English",
        "Czech",
        "Sequential chopping",
        "97.44",
        "96.21",
        "Random without replacement",
        "97.44",
        "96.20",
        "Random with replacement",
        "97.44",
        "96.21",
        "English",
        "Czech",
        "No supervised data",
        "97.37",
        "95.88",
        "Once at the beginning",
        "97.40",
        "96.00",
        "Every training iteration",
        "97.44",
        "96.21"
      ]
    },
    {
      "heading": "6. Results",
      "text": [
        "In Tables 10 and 11, the main results (on the eval-test data sets) are summarized.",
        "The state-of-the art taggers are using feature sets discribed in the corresponding articles ((Collins, 2002), (Gimenez and Marquez, 2004), (Toutanova et al., 2003) and (Shen et al., 2007)), Morce supervised and Morce semi-supervised are using feature set desribed in section 4.",
        "For significance tests, we have used the paired Wilcoxon signed rank test as implemented in the R package (R Development Core Team, 2008) in wilcox.test() , dividing the data into 100 chunks (data pairs).",
        "The combination of the three existing English taggers seems to be best, but it is not significantly better than our semi-supervised approach.",
        "The combination is significantly better than (Shen et al., 2007) at a very high level, but more importantly, Shen s results (currently representing the replicable state-of-the-art in POS tagging) have been significantly surpassed also by the semi-supervised Morce (at the 99 % confidence level).",
        "In addition, the semi-supervised Morce performs (on single CPU and development data set) 77 times faster than the combination and 23 times faster than (Shen et al., 2007).",
        "The best results (Table 11) are statistically significantly better than the previous results: the semi-supervised Morce is significantly better than both the combination and the supervised (original) variant at a very high level.",
        "GEN(x)",
        "Accuracy",
        "List of tags derived from train",
        "95.89",
        "Our morphological analyzer",
        "97.17",
        "Full tagset",
        "97.15",
        "Tagger",
        "accuracy",
        "Collins",
        "97.07 %",
        "SVM",
        "97.16 %",
        "Stanford",
        "97.24 %",
        "Shen",
        "97.33 %",
        "Morce supervised",
        "97.23 %",
        "combination",
        "97.48 %",
        "Morce semi-supervised",
        "97.44 %",
        "Tagger",
        "accuracy",
        "Feature-based",
        "94.04 %",
        "HMM",
        "94.82 %",
        "Morce supervised",
        "95.67 %",
        "combination",
        "95.70 %",
        "Morce semi-supervised",
        "95.89 %",
        "Feature set",
        "Accuracy",
        "Collins'",
        "97.38",
        "Our's",
        "97.44",
        "GEN(x)",
        "Accuracy",
        "List of tags derived from train",
        "97.13",
        "Our morphological analyzer",
        "97.44"
      ]
    },
    {
      "heading": "7. Download",
      "text": [
        "We decided to publish our system for wide use under the name COMPOST (Common POS Tagger).",
        "All the programs, patches and data files are available at the website http://ufal.mff.cuni.cz/compost under either the original data provider license, or under the usual GNU General Public License, unless they are available from the widely-known and easily obtainable sources (such as the LDC, in which case pointers are provided on the download website).",
        "The Compost website also contains easy-to-run Linux binaries of the best English and Czech single taggers (based on the Morce technology) as described in Section 6."
      ]
    },
    {
      "heading": "8. Conclusion and Future Work",
      "text": [
        "We have shown that the \"right\" mixture of supervised and unsupervised (auto-tagged) data can significantly improve tagging accuracy of the averaged perceptron on two typologically different languages (English and Czech), achieving the best known accuracy to date.",
        "To determine what is the contribution of the individual \"dimensions\" of the system setting, as described in Sect.",
        "5, we have performed experiments fixing all but one of the dimensions, and compared their contribution (or rather, their loss when compared to the best \"mix\" overall).",
        "For English, we found that excluding the state-of-the-art-tagger (in fact, a carefully selected combination of taggers yielding significantly higher quality than any of them has) drops the resulting accuracy the most (0.2 absolute).",
        "Significant yet smaller drop (less than 0.1 percent) appears when the manually tagged portion of the data is not used or used only once (or infrequently) in the input to the perceptron's learner.",
        "The difference in using various feature templates (yet all largely similar to what state-of-the-art taggers currently use) is not significant.",
        "Similarly, the way the unsupervised data is selected plays no role, either; this differs from the bagging technique (Breiman, 1996) where it is significant.",
        "For Czech, the drop in accuracy appears in all dimensions, except the unsupervised data selection one.",
        "We have used novel features inspired by previous work but not used in the standard perceptron setting yet (linguistically motivated tag classes in features, lookahead features).",
        "Interestingly, the resulting tagger is better than even a combination of the previous state-of-the-art taggers (for English, this comparison is inconclusive).",
        "We are working now on parallelization of the perceptron training, which seems to be possible (based i.a.",
        "on small-scale preliminary experiments with only a handful of parallel processes and specific data sharing arrangements among them).",
        "This would further speed up the training phase, not just as a nice bonus per se, but it would also allow for a semi-automated feature template selection, avoiding the (still manual) feature template preparation for individual languages.",
        "This would in turn facilitate one of our goals to (publicly) provide single-implementation, easy-to-maintain state-of-the-art tagging tools for as many languages as possible (we are currently preparing Dutch, Slovak and several other languages).",
        "Another area of possible future work is more principled tag classing for languages with large tagsets (in the order of 10), and/or adding syntactically-motivated features; it has helped Czech tagging accuracy even when only the \"in-trospectively\" defined classes have been added.",
        "It is an open question if a similar approach helps English as well (certain grammatical categories can be generalized from the current WSJ tagset as well, such as number, degree of comparison, 3rd person present tense).",
        "Finally, it would be nice to merge some of the approaches by (Toutanova et al., 2003) and (Shen et al., 2007) with the ideas of semi-supervised learning introduced here, since they seem orthogonal in at least some aspects (e.g., to replace the rudimentary lookahead features with full bidirec-tionality)."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "The research described here was supported by the projects MSM0021620838 and LC536 of Ministry of Education, Youth and Sports of the Czech Republic, GA405/09/0278 of the Grant Agency of the",
        "Czech Republic and 1ET101120503 of Academy of Sciences of the Czech Republic."
      ]
    }
  ]
}
