{
  "info": {
    "authors": [
      "Haodong Wu",
      "Eduardo de Paiva Alves",
      "Teiji Furugori"
    ],
    "book": "COLING-ACL",
    "id": "acl-P98-2231",
    "title": "Structural Disambiguation Based on Reliable Estimation of Strength of Association",
    "url": "https://aclweb.org/anthology/P98-2231",
    "year": 1998
  },
  "references": [
    "acl-C92-2070",
    "acl-C96-2190",
    "acl-J90-1003",
    "acl-J93-1001",
    "acl-J93-1005",
    "acl-J93-2006",
    "acl-P91-1034",
    "acl-P96-1055"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper proposes a new class-based method to estimate the strength of association in word co-occurrence for the purpose of structural disambiguation.",
        "To deal with sparseness of data, we use a conceptual dictionary as the source for acquiring upper classes of the words related in the co-occurrence, and then use t-scores to determine a pair of classes to be employed for calculating the strength of association.",
        "We have applied our method to determining dependency relations in Japanese and prepositional phrase attachments in English.",
        "The experimental results show that the method is sound, effective and useful in resolving structural ambiguities."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The strength of association between words provides lexical preferences for ambiguity resolution.",
        "It is usually estimated from statistics on word co-occurrences in large corpora (Hindle and Rooth, 1993).",
        "A problem with this approach is how to estimate the probability of word co-occurrences that are not observed in the training corpus.",
        "There are two main approaches to estimate the probability: smoothing methods (e.g., Church and Gale, 1991; Jelinek and Mercer, 1985; Katz, 1987) and class-based methods (e.g., Brown et al., 1992; Pereira and Tishby, 1992; Resnik, 1992; Yaxowsky, 1992).",
        "Smoothing methods estimate the probability of the unobserved co-occurrences by using frequencies of the individual words.",
        "For exam-pie, when eat and bread do not co-occur, the probability of (eat, bread) would be estimated by using the frequency of (eat) and (bread).",
        "A problem with this approach is that it pays no attention to the distributional characteristics of the individual words in question.",
        "Using this method, the probability of (eat, bread) and (eat, cars) would become the same when bread and cars have the same frequency.",
        "It is unacceptable from the linguistic point of view.",
        "Class-based methods, on the other hand, estimate the probabilities by associating a class with each word and collecting statistics on word class co-occurrences.",
        "For instance, instead of calculating the probability of (eat, bread) directly, these methods associate eat with the class [ingest] and bread with the class [food] and collect statistics on the classes [ingest] and [food].",
        "The accuracy of the estimation depends on the choice of classes, however.",
        "Some class-based methods (e.g., Yarowsky, 1992) associate each word with a single class without considering the other words in the co-occurrence.",
        "However, a word may need to be replaced by different class depending on the co-occurrence.",
        "Some classes may not have enough occurrences to allow a reliable estimation, while other classes may be too general and include too many words not relevant to the estimation.",
        "An alternative is to obtain various classes associated in a taxonomy with the words in question and select the classes according to a certain criteria.",
        "for which the association for the co-occurrence can be estimated.",
        "This approach may result in unreliable estimates, since some of the class co-occurrences used may be attributed to chance.",
        "Resnik (1993) selected all pairs of classes corresponding to the head of a prepositional phrase and weighted them to bias the computation of the association in favor of higher-frequency co-occurrences which he considered \"more reli-able.\" Contrary to this assumption, high frequency co-occurrences are unreliable when the probability that the co-occurrence may be attributed to chance is high.",
        "In this paper we propose a class-based method that selects the lowest classes in a taxonomy for which the co-occurrence confidence is above a threshold.",
        "We subsequently apply the method to solving structural ambiguities in Japanese dependency structures and English prepositional phrase attachments."
      ]
    },
    {
      "heading": "2 Class-based Estimation of",
      "text": []
    },
    {
      "heading": "Strength of Association",
      "text": [
        "The strength of association (SA) may be measured using the frequencies of word co-occurrences in large corpora.",
        "For instance, Church and Hanks (1990) calculated SA in terms of mutual information between two words wi and w2:",
        "here N is the size of the corpus used in the estimation, f (wi ,w2) is the frequency of the co-occurrence, f (wi ) and f (w2) that of each word.",
        "When no co-occurrence is observed, SA may be estimated using the frequencies of word classes that contain the words in question.",
        "The mutual information in this case is estimated by:",
        "here C1 and C2 are the word classes that respectively contain wi and w2, f(C1) and f (C2) the numbers of occurrences of all the words included in the word classes CI and C2, and f(C1, C2) is the number of co-occurrences of the word classes C1 and C2.",
        "Normally, the estimation using word classes needs to select classes, from a taxonomy, for which co-occurrences are significant.",
        "We use t-scores for this purpose'.",
        "For a class co-occurrence (Ci , C2), the t-score may be approximated by:",
        "We use the lowest class co-occurrence for which the confidence measured with t-scores is above a threshold 2.",
        "Given a co-occurrence containing the word w, our method selects a class for w in the following way:",
        "Let us see what this means with an example.",
        "Suppose we try to estimate SA for (produce, telephone)3 .",
        "See Table 1.",
        "Here f (v), 1(n) and f (vn) are the frequencies for the verb produce, classes for the noun telephone, and co-occurrences between the verb and the classes for telephone, respectively: and t is the t-score4.",
        "'The t-score (Church and Mercer, 1993) compares the hypothesis that a co-occurrence is significant against the null hypothesis that the co-occurrence can be attributed to chance.",
        "2 The default threshold for t-score is 1.28 which corresponds to a confidence level of 90%.",
        "t-scores are often inflated due to certain violations of assumptions.",
        "3 The data was obtained from 68,623 verb-noun pairs in EDR Corpus (EDR, 1993).",
        "'In our theory, we are to use each pair of (C`, C3), where i=1,2,...m, j=1,2,...,n, to calculate strengths of lexical associations.",
        "But our experiments show that upper classes of a verb are very unreliable to be used to measure the strengths.",
        "The reason may be that, unlike nouns, the verbs would not have a \"neat\" hierarchy or that the upper classes of a verb become too general as they contain too many concepts underneath them.",
        "Because of this observation, we use, for the classes of a",
        "verb classes for telephone f(v) f(n) f(vn) t-score produce concrete thing 671 18926 100 -4.6 produce inanimate object 671 5593 69 0.83 produce implement/tool 671 2138 35 1.91 produce machine 671 664 19 2.86 produce communication machine 671 83 1 0.25 produce telephone 671 24 0 Table 1 Estimation of (produce telephone) The lowest class co-occurrence (produce, communication machine) has a low t-score and produces a bad estimation.",
        "The most frequent co-occurrence (produce, concrete thing) has a low t-score also reflecting the fact that it may be attributed to chance.",
        "The t-scores for (produce, machine) and (produce, implement/tool) are high and show that these co-occurrences are significant.",
        "Among them, our method selects the lowest class co-occurrence for which the t-score is above the threshold: (produce, machine)."
      ]
    },
    {
      "heading": "3 Disambiguation Using",
      "text": []
    },
    {
      "heading": "Class-Based Estimation",
      "text": [
        "We now apply our method to estimate SA for two different types of syntactic constructions and use the results in resolving structural ambiguities."
      ]
    },
    {
      "heading": "3.1 Disambiguation of Dependency Relations in Japanese",
      "text": [
        "Identifying the dependency structure of a Japanese sentence is a difficult problem since the language allows relatively free word orders.",
        "A typical dependency relation in Japanese appears in the form of modifier-particle-modificand triplets.",
        "When a modifier is followed by a number of possible modificands, verb, the verb itself or, when it does not give us a good result, only the lowest class of the verb in calculating the strength of association (SA).",
        "Thus, for an example, the verb eat has a sequence of eat ingest â€“ .",
        "put something into body event concept in the class hierarchy, but we use only eat and ingest for the verb eat when calculating SA for (eat, apple).",
        "there arise situations in which syntactic rules may be unable to determine the dependency relation or the modifier-modificand relation.",
        "For instance, in",
        "46 Ai) '(vigorous) may modify either 'rI 4-51 ' (middle aged) or ' fVVElg ' ( health care).",
        "But which one is the modificand of ' It.k) '?",
        "We solve the ambiguity comparing the strength of association for the two or more possible dependency relations.",
        "Calculation of Strength of Association We calculate the Strength of Association (SA) score for modifier â€“ particle â€“ modi ficand by:",
        "where C'Tâ€žfier stands for the classes that include the modifier word, part is the particle following the modifier, in, the content word in the modificand phrase, and f the frequency.",
        "Let us see the process of obtaining SA score in an example ( - - < ) (literally: professor - subjectmarker - work).",
        "To calculate the frequencies for the classes associated with ' Val ', we obtain from the Co-occurrence Dictionary (COD)5 the number of occurrences for (w- 751-",
        "< >, where w can be any modifier.",
        "We then obtain from the Concept Dictionary (CD)6 the classes that include titt ' and then sum up all the occurrences of words included in the classes.",
        "The relevant portion of CD for ''in ( ectl - 75/ - t!",
        ")< ) is shown in Figure 1.",
        "The numbers in parenthesis here indicate the summed-up frequencies.",
        "We then calculate the t-score between 75/ - fltb < 'and all the classes that include 'kV '.",
        "See",
        "The t-score for the co-occurrence of the modifier and particle-modificand pair, and ' - < is higher than the threshold when ' tttl 'is replaced with [19111-Cla t.:: A mu] Using (4), the strength of association for the co-occurrence of ( - - it< ) is calculated from the SA between the class AM-Mk tz AINJ1 and ' < When the word in question has more than one sense, we estimate SA corresponding to each sense and choose the one that results in the highest SA score.",
        "For instance, we estimate SA between ' ttV ' and the various senses of and choose the highest value: in this case the one corresponding to the sense 'to be employed.'",
        "Determination of Most Strongly Associated Structure After calculating SA for each possible construction, we choose the construction with highest SA score as the most probable struc",
        "ture.",
        "See the following example:",
        ".technical progress work people stress innovation Here, the arrows show possible dependency relations, the numbers on the arrows the estimated SA, and the thick arrows the dependency with highest mutual information that means the most probable dependency relation.",
        "In the example, tniXte ' modifies AAA' and j < ' modifies A'.",
        "The estimated mutual information for ( MN:VE.751, ) is 2.79 and that for ( * < , A ) is 6.13.",
        "Thus, we choose ' as the modificand for IONTV751 ' and' A' as that for < In the example shown in Figure 2, our method selects the most likely modifier-modificand relation.",
        "Experiment Disambiguation of dependency relations was done using 75 ambiguous constructions from Fukumoto (1992).",
        "Solving the ambiguity in the constructions involves choosing among two or more modifier-particle-modificand relations.",
        "The training data consists of all 568,000 modifier-particle-modificand triplets in COD.",
        "Evaluation We evaluated the performance of our method comparing its results with those of other methods using the same test and training data.",
        "Table 3 shows the various results (success rates).",
        "Here, (1) indicates the performance obtained using the principle of Closest Attachment (Kimball, 1973); (2) shows the performance obtained using the lowest observed class co-occurrence (Weischedel et al., 1993); (3) is the result from the maximum mutual information over all pairs of classes corresponding to the words in the co-occurrence (Resnik, 1993; Alves, 1996); and (4) shows the performance of our method'.",
        "Closest attachment (1) has a low performance since it fails to take into consideration the identity of the words involved in the decision.",
        "Selecting the lowest classes (2) often produces unreliable estimates and wrong decisions due to data sparseness.",
        "Selecting the classes with highest mutual information (3) results in overgeneralization that may lead to incorrect attachments.",
        "Our method avoids both estimating from unreliable classes and overgeneralization and results in better estimates and a better performance.",
        "A qualitative analysis of our results shows two causes of errors, however.",
        "Some errors occurred when there were not enough occurrences of the particle-modificand pattern to estimate"
      ]
    },
    {
      "heading": "3.2 Prepositional Phrase Attachment in English",
      "text": [
        "Prepositional phrase (PP) attachment is a paradigm case of syntactic ambiguity.",
        "The most probable attachment may be chosen comparing the SA between the PP and the various attachment elements.",
        "Here SA is measured by:",
        "where Cu, stands for the class that includes the word w and f is the frequency in a training data containing verb-nounl-preposition-noun2 constructions.",
        "Our method selects from a taxonomy the classes to be used to calculate the SA score and",
        "then chooses the attachment with highest SA score as the most probable.",
        "Experiment We performed a PP attachment experiment on the data that consists of all the 21,046 semantically annotated verb-noun-preposition-noun constructions found in EDR English Corpus.",
        "We set aside 500 constructions for test and used the remaining 20,546 as training data.",
        "We first performed the experiment using various values for the threshold.",
        "Table 4 shows the results.",
        "The first line here shows the default which corresponds to the most likely attachment for each preposition.",
        "For instance, the preposition of is attached to the noun, reflecting the fact that PP's led by of are mostly attached to nouns in the training data.",
        "The 'confidence' values correspond to a binomial distribution and are given only as a references.",
        "The precision grows with t-scores, while coverage decreases.",
        "In order to improve coverage, when the method cannot find a class co-occurrence for which the t-score is above the threshold, we recursively tried to find a co-occurrence using the threshold immediately smaller (see Table 4).",
        "When the method could not find co-occurrences with t-score above the smallest threshold, the default was used.",
        "The overall success rates are shown in \"success\" col-urnn in Table 4.",
        "8 As another way of reducing the sparse data problem, we clustered prepositions using the method described in Wtt and Furugori (1996).",
        "Prepositions like synonyms and antonyms are clustered into groups and replaced by a representative preposition (e.g., till and pending are replaced by until; amongst, amid and amidst are replaced by among.).",
        "Evaluation We evaluated the performance of our method comparing its results with those of other methods with the same test and training data.",
        "The results are given in Table 5.",
        "Here, (5) shows the performance of two native speakers who were just presented quadruples of four head words without surrounding contexts.",
        "The lower bound and the upper bound on the performance of our method seem to be 59.6% scored by the simple heuristic of closest attachment (1) and 87.0% by human beings (4).",
        "Obviously, the success rate of closest attachment (1) is low as it always attaches a word to the noun without considering the words in question.",
        "The unanticipated low success rate of human judges is partly due to the fact that sometimes constructions were inherently ambiguous so that their choices differed from the annotation in the corpus.",
        "Our method (4) performed better than the lowest classes method (2) and maximum MI method (3).",
        "It owes mainly to the fact that our method makes the estimation from class co-occurrences that are more reliable."
      ]
    },
    {
      "heading": "4 Concluding Remarks",
      "text": [
        "We proposed a class-based method that selects classes to be used to estimate the strength of association for word co-occurrences.",
        "The classes selected by our method can be used to estimate various types of strength of association in different applications.",
        "The method differs from other class-based methods in that it allows identification of a reliable and specific class for each co-occurrence in consideration and can deal with date sparseness problem more efficiently.",
        "It",
        "overcame the shortcomings from other methods: overgeneralization and employment of unreliable class co-occurrences.",
        "We applied our method to two structural disambiguation experiments.",
        "In both experiments the performance is significantly better than those of others."
      ]
    }
  ]
}
