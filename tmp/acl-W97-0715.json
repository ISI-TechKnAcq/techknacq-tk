{
  "info": {
    "authors": [
      "Ulrich Reimer",
      "Udo Hahn"
    ],
    "book": "Workshop on Intelligent Scalable Text Summarization",
    "id": "acl-W97-0715",
    "title": "A Formal Model of Text Summarization Based on Condensation Operators of a Terminological Logic",
    "url": "https://aclweb.org/anthology/W97-0715",
    "year": 1997
  },
  "references": [
    "acl-J80-3001"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We present an approach to text summarization that is entirely rooted in the formal description of a classification-based model of terminological knowledge representation and reasoning Text summarization is considered an operator-based transformation process by which knowledge representation structures, as generated by the text understander, are mapped to conceptually condensed representation structures forming a text summary at the representation level • The framework we propose offers a variety of subtle parameters on which scalable text summarization can be based"
      ]
    },
    {
      "heading": "Introduction",
      "text": [
        "From its very beginning, the development of text understanding systems has been intimately tied to the field of knowledge representation and reasoning methods (Schank & Abelson 77) This close relationship was justified by the observation that any adequate form of text understanding not only requires grammatical knowledge about the particular language, but also, among others, has to incorporate knowledge about the domain the text deals with Thus, the uderencing capabilities of knowledge representation languages were considered crucial for any adequate design of text understanding systems Out of this tradition a series of knowledge-based text summarization systems evolved, the methodology of which was almost exclusively based on the Schankian-type of Conceptual Dependency (CD) representations (e g, (Cullingford• '78, Lehnert 81, DeJong 82, Dyer.",
        "83, Tait 85, Alterman 86)) CD representations, however, are formally underspect-fied representation devices lacking any serious formal foundation According to this, the summarization operations these first-generation systems provide use only informal heuristics to determine the salient topics from the text representation structures for the purpose of summarization A second generation of summarization systems then adapted a more mature knowledge representation approach, one based on the evolving methodological framework of hybrid, classification-based knowledge representation languages (d (Woods & Schmolze 92) for a survey) Among these systems count SUSY (Pum et al. 85), SCISOR (Rau 87), and TOPIC (Reimer & Hahn 88), but even in these frameworks no attempt was made to properly integrate the text summarization process into the formal reasoning mechanisms of the underlying knowledge representation language This is where our interest comes in We propose here a model of text summarization that is entirely embedded in the framework of a classification-based model of terminological reasoning Text summarization is considered a formally guided transformation process on knowledge representation structures, the so-called text knowledge base, as derived by a natural language text parser The transformations involved inherit the formal rigor of the underlying knowledge representation model, as corresponding summarization operators build on that model Thus, our work describes a methodologically coherent, representation-theory-based approach to text summarization that has been lacking in the literature so far (for a survey d (Hutchins 87)) Aside from these purely representational considerations, the terminological reasoning framework for the summarization model we propose offers a variety of subtle parameters on which scalable summarization processes can be based This contrasts, in particular, with those approaches to text summarization which almost entirely rely upon built-in features of franie and script-based representations and, consequently,",
        "provide rather simple reduction heuristics in order to produce text summaries (e g, (DeJong 82, Young & Hayes 85)) The formal model we present has been tested in TOPIC (Reimer & Hahn 88), a text summarization system which has been applied to expository texts in the domain of computer equipment as well as to various kinds of texts dealing with legal issues (company regulations, advisory texts, etc ) This paper is organized as follows In Section 2 we lay down a description of the syntax and semantics of the terminological logic which serves as the formal backbone for the specification of condensation operators on (text) knowledge bases From this formal description we then turn to the formal model of text summarization in Section 3"
      ]
    },
    {
      "heading": "2 The Terminological Knowledge Representation Model",
      "text": [
        "In the following, we describe a subset of a terminological logic (for an introduction to its underlying basic notational conventions, cf (Woods & Schmolze 92)) Section 2 1 considers the terminological component, while Section 2 2 deals with appropriate extensions for representing text-specific knowledge"
      ]
    },
    {
      "heading": "2.1 The Basic Terminological Component",
      "text": [
        "We distinguish two kinds of relations, namely properties and conceptual relationships A property denotes a relation between individuals and string or integer values A conceptual relationship denotes a relation between two individuals The concept description language provides constructs to formulate necessary (and possibly sufficient) conditions on the properties and conceptual relationships every element of a concept class is required to have The syntax of this language is given in Fig 1",
        "Every constructor in Fig 1 can be used to define a concept class (c.f Fig 5) The all-p constructor introduces the class of individuals all of which have a certain property (whose value can vary from individual to individual) For example, (all-p price [8200,85000]) denotes the class of individuals that have a property called 'price' with a value ranging between $200 and $5000 An individual can only have one value for each of its properties (cf Fig 2) The all-r constructor introduces a class of individuals that all participate in car-tam kind of relationship to individuals from one of the concept classes given in the constructor For example, (all-r equipped-with OperattngSystem ApplwationSoftware) denotes the class of individuals that are in a relationship called 'equipped-with' only to individuals of the class `OperatingSystem' or the class 'ApplicationSoftware' The distinction between the constructs all-p and all-r is uncommon in the domain of terminological logics (Woods & Schmolze 92), because primitive types like string and integer are usually considered to be concept classes as well As we will see In Section 3, the terminological reasoning underlying the text condensation process exploits this distinction between properties and relationships The exist-v constructor introduces the class of individuals that all have a certain property value For example, (exist-v weight 6 Ms ) denotes the class of individuals that have a property called 'weight' .",
        "with the value '6 Sibs' The exist-e constructor de-lines the class of individuals that have a conceptual relationship to at least one individual of a specific concept class For example, (exist-c has-part Cpu) denotes the class of individuals that are in a relationship called `has-part' to at least one individual of the class `Cpu' With the and constructor several class descriptions can be combined into one (cf Fig 5) The model-theoretic semantics of the terminological language we use is depicted in Fig 2"
      ]
    },
    {
      "heading": "2.2 Representing Text Knowledge",
      "text": [
        "TOPIC's text parser heavily relies on terminological knowledge about the domain the texts deal with (Hahn 89) In the course of text analysis, the parser extends this domain knowledge incrementally by new concept definitions In order to distinguish between prior domain knowledge and newly acquired text knowledge we extend our basic terminological language with the constructs specified in Fig a The operator <r indicates a primitive concept originating from the text analysis Only a limited number of constructs can be used for such a concept definition – they correspond to the kinds of knowledge the parser can extract from a text (see Fig 5) • A new concept can only be acquired when the text makes a reference to a superordmate concept already known in the domain knowledge Thus, the concept expression on the right-hand side of the <T construct must comprise a reference to a superordmate concept, as expressed",
        "e[c] C *exist-] e[a11-p prop ri r.)] = e(all-r ref ci ea)] = - ej(exist-v prop v)] = e((exist-c rel c)] =",
        "• Properties of a new concept can be learned (exist-v construct) • Relationships to other concepts can be learned (exist-c construct) in case the relationship range is already defined by a corresponding all-r construct",
        "The text-knowledge-specific versions of the exist-v and exist-c constructs have an additional argument which serves as a flag that is set whenever one of these constructs is added to a concept description (i e , when the associated property or relationship has been learned) The text condensation component of TOPIC makes use of this flag in order to determine those facts which have been learned since a certain reference point (where all flags were set to 0) Besides acquiring new domain knowledge from a text, the parser performs bookkeeping activities in order to record how often a concept, a property of a concept, or a relationship to another concept is explicitly or implicitly mentioned in the text For this purpose, we provide the constructs ccount, pcount, and rcount for concept descriptions These constructs belong to the text knowledge and can be applied to concept descriptions derived from the text as well as to concepts of the domain knowledge The ccount (pcount) construct indicates how often (a property of) a concept has been mentioned, whereas (rcount rd conc aweight) indicates how often the relationship rel to a concept conc has been referred to We call the numbers introduced by the count operators activation weights An (rcount rel conc aweight) construct can only occur as part of a text concept description when it also contains a construct (all-r rel c1 cn) where conc is subsumed by one of the c,s If this is not the case, rcount refers to a concept being related via a relationship rel which is not in the range of this relationship – thus, the rcount statement would make no sense Since none of the count constructs (and the flags) make an assertion about the meaning of the concepts involved, they have no influence on the concepts' extension (cf Fig 4) Fig 5 illustrates the application of multiple knowledge base operations resulting in the text knowledge representation for the newly learned concept Notebooster' as a specialization of 'Notebook'"
      ]
    },
    {
      "heading": "3 Text Knowledge Condensation",
      "text": [
        "The text condensation process examines the text knowledge base generated by the parser to determine certain distributions of activation weights, patterns of property and relationship assignments to concept descriptions, and particular connectivity patterns of active concepts in the concept hierarchy These constitute the basis for the construction of thematic descriptions as the result of text condensation Only the most significant concepts, relationships and properties (hereafter called salient) are considered as part of a topic description (cf Section 3 1) Thus, text condensation (or, equally, text summarization) can be considered an abstraction process on (text) knowledge bases A topic description is a combination of salient concepts, relationships and properties of a formal text unit The computation of these concepts is started only in certain well-defined intervals In the sub-language domain of expository texts, at least, topic",
        "shifts occur predominantly at paragraph boundaries Therefore, text condensation IS started at the end of every paragraph so that thematic overlaps as well as topic breaks between adjacent paragraphs can be detected and the extension of a topic be exactly delimited The condensation process yields a set of topic descriptions, each one c.haractenzmg one or more adjacent paragraphs of the text (cf Section 3 2) Finally, the entire collection of topic descriptions of a single text can be generalized in terms of a hierarchical text graph (cf Section3 3), the representation form of a text summary"
      ]
    },
    {
      "heading": "3.1 Condensation Operators",
      "text": [
        "We apply several operators to text knowledge bases to determine which concepts, properties, and relationships play a dominant role in the corresponding texts and thus should become part of their topic description All of these operators are grounded in the semantics of the underlying terminological logic Some of the operators make additional use of cut-off values which are heuristically motivated and have been evaluated empirically"
      ]
    },
    {
      "heading": "Salient Concepts:",
      "text": [
        "There are several criteria to determine salient concepts The most simple, less \"knowledgeable\" critenon considers all those concepts salient whose activation weight exceeds the average activation weight of all active concepts 1 A second criterion renders a concept salient, if the total sum of references made to properties of it and to relationships to other concepts-is greater than it is, on the average, the case for all other active concepts (S C1) exploits the structure of the aggregation hierarchy and evaluates it by the associated activation weights (for the definitions of sets and functions we use below, cf Table 1)",
        "While (SC 1) checks the total number of references made to any property or relationship, (SC2) is concerned with the number of different properties and relationships mentioned 'Throughout the paper, we call a concept c an active one, if ccount(c) >0 (cf Table 1)"
      ]
    },
    {
      "heading": "rpj eRuP",
      "text": [
        "IIACII The following two criteria exploit the inherent specialization structure of concept hierarchies (cf also (Lin 95) for a similar perspective on using semantic generalization relations for the computation of concept salience) They thus resemble criteria as used for the definition of macro rules to achieve sum-manes of texts (Correira 80, Dijk 80, Fum et al. 85) These criteria also incorporate some notion of graph connectivity that has previously been considered by (Lehnert 81) for text summarization purposes (SC3) determines an active concept c as being salient if a significant amount of subordinates of c are active, too (SC4) is similar but it marks all non-active (9 concepts as being salient which are related to a significant number of active subordinates Thus, concepts can be included in the topic description which have never been mentioned explicitly in a text (SC4) only yields the most specific concepts, 1 e , it excludes concepts for which the main criterion is fulfilled, but which are superordmate to another concept that also fulfills the criterion Lastly, (SC4) has a more stringent cut-off criterion This is necessary because it makes non-active concepts salient, accordingly, one has to be careful not to include irrelevant concepts Therefore, (SC4) requires a quarter of all subordinates (at least 3) to be active, while (SC3) has a relative cut-off value which gives lower percentages for greater numbers of subordinates (the cut-off values have been determined empirically)",
        "where",
        "Salient Relationships and Salient Properties: Just as certain concepts may have been dealt with more extensively in a text than other ones, single features of a concept definition may have been more focused on than other features of the same concept The following criterion renders a relationship (or property) rp salient if the number of concepts (or property values) to which c has been related via rp Is greater than it is, on the average, the case for relationships (or properties) in c Note that c must be a concept learned during text parsing, as learning new.",
        "features is only possible for such concepts (SR1) evaluated for salient concepts only because we are not interested in salient features of concepts being irrelevant for a topic description"
      ]
    },
    {
      "heading": "Related Salient Concepts:",
      "text": [
        "A concept c' is considered a related salient concept for the salient concept c if there is a relationship rel from c to c' where the sum of the activation weights of all relationships of type rd l from c to ci or to subordinates of c' is greater than the average activation weight of all active relationships for c If c' is determined as a related salient concept for c, then the associated relationship rel becomes a salient relationship of c This criterion combines knowledge about conceptual aggregation and concept hierarchies with a numerical weights (SRC1) A relationship re/ between a salient concept c and some concept c' is considered salient and c' is considered a related salient concept if E rpactive(c, rel,) .> 3 and the following holds",
        "In the following, (c) denotes a salient concept c, (c r) a salient relationship r of concept c, and (c r c') denotes a related salient concept c' for concept c with respect to the relationship r"
      ]
    },
    {
      "heading": "3.2 Paragraph-Level Topic Descriptions",
      "text": [
        "The condensation operators just introduced are applied at the end of every paragraph to the text knowledge base which results from parsing that paragraph They yield a set of salient concepts, relationships, properties, and related salient concepts In the .next step, these raw data are combined to form a compound topic description for that paragraph The combination is performed according to the following rules",
        "• A salient concept (c) which is already covered by a salient relationship or property (c rp) or a related salient concept (c r ci) is removed • A salient relationship (c r) already covered by a related salient concept (c r c') is removed",
        "After having determined the topic description td of the previous paragraph a check is made whether this paragraph deals with the same topic as the immediately preceding paragraph(s), or vice versa If this is the case, the topic description td of the current paragraph is added to the topic description of the preceding paragraph(s), otherwise a new current topic description is created and set to td Formally (cf also Table 2) Let td be the topic description of the last paragraph and td, be the topic description of one or more paragraphs immediately preceding td, then td, is set to td, u td td,Utd td, V td,utd td otherwise Id, Is not modified and td,A4 is set to td For example, the following two topic descriptions of adjacent paragraphs would be combined into one {(Notebooster has-part 486SL), (Notepad)}, {(Notebooster has-part)) .",
        "Analyzing a text this way yields a set of consecutive topic descriptions tdi „td„, each one characterizing the topic of one or more adjacent paragraphs To every topic description td, we associate the corresponding text passage and the facts acquired from it We call the resulting compound structure, in which different media combine, a (hy-per)tert constituent"
      ]
    },
    {
      "heading": "3.3 The Text Graph",
      "text": [
        "From the topic description contained in a text constituent, more generic constituents can be derived in terms of a hierarchy of topic descriptions, forming a text graph The construction of a text graph proceeds from the examination of every pair of basic topic descriptions and takes their conceptual commonalities to generate more genenc thematic characterizations Exhaustively applying this procedure (also taking the newly generated topic abstractions",
        "td , if 3r (c r) E td rdui(c)} = 3r, c' (c r c') E td WU{ (c) , else",
        "Table 2 The Operator U for Combining Topic Descriptions ( \\ stands for the set complement operator) into consideration) results in a text graph as a hierarchy of topic descriptions The most specific descriptions (they correspond to the text constituents) form the leaf nodes of the text graph, the generalized topic descriptions constitute its non-leaf nodes Their hierarchical organization yields different levels of granularity of text summarization (see Fig 6) It is exactly this emergent generalization property of the text graph that we consider the source of our scalability arguments Very brief summaries, only intended to capture the main topics of the text, can be generated from the upper level of the text graph Continuously deepening the traversal level of the text graph provides access to more and more specific information Our procedure thus combines the potential for supplying summaries on the indicative as well as informative level of text knowledge abstraction (cf (Borko & Bernier 76) for the distinction between indicative and informative abstracting)"
      ]
    },
    {
      "heading": "4 Related Work",
      "text": [
        "The task domain of text summarization is characterized by a \"clash of civilizations' From the point of view of natural language understanding proper (Schank & Abelson 77, Dyer 83) it is considered a heavily knowledge-based task requiring a substantial knowledge background In the field of information retrieval, however, the corresponding task of automatic abstracting, has been considered from its very beginning (Luhn 58), a problem that can be dealt with by surface-level pattern matching techniques and statistical methods originally developed for lexical selection tasks such as automatic indexing or classification (Salton et al. 94) This approach has recently been given a lot of attention again, mainly due to the renaissance of statistical methodology in the field of parsing and tagging (Kupiec 95) Given a statistical approach, however, automatic abstracting boils down to a sentence extraction problem, viz determining the most salient sentences based on surface-level lexical or positional indicators We adhere to the knowledge-based paradigm of abstracting and propose to fully integrate text knowledge abstraction in a terminological reasoning model In such an approach, text understanding and summarization are considered within a formally homogeneous framework Moreover, and most important, this model allows for a staged provision of information in summaries based on conceptual criteria (as illustrated by the discussion of text graphs) Such a functionality is unlikely to be achieved by surface-oriented approaches due to their inherent limitations to provide cohesive summaries from large sets of extracted sentences (Fame 90)"
      ]
    },
    {
      "heading": "5 Conclusions",
      "text": [
        "We have mtroducecl an approach to text summarization which is solidly rooted in the formal semantics of the underlying termmological representation system In this approach, text summarization is an operator-based transformation process on knowledge representation structures that have been derived by the text understanding system Currently, the summarization process considers only activity and connectivity patterns in the text knowledge base In the future, we plan to augment these criteria and to ex",
        "plod text coherence patterns for summarization (cf (Hahn 90) and related proposals by (Alterman 86)) The implementation of the summarization system and its associated text understander have proved functional with expository texts in the domain of information technology as well as with texts from the legal and business domains"
      ]
    }
  ]
}
