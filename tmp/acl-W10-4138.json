{
  "info": {
    "authors": [
      "Tian-Jian Jiang",
      "Shih-Hung Liu",
      "Cheng-Lung Sung",
      "Wen-Lian Hsu"
    ],
    "book": "Proceedings of the Joint Conference on Chinese Language Processing",
    "id": "acl-W10-4138",
    "title": "Term Contributed Boundary Tagging by Conditional Random Fields for SIGHAN 2010 Chinese Word Segmentation Bakeoff",
    "url": "https://aclweb.org/anthology/W10-4138",
    "year": 2010
  },
  "references": [
    "acl-C04-1081",
    "acl-I05-3027",
    "acl-N06-2049",
    "acl-W03-1728"
  ],
  "sections": [
    {
      "text": [
        "Tian-Jian Jiang^ Shih-Hung Liu* Cheng-Lung Sung* Wen-Lian Hsu^",
        "^Department of ^Department of ^Institute of",
        "Computer Science Electrical Engineering Information Science",
        "National Tsing-Hua University National Taiwan University Academia Sinica",
        "This paper presents a Chinese word segmentation system submitted to the closed training evaluations of CIPS-SIGHAN-2010 bakeoff.",
        "The system uses a conditional random field model with one simple feature called term contributed boundaries (TCB) in addition to the \"BI\" character-based tagging approach.",
        "TCB can be extracted from unlabeled corpora automatically, and segmentation variations of different domains are expected to be reflected implicitly.",
        "The experiment result shows that TCB does improve \"BI\" tagging domain-independently about 1% of the F1 measure score."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "The CIPS-SIGHAN-2010 bakeoff task of Chinese word segmentation is focused on cross-domain texts.",
        "The design of data set is challenging particularly.",
        "The domain-specific training corpora remain unlabeled, and two of the test corpora keep domains unknown before releasing, therefore it is not easy to apply ordinary machine learning approaches, especially for the closed training evaluations."
      ]
    },
    {
      "heading": "2. Methodology",
      "text": [
        "2.1 The \"BI\" Character-Based Tagging of Conditional Random Field as Baseline",
        "The character-based \"OBI\" tagging of Conditional Random Field (Lafferty et al., 2001) has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).",
        "Under the scheme, each character of a word is labeled as 'B' if it is the first character of a multiple-character word, or 'I' otherwise.",
        "If the character is a single-character word itself, \"O\" will be its label.",
        "As Table 1 shows, the lost of performance is about 1% by replacing \"O\" with \"B\" for character-based CRF tagging on the dataset of CIPS-SIGHAN-2010 bakeoff task of Chinese word segmentation, thus we choose \"BI\" as our baseline for simplicity, with this 1% lost bearing in mind.",
        "In tables of this paper, SC stands for Simplified Chinese and TC represents for Traditional Chinese.",
        "Test corpora of SC and TC are divided into four domains, where suffix A, B, C and D attached, for texts of literature, computer, medicine and finance, respectively.",
        "Table 1.",
        "OBI vs. BI; where the lost of F > 1%, such as SC-B, is caused by incorrect English segments that will be discussed in the section 4.",
        "R",
        "P",
        "F",
        "OOV",
        "SC-A",
        "OBI",
        "0.906",
        "0.916",
        "0.911",
        "0.539",
        "BI",
        "0.896",
        "0.907",
        "0.901",
        "0.508",
        "SC-B",
        "OBI",
        "0.868",
        "0.797",
        "0.831",
        "0.410",
        "BI",
        "0.850",
        "0.763",
        "0.805",
        "0.327",
        "SC-C",
        "OBI",
        "0.897",
        "0.897",
        "0.897",
        "0.590",
        "BI",
        "0.888",
        "0.886",
        "0.887",
        "0.551",
        "SC-D",
        "OBI",
        "0.900",
        "0.903",
        "0.901",
        "0.472",
        "BI",
        "0.888",
        "0.891",
        "0.890",
        "0.419",
        "TC-A",
        "OBI",
        "0.873",
        "0.898",
        "0.886",
        "0.727",
        "BI",
        "0.856",
        "0.884",
        "0.870",
        "0.674",
        "TC-B",
        "OBI",
        "0.906",
        "0.932",
        "0.919",
        "0.578",
        "BI",
        "0.894",
        "0.920",
        "0.907",
        "0.551",
        "TC-C",
        "OBI",
        "0.902",
        "0.923",
        "0.913",
        "0.722",
        "BI",
        "0.891",
        "0.914",
        "0.902",
        "0.674",
        "TC-D",
        "OBI",
        "0.924",
        "0.934",
        "0.929",
        "0.765",
        "BI",
        "0.908",
        "0.922",
        "0.915",
        "0.722",
        "The word boundary and the word frequency are the standard notions of frequency in corpus-based natural language processing, but they lack the correct information about the actual boundary and frequency of a phrase's occurrence.",
        "The distortion of phrase boundaries and frequencies was first observed in the Vodis Corpus when the bigram \"RAIL ENQUIRIES\" and tri-gram \"BRITISH RAIL ENQUIRIES\" were examined and reported by O'Boyle (1993).",
        "Both of them occur 73 times, which is a large number for such a small corpus.",
        "\"ENQUIRIES\" follows \"RAIL\" with a very high probability when it is preceded by \"BRITISH.\"",
        "However, when \"RAIL\" is preceded by words other than \"BRITISH,\" \"ENQUIRIES\" does not occur, but words like \"TICKET\" or \"JOURNEY\" may.",
        "Thus, the bigram \"RAIL ENQUIRIES\" gives a misleading probability that \"RAIL\" is followed by \"ENQUIRIES\" irrespective of what precedes it.",
        "This problem happens not only with word-token corpora but also with corpora in which all the compounds are tagged as units since overlapping N-grams still appear, therefore corresponding solutions such as those of Zhang et al.",
        "(2006) were proposed.",
        "We uses suffix array algorithm to calculate exact boundaries of phrase and their frequencies (Sung et al., 2008), called term contributed boundaries (TCB) and term contributed frequencies (TCF), respectively, to analogize similarities and differences with the term frequencies (TF).",
        "For example, in Vodis Corpus, the original",
        "TF of the term \"RAIL ENQUIRIES\" is 73.",
        "However, the actual TCF of \"RAIL ENQUIRIES\" is 0, since all of the frequency values are contributed by the term \"BRITISH RAIL EN",
        "QUIRIES\".",
        "In this case, we can see that 'BRITISH RAIL ENQUIRIES' is really a more frequent term in the corpus, where \"RAIL ENQUIRIES\" is not.",
        "Hence the TCB of \"BRITISH RAIL ENQUIRIES\" is ready for CRF tagging as \"BRITISH/TB RAIL/TB ENQUIRIES/TI,\" for example."
      ]
    },
    {
      "heading": "3. Experiments",
      "text": [
        "Besides submitted results, there are several different experiments that we have done.",
        "The configuration is about the trade-off between data sparseness and domain fitness.",
        "For the sake of OOV issue, TCBs from all the training and test corpora are included in the configuration of submitted results.",
        "For potentially better consistency to different types of text, TCBs from the training corpora and/or test corpora are grouped by corresponding domains of test corpora.",
        "Table 2 and Table 3 provide the details, where the baseline is the character-based \"BI\" tagging, and others are \"BI\" with additional different TCB configurations: TCBall stands for the submitted results; TCBa, TCBb, TCBta, TCBft, TCBte, TCBtd represents TCB extracted from the training corpus A, B, and the test corpus A, B, C, D, respectively.",
        "Table 2 indicates that F1 measure scores can be improved by TCB about 1%, do-main-independently.",
        "Table 3 gives a hint of the major contribution of performance is from TCB of each test corpus.",
        "R",
        "P",
        "F",
        "OOV",
        "SC-A",
        "BI",
        "0.896",
        "0.907",
        "0.901",
        "0.508",
        "TCBall",
        "0.917",
        "0.921",
        "0.919",
        "0.699",
        "SC-B",
        "BI",
        "0.850",
        "0.763",
        "0.805",
        "0.327",
        "TCBall",
        "0.876",
        "0.799",
        "0.836",
        "0.456",
        "SC-C",
        "BI",
        "0.888",
        "0.886",
        "0.887",
        "0.551",
        "TCBall",
        "0.900",
        "0.896",
        "0.898",
        "0.699",
        "SC-D",
        "BI",
        "0.888",
        "0.891",
        "0.890",
        "0.419",
        "TCBall",
        "0.910",
        "0.906",
        "0.908",
        "0.562",
        "TC-A",
        "BI",
        "0.856",
        "0.884",
        "0.870",
        "0.674",
        "TCBall",
        "0.871",
        "0.891",
        "0.881",
        "0.670",
        "TC-B",
        "BI",
        "0.894",
        "0.920",
        "0.907",
        "0.551",
        "TCBall",
        "0.913",
        "0.917",
        "0.915",
        "0.663",
        "TC-C",
        "BI",
        "0.891",
        "0.914",
        "0.902",
        "0.674",
        "TCBall",
        "0.900",
        "0.915",
        "0.908",
        "0.668",
        "TC-D",
        "BI",
        "0.908",
        "0.922",
        "0.915",
        "0.722",
        "TCBall",
        "0.929",
        "0.922",
        "0.925",
        "0.732",
        "TCBta + TCBa",
        "TCB vs. TCBall",
        "Table 3b.",
        "Traditional Chinese Domain-specific"
      ]
    },
    {
      "heading": "4. Error Analysis",
      "text": [
        "The most significant type of error in our results is unintentionally segmented English words.",
        "Rather than developing another set of tag for English alphabets, we applies post-processing to fix this problem under the restriction of closed training by using only alphanumeric character information.",
        "Table 4 compares F1 measure score of the Simplified Chinese experiment results before and after the post-processing.",
        "SC-A OBI BI",
        "TCBall SC-B OBI",
        "TCBtb + TCBb TCBall SC-C OBI",
        "TCBall SC-D OBI",
        "F1 measure score",
        "The major difference between gold standards of the Simplified Chinese corpora and the Traditional Chinese corpora is about non-Chinese characters.",
        "All of the alphanumeric and the punctuation sequences are separated from Chinese sequences in the Simplified Chinese corpora, but can be part of the Chinese word segments in the Traditional Chinese corpora.",
        "For example, a phrase \"ISffl / simvastatin / ( / statins II / M / – / S / ) \" ('/' represents the word boundary) from the domain C of the test data cannot be either recognized by \"BI\" and/or TCB tagging approaches, or post-processed.",
        "This is the reason why Table 4 does not come along with Traditional Chinese experiment results.",
        "Some errors are due to inconsistencies in the gold standard of non-Chinese character, For example, in the Traditional Chinese corpora, some percentage digits are separated from their percentage signs, meanwhile those percentage signs are connected to parentheses right next to them."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "This paper introduces a simple CRF feature called term contributed boundaries (TCB) for",
        "F",
        "OOV",
        "SC-A",
        "TCBta",
        "0.918",
        "0.690",
        "TCBa",
        "0.917",
        "0.679",
        "TCBta + TCBa",
        "0.917",
        "0.690",
        "TCBall",
        "0.919",
        "0.699",
        "SC-B",
        "TCBtb",
        "0.832",
        "0.465",
        "TCBb",
        "0.828",
        "0.453",
        "TCBtb + TCBb",
        "0.830",
        "0.459",
        "TCBall",
        "0.836",
        "0.456",
        "SC-C",
        "TCBtc",
        "0.897",
        "0.618",
        "TCBall",
        "0.898",
        "0.699",
        "SC-D",
        "TCBtd",
        "0.905",
        "0.557",
        "TCBall",
        "0.910",
        "0.562",
        "Table 3a.",
        "Simplified Chinese Domain-specific",
        "TCB vs. TCBall",
        "F",
        "OOV",
        "TC-A",
        "TCBta",
        "0.889",
        "0.706",
        "TCBa",
        "0.888",
        "0.690",
        "TCBta + TCBa",
        "0.889",
        "0.710",
        "TCBall",
        "0.881",
        "0.670",
        "TC-B",
        "TCBtb",
        "0.911",
        "0.636",
        "TCBb",
        "0.921",
        "0.696",
        "TCBtb + TCBb",
        "0.912",
        "0.641",
        "TCBall",
        "0.915",
        "0.663",
        "TC-C",
        "TCBtc",
        "0.918",
        "0.705",
        "TCBall",
        "0.908",
        "0.668",
        "TC-D",
        "TCBtd",
        "0.927",
        "0.717",
        "TCBall",
        "0.925",
        "0.732",
        "Chinese word segmentation.",
        "The experiment result shows that it can improve the basic \"BI\" tagging scheme about 1% of the F1 measure score, domain-independently.",
        "Further tagging scheme for non-Chinese characters are desired for recognizing some sophisticated gold standard of Chinese word segmentation that concatenates alphanumeric characters to Chinese characters.",
        "Acknowledgement",
        "The CRF model used in this paper is developed based on CRF++, http://crfpp.sourceforge.net/",
        "Term Contributed Boundaries used in this paper are extracted by YASA, http://yasa.",
        "newzilla.",
        "org/"
      ]
    }
  ]
}
