{
  "info": {
    "authors": [
      "Maja Popović"
    ],
    "book": "Proceedings of the Sixth Workshop on Statistical Machine Translation",
    "id": "acl-W11-2110",
    "title": "Morphemes and POS tags for n-gram based evaluation metrics",
    "url": "https://aclweb.org/anthology/W11-2110",
    "year": 2011
  },
  "references": [
    "acl-E09-1087",
    "acl-P02-1040",
    "acl-W09-0401",
    "acl-W09-0402",
    "acl-W10-1703"
  ],
  "sections": [
    {
      "text": [
        "Maja Popovic",
        "German Research Center for Artificial Intelligence (DFKI) Language Technology (LT), Berlin, Germany maj a.popovic@dfki.de",
        "We propose the use of morphemes for automatic evaluation of machine translation output, and systematically investigate a set of F score and bleu score based metrics calculated on words, morphemes and pos tags along with all corresponding combinations.",
        "Correlations between the new metrics and human judgments are calculated on the data of the third, fourth and fifth shared tasks of the Statistical Machine Translation Workshop.",
        "Machine translation outputs in five different European languages are used: English, Spanish, French, German and Czech.",
        "The results show that the F scores which take into account morphemes and pos tags are the most promising metrics."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Recent investigations have shown that the n-gram based evaluation metrics calculated on Part-of-Speech (pos) sequences correlate very well with human judgments (Callison-Burch et al., 2008; Callison-Burch et al., 2009; Popovic and Ney, 2009) clearly outperforming the widely used metrics BLEU and ter.",
        "The bleu score measured on morphemes is shown to be useful for evaluation of morphologically rich languages (Luong et al., 2010).",
        "We propose the use of morphemes for a set of n-gram based automatic evaluation metrics and investigate the correlation of the novel metrics with human judgments.",
        "We carry out a systematic comparison between the F and BLEU based metrics calculated on various combinations of words, morphemes and pos tags.",
        "The focus of this work is not a comparison of the morpheme and pos based metrics with the standard evaluation metrics as in (Popovic and Ney, 2009), but rather a comparison within the proposed set of metrics in order to decide which score(s) should be submitted to the wmt 2011 evaluation task.",
        "There are fifteen evaluation metrics in total, which can be divided in three groups: the metrics calculated on single units, i.e. words, morphemes or POS tags alone, the metrics calculated on pairs, i.e. words and pos tags, words and morphemes as well as morphemes and POS tags, and the metrics which take everything into account - lexical, morphological and syntactic information, i.e. words, morphemes and pos tags.",
        "Spearman's rank correlation coefficients on the document (system) level between all the metrics and the human ranking are computed on the English, French, Spanish, German and Czech texts generated by various translation systems in the framework of the third (Callison-Burch et al., fifth (Callison-Burch et al., 2010) shared translation tasks."
      ]
    },
    {
      "heading": "2. Evaluation metrics",
      "text": [
        "We carried out a systematic comparison between the following metrics:",
        "• single unit (word/morpheme/POS) metrics: - wordF",
        "Standard F score: takes into account all word n-grams which have a counterpart both in the corresponding reference and in the hypothesis.",
        "Morpheme F score: takes into account all morpheme n-grams which have a counterpart both in the corresponding reference and in the hypothesis.",
        "pos F score: takes into account all pos n-grams which have a counterpart both in the corresponding reference and in the hypothesis.",
        "The standard bleu score (Papineni et al., 2002).",
        "- posBleu",
        "The standard BLEU score calculated on pos tags.",
        "- morphBleu",
        "The standard BLEU score calculated on morphemes.",
        "• pairwise metrics:",
        "F score of word and pos n-grams.",
        "F score of word and morpheme n-grams.",
        "F score of morpheme and pos n-grams.",
        "Arithmetic mean of bleu and posBleu scores.",
        "Arithmetic mean of bleu and MOR-phBleu scores.",
        "Arithmetic mean of morphBleu and posBleu scores.",
        "• metrics taking everything into account:",
        "F score on word, morpheme and pos n-grams.",
        "- wmpBleu",
        "Arithmetic mean of bleu, morphBleu and posBleu scores.",
        "- wmpFBleu",
        "Arithmetic mean ofall F and BLEu scores.",
        "The prerequisite for pos based metrics is availability of an appropriate pos tagger for the target language.",
        "It should be noted that the pos tags cannot be only basic but must have all details (e.g. verb tenses, cases, number, gender, etc.).",
        "For the morpheme based metrics, a tool for splitting words into morphemes is necessary.",
        "All the F scores and the BLEu scores are based on four-grams (i.e. the value of maximal n is 4).",
        "Preliminary experiments on the morpheme based measures showed that there is no improvement by using six-grams, seven-grams or eight-grams.",
        "As for the n-gram averaging, BLEu scores use geometric mean.",
        "However, it is also argued not to be optimal because the score becomes equal to zero even ifonly one of the n-gram counts is equal to zero.",
        "In addition, previous experiments on the syntax-oriented n-gram metrics (Popovic and Ney, 2009) showed that there is no significant difference between arithmetic and geometric mean in the terms ofcorrelation coefficients.",
        "Therefore, arithmetic averaging without weights is used for all F-scores.",
        "For the wmpF score, an additional experiment with weights is carried out as well.",
        "Experimental set-up",
        "The evaluation metrics were compared with human rankings by means of Spearman correlation coefficients p. Spearman's rank correlation coefficient is equivalent to pearson correlation on ranks, and its advantage is that it makes fewer assumptions about the data.",
        "The possible values of p range between 1 (if all systems are ranked in the same order) and 1 (if all systems are ranked in the reverse order).",
        "Thus the higher the value of p for an automatic metric, the more similar is to the human metric.",
        "The scores were calculated for outputs of translations from spanish, French, German and Czech into English and vice versa.",
        "spanish, French, German and English pos tags were produced using the Tree-Tagger, and the Czech texts are tagged using the",
        "COMPOST tagger (Spoustova et al., 2009).",
        "In this way, all references and hypotheses were provided with detailed pos tags.",
        "The words of all outputs were split into morphemes using the Morfessor tool (Creutz and La-gus, 2005).",
        "The tool is corpus-based and language-independent: it takes a text as input and produces a segmentation of the word forms observed in the text.",
        "The obtained results are not strictly linguistic, however they often resemble a linguistic morpheme segmentation.",
        "once a morpheme segmentation has been learnt from some text, it can be used for segmenting new texts.",
        "In our experiments, for each document, first a corresponding reference translation has been split, and then this segmentation is used for splitting all translation hypotheses.",
        "In this way, possible discrepancies between reference and hypothesis segmentation of the same word are avoided.",
        "Effects of the training on the large(r) monolingual corpora have not been investigated yet.",
        "In Table 1, an English reference sentence can be seen along with its morpheme and pos equivalents.",
        "words Another leading role in the film is played by Matt Damon .",
        "morphemes An other leading role in the film is played by Matt Damon .",
        "VBZ VBN IN NP NP SENT Comparison of metrics",
        "For each evaluation metric described in section 2, the system level Spearman correlation coefficients p were calculated for each document.",
        "In total, 33 correlation coefficients were obtained for each metric four English outputs from the wmt 2010 task, five from the wmt 2009 and eight from the wmt 2008 task, together with sixteen outputs in other four target languages.",
        "The obtained correlation results were then summarised into the following three values:",
        "a correlation coefficient averaged over all translation outputs; percentage of documents where the particular metric has better correlation than the other metrics investigated in this work; percentage of documents where the particular metric has better or equal correlation than the other metrics investigated in this work.",
        "These values for each metric are presented in Table 2.",
        "Table 2: Average correlation mean (column 1), rank> (column 2) and rank> (column 3) for each evaluation metric.",
        "Bold represents the best value in the particular metric group.",
        "The most promising metrics are the F scores containing pos and morpheme information, namely wmpF', mpF and posF, as well as the posBleu score.",
        "The standard BLEu score has very low values.",
        "It can be observed that the morpheme based metrics outperform the word based metrics, however not the pos based metrics.",
        "As for pairwise metrics, the mpF score seems to be very promising.",
        "Adding the actual original words unfortunately deteriorates the system level correlations, nevertheless omitting the words can possibly lead to the poor sentence level correlations.",
        "Therefore an additional experiment is carried out with the most promising metric containing words, namely the wmpF score: a weighted wmpF' score is introduced, with word weight of 0.2, morpheme weight of 0.3 and pos weight of 0.5. wmpF' clearly outperforms the simple WMPF score without weights, and it is comparable to the morpheme-POS F score mpF as well as POS-based metrics posF and posBleu.",
        "Apart from that, it can be observed that, in general, the F scores are better than the BLEu scores.",
        "The combination of all F and all bleu scores (wmpFBleu) is better than the wmpBleu score, but does not yield any improvements over the wmpF score.",
        "metric",
        "mean",
        "rank>",
        "rank>",
        "wordF",
        "0.550",
        "24.2",
        "42.6",
        "morphF",
        "0.608",
        "40.0",
        "58.0",
        "posF",
        "0.673",
        "63.4",
        "78.0",
        "bleu",
        "0.566",
        "20.6",
        "38.6",
        "morphBleu",
        "0.567",
        "29.9",
        "44.6",
        "posBleu",
        "0.674",
        "54.7",
        "66.9",
        "wpF",
        "0.627",
        "44.0",
        "66.9",
        "wmF",
        "0.587",
        "37.0",
        "53.9",
        "mpF",
        "0.669",
        "51.9",
        "77.4",
        "wpBleu",
        "0.629",
        "41.0",
        "57.4",
        "wmBleu",
        "0.557",
        "23.6",
        "41.0",
        "mpBleu",
        "0.634",
        "44.6",
        "66.6",
        "wmpF",
        "0.645",
        "46.3",
        "71.1",
        "wmpBleu",
        "0.610",
        "32.7",
        "54.7",
        "wmpFBleu",
        "0.628",
        "35.8",
        "61.6",
        "wmpF'",
        "0.668",
        "51.9",
        "78.8",
        "The most promising metrics are the F scores containing POS and morpheme information, namely posF, mpF and wmpF' together with the wmpF, as well as the posBleu score.",
        "The standard bleu score has the third lowest average correlation and the lowest rank values."
      ]
    },
    {
      "heading": "4. Conclusions",
      "text": [
        "The results presented in this article show that the use of morphemes improves n-gram based automatic evaluation metrics, particularly in combination with syntactic information in the form of detailed POS tags.",
        "Especially promising are the weighted wmpF and the mpF scores, which have been submitted to the WMT 2011 evaluation task.",
        "Weights for these two metrics should be further investigated in future work, as well as the possible impact of different morpheme splittings (such as training on larger texts)."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work has partly been developed within the taraXU project financed by TSB Technologiestiftung Berlin - Zukunftsfonds Berlin, co-financed by the European union - European fund for regional development.",
        "Chris Callison-Burch, philipp Koehn, Christof Monz, and Josh Schroeder.",
        "2009.",
        "Findings of the 2009 Workshop on statistical Machine Translation.",
        "In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 1-28, Athens, Greece, March.",
        "Chris Callison-Burch, philipp Koehn, Christof Monz, Kay peterson, Mark przybocki, and omar Zaidan.",
        "2010.",
        "Findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation.",
        "In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR (WMT 10), pages 17-53, Uppsala, Sweden, July.",
        "Mathias Creutz and Krista Lagus 2005 unsupervised morpheme segmentation and morphology induction from text corpora using morfessor 1.0.",
        "Technical Report Report A81, Computer and Information science, Helsinki University of Technology, Helsinki, Finland, March.",
        "Minh-Thang Luong, Preslav Nakov, and Min-Yen Kan. 2010.",
        "A Hybrid Morpheme-Word Representation for Machine Translation of Morphologically Rich Languages.",
        "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 10), pages 148-157, Cambridge, MA, October.",
        "Kishore papineni, salim Roukos, Todd Ward, and Wie-Jing Zhu.",
        "2002.",
        "BLEu: a method for automatic evaluation of machine translation.",
        "In Proceedings ofthe 40th Annual Meeting of the Association for Computational Linguistics (ACL 02), pages 311-318, Philadelphia, pA, July.",
        "Maja Popovic and Hermann Ney.",
        "2009.",
        "Syntax-oriented evaluation measures for machine translation output.",
        "In Proceedings of the 4th EACL 09 Workshop on Statistical Machine Translation (WMT 09), pages 29-32, Athens, Greece, March.",
        "Drahomira \"Johanka\" Spoustova, Jan Hajic, Jan Raab, and Miroslav spousta.",
        "2009. semi-supervised training for the averaged perceptron pos tagger.",
        "In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages 763-771, Athens, Greece, March."
      ]
    }
  ]
}
