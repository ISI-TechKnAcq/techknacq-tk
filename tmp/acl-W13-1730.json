{
  "info": {
    "authors": [
      "Barbora Hladka",
      "Martin Holub",
      "Vincent Kriz"
    ],
    "book": "BEA",
    "id": "acl-W13-1730",
    "title": "Feature Engineering in the NLI Shared Task 2013: Charles University Submission Report",
    "url": "https://aclweb.org/anthology/W13-1730",
    "year": 2013
  },
  "references": [
    "acl-N03-1033",
    "acl-P12-2039",
    "acl-W08-1205",
    "acl-W10-1004",
    "acl-W10-1802",
    "acl-W12-2024",
    "acl-W13-1706"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, pages 232?241, Atlanta, Georgia, June 13 2013. c?2013 Association for Computational Linguistics Feature Engineering in the NLI Shared Task 2013:"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "Our goal is to predict the first language (L1) of English essays's authors with the help of the TOEFL11 corpus where L1, prompts (topics) and proficiency levels are provided.",
        "Thus we approach this task as a classification task employing machine learning methods.",
        "Out of key concepts of machine learning, we focus on feature engineering.",
        "We design features across all the L1 languages not making use of knowledge of prompt and proficiency level.",
        "During system development, we experimented with various techniques for feature filtering and combination optimized with respect to the notion of mutual information and information gain.",
        "We trained four different SVM models and combined them through majority voting achieving accuracy 72.5%."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Learner corpora are collections of texts written by second language (L2) learners, e.g. English as L2 ?",
        "ICLE (Granger et al., 2009), Lang-8 (Tajiri et al., 2012), Cambridge Learner Corpus,1 German as L2 ?",
        "FALKO (Reznicek et al., 2012), Czech as L2 ?",
        "CzeSL (Hana et al., 2010).",
        "They are a valuable resource for second language acquisition research, identifying typical difficulties of learners of a certain proficiency level (e.g. low/medium/high) or learners of a certain native language (L1 learners of L2).",
        "Research on the learner corpora does not concentrate on text collections only.",
        "Studying the errors in learner language is undertaken in the form",
        "of error annotation like in the projects (Hana et al., 2012), (Boyd et al., 2012), (Rozovskaya and Roth, 2010), (Tetreault and Chodorow, 2008).",
        "Once the errors and other relevant data are recognized in the learner corpora, automatic procedures for e.g. error correction, author profiling, native language identification etc.",
        "can be designed.",
        "Our attention is focused on the task of automatic Native Language Identification (NLI), namely with English as L2.",
        "In this report, we summarize the involment of the Charles University team in the first shared task in NLI co-located with the 8th Workshop on Innovative Use of NLP for Building Educational Applications in June 2013 in Atlanta, USA.",
        "The report is organized as follows: we briefly review related works in Section 2.",
        "The data sets to experiment with are characterized in Section 3.",
        "Section 4 lists the main concepts we pursue during the system development.",
        "Our approach is entirely focused on feature engineering and thus Section 5 is the most important one.",
        "We present there our main motivation for making such a decision, describe patterns according to which the features are generated and techniques that manipulate the features.",
        "We revise our ideas experimentally as documented in Section 6.",
        "In total, we submitted five systems to the subtask of closed-training.",
        "In Sections 7 and 8, we describe these systems and discuss their results in detail.",
        "We summarize our two month effort in the shared task in Section 9."
      ]
    },
    {
      "heading": "2 Related work",
      "text": [
        "We understand the task of native language identification as a subtask of natural language processing and we consider it as still a young task since the very first attempt to address it occurred eight years ago in 2005, as evident from the literature, namely (Koppel et al., 2005b), (Koppel et al., 2005a).",
        "We appreciate all the previous work concerned with the given topic but we focus on the latest three papers only, all of them published at the 24th International Conference on Computational Linguistics held in December 2012 in Bombay, India, namely (Brooke and Hirst, 2012), (Bykh and Meur-ers, 2012), and (Tetreault et al., 2012).",
        "They provide a comprehensive review of everything done since the very first attempts.",
        "We do not want to replicate their chapters.",
        "Rather, we summarize them from the aspects we consider the most important ones in any machine learning system, namely the data, the feature design, the feature manipulation, and the machine learning methods - see Table 1."
      ]
    },
    {
      "heading": "3 Data sets",
      "text": [
        "A new publicly available corpus of non-native English writing called TOEFL112 consists of essays on eight different topics written by non-native speakers of three proficiency levels (low/medium/high); the essays?",
        "authors have 11 different native languages.",
        "The corpus contains 1,100 essays per language with an average of 348 word tokens per essay.",
        "A corpus description and motivation to build such corpus can be found in (Blanchard et al., 2013).",
        "The texts from TOEFL11 were released for the purpose of the shared task as three subsets, namely Train for training, DevTest for testing while system development, and EvalTest for final testing.",
        "The texts were already tokenized and we processed them with the Standford POS tagger (Toutanova et al., 2003)."
      ]
    },
    {
      "heading": "4 System settings",
      "text": [
        "1.",
        "Task: Having a collection of English essays written by non-native speakers, the goal is to",
        "predict a native language of the essays?",
        "authors.",
        "2Source: Derived from data provided by ETS.",
        "Copyright c?",
        "2013 ETS.",
        "www.ets.org.",
        "Languages L1 are known in advance.",
        "Since we have a collection of English essays for which L1 is known (TOEFL11) at our disposal, we formulate this task as a classification task addressed by using supervised machine learning methods.",
        "2.",
        "Feature set: A setA = {A1, A2, ..., Am} ofm features where m changes as we perform various feature combinations and filtering steps.",
        "We prefer to work with binary features.",
        "We do not include two extra features, proficiency level and prompt, provided with the data.",
        "In addition, we design features across all 11 languages, i.e. we do not design features separately for a particular L1.",
        "Doing so, we address the task of predicting L1 from the text only, without any additional knowledge.",
        "3.",
        "Input data: A set X of instances being texts from TOEFL11 corpus represented as feature vectors, x = ?x1, x2, ..., xm?",
        "?",
        "X,xi ?",
        "Ai.",
        "4.",
        "Output classes: A set C of L1 languages, C = {ARA, CHIN, FRE, GER, HIN, ITA, JPN, KOR, SPA, TEL, TUR}, |C |= 11.",
        "5.",
        "True prediction: A set D = {< x, y >: x ?",
        "X , y ?",
        "C}, |D |= 12, 100 and its pairwise disjoint subsets Train, DevTest, EvalTest where Train ?",
        "DevTest ?",
        "EvalTest = D,",
        "6.",
        "Training data: Train ?",
        "DevTest.",
        "No other type of training data is used.",
        "7.",
        "Learning mechanism: Since we focus on fea",
        "ture engineering, we do not study appropriateness of particular machine learning methods to our task in details.",
        "Instead, reviewing the related works, we selected the Support Vector Machine algorithm to experiment with.",
        "8.",
        "Evaluation: 10-fold cross-validation with the sample Train ?",
        "DevTest.",
        "Accuracy, Precision, Recall.",
        "Proficiency-based evaluation.",
        "Topic-based evaluation."
      ]
    },
    {
      "heading": "PAPER DATA FEATURE FEATURE ML DESIGN MANIPULATION METHOD",
      "text": []
    },
    {
      "heading": "5 Feature engineering",
      "text": [
        "We split the process of feature engineering into two mutually interlinked steps.",
        "The first step aims at an understanding of the task projected into features describing properties of entities we experiment with.",
        "These experiments represent the second step where we find out how the features interact with each other and how they interact with a chosen machine learning algorithm.",
        "We compose a feature family as a group of patterns that are relevant for a particular task.",
        "The features are then extracted from the data according to them.",
        "Since we experiment with English texts written by non-native speakers, we have to search for specific and identifiable text properties, i.e. tendencies of certain first language writers, based on the errors caused by the difference between L1 and L2.",
        "In addition, we look for phenomena that are not necessarily incorrect in written English but they provide clear evidence of characteristics typical for L1.",
        "Our feature family is built from chunks of various length in the texts, formally lexically and part-of-speech based n-grams.",
        "In total, the feature family contains eight patterns described in Table 2 - six for binary features l,n,p,s1,s2,sp and two for continuous features a,r.",
        "Outside the feature family, its patterns can be combined into joint patterns, like l+sp, n+sp+r.",
        "Considering the key issues of machine learning,",
        "we mainly pay attention to overfitting.",
        "We are aware of many aspects that may cause overfitting, like complexity of the model trained, noise in training data, a small amount of training data.",
        "Features can lead to overfitting as well, thus we address it using elaborated feature engineering visualised in Figure 1.",
        "We can see there the data components and the process components having the features in common.",
        "The scheme can be traced either with individual patterns from the feature family or with joint patterns.",
        "Both basic feature filtering and advanced feature manipulation apply selected concepts from informa"
      ]
    },
    {
      "heading": "FEATURE DESCRIPTION EXAMPLES FAMILY n=1,2,3 PATTERN",
      "text": [
        "l n-grams of lemmas picture; to see; you, be, not n n-grams of words picture; to see; you, are, not p n-grams of function words and POS tags of content words, i.e. nouns, verbs, adjectives, cardinal numbers not; PRP; you, VBP; JJ, to, VB s1 skipgrams of words: bigram wi?2, wi and trigrams wi?3, wi?1, wi, wi?3, wi?2, wi extracted from a sequence of words wi?3 wi?2 wi?1 wi you,not; able, see; to, see,in; to things, in s2 skipgrams of words: bigrams wi?3, wi, wi?4, wi and trigrams wi?4, wi?3, wi, wi?4, wi?2, wi, wi?4, wi?1, wi extracted from a sequence of words",
        "sp n-grams of function words and shrunken POS tags of content words: POS tags N* are shrunken into a tag N, V* into V, J* into J not; PRP; you V; J to V a relative frequency of POS tags and function words r relative frequency of POS tags",
        "see things in a big picture.",
        "tagged as follows: (You/you/PRP are/be/VBP not/not/RB able/able/JJ to/to/TO see/see/VB things/thing/NNS in/in/IN a/a/DT big/big/JJ picture/picture/NN ././.)",
        "tion theory."
      ]
    },
    {
      "heading": "5.1 Concepts from information theory",
      "text": [
        "Consider a random variable A having two possible values 0 and 1 where the probability of 1 is p and 0 is 1 ?",
        "p. A degree of uncertainty we deal with when predicting the value of the variable depends on p. If p is close to zero or one, then we are almost confident about the value and our uncertainty is low.",
        "If the values are equally likely (i.e. p = 0.5), our uncertainty is maximal.",
        "The entropy H(A) measures the uncertainty.",
        "In other words, it quantifies the amount of information needed to predict the value of the variable.",
        "The formula 1 for the entropy treats variables with N ?",
        "1 possible values.",
        "The conditional entropy H(A|B) quantifies the amount of information needed to predict the value of the random variable A given that the value of another random variable B is known, see Formula 2.",
        "decreases reflects additional information about A provided by B and is called mutual information I(A;B) - see Formula 3.",
        "In other words, I(A;B) quantifies the mutual dependence of two random variables A and B.",
        "Proceeding from statistics to machine learning, independent random variables correspond to features.",
        "Thus we can directly speak about the entropy of a feature, the conditional entropy of a feature given another feature and the mutual information of two features.",
        "Information gain of feature Ak - IG(Ak) - measures the expected reduction in entropy caused by partitioning the data set Data according to the values of the feature Ak (Quinlan, 1987):",
        "where Avk = {v1, v2, ..., vc} is a set of possible values of feature Ak and Dvi is a subset of Data con-tainig instances with the feature value xk = vj .",
        "C being a target feature, H(Data) = H(C).",
        "Thus the mutual information between C and Ak -",
        "All mentioned concepts are visualized in Figure 2 for our settings: ?",
        "Our target feature C has eleven possible values (i.e. L1 languages).",
        "These values are uniformly distributed in the data D, thus",
        "3.46.",
        "Sample features (only for illustration) A1, A2, A3, A4 ?",
        "A are binary features so H(Ai) ?",
        "1 < H(C) = 3.46, i = 1, ..., 4.",
        "The circle areas correspond to the entropy of features.",
        "?",
        "The black areas correspond to mutual information I(Ai;Ak).",
        "?",
        "The striped areas correspond to the mutual information I(C;Ak) between C and Ak.",
        "?",
        "Features A1 and A3 are independent, so",
        "In addition to the concepts from information theory, we introduce another measure to quantify features: the document frequency of feature Ak ?",
        "df(Ak) is the number of texts in which Ak occurs, i.e. df(Ak) ?",
        "0."
      ]
    },
    {
      "heading": "5.2 Discussion on features",
      "text": [
        "We impose a fundamental requirement on features: they should be both informative (i.e. useful for the classification task) and robust (i.e. not sensitive to training data).",
        "We control the criterion of being informative by information gain maximization.",
        "The criterion of being robust is quantified by document frequency.",
        "If df(Ak) is high enough, then we can expect that Ak will occur in test data frequently.",
        "We propose two techniques to increase df : (i) filtering out features with low df ; (ii) feature combination driven by IG.",
        "The fulfillment of both criteria is always dependent on training data, i.e. the final feature set tends to fit training data and our goal is to weaken this tendency in order to get a more robust feature set.",
        "Both basic feature filtering and advanced feature combination help us to address this issue."
      ]
    },
    {
      "heading": "5.3 Basic feature filtering",
      "text": [
        "We obtained the feature setA0 by extracting features according to the feature family patterns) from the training data.",
        "Basic feature filtering removes features from A0 in two steps that result in a primary feature set A1:",
        "1.",
        "Remove binary feature Ak if df(Ak) < ?df .",
        "Remove continous feature Ak if relative frequency(Ak) < ?rf or df(relative frequency(Ak) ?",
        "?rf ) < ?df .",
        "2.",
        "Remove binary feature Ak if IG(Ak) ?",
        "?IG."
      ]
    },
    {
      "heading": "5.4 Advanced feature manipulation",
      "text": [
        "The process of advanced feature manipulation handles m input features from the primary feature set A1 in two different ways, filter them and combine them, in order to generate a final feature set Af ready to train the model: ?",
        "Filter them.",
        "We use Fast Correlation-Based Filter (FCBF; (Fleuret, 2004), (Yu and Liu, 2003)) that addresses the correlation between features.",
        "It first ranks the features according to their information gain, i.e. IG(A1) ?",
        "IG(A2) ?",
        "... ?",
        "IG(Am).",
        "In the second step, it iteratively removes any featureAk if there exists a feature Aj such that IG(Aj) ?",
        "IG(Ak) and I(Ak;Aj) ?",
        "IG(Ak), i.e. Aj is better as a predictor of C and Ak is more similar to Aj than to C. In the situation visualized in Figure 2, the feature A4 will be filtered out because there is a featureA3 such that",
        "IG(A3) ?",
        "IG(A4) and I(A3;A4) ?",
        "IG(A4) ?",
        "Combine them.",
        "We combine (COMB) binary features using logical operations (AND, OR, XOR, AND NOT, etc.)",
        "getting a new binary",
        "feature.",
        "For example, if we combine two features A1 and A2 using the OR operator, we get a new binary feature Y = A1 OR A2 for which the inequalities df(Y ) > df(A1) and df(Y ) > df(A2) hold.",
        "Thus we get a feature that is more robust than the two input features.",
        "To know whether it is more informative, we need to know how high IG(Y ) is with respect to IG(A1) and IG(A2).",
        "Without loss of generality, assume that IG(A1) > IG(A2).",
        "If IG(Y ) > IG(A1) > IG(A2), then Y is more informative than A1 and A2, but both of these features could be informative enough as well.",
        "It depends on the threshold we set up for being informative.",
        "We can easily iterate this process - let Y1 = A1 ORA2 and Y2 = A3 ORA4.",
        "Then we can combine Y3 = Y1 OR A5 or Y4 = Y1 OR Y2, etc.",
        "Then, advanced feature manupilation runs according to scenarios formed as a series of FCBF and COMB, for example A1 ?",
        "FCBF ?",
        "COMB ?",
        "FCBF?",
        "Af or A1 ?",
        "COMB?",
        "FCBF?",
        "Af ."
      ]
    },
    {
      "heading": "6 System development",
      "text": [
        "During system development, we formulated hypotheses how to avoid overfitting and get features robust and informative enough.",
        "In parallel, we run the experiments with parameters using which we controlled this requirement.",
        "Basic feature filtering We set the thresholds ?df , ?IG, ?rf empirically to the values 4, 0 and 0.02, respectively.",
        "Table 3 shows the changes in the size of the initial feature set after the basic feature filtering.",
        "It is evident that even such trivial filtering reduces the number of features substantially."
      ]
    },
    {
      "heading": "FEATURE INITIAL AFTER AFTER",
      "text": [
        "feature sets after basic filtering of A0 (3rd column) .",
        "Learning mechanisms Originally, we started with two learning algorithms, Random Forests (RF) and Support Vector Machines (SVM), running them in the R system.",
        "The Random forests4 algorithm joins randomness with classification decision trees.",
        "They iterate the process of two random selections and training a decision tree k-times on a subset ofm features.",
        "Each of them classifies a new input instance x and the class with the most votes becomes the output class of x.",
        "Support Vector Machines (Vapnik, 1995) efficiently perform both linear and non-linear classification employing different Kernel functions and",
        "avoiding the overfitting by two parameters, cost and gamma.",
        "We run a number of initial experiments with the following settings: the feature family pattern n; the basic feature filtering, RF with different values of parameters k and m, SVM with different values of parameters kernel, gamma and cost Cross-validation on the data set Train performed with SVM showed significantly better results than those obtained with RF.",
        "We were quite suprised that RF ran with low performance so that we decided to stop experimenting with this algorithm.",
        "Step by step, we added patterns into the feature family and carried out experiments with SVM only on the data set Train ?",
        "DevTest.",
        "We fixed the values of the SVM parameters kernel, degree, gamma, cost after several experiments as follows kernel = polynomial, degree = 1, gamma = 0.0004, cost = 1.",
        "Then we included the advanced feature manipulation into the experiments according to the scenariosA1 ?",
        "FCBF ?",
        "COMB ?",
        "FCBF ?",
        "Af and A1 ?",
        "COMB ?",
        "FCBF?",
        "Af .",
        "COMB was composed using the OR operator only.",
        "Unfortunately, none of them outperformed the initial experiments with the basic filtering only.",
        "Table 4 contains candidates for the final submission.",
        "The highlighted candidates were finally selected for the submission.",
        "In total, we submitted five systems to the closed-training subtask - see their overview in Table 5.",
        "The results correspond to our expectations that we made based on the results of cross-validation presented in",
        "outcome of majority voting of the remaining four systems.",
        "The performance of this system per language is presented in Table 7.",
        "Table 6 reports accuracy results when doing 10- fold cross-validation on Train ?",
        "DevTest.",
        "The folds for this experiment were provided by the organizers to get more reliable comparison of the NLI systems.",
        "It is interesting to analyse the complementarity of the CUNI-closed-[2-5] systems that affects the performance of CUNI-closed-1.",
        "In Table 8, we list the numerical characteristics of five possible situations that can occur when comparing the outputs of two systems i and j.",
        "Situations 2 and 3 capture how complementary the systems are.",
        "The numbers for our systems are presented in Table 9.",
        "We grouped languages according to the thresholds of F-measure.",
        "First we did it across the data, no matter what the proficiency level and prompt are - see the first row of Table 10.",
        "Second we did grouping",
        "1. the number of instances both systems predicted correctly; 2. the number of instances both systems predicted incorrectly; 3. the number of instances the systems predicted differently: i system correctly and j system incorrectly; 4. the number of instance the systems predicted differently: i system incorrectly and j system correctly; 5. the number of instances the systems predicted differently and both incorrectly.",
        "guages sorted according to F-measure w.r.t.",
        "proficiency level.",
        "for a particular proficiency level - see the remaining rows in Table 10.",
        "We can see that both GER and ITA are languages with the highest F-measure on all levels.",
        "Third we grouped by a particular prompt - see Table 11.",
        "We can see there diversed numbers for L1 languages despite the fact that prompts are formulated generally.",
        "Even more, we observe a topic similarity between prompts P2, P3, and P8, between P4 and P5, and between P1 and P7."
      ]
    },
    {
      "heading": "8 Future plans",
      "text": [
        "In our future research, w want to elaborate ideas that concern the feature engineering.",
        "We plan to work with the feature family that we designed in our initial experiments.",
        "However, we will think about more specific patterns in the essays, like the average count of tokens/punctuation/capitalized nouns/articles per sentence.",
        "As Table 12 shows, there is only one candidate, namely the number of tokens in sentence, to be taken into considerations since there is the largest difference between minimum and maximum.",
        "We confronted Ken Lackman,5 an English teacher, with the task of manual native language identification by English teachers.",
        "He says: ?I think",
        "it's quite possible to do but you would need a set of guidelines to supply teachers with.",
        "The guidelines would list tendancies of certain first language writers, based on errors caused by difference between L1 and L2.",
        "For example, Germans tend to capitalize too many nouns, since there are far more nouns capitalized in their language, Asians tend to leave out articles and Arab students tend to use the verb ?to be?",
        "inappropriately before other verbs.?",
        "Looking into the data, we observe the phenomena Ken is speaking about, but the quantity of them is not statistically significant to distinguish L1s.",
        "We formulate an idea of a bootstrapped feature extraction that has not been published yet, at least to our knowledge.",
        "Let us assume a set of operations that can be performed over a feature set (so far, we have proposed two possible operations with the features, filtering them out and their combinations).",
        "Determining whether a condition to perform a given operation holds is done on the high number of random samples.",
        "If the condition holds on the majority of them, then the operation is performed.",
        "The only parameter that must be set up is the majority.",
        "Instead of setting a threshold that is adjusted for all the features, bootstrapped feature extraction deals with fitting the data individually for each feature."
      ]
    },
    {
      "heading": "9 Conclusion",
      "text": [
        "It was the very first experience for our team to address the task of NLI.",
        "We assess it as very stimulating and we understand our participation as setting the baseline for applying other ideas.",
        "An overall table of results (Tetreault et al., 2013) for all the teams involved in the NLI 2013 Shared Task shows that there is still space for improvement of our baseline.",
        "We really appreciate all the work done by the organizers.",
        "They?ve made an effort to prepare the high-quality data and set up the framework by which the use of various NLI systems can be reliably compared."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "The authors would like to thank Eva Hajic?ova?",
        "and Jirka Hana for their valuable comments.",
        "We also thank Ken Lackman and Leslie Ryan6 for sharing",
        "their teaching experience.",
        "This research was supported by the Czech Science Foundation, grant no.",
        "P103/12/G084 and the Technology Agency of the Czech Republic, grant no.",
        "TA02010182."
      ]
    }
  ]
}
