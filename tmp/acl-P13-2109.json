{
  "info": {
    "authors": [
      "Andre Martins",
      "Miguel Almeida",
      "Noah A. Smith"
    ],
    "book": "ACL",
    "id": "acl-P13-2109",
    "title": "Turning on the Turbo: Fast Third-Order Non-Projective Turbo Parsers",
    "url": "https://aclweb.org/anthology/P13-2109",
    "year": 2013
  },
  "references": [
    "acl-C96-1058",
    "acl-D07-1101",
    "acl-D08-1016",
    "acl-D10-1001",
    "acl-D10-1004",
    "acl-D10-1125",
    "acl-D11-1022",
    "acl-D12-1030",
    "acl-E06-1011",
    "acl-H05-1066",
    "acl-N12-1054",
    "acl-P09-1039",
    "acl-P10-1001",
    "acl-P10-1110",
    "acl-P11-2033",
    "acl-W06-2920",
    "acl-W06-2932",
    "acl-W06-2933",
    "acl-W07-2216",
    "acl-W08-2121"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 617?622, Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics Turning on the Turbo: Fast Third-Order Non-Projective Turbo Parsers Andre?",
        "F. T.",
        "Martins??",
        "Miguel B.",
        "Almeida??",
        "Noah A. Smith# ?Priberam Labs, Alameda D. Afonso Henriques, 41, 2o, 1000-123 Lisboa, Portugal ?Instituto de Telecomunicac?o?es, Instituto Superior Te?cnico, 1049-001 Lisboa, Portugal"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "We present fast, accurate, direct non-projective dependency parsers with third-order features.",
        "Our approach uses AD3, an accelerated dual decomposition algorithm which we extend to handle specialized head automata and sequential head bigram models.",
        "Experiments in fourteen languages yield parsing speeds competitive to projective parsers, with state-of-the-art accuracies for the largest datasets (English, Czech, and German)."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Dependency parsing has become a prominent approach to syntax in the last few years, with increasingly fast and accurate models being devised (Ku?bler et al., 2009; Huang and Sagae, 2010; Zhang and Nivre, 2011; Rush and Petrov, 2012).",
        "In projective parsing, the arcs in the dependency tree are constrained to be nested, and the problem of finding the best tree can be addressed with dynamic programming.",
        "This results in cubic-time decoders for arc-factored and sibling second-order models (Eisner, 1996; McDonald and Pereira, 2006), and quartic-time for grandparent models (Carreras, 2007) and third-order models (Koo and Collins, 2010).",
        "Recently, Rush and Petrov (2012) trained third-order parsers with vine pruning cascades, achieving runtimes only a small factor slower than first-order systems.",
        "Third-order features have also been included in transition systems (Zhang and Nivre, 2011) and graph-based parsers with cube-pruning (Zhang and McDonald, 2012).",
        "Unfortunately, non-projective dependency parsers (appropriate for languages with a more flexible word order, such as Czech, Dutch, and German) lag behind these recent advances.",
        "The main obstacle is that non-projective parsing is NP-hard beyond arc-factored models (McDonald and Satta, 2007).",
        "Approximate parsers have therefore been introduced, based on belief propagation (Smith and Eisner, 2008), dual decomposition (Koo et al., 2010), or multi-commodity flows (Martins et al., 2009, 2011).",
        "These are all instances of turbo parsers, as shown by Martins et al.",
        "(2010): the underlying approximations come from the fact that they run global inference in factor graphs ignoring loop effects.",
        "While this line of research has led to accuracy gains, none of these parsers use third-order contexts, and their speeds are well behind those of projective parsers.",
        "This paper bridges the gap above by presenting the following contributions: ?",
        "We apply the third-order feature models of Koo and Collins (2010) to non-projective parsing.",
        "?",
        "This extension is non-trivial since exact dynamic programming is not applicable.",
        "Instead, we adapt AD3, the dual decomposition algorithm proposed by Martins et al. (2011), to handle third-order features, by introducing specialized head automata.",
        "?",
        "We make our parser substantially faster than the many-components approach of Martins et al. (2011).",
        "While AD3 requires solving quadratic subproblems as an intermediate step, recent results (Martins et al., 2012) show that they can be addressed with the same oracles used in the sub-gradient method (Koo et al., 2010).",
        "This enables AD3 to exploit combinatorial subproblems like the the head automata above.",
        "Along with this paper, we provide a free distribution of our parsers, including training code.1"
      ]
    },
    {
      "heading": "2 Dependency Parsing with AD3",
      "text": [
        "Dual decomposition is a class of optimization techniques that tackle the dual of combinatorial",
        "order models factor over arcs (Eisner, 1996; McDonald et al., 2005), and second-order models include also consecutive siblings and grandparents (Carreras, 2007).",
        "Our parsers add also arbitrary siblings (not necessarily consecutive) and head bi-grams, as in Martins et al. (2011), in addition to third-order features for grand-and tri-siblings (Koo and Collins, 2010).",
        "problems in a modular and extensible manner (Ko-modakis et al., 2007; Rush et al., 2010).",
        "In this paper, we employ alternating directions dual decomposition (AD3; Martins et al., 2011).",
        "Like the subgradient algorithm of Rush et al. (2010), AD3 splits the original problem into local subproblems, and seeks an agreement on the overlapping variables.",
        "The difference is that the AD3 subproblems have an additional quadratic term to accelerate consensus.",
        "Recent analysis (Martins et al., 2012) has shown that: (i) AD3 converges at a faster rate,2 and (ii) the quadratic subproblems can be solved using the same combinatorial machinery that is used in the subgradient algorithm.",
        "This opens the door for larger subproblems (such as the combination of trees and head automata in Koo et al., 2010) instead of a many-components approach (Martins et al., 2011), while still enjoying faster convergence."
      ]
    },
    {
      "heading": "2.1 Our Setup",
      "text": [
        "Given a sentence with L words, to which we prepend a root symbol $, let A := {?h,m?",
        "|h ?",
        "{0, .",
        ".",
        ".",
        ", L}, m ?",
        "{1, .",
        ".",
        ".",
        ", L}, h 6= m} be the set of possible dependency arcs.",
        "We parame-terize a dependency tree via an indicator vector u := ?ua?a?A, where ua is 1 if the arc a is in the tree, and 0 otherwise, and we denote by Y ?",
        "R|A| the set of such vectors that are indicators of well-2Concretely, AD3 needs O(1/) iterations to converge to a accurate solution, while subgradient needs O(1/2).",
        "formed trees.",
        "Let {As}Ss=1 be a cover of A, where each As ?",
        "A.",
        "We assume that the score of a parse tree u ?",
        "Y decomposes as f(u) :=?Ss=1 fs(zs), where each zs := ?zs,a?a?As is a ?partial view?",
        "of u, and each local score function fs comes from a feature-based linear model.",
        "Past work in dependency parsing considered either (i) a few ?large?",
        "components, such as trees and head automata (Smith and Eisner, 2008; Koo et al., 2010), or (ii) many ?small?",
        "components, coming from a multi-commodity flow formulation (Martins et al., 2009, 2011).",
        "Let Ys ?",
        "R|As |denote the set of feasible realizations of zs, i.e., those that are partial views of an actual parse tree.",
        "A tu-ple of views ?z1, .",
        ".",
        ".",
        ",zS?",
        "?",
        "?Ss=1 Ys is said to be globally consistent if zs,a = zs?,a holds for every a, s and s?",
        "such that a ?",
        "As?As?",
        ".",
        "We assume each parse u ?",
        "Y corresponds uniquely to a globally consistent tuple of views, and vice-versa.",
        "Following Martins et al. (2011), the problem of obtaining the best-scored tree can be written as follows: maximize ?Ss=1 fs(zs) w.r.t.",
        "u ?",
        "R|A|, zs ?",
        "Ys, 's s.t.",
        "zs,a = ua, ?s, ?a ?",
        "As, (1) where the equality constraint ensures that the partial views ?glue?",
        "together to form a coherent parse tree.3"
      ]
    },
    {
      "heading": "2.2 Dual Decomposition and AD3",
      "text": [
        "Dual decomposition methods dualize out the equality constraint in Eq.",
        "1 by introducing Lagrange multipliers ?s,a.",
        "In doing so, they solve a relaxation where the combinatorial sets Ys are replaced by their convex hulls Zs := conv(Ys).4 All that is necessary is the following assumption: Assumption 1 (Local-Max Oracle).",
        "Every s ?",
        "{1, .",
        ".",
        ".",
        ", S} has an oracle that solves efficiently any instance of the following subproblem:",
        "Typically, Assumption 1 is met whenever the maximization of fs over Ys is tractable, since the objective in Eq.",
        "2 just adds a linear function to fs.",
        "3Note that any tuple ?z1, .",
        ".",
        ".",
        ", zS?",
        "?",
        "?Ss=1 Ys satisfyingthe equality constraints will be globally consistent; this fact, due the assumptions above, will imply u ?",
        "Y.",
        "|Ys|}.",
        "Its members represent marginal probabilities over the arcs in As.",
        "The AD3 algorithm (Martins et al., 2011) alternates among the following iterative updates: ?",
        "z-updates, which decouple over s = 1, .",
        ".",
        ".",
        ", S, and solve a penalized version of Eq.",
        "2:",
        "a )2.",
        "(3) Above, ?",
        "is a constant and the quadratic term penalizes deviations from the current global solution (stored in u(t)).5 We will see (Prop.",
        "2) that this problem can be solved iteratively using only the Local-Max Oracle (Eq.",
        "2).",
        "?",
        "u-updates, a simple averaging operation:",
        "?",
        "?-updates, where the Lagrange multipliers are adjusted to penalize disagreements:",
        "In sum, the only difference between AD3 and the subgradient method is in the z-updates, which in AD3 require solving a quadratic problem.",
        "While closed-form solutions have been developed for some specialized components (Martins et al., 2011), this problem is in general more difficult than the one arising in the subgradient algorithm.",
        "However, the following result, proved in Martins et al. (2012), allows to expand the scope of AD3 to any problem which satisfies Assumption 1.",
        "Proposition 2.",
        "The problem in Eq.",
        "3 admits a solution z's which is spanned by a sparse basis W ?",
        "Ys with cardinality at most |W |?",
        "O(|As|).",
        "In other words, there is a distribution ?",
        "with support in W such that z's =",
        "Prop.",
        "2 has motivated an active set alorithm (Martins et al., 2012) that maintains an estimate of W by iteratively adding and removing elements computed through the oracle in Eq.",
        "2.7 Typically, very few iterations are necessary and great speed-ups are achieved by warm-starting W with the active set computed in the previous AD3 iteration.",
        "This has a huge impact in practice and is crucial to obtain the fast runtimes in ?4 (see Fig. 2).",
        "(1999), ?16.4, which effectively exploits the sparse representation of z's .",
        "For details, see Martins et al. (2012).",
        "dient.",
        "We show averaged runtimes in PTB ?22 as a function of the sentence length.",
        "For subgradient, we chose for each sentence the most favorable stepsize in {0.001, 0.01, 0.1, 1}."
      ]
    },
    {
      "heading": "3 Solving the Subproblems",
      "text": [
        "We next describe the actual components used in our third-order parsers.",
        "Tree component.",
        "We use an arc-factored score function (McDonald et al., 2005): f TREE(z) =?L m=1 ?ARC(pi(m),m), where pi(m) is the parent of the mth word according to the parse tree z, and ?ARC(h,m) is the score of an individual arc.",
        "The parse tree that maximizes this function can be found in time O(L3) via the Chu-Liu-Edmonds?",
        "algorithm (Chu and Liu, 1965; Edmonds, 1967).8 Grand-sibling head automata.",
        "Let Ainh and Aouth denote respectively the sets of incoming and outgoing candidate arcs for the hth word, where the latter subdivides into arcs pointing to the right, Aouth,?, and to the left, Aouth,?.",
        "Define the sets AGSIBh,?",
        "= Ainh ?Aouth,?",
        "andAGSIBh,?",
        "= Ainh ?Aouth,?.",
        "We describe right-side grand-sibling head automata; their left-side counterparts are analogous.",
        "For each head word h in the parse tree z, define g := pi(h), and let ?m0,m1, .",
        ".",
        ".",
        ",mp+1?",
        "be the sequence of right modifiers of h, with m0 = START and mp+1 = END.",
        "Then, we have the following grand-sibling component:",
        "where we use the shorthand z|B to denote the subvector of z indexed by the arcs in B ?",
        "A.",
        "Note that this score function absorbs grandparent and consecutive sibling scores, in addition to the grand-sibling scores.9 For each h, fGSIBh,?",
        "can be 8In fact, there is an asymptotically fasterO(L2) algorithm (Tarjan, 1977).",
        "Moreover, if the set of possible arcs is reduced to a subset B ?",
        "A (via pruning), then the fastest known algorithm (Gabow et al., 1986) runs in O(|B|+L logL) time.",
        "without pruning, limiting the number of candidate heads, and limiting (in addition) the number of modifiers.",
        "Note the O(L logL) total runtime per AD3 iteration in the latter case.",
        "maximized in time O(L3) with dynamic programming, yielding O(L4) total runtime.",
        "Tri-sibling head automata.",
        "In addition, we define left and right-side tri-sibling head automata that remember the previous two modifiers of a head word.",
        "This corresponds to the following component function (for the right-side case):",
        "Again, each of these functions can be maximized in time O(L3), yielding O(L4) runtime.",
        "Sequential head bigram model.",
        "Head bigrams can be captured with a simple sequence model:",
        "Each score ?HB(m,h, h?)",
        "is obtained via features that look at the heads of consecutive words (as in Martins et al. (2011)).",
        "This function can be maximized in time O(L3) with the Viterbi algorithm.",
        "Arbitrary siblings.",
        "We handle arbitrary siblings as in Martins et al. (2011), definingO(L3) component functions of the form fASIBh,m,s(z?h,m?, z?h,s?)",
        "= ?ASIB(h,m, s).",
        "In this case, the quadratic problem in Eq.",
        "3 can be solved directly in constant time.",
        "Tab.",
        "1 details the time complexities of each subproblem.",
        "Without pruning, each iteration of AD3 has O(L4) runtime.",
        "With a simple strategy that limits the number of candidate heads per word to a constant K, this drops to cubic time.10 Further speed-ups are possible with more pruning: by limiting the number of possible modifiers to a constant J , the runtime would reduce to O(L logL).",
        "10In our experiments, we employed this strategy withK = 10, by pruning with a first-order probabilistic model.",
        "Following Koo and Collins (2010), for each word m, we also pruned away incoming arcs ?h,m?",
        "with posterior probability less than 0.0001 times the probability of the most likely head.",
        "We report unlabeled attachment scores (UAS) ignoring punctuation, and parsing speeds in tokens per second.",
        "Our speeds include the time necessary for pruning, evaluating features, and decoding, as measured on a Intel Core i7 processor @3.4 GHz.",
        "The others are speeds reported in the cited papers; those marked with ?",
        "were converted from times per sentence."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": [
        "We first evaluated our non-projective parser in a projective English dataset, to see how its speed and accuracy compares with recent projective parsers, which can take advantage of dynamic programming.",
        "To this end, we converted the Penn Treebank to dependencies through (i) the head rules of Yamada and Matsumoto (2003) (PTB-YM) and (ii) basic dependencies from the Stanford parser 2.0.5 (PTB-S).11 We trained by running 10 epochs of cost-augmented MIRA (Crammer et al., 2006).",
        "To ensure valid parse trees at test time, we rounded fractional solutions as in Martins et al. (2009)?",
        "yet, solutions were integral ?",
        "95% of the time.",
        "Tab.",
        "2 shows the results in the dev-set (top block) and in the test-set (two bottom blocks).",
        "In the dev-set, we see consistent gains when more expressive features are added, the best accuracies being achieved with the full third-order model; this comes at the cost of a 6-fold drop in runtime compared with a first-order model.",
        "By looking at the two bottom blocks, we observe that our parser has slightly better accuracies than recent projective parsers, with comparable speed levels (with the exception of the highly optimized vine cascade approach of Rush and Petrov, 2012).",
        "11We train on sections ?02?21, use ?22 as validation data, and test on ?23.",
        "We trained a simple 2nd-order tagger with 10-fold jackknifing to obtain automatic part-of-speech tags for ?22?23, with accuracies 97.2% and 96.9%, respectively.",
        "?Best Published UAS?",
        "includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010, 2011), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012).",
        "The last two are shown separately in the rightmost columns.",
        "In our second experiment (Tab.",
        "3), we used 14 datasets, most of which are non-projective, from the CoNLL 2006 and 2008 shared tasks (Buch-holz and Marsi, 2006; Surdeanu et al., 2008).",
        "Our third-order model achieved the best reported scores for English, Czech, German, and Dutch?",
        "which includes the three largest datasets and the ones with the most non-projective dependencies?",
        "and is on par with the state of the art for the remaining languages.",
        "To our knowledge, the speeds are the highest reported among higher-order non-projective parsers, and only about 3?",
        "4 times slower than the vine parser of Rush and Petrov (2012), which has lower accuracies."
      ]
    },
    {
      "heading": "5 Conclusions",
      "text": [
        "We presented new third-order non-projective parsers which are both fast and accurate.",
        "We decoded with AD3, an accelerated dual decomposition algorithm which we adapted to handle large components, including specialized head automata for the third-order features, and a sequence model for head bigrams.",
        "Results are above the state of the art for large datasets and non-projective languages.",
        "In the hope that other researchers may find our implementation useful or are willing to contribute with further improvements, we made our parsers publicly available as open source software."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We thank all reviewers for their insightful comments and Lingpeng Kong for help in converting the Penn Treebank to Stanford dependencies.",
        "This work was partially supported by the EU/FEDER programme, QREN/POR Lisboa (Portugal), under the Intelligo project (contract 2012/24803), by a FCT grant PTDC/EEI-SII/2312/2012, and by NSF grant IIS-1054319."
      ]
    }
  ]
}
