{
  "info": {
    "authors": [
      "Emmanuel Planas",
      "Osamu Furuse"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-2090",
    "title": "Multi-Level Similar Segment Matching Algorithm for Translation Memories and Example-Based Machine Translation",
    "url": "https://aclweb.org/anthology/C00-2090",
    "year": 2000
  },
  "references": [
    "acl-J93-1004",
    "acl-P98-1121"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We propose a dynamic programming algorithm for calculating the similarity between two segments of words of the same language.",
        "The similarity is considered as a vector whose coordinates refer to the levels of analysis of the segments.",
        "This algorithm is extremely efficient for retrieving the best example in Translation Memory systems.",
        "The calculus being constructive, it also gives the correspondences between the words of the two segments.",
        "This allows the extension of Translation Memory systems towards Example-based Machine Translation."
      ]
    },
    {
      "heading": "Introduction",
      "text": [
        "In Translation Memory (TM) or Example-Based Machine Translation (EBMT) systems, one of the decisive tasks is to retrieve from the database, the example that best approaches the input sentence.",
        "In Planas (1999) we proposed a two-step retrieval procedure, where a rapid and rough index-based search gives a short list of example candidates, and a refined matching selects the best candidates from this list.",
        "This procedure drastically improves the reusability rate of selected examples to 97% at worst, for our English-Japanese TM prototype; with the classical TM strategy, this rate would constantly decline with the number of non matched words.",
        "It also allows a better recall rate when searching for very similar examples.",
        "We describe here the Multilevel Similar Segment Matching (MSSM) algorithm on which is based the second step of the above retrieval procedure.",
        "This algorithm does not only give the distance between the input and the example source segments, but also indicates which words would match together.",
        "It uses F different levels"
      ]
    },
    {
      "heading": "Osamu FURUSE Cyber Solutions Laboratories 2-4, Hikaridai Seika-cho Soraku-gun Kyoto, 619-0237 Japan",
      "text": [
        "of data (surface words, lemmas, parts of speech (POS), etc.)",
        "in a combined and uniform way.",
        "The computation of the worst case requires F*m*(n-m+2) operations, where rn and n are respectively the lengths of the input and the candidate (m<=n).",
        "This leads to a linear behavior when m and n have similar lengths, which is often the case for TM segments'.",
        "Furthermore, because this algorithm gives the exact matching links (along with the level of match) between all of the words of the input and the candidate sentence, it prepares the transfer stage of an evolution of TM that we call Shallow Translation.",
        "This involves substituting in the corresponding translated candidate (stored in the memory), the translation of the substituted words, provided that the input and the candidate are \"similar enough\"."
      ]
    },
    {
      "heading": "1 Matching Principle 1.1 The TELA Structure",
      "text": [
        "The purpose of this algorithm is to match two segments of words: input I and candidate C. These can each be any sequence of words: phrases, sentences, or paragraphs, for example.",
        "Let us consider input I of length m, not as a single segment of surface words, but rather as a group of F parallel layered segments ro,,„,,) each bearing m tokens.",
        "Such a structure is shown in Figure 1, and we call it a TELA structure2.",
        "On each layer f, the i-th token corresponds to one of the paradigms of the i-th word of input I.",
        "In our implementation, we use a shallow analyzer that gives three paradigms (F=3) for each surface",
        "word of the segments: the surface word itself (f=1), its lemma (f=2), and its POS tag (f=3).",
        "Because we do not need a syntactic analyzer, the time required for this analysis is not an handicap, moreover such parsers are available for many languages.",
        "Let C be a candidate segment of length n, for matching input I of length in (n>=m).",
        "The basic problem involves matching the elements of the set to those of Only three layers are shown in the following examples but other types of layers, like semantics, or even non linguistic information like layout features can be considered, as in Planas (1998).",
        "Our algorithm is written for the general case (F layers)."
      ]
    },
    {
      "heading": "1.2 Edit Distance based Similarity",
      "text": [
        "We consider a match from C to I as an edit distance process.",
        "This edition uses a sequence of basic edit operations between the words of the segments, like in Wagner & Fisher (1974) who used four basic operations: deletion, insertion, strict and equal substitution between the letters of a word.",
        "This approach has also been followed by Gale & Church (1993) for their alignment algorithm, with six operations.",
        "Here, we only consider deletions and equalities (i.e. equal substitutions): F+1 basic operations in total3.",
        "One equality corresponds to each of the F layers, and a deletion affects all layers at once.",
        "In Figure 1, the items in bold match each other, and the strikethrough ones have to be deleted.",
        "The edition of C into I involves five deletions (\"Nikkei\", \"journal\", \"reported\", \"that\", \"really\"), one equality at layer 1 (\"stayed\"), two at layer 2 3 Lepage (1998) also uses deletions and one level of equality for calculating his \"pseudo-distance\", for getting the similarity between two strings.",
        "(\"stay\", \"strong\"), and four at layer 3 (\"PN\", \"verb\", \"adj\", \"noun\").",
        "At the Word level, the similarity between the two segments is considered to be the relative number of words of the input segment that are matched by some word of the candidate segment in the matching zone (from \"NTT\" to \"Monday\" in our example): 1/4 in Figure 1.",
        "The same similarity can be considered at different levels.",
        "Here, the lemma similarity is 2/4, and the POS similarity is 4/4.",
        "We consider the total similarity as a vector involving all layer equalities, plus deletions: a(C, I) = (1/4, 2/4, 4/4, 1-1/4, 1-5/9) The fourth coordinate counts the complementary proportion of deletions in the \"matching zone\" of the candidate C. The last coordinate counts the same proportion, relatively to the whole candidate.",
        "We take the complement to 1 because, the more deletions there are, the smaller the similarity becomes.",
        "When different Ci candidates are possible for matching 1, the greatest a(Cio, I), according to common the partial order on vectors, determines the best candidate Ci0."
      ]
    },
    {
      "heading": "1.3 Matching Strategy",
      "text": [
        "We try to match each word C; of candidate C, to a word 1i of input I.",
        "C; matches 1i if one of the paradigms of C1 equals one of the paradigms of at the same level f, i.e. if C11 and Ili, are equal.",
        "When a failure to match two words with their paradigms C11 to Ifj occurs at a given level f, we try to match the words at the next upper level f+ 1 : C1441 and f+Ii.",
        "When all of the possible layers of the two words have been tried without success, we try to match the next word Co to the same C; does not match any word of I at any",
        "level, we consider that it has to be deleted.",
        "All words of I have to be matched by some word of C: no insertion is allowed (sec section 1.3.4).",
        "With TM tools, if some useful candidates are found, they usually utilize words similar to the input words because translation memories are applied within very similar documents, most of the time between ancient and newer versions of a same document.",
        "When the priority is rapidity (rather than non-ambiguity), we can consider that a match is reached as soon as a word of C and a word of I match at a certain layer f. It is riot necessary to look at upper levels, for they should match because of the expected similarity between the input and the candidate.",
        "The previous example illustrates this.",
        "As upper levels are not tested, this allows a gain in the number of iterations of the algorithm.",
        "Experiments (see lianas (1999)) have confirmed this to be a correct strategy for TM.",
        "That's why, we consider from now on dealing with such a lazy match."
      ]
    },
    {
      "heading": "1.3.3 Exhaustive match",
      "text": [
        "in the most general case, ambiguity problems prevent us from employing the lazy strategy, and a correct match requires that whenever two items C1, and match at a certain level f, they should match at upper levels.",
        "Here is an example:",
        "in C2, the lemma \"stay\" of surface word \"stay\" matches the lemma \"stay\" of surface word \"stayed\" of I, but they do not match at the POS level (noun and verb).",
        "The algorithm should go to this level to find that there is no match.",
        "Once again, however, because this algorithm has been built for TM systems, such ambiguities hardly occur.",
        "If some items in I are not matched by any item of C, the match involves an insertion.",
        "Case of Translation Memories If the candidate sentences are to be used by a human translator, s/he will be able to insert the missing word at the right place.",
        "Accordingly, a match with insertion can be used for pure TM.",
        "In the EBMT system we are targeting, we plan to use the matching sub-string of C for adaptation to I without syntactic rules.",
        "Accordingly, we consider that we do not know where to insert the non matching item: in this case, we force the algorithm to stop it' an insertion is needed for matching C and I.",
        "From now on, we will follow this position.",
        "We want the output of the algorithm as a list of triplets (C11 1'j called a \"trace\", where CI; corresponds to Ifj through the \"op\" operation.",
        "We note op=\"f\" an equality at level f, and op=\"0\" a deletion.",
        "For Example 1, the trace should be:"
      ]
    },
    {
      "heading": "Sellers algorithms 2.1 Algorithm Principle",
      "text": [
        "The Wagner & Fischer (W&F) dynamic programming algorithm in Figure 3 gives the edit distance between C and I: For j=0 to m d[j, //initiating the columns For i=1 to n d[0, i]=i //initiating the rows For i=1 to n For j=1 to m If(I[j]=C[i]) {d=d[i-1, O]}//equality Else {d=d[i-1., j-1]+1) //subst.",
        "d[j,i]=min(d[i-1., j]+1, d[i, j-1]+1., d)",
        "The distance is obtained in m*n operations, by building an [m+1, 11+11 array (see Figure 6).",
        "in addition, W&F (1974) proposed a backtracking procedure, shown in Figure 4, that scans back this array to give a \"trace\" of the match between",
        "C and 1 (i.e. it prints the position of the matching words), in (m+n) operations.",
        "The trace is then obtained in (mn+m+n) operations in total.",
        "This algorithm was previously used in Planas (1998) at each layer of a TELA structure to give a trace by layer.",
        "The data from the traces of the different layers were combined afterwards for the purposes of TM and EBMT.",
        "However, this procedure is not optimal for at least two reasons.",
        "First, the layers are compared in an independent way, leading to a waste of time in the case of TM, because the lazy match phenomenon is not used.",
        "Second, the combination of the results was processed after the algorithm, and this required a supplementary process.",
        "One can imagine that processing the whole data in the flow of the instructions of the algorithm is more efficient.",
        "do interest us.",
        "We therefore reduce the test in the algorithm to that shown in Figure 5.",
        "Furthermore, we initiate the columns of the array with infinite values (huge values in practice) to show that initial insertions are not possible, and the rows to \"0\", to count the deletions relatively to input I.",
        "See Sellers (1980) for a due explanation.",
        "An example of the successive scores calculated with this algorithm are shown in Figure 6.",
        "The total distance (equal to 1) between C and I appears in the lowest right cell.",
        "The fact that only two operations are used eradicates the ambiguity that appears in selecting the next cell in the W&F algorithm backtracking procedure with four operations.",
        "In our algorithm, either there is an equality (cost 0), or a deletion (cost 1).",
        "The possibility of having the same cost 1 for insertions, deletions, or strict substitutions has been eliminated."
      ]
    },
    {
      "heading": "2.3 Introducing one equality per level",
      "text": [
        "As mentioned previously, we need to match items at different layers.",
        "We introduce here two new points to deal with this:",
        "• In order to keep the score for each equality deletion, d[i,j] is a vector instead of a number: d[i,j]=[score,,...,score,„ score__].",
        "• In this vector, score, through score, store the number of equalities for each layer f, and score__ records the number of deletions, as in W&F (underlined in the arrays).",
        "vectors involved in a match.",
        "To calculate the successive d[i,j], we use the algorithm of Figure 5 adapted for F levels in Figure 8.",
        "We first try to get the maximum member of equalities and then the minimum of deletions.",
        "Each time we find a new match in the first column, we start a new path (see I' matching with C', C' and C7 in Figure 7).",
        "If one of the vectors of the last column of the array is such that: SUM,<=f<=,:(scoref) = m, there is a matching substring of C in which there is a matching word for each of the words of I: this constitutes a solution.",
        "In our example, cell (7, 4), with score 1210 shows that there is a sub chain of the candidate that matches the input with 1, 2, and 1 matches at the word, lemma, and POS levels and 0 deletions.",
        "Cell (8, 4) indicates a similar match, but with 1 deletion (\"morning\").",
        "The best path then ends at cell (7,4).",
        "Starting from this cell, we can retrieve the full solution using the W&F backtrack algorithm adapted to F levels.",
        "This approach allows us to choose as compact a string as possible.",
        "When there are several possible paths, like in Figure 9, the algorithm is able to choose the best matching sub-string.",
        "If we are looking for a similarity involving first",
        "surface word matches, then lemmas and parts of speech, then cell (4,4) of score 2200 will be chosen.",
        "This strategy can be adapted to particular needs: it suffices to change the order of the scores in the vectors."
      ]
    },
    {
      "heading": "3 Optimizing",
      "text": []
    },
    {
      "heading": "3.1 Triangularization of the array",
      "text": [
        "In this algorithm, for each there must be at least one possible matching C1.",
        "Hence, in a valid path, there are at least m matches.",
        "As a match between C1 and Ij occurs when \"stepping across a diagonal\", the (m-1) first diagonals (from the lower left corner of the array) can not give birth to a valid path.",
        "Therefore, we do not calculate d[i,j] across these small diagonals.",
        "Symmetrically, the small diagonals after the last full one (in the upper right corner) cannot give birth to a valid path.",
        "We then also eliminate these (m-1) last diagonals.",
        "This gives a reduced matrix as shown in the new example in Figure 10.",
        "The computed cells are then situated in a parallelogram of dimensions (n-m+1) and m. The results is: only m(n-m+l) cells have to be computed.",
        "Instead of initiating the first row 0 to \"inf\", we initiate the cells of the diagonal just before the last full top diagonal (between cell (0,1) and cell (3,4) in Figure 10) to \"000inf\" to be sure that no insertion is possible."
      ]
    },
    {
      "heading": "3.2. Complexity",
      "text": [
        "The worst time complexity of this algorithm is F-proportional to the number of cells in the computed array, which is m*(n-m+1).",
        "With the \"lazy\" strategy, all F levels are often not visited.",
        "As the number of cells computed by the W&F algorithm is mi=n, our algorithm is always more rapid.",
        "The backtracking algorithm takes m+n operations in the W&F algorithm, as well as in our algorithm, leading to m(n-m+2)+n operations in the MSSM algorithm, and m(n+1)+n operations in the W&F algorithm.",
        "The general complexity is then sub-quadratic.",
        "When the lengths of both segments to be compared are similar (like it often happens in TMs), the complexity tends towards linearity.",
        "The two graphics in Figure 11 show two interesting particular cases (m=n and m running from 1 to n=10), comparing W&F and our algorithm.",
        "For strings of similar lengths, the longer they are, the more the MSSM algorithm becomes interesting.",
        "When n is fixed, the MSSM algorithm is more interesting for extreme values of the length of I: small and similar to n."
      ]
    },
    {
      "heading": "Conclusions",
      "text": [
        "The first contribution of this algorithm is to provide TM and EBMT systems with a precise and quick way to compare segments of words with a similarity vector.",
        "This leads to an almost complete eradication of noise for the matter of retrieving similar sentences in TM systems (97% \"reusability\" in our prototype).",
        "The second is to offer an unambiguous word to word matching through the \"trace\".",
        "This last point opens the way to the Shallow Translation paradigm.",
        "For more information about the use of this algorithm, please refer to Planas (1999).",
        "These two contributions bring in the main difference with relative research4 concentrating on similarity only, represented by a sole integer.",
        "The TELA structure, that allows the parallel use of different layers of analysis (linguistic paradigms, but possibly non linguistic information) is essential to this work because it provides the algorithm with the supplementary information classical systems lack.",
        "The fact that the shallow parser (lemmas, POS) is ambiguous or not does not affect significantly the performance of the algorithm.",
        "If the same parser is used for both example and input segments, parallel errors compensate each other.",
        "Of course, these errors do have an influence for EBMT: the non ambiguity is then a must.",
        "A first evaluation of the MSSM speed gives 0.5 to 2 milliseconds for comparing only5 two randomly chosen English or Japanese sentences over 3 levels (word, lemmas, POS).",
        "The",
        "implementation has been done with a DELL Optiplex GX1 233 Mhz, Window NT, Java 118.",
        "This algorithm can be improved in different ways.",
        "For speed, we can introduce a similarity threshold so as not to evaluate the last cells of the columns of the computed array as soon as the threshold is overtaken.",
        "For adaptability, being able to deal with a different number of tokens according to each layer will allow us to deal nicely with compound words.",
        "In short, if the basis of this matching algorithm is the W&F algorithm, other algorithms can be adapted similarly to deal with multilevel data."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "Thanks to Takayuki Adachi, Francis Bond, Timothy Balwin, and Christian Boitet for their useful remarks and fruitful discussions."
      ]
    }
  ]
}
