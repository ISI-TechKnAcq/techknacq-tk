{
  "info": {
    "authors": [
      "Sergio Penkale",
      "Rejwanul Haque",
      "Sandipan Dandapat",
      "Pratyush Banerjee",
      "Ankit Kumar Srivastava",
      "Jinhua Du",
      "Pavel Pecina",
      "Sudip Kumar Naskar",
      "Mikel L. Forcada",
      "Andy Way"
    ],
    "book": "Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR",
    "id": "acl-W10-1720",
    "title": "MATREX: The DCU MT System for WMT 2010",
    "url": "https://aclweb.org/anthology/W10-1720",
    "year": 2010
  },
  "references": [
    "acl-D07-1091",
    "acl-J07-2003",
    "acl-N04-1022",
    "acl-N07-1029",
    "acl-P02-1038",
    "acl-P02-1040",
    "acl-P03-1021",
    "acl-P07-2045",
    "acl-P96-1041",
    "acl-W04-3250",
    "acl-W06-3110",
    "acl-W07-0712",
    "acl-W96-0213"
  ],
  "sections": [
    {
      "text": [
        "MaTrEx: The DCU MT System for WMT 2010",
        "Sergio Penkale, Rejwanul Haque, Sandipan Dandapat, Pratyush Banerjee, Ankit K. Srivastava, Jinhua Du, Pavel Pecina, Sudip Kumar Naskar, Mikel L. Forcada, Andy Way",
        "CNGL, School of Computing Dublin City University, Dublin 9, Ireland",
        "{ spenkale, rhaque, sdandapat, pbanerjee, asrivastava, jdu, ppecina, snaskar, mforcada, away }@computing.dcu.ie",
        "This paper describes the DCU machine translation system in the evaluation campaign of the Joint Fifth Workshop on Statistical Machine Translation and Metrics in ACL-2010.",
        "We describe the modular design of our multi-engine machine translation (MT) system with particular focus on the components used in this participation.",
        "We participated in the English-Spanish and English-Czech translation tasks, in which we employed our multi-engine architecture to translate.",
        "We also participated in the system combination task which was carried out by the MBR decoder and confusion network decoder."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "In this paper, we present the DCU multi-engine MT system MaTrEx (Machine Translation using Examples).",
        "This system exploits example-based MT, statistical MT (SMT), and system combination techniques.",
        "We participated in the English-Spanish (en-es) and English-Czech (en-cs) translation tasks.",
        "For these two tasks, we employ several individual MT systems: 1) Baseline: phrase-based SMT (Koehn et al., 2007); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004); 3) Factored translation model (Koehn and Hoang, 2007); 4) Source-side context-informed (SSCI) systems (Stroppa et al., 2007); 5) the moses-chart (a Moses implementation of the hierarchical phrase-based (HPB) approach of Chiang (2007)) and 6) Apertium (Forcada et al., 2009) rule-based machine translation (RBMT).",
        "Finally, we use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final translation.",
        "For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the confusion network (CN) (Mangu et al., 2000).",
        "We then build the CN using the TER metric (Snover et al., 2006), and finally search for the best translation.",
        "The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used for the shared task.",
        "In Section 3, we outline the complete system setup for the shared task and provide evaluation results on the test set.",
        "Section 4 concludes the paper."
      ]
    },
    {
      "heading": "2. The MaTrEx System",
      "text": [
        "The MaTrEx system is a combination-based multi-engine architecture, which exploits aspects of both the EBMT and SMT paradigms.",
        "The architecture includes various individual systems: phrase-based, example-based, hierarchical phrase-based and tree-based MT.",
        "The combination structure uses the MBR and CN decoders, and is based on a word-level combination strategy (Du et al., 2009).",
        "In the final stage, we use a new rescoring module to process the N-best list generated by the combination module.",
        "Figure 1 illustrates the architecture.",
        "The EBMT system uses a language-specific, reduced set of closed-class marker morphemes or lexemes (Gough and Way, 2004) to define a way to segment sentences into chunks, which are then aligned using an edit-distance-style algorithm, in l^^which edit costs depend on word-to-word transla-",
        "Apertium EBMT Baseline Factored HPB",
        "MERT [*-» Rescore/MERT Decoding System Combination",
        "Figure 1: System Framework.",
        "tion probabilities and the amount of word-to-word cognates (Stroppa and Way, 2006).",
        "Once these phrase pairs were obtained they were merged with the phrase pairs extracted by the baseline system adding word alignment information.",
        "Apertium is a free/open-source platform for RBMT.",
        "The current version of the en-es system in Apertium was used for the system combination task (section 2.7), and its morphological analysers and part-of-speech taggers were used to build a factored Moses model.",
        "We also used a factored model for the en-es translation task.",
        "Factored models (Koehn and Hoang, 2007) facilitate the translation by breaking it down into several factors which are further combined using a log-linear model (Och and Ney, 2002).",
        "We used three factors in our factored translation model, which are used in two different decoding paths: a surface form (SF) to SF translation factor, a lemma to lemma translation factor, and a part-of-speech (PoS) to PoS translation factor.",
        "Finally, we used two decoding paths based on the above three translation factors: an SF to SF decoding path and a path which maps lemma to lemma, PoS to PoS, and an SF generated using the TL lemma and PoS.",
        "The lemmas and PoS for en and es were obtained using Apertium (section 2.3).",
        "One natural way to express a context-informed feature (hMBL) is to view it as the conditional probability of the target phrases (êk ) given the source phrase (f k) and its source-side context information (CI):",
        "hmbl = log P(êk\\fk, Cl(fk))",
        "We use a memory-based machine learning (MBL) classifier (TRIBL: Daelemans and van den Bosch (2005)) that is able to estimate P(êk \\ fk, CI(fk)) by similarity-based reasoning over memorized nearest-neighbour examples of source-target phrase translations.",
        "In equation (1), SSCI may include any feature (lexical, syntactic, etc.",
        "), which can provide useful information to disambiguate a given source phrase.",
        "In addition to using local words and PoS-tags as features, as in (Stroppa et al., 2007), we incorporate grammatical dependency relations (Haque et al., 2009a) and supertags (Haque et al., 2009b) as syntactic source context features in the log-linear",
        "PB-SMT model.",
        "In addition to the above feature, we derived a simple binary feature hbest, defined in (2):",
        "We performed experiments by integrating these two features, hMBL and hbest, directly into the log-linear framework of Moses.",
        "For the en-cs translation task, we built a weighted synchronous context-free grammar model (Chiang, 2007) of translation that uses the bilingual phrase pairs of PB-SMT as a starting point to learn hierarchical rules.",
        "We used the open-source Tree-Based translation system moses-chart to perform this experiment.",
        "1 if êk maximizes P (êk \\fk, CI(fk ))"
      ]
    },
    {
      "heading": "0. otherwise",
      "text": [
        "Multiple 1-best",
        "Multiple 1-best",
        "i",
        "1",
        "MBR Decoder",
        "MBR Decoder",
        "1",
        "1",
        "CN/MERT",
        "CN/MERT",
        "1",
        "Rescore/MERT",
        "Rescore/MERT",
        "For multiple system combination, we used an MBR-CN framework (Du et al., 2009, 2010) as shown in Figure 1.",
        "Due to the varying word order in the MT hypotheses, it is essential to define the backbone which determines the general word order of the CN.",
        "Instead of using a single system output as the skeleton, we employ an MBR decoder to select the best single system output Erfrom the merged N-best list by minimizing the where Ns indicates the number of translations in the merged N-best list, and {Ei}N=;1 are the translations themselves.",
        "In our task, we only merge the 1 best output of each individual system.",
        "The CN is built by aligning other hypotheses against the backbone, based on the TER metric.",
        "Null words are allowed in the alignment.",
        "Either votes or different confidence measures are assigned to each word in the network.",
        "Each arc in the CN represents an alternative word at that position in the sentence and the number of votes for each word is counted when constructing the network.",
        "The features we used are as follows:",
        "• word posterior probability (Fiscus, 1997);",
        "• 3, 4-gram target language model;",
        "• word length penalty;",
        "• Null word length penalty;",
        "We use MERT (Och, 2003) to tune the weights of the CN.",
        "Rescoring is a very important part in postprocessing which can select a better hypothesis from the N-best list.",
        "We augmented our previous rescoring model (Du et al., 2009) with more large-scale data.",
        "The features we used include:",
        "• Direct and inverse IBM model;",
        "• Sentence length posterior probability (Zens",
        "• N-gram posterior probabilities within the N-",
        "• Minimum Bayes Risk probability;",
        "• Length ratio between source and target sentence;",
        "The weights are optimized via MERT."
      ]
    },
    {
      "heading": "3. Experimental Setup",
      "text": [
        "This section describes our experimental setup for the en-cs and en-es translation tasks.",
        "Bilingual data: In the experiments we used data sets provided by the workshop organizers.",
        "For the en -cs translation table extraction we employed both parallel corpora (News-Commentary10 and CzEng 0.9), and for the en-es experiments, we used the Europarl(Koehn, 2005), News Commentary and United Nations parallel data.",
        "We used a maximum sentence length of 80 for en-es and 40 for en-cs.",
        "Detailed statistics are shown in Table 1.",
        "Table 1: Statistics of en-cs and en-es parallel data.",
        "Monolingual data: For language modeling purposes, in addition to the target parts of the bilingual data, we used the monolingual News corpus for cs ; and the Gigaword corpus for es.",
        "For both languages, we used the SRILM toolkit (Stolcke, 2002) to train a 5-gram language model using all monolingual data provided.",
        "However, for en-es we used the IRSTLM toolkit (Federico and Cet-tolo, 2007) to train a 5-gram language model using the es Gigaword corpus.",
        "Both language models use modified Kneser-Ney smoothing (Chen and Goodman, 1996).",
        "Statistics for the monolingual corpora are given in Table 2.",
        "Table 2: Statistics of Monolingual Data.",
        "E/N/NC/UN refers to EuroparVNews/NewsXommentary/UnitecLNations corpora.",
        "For all the systems except Apertium, we first lowercase and tokenize all the monolingual and bilingual data using the tools provided by the WMT10 organizers.",
        "After translation, system combination output is detokenised and true-cased.",
        "Corpus",
        "Langs.",
        "Sent.",
        "Source tokens",
        "Target tokens",
        "Europarl",
        "News-comm",
        "UN",
        "en-es en-es en-es",
        "1.6M 97k 5.9M",
        "43M 2.4M 160M",
        "45M 2.7M 190M",
        "News-Comm CzEng",
        "en-cs en-cs",
        "85k 7.8M",
        "1.8M 80M",
        "1.6M 69M",
        "Corpus",
        "Language",
        "Sentences",
        "Tokens",
        "E/N/NC/UN",
        "es",
        "9,6M",
        "290M",
        "Gigaword",
        "es",
        "40M",
        "1,2G",
        "News",
        "cs",
        "13M",
        "210M",
        "The CzEng corpus (Bojar and Zabokrtsky, 2009) is a collection of parallel texts from sources of different quality and as such it contains some noise.",
        "As the first step, we discarded those sentence pairs having more than 10% of non-Latin characters.",
        "The CzEng corpus is quite large (8M sentence pairs).",
        "Although we were able to build a vanilla SMT system on all parallel data available (News-Commentary + CzEng), we also attempted to build additional systems using News-Commentary data (which we considered indomain) and various in-domain subsets of CzEng hoping to achieve better results on domain-specific data.",
        "For our first system, we selected 128,218 sentence pairs from CzEng labeled as news.",
        "For the other two systems, we selected subsets of 2M and 4M sentence pairs identified as most similar to the development sets (as a sample of in-domain data) based on cosine similarity of their representation in a TF-IDF weighted vector space model (cf. Byrne et al.",
        "(2003)).",
        "We also applied the pseudo-relevavance-feedback technique for query expansion (Manning et al., 2008) to select another subset with 2M sentence pairs.",
        "We used the output of 15 systems for system combination for the en-cs translation task.",
        "Among these, 5 systems were built using Moses and varying the size of the training data (DCU-",
        "News); 9 context-informed PB-SMT systems (DCU-SSCI-*) using (combinations of) various context features (word, PoS, supertags and dependency relations) trained only on the News Commentary data (marked with \\ in Table 4); and one system using the moses-chart decoder, also trained on the news commentary data.",
        "Three baseline systems using Moses were built, where we varied the amount of training data used:",
        "• epn: This system uses all of the Europarl and News-Commentary parallel data.",
        "• UN-half: This system uses the data suplied to \"epn\", plus an additional 2.1M sentences pairs randomly selected from the United Nations corpus.",
        "• all: This system uses all of the available parallel data.",
        "For en-es we also obtained output from the factored model (trained only on the news commentary corpus) and the Apertium RBMT system.",
        "We also derived phrase alignments using the",
        "MaTrEx EBMT system (Stroppa and Way, 2006), and added those phrase translations in the Moses phrase table.",
        "The systems marked with * use a language model built using the Spanish Gigaword corpus, in addition to the one built using the provided monolingual data.",
        "These 6 sets of system outputs are then used for system combination.",
        "The evaluation results for en-es and en-cs experiments are shown in Table 3 and Table 4 respectively.",
        "The output of the systems marked f were submitted in the shared tasks.",
        "Table 3: en-es experimental results.",
        "Table 4: en-cs experimental results."
      ]
    },
    {
      "heading": "4. Conclusion",
      "text": [
        "This paper presents the Dublin City University MT system in WMT2010 shared task campaign.",
        "This was DCU's first attempt to translate from en toes and cs in any shared task.",
        "We developed a multi-engine framework which combined the outputs of several individual MT systems and gener-146ated a new N-best list after CN decoding.",
        "Then by using some global features, the rescoring model generated the final translation output.",
        "The experimental results demonstrated that the combination module and rescoring module are effective in our framework for both language pairs, and produce statistically significant improvements as measured by bootstrap resampling methods (Koehn, 2004) on BLEU over the single best system.",
        "System",
        "BLEU",
        "NIST",
        "METEOR",
        "TER",
        "DCU-half j* DCU-all j* DCU-epn j*",
        "29.77% 29.63% 29.45%",
        "7.68 7.66 7.66",
        "59.86% 59.82% 59.71%",
        "59.55% 59.74% 59.64%",
        "DCU-ebmt j*",
        "29.38%",
        "7.62",
        "59.59%",
        "60.11%",
        "DCU-factor",
        "22.58%",
        "6.56",
        "54.94%",
        "67.65%",
        "DCU-apertium",
        "19.22%",
        "6.37",
        "49.68%",
        "67.68%",
        "DCU-system-combination j",
        "30.42%",
        "7.78",
        "60.56%",
        "58.71%",
        "System",
        "BLEU",
        "NIST",
        "METEOR",
        "TER",
        "DCU-All",
        "10.91%",
        "4.60",
        "39.18%",
        "81.76%",
        "DCU-Ex2M",
        "10.63%",
        "4.56",
        "39.12%",
        "81.96%",
        "DCU-4M",
        "10.61%",
        "4.56",
        "39.26%",
        "82.04%",
        "DCU-2M",
        "10.48%",
        "4.58",
        "39.35%",
        "81.56%",
        "DCU-Chart",
        "9.34%",
        "4.25",
        "37.04%",
        "83.87%",
        "DCU-News",
        "8.64%",
        "4.16",
        "36.27%",
        "84.96%",
        "DCU-SSCI-ccgJ",
        "8.26%",
        "4.02",
        "34.76%",
        "85.58%",
        "DCU-SSCI-supertag-pairj",
        "8.11%",
        "3.95",
        "34.93%",
        "86.63%",
        "DCU-SSCI-ccg-ltagj",
        "8.09%",
        "3.96",
        "34.90%",
        "86.62%",
        "DCU-SSCI-PRJ",
        "8.06%",
        "4.00",
        "34.89%",
        "85.99%",
        "DCU-SSCI-baseJ",
        "8.05%",
        "3.97",
        "34.61%",
        "86.02%",
        "DCU-SSCI-PRIRJ",
        "8.03%",
        "3.99",
        "34.81%",
        "85.98%",
        "DCU-SSCI-ltagJ",
        "8.00%",
        "3.95",
        "34.57%",
        "86.41%",
        "DCU-SSCI-PoSJ",
        "7.91%",
        "3.94",
        "34.57%",
        "86.51%",
        "DCU-SSCI-wordJ",
        "7.57%",
        "3.88",
        "34.16%",
        "87.14%",
        "DCU-system-combination j",
        "13.22%",
        "4.98",
        "40.39%",
        "78.59%",
        "Acknowledgements: This work is supported by Science Foundation Ireland (Grant No.",
        "07/CE/I1142) and by PANACEA, a 7th Framework Research Programme of the European",
        "Union, contract number 7FP-ITC-248064.",
        "M.L.",
        "Forcada's sabbatical stay at Dublin City University is supported by Science Foundation Ireland through ETS Walton Award 07/W.1/I1802 and by the Universitat d'Alacant (Spain)."
      ]
    }
  ]
}
