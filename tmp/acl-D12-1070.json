{
  "info": {
    "authors": [
      "Ping Xu",
      "Pascale Fung"
    ],
    "book": "EMNLP",
    "id": "acl-D12-1070",
    "title": "Cross-Lingual Language Modeling with Syntactic Reordering for Low-Resource Speech Recognition",
    "url": "https://aclweb.org/anthology/D12-1070",
    "year": 2012
  },
  "references": [
    "acl-C04-1030",
    "acl-D09-1141",
    "acl-H05-1021",
    "acl-J03-1002",
    "acl-J04-2004",
    "acl-J97-3002",
    "acl-J99-4005",
    "acl-N03-1019",
    "acl-P02-1040",
    "acl-P03-1019",
    "acl-W03-1003",
    "acl-W05-0831",
    "acl-W99-0604"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 766?776, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics Cross-Lingual Language Modeling with Syntactic Reordering for"
      ]
    },
    {
      "heading": "Abstract",
      "text": [
        "This paper proposes cross-lingual language modeling for transcribing source resource-poor languages and translating them into target resource-rich languages if necessary.",
        "Our focus is to improve the speech recognition performance of low-resource languages by leveraging the language model statistics from resource-rich languages.",
        "The most challenging work of cross-lingual language modeling is to solve the syntactic discrepancies between the source and target languages.",
        "We therefore propose syntactic reordering for cross-lingual language modeling, and present a first result that compares inversion transduction grammar (ITG) reordering constraints to IBM and local constraints in an integrated speech transcription and translation system.",
        "Evaluations on resource-poor Cantonese speech transcription and Cantonese to resource-rich Mandarin translation tasks show that our proposed approach improves the system performance significantly, up to 3.4% relative WER reduction in Cantonese transcription and 13.3% relative bilingual evaluation understudy (BLEU) score improvement in Mandarin transcription compared with the system without reordering."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Statistical language modeling techniques have achieved remarkable success in speech and language processing (Clarkson and Rosenfeld, 1997; Stolcke, 2002).",
        "However, this success largely depends on the availability of a large amount of suitable text data in a language.",
        "Without sufficient text data for training, it is very difficult to build a practical and usable statistical language model.",
        "Therefore, most of the advances have been reported in so called resource-rich language such as English, Mandarin and Japanese, after creating linguistic resources of these languages at considerable cost.",
        "Today there are more than 6000 living languages spoken in the world (Gordon et al2005), and most of them have little transcribed texts and are considered as resource-poor languages (Nakov and Ng, 2009).",
        "Many of these languages are actually spoken by a huge number of speakers (e.g. some Chinese and Indian languages), and thus there is still a great demand to build speech and language processing systems for these languages.",
        "Owing to data scarcity, most often an interpolation (Bellegarda, 2004) of language models between a resource-poor language and a resource-rich language is used in most low-resource ASR systems.",
        "Some researchers have proposed transforming resource-rich language models to resource-poor language models by word-level transduction, either in a context-independent or context-dependent manner (Hori et al2003; Akita and Kawahara, 2006; Jensson et al2009; Neubig et al2010).",
        "In (Jensson et al2009), a simple dictionary based context-independent transduction from a resource-rich language to a resource-poor language is exploited to improve speech recognition of the resource-poor language.",
        "In (Hori et al2003; Akita and Kawahara, 2006; Neubig et al2010), context-dependent transduction is exploited.",
        "In their case, the resource-poor language is a spoken language, and the resource-rich language is a written language.",
        "They carried out language model transformation since the input speech",
        "is in speaking-style and the output text is in written-style.",
        "Others have investigated cross-lingual information between a resource-poor language and a resource-rich language.",
        "In (Khudanpur and Kim, 2002), cross-language cues are used to improve a language model of a resource-poor language.",
        "They used cross-lingual unigram probabilities trained from a story-specific parallel corpus of the resource-poor and resource-rich languages.",
        "They interpolate the language model of the resource-poor language with those unigram probabilities.",
        "In (Kim and Khudanpur, 2003), an n-gram language model in a resource-poor language is interpolated with cross-lingual unigram trigger probabilities.",
        "These triggers are word pairs of the resource-poor and resource-rich languages with the highest mutual information across these two languages.",
        "Another way of estimating those unigram probabilities is using latent semantic analysis by measuring cosine similarities from a document-aligned corpus for any given word pair (Kim and Khudanpur, 2004).",
        "Both interpolation and word-level transduction approaches fail to meet the challenge of syntactic discrepancies between the resource-poor and resource-rich languages.",
        "This syntactic discrepancies exist, for example, even between the Sinitic languages and Indian languages1 of the same family.",
        "Sinitic languages such as Cantonese/Yue, Shanghai/Wu, etc.",
        "are officially considered as ?dialects?",
        "of the standard Chinese Mandarin (or Putonghua)2.",
        "However, they differ greatly from Mandarin in all aspects and are not mutually comprehensible.",
        "For instance, in addition to lexical and pronunciation differences, Cantonese Chinese (Lee, 2011) differs syntactically from Mandarin as well - we found that there are approximately 10% syntactic inversions between sentences of the two forms of Chinese.",
        "We suggest that a better approach than interpolation and word-level transduction is to use cross-lingual language modeling with syntactic reorder",
        "there are very few written texts available for training language models.",
        "In this paper, we treat Cantonese as a typical resource-poor language and Mandarin as a typical resource-rich language.",
        "This language pair will be used for illustration purposes throughout this paper.",
        "ing.",
        "A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences.",
        "It has been shown in (Zens and Ney, 2003; Kanthak et al2005; Dreyer et al2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs.",
        "Previous work on weighted finite-state transducer (WFST) based speech translation such as (Casacuberta et al2004; Zhou et al2005; Zhou et al2006; Mathias and Byrne, 2006; Ma-tusov et al2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules.",
        "We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual language modeling for speech recognition.",
        "We will implement a cross-lingual language model using WFSTs, and integrate it into a WFST-based speech recognition search space to give both resource-poor language and resource-rich language transcriptions.",
        "This creates an integrated speech transcription and translation framework.",
        "This paper is organized as follows: Section 2 presents our proposed cross-lingual language modeling with syntactic reordering.",
        "In Section 3, we discuss speech recognition with cross-lingual language models.",
        "Section 4 and 5 give the experimental setup and results.",
        "We conclude our work at the end of this paper."
      ]
    },
    {
      "heading": "2 Cross-lingual Language Modeling with",
      "text": []
    },
    {
      "heading": "Syntactic Reordering",
      "text": [
        "In automatic speech recognition (ASR), given an observed source speech vector X, the decoding process searches the best word sequence v?I1 (consists of words v1, v2, ..., vI ) by maximizing the posterior probability P (vI1 |X), where vI1 is the source transcript representing the transcription of the source speech (see Eq.",
        "(1)).",
        "According to Bayes?",
        "law, we can decompose P (vI1 |X) into an acoustic model P (X|vI1) and a language model P (vI1).",
        "If a source language Lv is a resource-rich language, then the language model P (vI1) can be well estimated from sufficient training texts.",
        "However, if the source lan",
        "guage Lv is a resource-poor language, then the language model P (vI1) cannot be reliably or robustly estimated due to lack of training texts.",
        "Since this paper tackles the language modeling challenge for low-resource speech recognition, here we just assume that the source language Lv is a resource-poor language.",
        "We further assume that there is a target language Lw, which is a resource-rich language closely related to the language Lv.",
        "In order to improve the language model P (vI1) of the resource-poor language Lv, we introduce cross-lingual language modeling by decomposing the language model P (vI1) into a translation model P (vI1 |wJ1 ) and a language model P (wJ1 ) of the resource-rich language Lw (see Eq.",
        "(1)).",
        "wJ1 is the target resource-rich language transcript that consists of words w1, w2, ..., wJ .",
        "P (vI1 |wJ1 )P (wJ1 ) is defined as a cross-lingual language model.",
        "It lever-ages the abundant statistics from the language model P (wJ1 ) to improve the language model P (vI1) of the resource-poor language.",
        "The translation model P (vI1 |wJ1 ) can be estimated by addressing the discrepancies between the resource-poor language Lv and the resource-rich language Lw, which can be modeled from a parallel corpus of the Lv transcript vI1 and the Lw transcript wJ1 .",
        "For the syntactic inversions, we reorder the word or phrase positions of the Lw language model into those of the Lv language model.",
        "We have observed that most of the words are aligned monotonically between Lv and Lw within a phrase.",
        "This paper, therefore only considers phrase-level reordering, which effectively preserves the monotonic word sequences within phrases, and significantly reduces the number of reordering paths compared with word-level reordering."
      ]
    },
    {
      "heading": "2.1 Preprocessing: Phrase Extraction and Segmentation",
      "text": [
        "Our discussion starts with phrase extraction from the parallel corpus.",
        "We define a phrase sequence v?K1 (consists of phrases v?1, v?2, ..., v?K ) segmented from the word-level Lv transcript vI1 and w?K1 (consists of phrases w?1, w?2, ..., w?K ) segmented from the word-level Lw transcript wJ1 .",
        "Furthermore, we define a reordering sequence rK1 , of which the detail can be found in Section 2.2.",
        "The phrase-level translation model P (vI1 |wJ1 ) is decomposed into four components (see Eq.",
        "(2)): segmentation model P (w?K1 |wJ1 ), phrasal reordering model P (rK1 |w?K1 , wJ1 ), phrase-to-phrase transduction model P (v?K1 |rK1 , w?K1 , wJ1 ) and reconstruction model P (vI1 |v?K1 , rK1 , w?K1 , wJ1 ).",
        "Before presenting each component model, we need to extract two phrase tables for the Lv transcript and the Lw transcript, respectively.",
        "The phrase extraction is based on word-to-word alignments of the parallel corpus.",
        "We train word alignments in both directions with GIZA++, and then symmetrize the two alignments using the refined method (Och and Ney, 2003).",
        "Figure 1 shows an example of word-to-word alignment results between an Lv transcript (Cantonese) and an Lw transcript (Mandarin), from which phrase-to-phrase alignments are derived by identifying deletion, substitution, insertion and inversion.",
        "Prior to phrasal reordering, the segmentation model P (w?K1 |wJ1 ) implemented by a segmentation WFST Sw is applied to segment a word sequence wJ1 in the Lw language model into a phrase sequence {w?1, w?2, ..., w?K}.",
        "The maximum number of words that can be segmented into one phrase is controlled by a segmentation order s. An example of Sw is shown in Figure 3(a1).",
        "It segments a word sequence {w1, w2, w3} into a phrase sequence {w1, w2 w3} after performing composition (Mohri, 2009) with the target Lw language model (see Figure 3(b1 & b2))3."
      ]
    },
    {
      "heading": "2.2 Phrasal Reordering Model",
      "text": [
        "Given a phrase sequence {w?1, w?2, ..., w?K} of the Lw transcript, the role of the reordering model P (rK1 |w?K1 , wJ1 ) is to reorder phrase positions of the Lw transcript into those of the Lv transcript by permutation of w?K1 according to a reordering sequence {rK1 : rk ?",
        "{1, 2, ...,K}, rk 6= rk?",
        "6=k}.",
        "The phrase sequence {w?1, w?2, ..., w?K} is therefore reordered into {w?r1 , w?r2 , ..., w?rK } consequently (see Figure 2 where K = 3).",
        "Since arbitrary permutations of K phrases are NP-hard (Knight, 1999), reordering constraints have to be set over rK1 to reduce the number of permutations.",
        "There are three reordering constraints widely used in statistical machine translation, namely local constraints, IBM constraints and ITG constraints.",
        "Here we would like to point out that this is the first time that reordering constraints have been incorporated into a cross-lingual language model for speech recognition."
      ]
    },
    {
      "heading": "Reordering Constraints",
      "text": [
        "Local constraints make the restriction that one phrase can jump at most L?1 phrases either forward or backward, where L is the reordering distance (or window size of permutation)4 .",
        "The generation of rK1 under local constraints can be viewed as solving of the following problem (Kl?ve, 2009): secutive words forming a phrase.",
        "for all k?",
        "IBM constraints, a superset of local constraints (Dreyer et al2007), generate permutations rK1 deviate from the monotonic phrase order {rK1 : rk = k}.",
        "More specifically, any phrase position rk can be selected from the positions of the first m yet uncovered phrases (see Eq.",
        "(3)).",
        "A typical value of m is 4 (Zens and Ney, 2003), and we write IBM constraints",
        "ITG constraints provide a more faithful coverage of syntactic reordering in the parallel data than local constraints and IBM constraints.",
        "Our presentation of ITG constraints starts with defining of some permutation sets.",
        "Let SK be the set of permutations on {1,2,. .",
        ".",
        ",K}.",
        "A permutation rK1 ?",
        "SK , where rK1 = r1r2 .",
        ".",
        ".",
        "rK , contains a subsequence of type ?",
        "?",
        "SM if and only if a sequence of indices 1 ?",
        "i1 < i2 < .",
        ".",
        ".",
        "< iM ?",
        "K exists such that ri1ri2 .",
        ".",
        ".",
        "riM has all the same pairwise comparisons as ?",
        ".",
        "We denote the set of permutations of SK not containing subsequences of type ?",
        "by SK(?).",
        "If we have sets SK(?1), .",
        ".",
        ".",
        ", SK(?p), we denote the set SK(?1)?",
        ".",
        ".",
        ".",
        "?SK(?p) by SK(?1, .",
        ".",
        ".",
        ", ?p) (Barcucci et al2000).",
        "ITG constraints allow the permutation set SK(3142, 2413), which forbids subsequence of type (3, 1, 4, 2) and its dual (2, 4, 1, 3).",
        "Explicitly, ITG constraints avoid any permutation rK1 satisfying either ri2 < ri4 < ri1 < ri3 or ri3 < ri1 < ri4 < ri2 , where 1 ?",
        "i1 < i2 < i3 < i4 ?",
        "K .",
        "In (Wu, 1997), these forbidden subsequences are called ?inside-out?",
        "transpositions.",
        "They are fairly distorted matchings, and hardly observed in real parallel data.",
        "In order to get an intuitive sense of the reordering capability of those three constraints, we list the number of permutations under local constraints, IBM constraints as well as ITG constraints5 in Table 1.",
        "5Interestingly, when K = L, the number of permuta",
        "We can see that given the same K (K ?",
        "10) and L (L ?",
        "6), IBM constraints have less permutations than local constraints, and ITG constraints have less permutations than IBM constraints in general (only one exception when K = L = 6).",
        "These observations indicate that ITG constraints can filter out more unlikely permutations for a fixed reordering distance, resulting in longer distance reordering capability.",
        "Table 1 also tells us that the phrase number K and the reordering distance L for any of the constraints cannot be too large for practical implementation.",
        "For instance, if L = 6 and K goes from 6 to 7, the order of magnitude of NLocal, NIBM(4) and NITG increases from 2 to 3.",
        "Hence, phrases for permutation should be selective to cover the most possible re-orderings.",
        "If long reordering distances are allowed, unlikely permutations should be pruned so that the memory consumption becomes manageable."
      ]
    },
    {
      "heading": "Reordering Sequence Distribution",
      "text": [
        "So far we have discussed the issue that how to generate permutations for the reordering model using reordering constraints.",
        "Another issue is how to parameterize the reordering sequence distribution.",
        "Both ITG constraints and other constraints assume that all permutations are equally probable.",
        "However, it makes sense to restrict those non-monotonic re-orderings when performing the translation.",
        "This not only helps the search of the most likely permutation, but also guides the pruning of unlikely permutations.",
        "We make a first order Markov assumption over the phrasal reordering model P (rK1 |w?K1 , wJ1 ) (see Eq.",
        "(4)).",
        "The reordering sequence distribution is param-eterized to assign decreasing likelihood to phrase re-orderings {w?r1 , w?r2 , .",
        ".",
        ".",
        ", w?rK} that diverge from the original word order (Och et al1999; Kumar et al. 2005).",
        "Suppose w?rk = wl",
        "q , the reordering sequence distribution is set as Eq.",
        "(5), where p0 is a tuning factor.",
        "We normalize the probabilities P (rk|rk?1) such that",
        "Assume that we have a phrase sequence {w?1, w?2, w?3}, Figure 2 shows the phrasal reordering model implemented by a reordering WFST ?r under the first order Markov assumption for this phrase sequence.",
        "Figure 3(a2) gives one more example of ?r, which reorders the phrase sequence {w1, w2 w3} into {w2 w3, w1}6.",
        "Within the WFST paradigm, reordering models under any of those constraints can be integrated into the cross-lingual language model.",
        "menting the phrasal reordering model under the first order Markov assumption."
      ]
    },
    {
      "heading": "2.3 Phrase-to-Phrase Transduction Model",
      "text": [
        "Once the phrase sequence of the Lw transcript is reordered into the Lv transcript order, we use the phrase-to-phrase transduction model specified in Eq.",
        "(6) to perform the cross-language transduction.",
        "Given sufficient parallel training data, the context-dependent phrase-to-phrase transduction model can be estimated using the GIATI method (Casacuberta and Vidal, 2004).",
        "However, for the translation task with scarce training data, the context-dependent transduction probabilities may not be reliably estimated.",
        "Therefore, we assume that a phrase v?k is generated independently by each phrase w?rk .",
        "C(v?k, w?rk) is the number of times that phrase v?k is aligned to w?rk in the parallel corpus.",
        "This model can be implemented by a WFST Tvw which transduces v?k to w?rk .",
        "Figure 3(a3) shows an example of Tvw transducing v2 v3 to w2 w3."
      ]
    },
    {
      "heading": "2.4 Reconstruction Model",
      "text": [
        "Reconstruction model P (vI1 |v?K1 , rK1 , w?K1 , wJ1 ) operates in the opposite direction as the segmentation 6For simplicity, reordering sequence distributions are not shown there.",
        "model.",
        "It generates a word sequence vI1 from a phrase sequence v?K1 .",
        "The reconstruction model can be implemented by a WFST Rv.",
        "An example of Rv is shown in Figure 3(a4), which reconstructs a phrase v2 v3 into a word sequence {v2, v3}."
      ]
    },
    {
      "heading": "3 Speech Recognition with Cross-Lingual",
      "text": []
    },
    {
      "heading": "Language Models",
      "text": [
        "The translation model P (vI1 |wJ1 ) can be constructed via WFST composition (denoted by ?)",
        "(Mohri, 2009) of all the component models as shown in Eq.",
        "(7) and Figure 3, where T is the final composed WFST that transduces vI1 to wJ1 .",
        "The cross-lingual language model Gcl is constructed through composition (see Eq.",
        "(8)) of the translation model and a resource-rich language model G.",
        "As the way of integrating a resource-rich language model G into ASR search space (Mohri et al. 2008), we can integrate the cross-lingual language model Gcl into ASR search space in a globally optimized way as well.",
        "The search space can be implemented using a transducer ASR, which is formulated with a unified WFST approach as shown in Eq.",
        "(9).",
        "Here H transduces HMM states to context-dependent phones.",
        "C represents a transduction from context-dependent phones to context-independent phones.",
        "L is a lexicon transducer which maps context-independent phone sequences to word strings restricted to the input symbols of the cross-lingual language model transducer Gcl.",
        "Eq.",
        "(9) outputs the recognition result in a resource-rich language.",
        "If recognition system requires recognition outputs in a resource-poor language, then the search space should be constructed as Eq.",
        "(10), where ?",
        "is a projection (Mohri, 2009) operator which projects the input label to the output label.",
        "Before decoding, the recognition transducer ASR can be optimized by a determinization operation right after each composition.",
        "represented by the Lw language model G (b1) is segmented into a phrase sequence {w1, w2 w3} (b2); {w1, w2 w3} is reordered into {w2 w3, w1} (b3); phrase w2 w3 is transduced to v2 v3 (b4); phrase v2 v3 is reconstructed into a word sequence {v2, v3} (b5).",
        "wk and vk represent wk and vk, respectively.",
        "?-?",
        "refers to ?",
        "or null symbol.",
        "Auxiliary symbols #1,#2, ?",
        "?",
        "?",
        "are used to make the WFST determinizable (Mohri, 2009) such that the transducer can be optimized by a determinization (Mohri, 2009) operation which significantly reduces the search network size."
      ]
    },
    {
      "heading": "4 Experimental Setup",
      "text": []
    },
    {
      "heading": "4.1 Corpus and Model Training",
      "text": [
        "To investigate the performance of our proposed cross-lingual language models, we have chosen Cantonese as a resource-poor language and Mandarin as a resource-rich language.",
        "We have collected Cantonese parliamentary speech from the Hong Kong Legislative Council.",
        "Currently we only have 4152 parallel transcribed sentences containing 19.4 hours of speech.",
        "It is separated into three sets, a training set (11.9 hours, 2700 sentences), a development set (3.7 hours, 788 sentences), and an evaluation set (3.8 hours, 664 sentences).",
        "The sentences in the evaluation set are a bit longer than those in the development set.",
        "The parallel transcriptions of the training set constitute a parallel corpus, which includes Cantonese transcription (manual transcription) of 106k words and Mandarin transcription (Hansard7 transcription) of 80k words.",
        "The statistics of substitutions, insertions, deletions and inversions identified in the parallel corpus are shown in Table 2.",
        "Besides the parallel corpus, we have a set of additional Mandarin transcriptions, which has",
        "The training set is used for training an acoustic model (including H and C) using a Maximum Likelihood criterion.",
        "It adopts 13 MFCC coefficients, together with 13 delta coefficients and 13 acceleration coefficients as the acoustic features.",
        "The acoustic model comprises 73 Hidden Markov Models (HMMs) to represent 70 Cantonese phonemes as well as silence, short pause, and noise.",
        "During the acoustic model training, tied-state crossword tri-phones are constructed by decision tree clustering.",
        "7Hansard is a name of the printed transcripts of parliamentary debates.",
        "The parallel corpus is used for training the translation model T .",
        "Together with the parallel corpus, the additional Mandarin transcriptions are used for training an interpolated word-level trigram language model G, where the lexicon size is about 28K.",
        "A modified scheme of Kneser-Ney discounting is applied for the language model G with a back-off threshold of 1 for unigram and 2 for bigram.",
        "The cross-lingual language model Gcl can be obtained by composition of T and G."
      ]
    },
    {
      "heading": "4.2 Decoding and Evaluation Method",
      "text": [
        "Decoding of the speech recognition search space ASR is performed by T 3 Decoder (Dixon et al., 2009), which is a state-of-the-art WFST-based LVCSR speech decoder.",
        "Decoding of ASR in Eq.",
        "(9) gives Mandarin outputs.",
        "Decoding of ASR in Eq.",
        "(10) gives Cantonese outputs.",
        "In our experiments, we use the following evaluation criteria: WER (word error rate).",
        "The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence (Zens et al2004).",
        "The WER relates the speech recognition accuracy.",
        "The lower WER, the better.",
        "BLEU (bilingual evaluation understudy) score.",
        "The BLEU score measures the precision of n-grams (unigrams, bigrams, trigrams and fourgrams) with respect to a reference translation with a penalty for too short sentences (Papineni et al2002).",
        "The BLEU score reflects the translation accuracy.",
        "The larger BLEU score, the better.",
        "We perform WER evaluation of decoding outputs of Eq.",
        "(10) and BLEU score evaluation of decoding outputs of Eq.",
        "(9) using the evaluation set.",
        "The WER evaluation is on the Cantonese output against the Cantonese reference transcription (manual transcription).",
        "The BLEU score evaluation is on the Mandarin output against the Mandarin reference transcription (Hansard transcription)."
      ]
    },
    {
      "heading": "4.3 Parameter Settings",
      "text": [
        "The performance of our proposed cross-lingual language models is sensitive to many parameters.",
        "Firstly, segmentation order s affects phrase extraction.",
        "The optimal value depends on the language",
        "pair and the size of corpus.",
        "Secondly, p0 in the first order Markov assumption affects the decoding results.",
        "Thirdly, the number of reordering permutations or paths are formidable when the reordering distance L is long as suggested by Table 1.",
        "Therefore, we apply histogram pruning to reordering paths, which only maintains top N most likely ones.",
        "The development set is used for tuning parameters p0 and N ."
      ]
    },
    {
      "heading": "5 Experimental Results",
      "text": [
        "The evaluation results of the proposed cross-lingual language models Gcl with reordering under various constraints are presented in Table 3, where Gcl = Ts?G = T3?G.8 In general, reordering has a significant effect on enhancing the performance of recognition and translation in the sense of WER reduction and BLEU improvement.",
        "Compared with the cross-lingual language model without reordering, the cross-lingual language model with reordering under local constraints gives 0.70% absolute WER reduction and 3.06 absolute BLEU improvement.",
        "The cross-lingual language model with reordering under IBM constraints gives 0.85% absolute WER reduction and 3.58 absolute BLEU improvement.",
        "The cross-lingual language model with reordering under ITG constraints yields the best performance, with 0.92% absolute WER reduction and 3.89 absolute BLEU improvement.",
        "All WER improvements pointed out here are statistically significant at 99% confidence according to a two-proportional z-test, and all BLEU improvements are statistically significant at 95% confidence according to a paired student t-test using bootstrap resampling.",
        "8We have chosen segmentation order s = 3 because it works the best in our system."
      ]
    },
    {
      "heading": "6 Conclusions",
      "text": [
        "We have proposed cross-lingual language modeling with phrase-level syntactic reordering for low-resource speech recognition.",
        "The cross-lingual language modeling enriches a resource-poor language model by leveraging the language model from a closely related resource-rich language.",
        "It provides an effective method to solve the low-resource language modeling challenge by using a large amount of resource-rich language (e.g. Mandarin) data and a small amount of resource-poor language (e.g. Cantonese) data, as well as some parallel data of resource-poor and resource-rich languages.",
        "With a cross-lingual language model, our ASR system can decode speech into transcriptions, either in a resource-poor language or a resource-rich language, using a single WFST-based speech decoder.",
        "We have presented a first end-to-end WFST source to target language transcription and translation system with syntactic reordering and global optimization.",
        "Our work is the first to use ITG constraints for the syntactic reordering in such an integrated system.",
        "We also did comparative study of ITG constraints, IBM constraints and local constraints in the reordering model, for completeness.",
        "We have also presented the determinizable design of each transducer for composing a cross-lingual language model such that we can optimize the search network by determinization.",
        "This is crucially important to successfully build a practical integrated system, and, of course, the work is extremely challenging.",
        "Experiments on Cantonese recognition and Cantonese to Mandarin translation tasks have shown that our proposed cross-lingual language model substantially improves the performance of the recognition and translation.",
        "The best system gives 12.5% relative WER reduction in Cantonese (resource-poor",
        "language) transcriptions over the system using interpolation.",
        "The best reordering model gives 3.4% relative WER reduction and 13.3% relative BLEU score improvement in Mandarin (resource-rich language) transcriptions over the system without reordering.",
        "The improvements have been found to be statistically significant.",
        "Even though the objective of our work is for speech recognition, our proposed cross-lingual language modeling can be easily applied to speech translation of other language pairs for efficient direct decoding from source speech to target text."
      ]
    },
    {
      "heading": "7 Acknowledgments",
      "text": [
        "This work is partially supported by ITS/189/09 and CERG#612211.",
        "The authors would like to thank Dr. Tasuku Oonishi for providing access to the T 3 decoder, and thank Prof. Sadaoki Furui and his team for useful discussions.",
        "Thanks should go to Yue Yu and Percy Cheung for collecting the Cantonese and Mandarin parallel data.",
        "Thanks also go to Ricky Chan for training the Cantonese acoustic model and Dr. Markus Saers for helping on training the GIZA word-to-word alignment models."
      ]
    }
  ]
}
