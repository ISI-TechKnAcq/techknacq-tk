{
  "info": {
    "authors": [
      "Joel Lang",
      "Mirella Lapata"
    ],
    "book": "EMNLP",
    "id": "acl-D11-1122",
    "title": "Unsupervised Semantic Role Induction with Graph Partitioning",
    "url": "https://aclweb.org/anthology/D11-1122",
    "year": 2011
  },
  "references": [
    "acl-D07-1002",
    "acl-D09-1002",
    "acl-D10-1056",
    "acl-D10-1073",
    "acl-J02-3001",
    "acl-J05-1004",
    "acl-J08-2001",
    "acl-J08-2006",
    "acl-N09-1014",
    "acl-N09-2004",
    "acl-N10-1137",
    "acl-P03-1002",
    "acl-P05-1077",
    "acl-P07-1025",
    "acl-P09-1004",
    "acl-P10-1024",
    "acl-P10-1149",
    "acl-P11-1112",
    "acl-P95-1026",
    "acl-W04-3213",
    "acl-W06-1601",
    "acl-W06-3812",
    "acl-W08-2121",
    "acl-W10-2301"
  ],
  "sections": [
    {
      "text": [
        "Joel Lang and Mirella Lapata",
        "Institute for Language, Cognition and Computation School of Informatics, University of Edinburgh 10 Crichton Street, Edinburgh EH8 9AB, UK",
        "In this paper we present a method for unsupervised semantic role induction which we formalize as a graph partitioning problem.",
        "Argument instances of a verb are represented as vertices in a graph whose edge weights quantify their role-semantic similarity.",
        "Graph partitioning is realized with an algorithm that iteratively assigns vertices to clusters based on the cluster assignments of neighboring vertices.",
        "Our method is algorithmically and conceptually simple, especially with respect to how problem-specific knowledge is incorporated into the model.",
        "Experimental results on the CoNLL 2008 benchmark dataset demonstrate that our model is competitive with other unsupervised approaches in terms of Fl whilst attaining significantly higher cluster purity."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Recent years have seen increased interest in the shallow semantic analysis of natural language text.",
        "The term is most commonly used to describe the automatic identification and labeling of the semantic roles conveyed by sentential constituents (Gildea and Jurafsky, 2002).",
        "Semantic roles describe the semantic relations that hold between a predicate and its arguments (e.g., \"who\" did \"what\" to \"whom\", \"when\", \"where\", and \"how\") abstracting over surface syntactic configurations.",
        "In the example sentences below, window occupies different syntactic positions – it is the object of broke in sentences (la,b), and the subject in (lc) – while bearing the same semantic role, i.e., the physical object affected by the breaking event.",
        "Analogously, ball is the instrument of break both when realized as a prepositional phrase in (la) and as a subject in (lb).",
        "(1) a.",
        "[Jim]Ao broke the [window]^ with a [ball]A2.",
        "b.",
        "The [ball]A2 broke the [window]^.",
        "c. The [window]^ broke [last night] tmp-",
        "The semantic roles in the examples are labeled in the style of PropBank (Palmer et al., 2005), a broad-coverage human-annotated corpus of semantic roles and their syntactic realizations.",
        "Under the Prop-Bank annotation framework (which we will assume throughout this paper) each predicate is associated with a set of core roles (named AO, Al, A2, and so on) whose interpretations are specific to that predicate and a set of adjunct roles such as location or time whose interpretation is common across predicates (e.g., last night in sentence (lc)).",
        "The availability of PropBank and related resources (e.g., FrameNet; Ruppenhofer et al.",
        "(2006)) has sparked the development of great many semantic role labeling systems most of which conceptualize the task as a supervised learning problem and rely on role-annotated data for model training.",
        "Most of these systems implement a two-stage architecture consisting of argument identification (determining the arguments of the verbal predicate) and argument classification (labeling these arguments with semantic roles).",
        "Despite being relatively shallow, se-",
        "'More precisely, AO and Al have a common interpretation across predicates as proto-agent and proto-patient in the sense ofDowty (1991).",
        "mantic role analysis has the potential of benefiting a wide spectrum of applications ranging from information extraction (Surdeanu et al., 2003) and question answering (Shen and Lapata, 2007), to machine translation (Wu and Fung, 2009) and summarization (Melli et al., 2005).",
        "Current approaches have high performance – a system will recall around 81% of the arguments correctly and 95% of those will be assigned a correct semantic role (see Marquez et al.",
        "(2008) for details), however only on languages and domains for which large amounts of role-annotated training data are available.",
        "For instance, systems trained on PropBank demonstrate a marked decrease in performance (approximately by 10%) when tested on out-of-domain data (Pradhan et al., 2008).",
        "Unfortunately, the reliance on role-annotated data which is expensive and time-consuming to produce for every language and domain, presents a major bottleneck to the widespread application ofsemantic role labeling.",
        "In this paper we argue that unsupervised methods offer a promising yet challenging alternative.",
        "If successful, such methods could lead to significant savings in terms of annotation effort and ultimately yield more portable semantic role labelers that require overall less engineering effort.",
        "Our approach formalizes semantic role induction as a graph partitioning problem.",
        "Given a verbal predicate, it constructs a weighted graph whose vertices correspond to argument instances of the verb and whose edge weights quantify the similarity between these instances.",
        "The graph is partitioned into vertex clusters representing semantic roles using a variant of Chinese Whispers, a graph-clustering algorithm proposed by Biemann (2006).",
        "The algorithm iteratively assigns cluster labels to graph vertices by greedily choosing the most common label amongst the neighbors of the vertex being updated.",
        "Beyond extending Chinese Whispers to the semantic role induction task, we also show how it can be understood as a type of Gibbs sampling when our graph is interpreted as a Markov random ield.",
        "Experimental results on the CoNLL 2008 benchmark dataset demonstrate that our method, despite its simplicity, improves upon competitive approaches in terms of F1 and achieves signiicantly higher cluster purity."
      ]
    },
    {
      "heading": "2. Related Work",
      "text": [
        "Although the bulk of previous work on semantic role labeling has primarily focused on supervised methods (Marquez et al., 2008), a few semi-supervised and unsupervised approaches have been proposed in the literature.",
        "The majority of semi-supervised models have been developed within a framework known as annotation projection.",
        "The idea is to combine labeled and unlabeled data by projecting annotations from a labeled source sentence onto an unlabeled target sentence within the same language (Furstenau and Lapata, 2009) or across different languages (Padó and Lapata, 2009).",
        "Outwith annotation projection, Gordon and Swanson (2007) propose to increase the coverage of PropBank to unseen verbs by inding syntactically similar (labeled) verbs and using their annotations as surrogate training data.",
        "Swier and Stevenson (2004) were the first to introduce an unsupervised semantic role labeling system.",
        "Their algorithm induces role labels following a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classiier trained on previously labeled instances.",
        "Their method starts with a dataset containing no role annotations at all, but crucially relies on VerbNet (Kipper et al., 2000) for identifying the arguments of predicates and making initial role assignments.",
        "VerbNet is a manually constructed lexicon of verb classes each of which is explicitly associated with argument realization and semantic role speciications.",
        "Subsequent work has focused on unsupervised methods for argument identiication and classiica-tion.",
        "Abend et al.",
        "(2009) recognize the arguments of predicates by relying solely on part of speech annotations whereas Abend and Rappoport (2010) distinguish between core and adjunct roles, using an unsupervised parser and part-of-speech tagger.",
        "Grenager and Manning (2006) address the role induction problem and propose a directed graphical model which relates a verb, its semantic roles, and their possible syntactic realizations.",
        "Latent variables represent the semantic roles of arguments and role induction corresponds to inferring the state of these latent variables.",
        "Following up on this work, Lang and Lapata (2010) formulate role induction as the process of detecting alternations and inding a canonical syntactic form for them.",
        "Verbal arguments are then assigned roles, according to their position in this canonical form, since each position references a speciic role.",
        "Their model extends the logistic classiier with hidden variables and is trained in a manner that takes advantage of the close relationship between syntactic functions and semantic roles.",
        "More recently, Lang and Lapata (2011) propose a clustering algorithm which irst splits the argument instances of a verb into ine-grained clusters based on syntactic cues and then executes a series of merge steps (mainly) based on lexical cues.",
        "The split phase creates a large number of small clusters with high purity but low collocation, i.e., while the instances in a particular cluster typically belong to the same role the instances for a particular role are commonly scattered amongst many clusters.",
        "The subsequent merge phase conflates clusters with the same role in order to increase collocation.",
        "Like Grenager and Manning (2006) and Lang and Lapata (2010; 2011), this paper describes an unsupervised method for semantic role induction, i.e., one that does not require any role annotated data or additional semantic resources for training.",
        "Contrary to these previous approaches, we conceptualize role induction in a novel way, as a graph partitioning problem.",
        "Our method is simple, computationally ef-icient, and does not rely on hidden variables.",
        "Moreover, the graph-based representation for verbs and their arguments affords greater modeling flexibility.",
        "A wide range of methods exist for inding partitions in graphs (Schaeffer, 2007), besides Chinese Whispers (Biemann, 2006), which could be easily applied to the semantic role induction problem.",
        "However, we leave this to future work.",
        "Graph-based methods are popular in natural language processing, especially with unsupervised learning problems (Chen and Ji, 2010).",
        "The Chinese Whispers algorithm itself (Biemann, 2006) has been previously applied to several tasks including word sense induction (Klapaftis and M., 2010) and unsupervised part-of-speech tagging (Christodoulopou-los et al., 2010).",
        "The same algorithm is also described in Abney (2007, pp.",
        "146-147) under the name \"clustering by propagation\".",
        "The term makes explicit the algorithm's connection to label propagation, a general framework for semi-supervised learning (Zhu et al., 2003) with applications to machine translation (Alexandrescu and Kirchhoff, 2009) , information extraction (Talukdar and Pereira, 2010) and structured part-of-speech tagging (Sub-ramanya et al., 2010).",
        "The basic idea behind label propagation is to represent labeled and unlabeled instances as vertices in an undirected graph with edges whose weights express similarity (and possibly dissimilarity) between the instances.",
        "Label information is then propagated between the vertices in such a way that similar instances tend to be assigned the same label.",
        "Analogously, Chinese Whispers works by propagating cluster membership information along the edges of a graph, even though the graph does not contain any human-labeled instance vertices."
      ]
    },
    {
      "heading": "3. Problem Setting",
      "text": [
        "We adopt the standard architecture of supervised semantic role labeling systems where argument identi-ication and argument classiication are treated separately.",
        "Our role labeler is fully unsupervised with respect to both tasks – it does not rely on any role annotated data or semantic resources.",
        "However, our system does not learn from raw text.",
        "In common with most semantic role labeling research, we assume that the input is syntactically analyzed in the form of dependency trees.",
        "We view argument identiication as a syntactic processing step that can be largely undertaken deterministically through structural analysis of the dependency tree.",
        "We therefore use a small set of rules to detect arguments with high precision and recall (see Section 4).",
        "Argument classiication is more challenging and must take into account syntactic as well as lexical-semantic information.",
        "Both types of information are incorporated into our model through a similarity function that assigns similarity scores to pairs of argument instances.",
        "Following previous work (Lang and Lapata, 2010; Grenager and Manning, 2006), our system outputs verb-speciic roles by grouping argument instances into clusters and labeling each argument instance with an identiier corresponding to the cluster it has been assigned to.",
        "Such identiiers are similar to PropBank-style core labels (e.g., A0, A1)."
      ]
    },
    {
      "heading": "4. Argument Identification",
      "text": [
        "Supervised semantic role labelers often employ a classiier in order to decide for each node in the parse tree whether or not it represents a semantic argument.",
        "Nodes classiied as arguments are then assigned a semantic role.",
        "In the unsupervised setting, we slightly reformulate argument identiication as the task of discarding as many non-semantic arguments as possible.",
        "This means that the argument identiication component does not make a inal positive decision for any of the argument candidates; instead, a inal decision is only made in the subsequent argument classiication stage.",
        "We discard or select argument candidates using the set of rules developed in Lang and Lapata (2011).",
        "These are mainly based on the parts of speech and syntactic relations encountered when traversing a dependency tree from the predicate node to the argument node.",
        "For each candidate, rules are considered in a prespeciied order and the irst matching rule is applied.",
        "When evaluated on its own, the argument identiication component obtained 88.1% precision (percentage of semantic arguments out of those identified) and 87.9% recall (percentage of identiied arguments out of all gold arguments)."
      ]
    },
    {
      "heading": "5. Argument Classification",
      "text": [
        "After identifying likely arguments for each verb, the next step is to infer a label for each argument instance.",
        "Since we aim to induce verb-speciic roles (see Section 3), we construct an undirected, weighted graph for each verb.",
        "Vertices correspond to verb argument instances and edge weights quantify the similarities between them.",
        "This argument-instance graph is then partitioned into clusters of vertices representing semantic roles and each argument instance is assigned a label that indicates the cluster it belongs to.",
        "In what follows we irst describe how the graph is constructed and then provide the details of our graph partitioning algorithm.",
        "Figure 1: Simplified example of an argument-instance graph.",
        "All pairs of vertices with non-zero similarity are connected through edges that are weighted with a similarity score ^>(vi, Vj).",
        "Upon updating the label for a vertex all neighboring vertices propagate their label to the vertex being updated.",
        "The score for each label is determined by summing together the weighted votes for that label and the label with the maximal score is chosen.",
        "For each verb we construct an undirected, weighted graph G = (V, E, <\\>) with vertices V, edges E, and edge weight function ^ as follows.",
        "Each argument instance in the corpus that belongs to the verb is added as a vertex.",
        "Then, for each possible pair of vertices (vi}Vj) we compute a weight §(vi,Vj) G R according to the function ^.",
        "If the weight is non-zero, an undirected edge e = (vi, Vj) with weight <\\>(vi, Vj) is added to the graph.",
        "The function ^ quantifies the similarity or dissimilarity between instances; positive values indicate that roles are likely to be the same, negative values indicate that roles are likely to differ, and zero values indicate that there is no evidence for either case.",
        "Our similarity function is symmetric, i.e., <\\>(Vi, Vj) = <\\>(Vj, Vi) and permits negative values (see Section 5.4 for a detailed description).",
        "Figure 1 shows an example of a graph for a verb with five argument instances (vertices A-E).",
        "Edges are drawn between pairs of vertices with non-zero similarity values.",
        "For instance, vertex D is connected to vertex A with weight 0.2, to vertex E with 1, and vertex C with – 1.",
        "Since edges are drawn between all pairs of vertices with non-zero similarity, the resulting graphs tend to be densely connected, which for large datasets may be prohibitively ineficient.",
        "A solution would be to sample a subset from all possible pairs, but we did not make use of any kind of edge pruning in our experiments.",
        "Graph partitioning is realized with a variant of Chinese Whispers (Biemann, 2006) whose details are given below.",
        "In addition, we discuss how our algorithm relates to other graph-based models in order to help provide a better theoretical understanding.",
        "We assume each vertex Vi is assigned a label li G {1... L} indicating the cluster it belongs to.",
        "Initially, each vertex belongs to its own cluster, i.e., we let the number of clusters L = |V | and set li i.",
        "Given this initial vertex labeling, the algorithm proceeds by iteratively updating the label for each vertex.",
        "The update is based on the labels of neighboring vertices and reflects their similarity to the vertex being updated.",
        "Intuitively, each neighboring vertex votes for the cluster it is currently assigned to, where the strength of the vote is determined by the similarity (i.e., edge weight) to the vertex being updated.",
        "The label li of vertex Vi is thus updated according to the following equation:",
        "li <r- arg max",
        "iterations the algorithm converges to a ixed labeling or oscillates between labelings that differ only in a few vertices.",
        "The result of the algorithm is a hard partitioning of the given graph, where the number of clusters is determined automatically.",
        "We make one important modiication to the basic algorithm described so far based on the intuition that higher scores for a label indicate more reliable propagations.",
        "More precisely, when updating vertex Vi to label l we deine the conidence of the update as the average similarity to neighbors with label l:",
        "conf (li l)",
        "where N(l) = {vjl(vi, Vj) G E A l = lj} denotes the set of Vi's neighbors with label l. In other words, for each label we compute a score by summing together the weights of edges to neighboring vertices with that label and select the label with the maximal score.",
        "Note that negative edges decrease the score for a particular label, thus demoting the label.",
        "Consider again Figure 1.",
        "Assume we wish to update vertex A.",
        "In addition, assume that B and E are currently assigned the same label (i.e., they belong to the same cluster) whereas C and D are each in different clusters.",
        "The score for cluster {B, E} is 0.4 + 0.8 = 1.2, the score for cluster {C} is 0.3 and the score for cluster {D} is 0.2.",
        "We would thus assign A to cluster {B, E} as it has the highest score.",
        "The algorithm is run for several iterations.",
        "At each iteration it passes over all vertices, and the update order of the vertices is chosen randomly.",
        "As the updates proceed, labels can disappear from the graph, whereby the number of clusters decreases.",
        "Empirically, we observe that for suficiently many",
        "We can then prioritize high-conidence updates by setting a threshold 0 and allowing only updates with confidence greater or equal to 0.",
        "The threshold is initially set to 1 (i.e., the maximal possible coni-dence) and then lowered by some small constant A after each iteration until it reaches a minimum 0min, at which point the algorithm terminates.",
        "This improves the resulting clustering, since it promotes reliable updates in earlier phases of the algorithm which in turn has a positive effect on successive updates.",
        "As described earlier, the edge weights in our graph are similarity scores, with positive values indicating similarity and negative values indicating dissimilarity.",
        "Determining the similarity function without access to labeled training data poses a major difficulty which we resolve by relying on prior linguistic knowledge.",
        "Speciically, we measure the similarity of argument instances based on three simple and intuitive criteria: (1) whether the instances are lexically similar; (2) whether the instances occur in the same syntactic position; and (3) whether the instances occur in the same frame (i.e., are arguments in the same clause).",
        "The same criteria were used in (Lang and Lapata, 2011) and shown effective in quantifying role-semantic similarity between clusters of argument instances.",
        "Lexical and syntactic similarity are scored through functions lex(vi} Vj) and syn(vi, Vj) with range [ – 1,1], whereas the third criterion enters the scoring function directly:",
        " – oo if viand v j are in same frame (4)",
        "lalex(Vi,Vj) + (1 – a)syn(Vi,Vj) otherwise.",
        "The irst case in the function expresses a common linguistic assumption, i.e., that two argument instances Viand Vj occurring in the same frame cannot have the same semantic role.",
        "The function implements this constraint by returning – oo.",
        "The syntactic similarity function s(Vi, Vj) indicates whether two argument instances occur in a similar syntactic position.",
        "We deine syntactic positions through four cues: the relation of the argument head word to its governor, verb voice (active/passive), the linear position of the argument relative to the verb (left/right) and the preposition used for realizing the argument (if any).",
        "The score is | where S is the number of cues which agree, i.e., have the same value.",
        "The syntactic score is set to zero when the governor relation of the arguments is not the same.",
        "Lexical similarity l (Vi, Vj) is measured in terms of the cosine of the angle between vectors hi and hj representing the argument head words:",
        "We obtain hi and hj from a simple semantic space model (Turney and Pantel, 2010) which requires no supervision (Section 6 describes the details of the model used in our experiments).",
        "Our similarity function weights the contribution of syntax vs. semantics equally, i.e., a is set to 0.5.",
        "This reflects the linguistic intuition that lexical and syntactic information are roughly of equal importance.",
        "This section briefly points out some connections to related models.",
        "The averaging procedure used for updating the graph vertices (Equation 2) appears in some form in most label propagation algorithms (see Talukdar (2010) for details).",
        "Label propagation algorithms are commonly interpreted as random walks",
        "Figure 2: The update rule (Equation 2) can be understood as choosing a minimal edge-cut, thereby greedily maximizing intra-cluster similarity and minimizing inter-cluster similarity.",
        "Assuming equal weight for all edges above, label 3 is chosen for the vertex being updated such that the sum of weights of edges crossing the cut is minimal.",
        "on graphs.",
        "In our case such an interpretation is not directly possible due to the presence of negative edge weights.",
        "This could be changed by transforming the edge weights onto a non-negative scale, but we ind the current setup more expedient for modeling dissimilarity.",
        "Our model could be also transformed into a probabilistic graphical model that speciies a distribution over vertex labels.",
        "In the transformed model each vertex corresponds to a random variable over labels and edges are associated with binary potential functions over vertex-pairs.",
        "Let 1(Vi = Vj) denote an indicator function which takes value 1 iff.",
        "li = lj and value 0, otherwise.",
        "Then pairwise potentials can be deined in terms of the original edge weights as \\\\f(Vi,Vj) = exp(1(Vi = Vj)((Vi,Vj)).",
        "A Gibbs sampler used to sample from the distribution of the resulting pairwise Markov random field (Bishop, 2006; Wainwright and Jordan, 2008) would employ almost the same update procedure as in Equation 2, the difference being that labels would be sampled according to their probabilities, rather than chosen deterministically based on scores.",
        "A third way of understanding the update rule is as a heuristic for maximizing intra-cluster similarity and minimizing inter-cluster similarity.",
        "By assigning the label with maximal score to Vi, we greedily maximize the sum of intra-cluster edge weights while minimizing the sum of inter-cluster edge weights, i.e., the weight of the edge-cut.",
        "This is illustrated in Figure 2.",
        "Cut-based methods are a common method in graph clustering (Schaeffer, 2007) and are also used for inference in pairwise Markov random ields like the one described in the previous paragraph (Boykov et al., 2001).",
        "Note that while it would be possible to transform our model into a model with a formal probabilistic interpretation (either as a graph random walk or as a probabilistic graphical model) this would not change the non-empirical nature of the similarity function, which is unavoidable in the unsupervised setting and is also common in the semi-supervised methods discussed in Section 2."
      ]
    },
    {
      "heading": "6. Experimental Setup",
      "text": [
        "In this section we describe how we assessed the performance of our model.",
        "We discuss the dataset on which our experiments were carried out, explain how our system's output was evaluated and present the methods used for comparison with our approach.",
        "Data We compared the output of our model against the PropBank gold standard annotations contained in the CoNLL 2008 shared task dataset (Sur-deanu et al., 2008).",
        "The latter was taken from the Wall Street Journal portion of the Penn Treebank and converted into a dependency format (Surdeanu et al., 2008).",
        "In addition to gold standard dependency parses, the dataset also contains automatic parses obtained from the MaltParser (Nivre et al., 2007) .",
        "The dataset provides annotations for verbal and nominal predicate-argument constructions, but we only considered the former, following previous work on semantic role labeling (Marquez et al., 2008) .",
        "All the experiments described in this paper use the CoNLL 2008 training dataset.",
        "Evaluation Metrics For each verb, we determine the extent to which argument instances in the clusters share the same gold standard role (purity) and the extent to which a particular gold standard role is assigned to a single cluster (collocation).",
        "More formally, for each group of verb-speciic clusters we measure the purity of the clusters as the percentage of instances belonging to the majority gold class in their respective cluster.",
        "Let N denote the total number of instances, Gj the set of instances belonging to the j-th gold class and Ci the set of instances belonging to the i-th cluster.",
        "Purity can be then written as:",
        "Collocation is deined as follows.",
        "For each gold role, we determine the cluster with the largest number of instances for that role (the role's primary cluster) and then compute the percentage of instances that belong to the primary cluster for each gold role:",
        "Per-verb scores are aggregated into an overall score by averaging over all verbs.",
        "We use the micro-average obtained by weighting the scores for individual verbs proportionately to the number of instances for that verb.",
        "Finally, we use the harmonic mean of purity and collocation as a single measure of clustering quality:",
        "Model Parameters Recall that our algorithm prioritizes updates with conidence higher than a threshold 0.",
        "Initially, 0 is set to 1 and its value decreases at each iteration by a small constant A which we set to 0.0025.",
        "The algorithm terminates when a minimum confidence 0min is reached.",
        "While choosing a value for A is straightforward – it simply has to be a small fraction of the maximal possible conidence – specifying 0min on the basis of objective prior knowledge is less so.",
        "And although a human judge could determine the optimal termination point based on several criteria such as clustering quality or the number of clusters, we used a development set instead for the sake of reproducibility and comparability.",
        "Speciically, we optimized 0min on the CoNLL test set and obtained best results with 0min = 3.",
        "This value was used for all our experiments and was also kept ixed for all verbs.",
        "Importantly, the development set was not used for any kind of supervised training.",
        "Table 1: Evaluation of the output of our graph partitioning algorithm compared to our previous models and a baseline that assigns arguments to clusters based on their syntactic function.",
        "v.",
        "Number of iterations",
        "Figure 3: Purity (vertical axis) against average number of clusters per verb (horizontal axis) on the auto/auto dataset.",
        "Recall that one of the components in our similarity function is lexical similarity which we measure using a vector-based model (see Section 5.4).",
        "We created such a model from the Google N-Grams corpus (Brants and Franz, 2006) using a context window of two words on both sides of the target word and co-occurrence frequencies as vector components (no weighting was applied).",
        "The large size of this corpus allows us to use bigram frequencies, rather than frequencies of individual words and to distinguish between left and right bigrams.",
        "We used randomized algorithms (Ravichandran et al., 2005) to build the semantic space efficiently.",
        "Comparison Models We compared our graph partitioning algorithm against three competitive approaches.",
        "The first one assigns argument instances to clusters according to their syntactic function (e.g., subject, object) as determined by a parser.",
        "This baseline has been previously used as a point of comparison by other unsupervised semantic role induction systems (Grenager and Manning, 2006; Lang and Lapata, 2010) and shown difficult to outperform.",
        "Figure 4: F1 (vertical axis) against number of iterations (horizontal axis) on the auto/auto dataset.",
        "Our implementation allocates up to N = 21 clustersfor each verb, one for each of the 20 most frequent syntactic functions and a default cluster for all other functions.",
        "We also compared our approach to Lang and Lapata (2010) using the same model settings (with 10 latent variables) and feature set proposed in that paper.",
        "Finally, our third comparison model is Lang and Lapata's (2011) split-merge clustering algorithm.",
        "Again we used the same parameters and number of clusters (on average 10 per verb).",
        "Our graph partitioning method uses identical cues for assessing role-semantic similarity as the method described in Lang and Lapata (2011)."
      ]
    },
    {
      "heading": "7. Results",
      "text": [
        "Our results are summarized in Table 1.",
        "We report cluster purity (PU), collocation (CO) and their harmonic mean (F1) for the baseline (Syntactic Function), our two previous models (the Latent Logistic classifier and Split-Merge) and the graph partitioning algorithm on four datasets.",
        "These result from the combination of automatic parses with automatically identified arguments (auto/auto), gold parses with",
        "Syntactic Function",
        "Latent Logistic",
        "Split-Merge",
        "Graph Partitioning",
        "PU",
        "CO",
        "F1",
        "PU",
        "CO",
        "F1",
        "PU",
        "CO",
        "F1",
        "PU",
        "CO",
        "F1",
        "auto/auto",
        "72.9",
        "73.9",
        "73.4",
        "73.2",
        "76.0",
        "74.6",
        "81.9",
        "71.2",
        "76.2",
        "82.5",
        "68.8",
        "75.0",
        "gold/auto",
        "77.7",
        "80.1",
        "78.9",
        "75.6",
        "79.4",
        "77.4",
        "84.0",
        "74.4",
        "78.9",
        "84.0",
        "73.5",
        "78.4",
        "auto/gold",
        "77.0",
        "71.0",
        "73.9",
        "77.9",
        "74.4",
        "76.2",
        "86.5",
        "69.8",
        "77.3",
        "87.4",
        "65.9",
        "75.2",
        "gold/gold",
        "81.6",
        "77.5",
        "79.5",
        "79.5",
        "76.5",
        "78.0",
        "88.7",
        "73.0",
        "80.1",
        "88.6",
        "70.7",
        "78.6",
        "Table 2: Clustering results for individual verbs on the auto/auto dataset with our graph partitioning algorithm and the syntactic function baseline; the scores were taken from a single run.",
        "automatic arguments (gold/auto), automatic parses with gold arguments (auto/gold) and gold parses with gold arguments (gold/gold).",
        "Table 1 reports averages across multiple runs.",
        "This was necessary in order to ensure that the results of our randomized graph partitioning algorithm are stable.",
        "The arguments for the auto/auto and gold/auto datasets were identified using the rules described in Lang and Lapata (2011) (see Section 4).",
        "Bold-face is used to highlight the best performing system under each measure (PU, CO, or F1) on each dataset.",
        "Compared to the Syntactic Function baseline, the Graph Partitioning algorithm has higher F1 on the auto/auto and auto/gold datasets but lags behind by 0.5 points on the gold/auto dataset and by 0.9 points on the gold/gold dataset.",
        "It attains highest purity on all datasets except for gold/gold, where it is 0.1 points below Split-Merge.",
        "When considering F1 in conjunction with purity and collocation, we observe that Graph Partitioning can attain higher purity than the comparison models by trading off collocation.",
        "If we were to hand label the clusters output by our system, purity would correspond to the quality of the resulting labeling, while collocation would determine the labeling effort.",
        "The relationship is illustrated more explicitly in Figure 3, which plots purity against the average number of clusters per verb on the auto/auto dataset.",
        "As the algorithm proceeds the number of clusters is reduced which results in a decrease of purity.",
        "The latter decreases more rapidly once the number of20 clusters per verb is reached.",
        "This is accompanied by a decreasing tradeoff ratio between collocation and purity: at this stage decreasing purity by one point increases collocation by roughly one point, whereas in earlier iterations a decrease of purity by one point goes together with several points increase in collocation.",
        "This is most likely due to the fact that the number of gold standard classes is around 20.",
        "Figure 4 shows the complete learning curve ofour graph partitioning method on the auto/auto dataset (F1 is plotted against the number of iterations).",
        "The algorithm naturally terminates at iteration 266 (when 0min = 1/3), but we have also plotted iterations beyond that point.",
        "Since lower values of 0 permit unreliable propagations, F1 eventually falls below the baseline (see Section 5.2).",
        "The importance of our propagation prioritization mechanism is further underlined by the fact that when it is not employed (i.e., when using the vanilla Chinese Whispers algorithm without any modifications), it performs substantially worse than the comparison models.",
        "On the auto/auto dataset, F1 converges to 59.1 (purity is 55.5 and collocation 63.2) within 10 iterations.",
        "Finally, Table 2 shows how performance varies across verbs.",
        "We report results for the Syntactic Function baseline and Graph Partitioning on the auto/auto dataset for 12 verbs.",
        "These were selected so as to exhibit varied occurrence frequencies and alternation patterns.",
        "As can be seen, the macroscopic result – increase in F1 and purity – also holds across verbs.",
        "Syntactic Function",
        "PU",
        "91.4",
        "68.6",
        "45.1",
        "59.7",
        "62.4 61.9 63.5",
        "75.9",
        "76.7",
        "69.6",
        "63.1",
        "53.7",
        "CO",
        "91.3",
        "71.9",
        "56.0",
        "68.4",
        "72.7 76.8 65.6",
        "79.7",
        "76.0",
        "63.8",
        "73.4",
        "58.9",
        "F1",
        "91.4",
        "70.2",
        "49.9",
        "63.7",
        "67.1 68.6 64.5",
        "77.7",
        "76.3",
        "66.6",
        "67.9",
        "56.2",
        "Graph Partitioning",
        "PU",
        "95.6",
        "83.5",
        "72.3",
        "75.4",
        "83.3 84.4 74.8",
        "84.8",
        "89.5",
        "83.0",
        "73.2",
        "66.3",
        "CO",
        "89.1",
        "62.7",
        "42.1",
        "64.2",
        "56.2 66.3 57.2",
        "73.2",
        "64.1",
        "54.3",
        "66.0",
        "57.7",
        "F1",
        "92.2",
        "71.6",
        "53.2",
        "69.4",
        "67.1 74.3 64.8",
        "78.5",
        "74.7",
        "65.7",
        "69.4",
        "61.7",
        "Verb",
        "say",
        "make",
        "go",
        "increase",
        "know tell consider",
        "acquire",
        "meet",
        "send",
        "open",
        "break",
        "Freq",
        "15238",
        "4250",
        "2109",
        "1392",
        "983 911 753",
        "704",
        "574",
        "506",
        "482",
        "246"
      ]
    },
    {
      "heading": "8. Conclusions",
      "text": [
        "In this paper we described an unsupervised method for semantic role induction, in which argument-instance graphs are partitioned into clusters representing semantic roles.",
        "The approach is conceptually and algorithmically simple and novel in its formalization of role induction as a graph partitioning problem.",
        "We believe this constitutes an interesting alternative for two reasons.",
        "Firstly, eliciting and encoding problem-specific knowledge in the form of instance-wise similarity judgments can be easier than encoding it into model structure e.g., by making statistical independence assumptions or assumptions about latent structure.",
        "Secondly, the approach is general and amenable to other graph partitioning algorithms and relates to well-known graph-based semi-supervised learning methods.",
        "The similarity function in this paper is by necessity rudimentary, since it cannot be estimated from data.",
        "Nevertheless, the resulting system attains competitive F1 and notably higher purity than the comparison models.",
        "Arguably, performance could be improved by developing a better similarity function.",
        "Therefore, in the future we intend to investigate how our system performs in a weakly supervised setting, where the similarity function is estimated from a small amount of labeled instances, since this would allow us to incorporate richer syntactic features and result in more precise similarity scores.",
        "Acknowledgments We are grateful to Charles Sutton for his valuable feedback on this work.",
        "The authors acknowledge the support of EPSRC (grant GR/T04540/01)."
      ]
    }
  ]
}
