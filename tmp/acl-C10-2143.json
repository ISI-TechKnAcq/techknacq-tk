{
  "info": {
    "authors": [
      "Katrin Tomanek",
      "Udo Hahn"
    ],
    "book": "COLING – POSTERS",
    "id": "acl-C10-2143",
    "title": "A Comparison of Models for Cost-Sensitive Active Learning",
    "url": "https://aclweb.org/anthology/C10-2143",
    "year": 2010
  },
  "references": [
    "acl-D07-1051",
    "acl-D08-1112",
    "acl-P09-1117",
    "acl-P96-1042",
    "acl-W05-0619"
  ],
  "sections": [
    {
      "text": [
        "Katrin Tomanek and Udo Hahn",
        "Jena University Language & Information Engineering (JULIE) Lab Friedrich-Schiller-Universitat Jena",
        "http://www.julielab.de",
        "Active Learning (AL) is a selective sampling strategy which has been shown to be particularly cost-efficient by drastically reducing the amount of training data to be manually annotated.",
        "For the annotation of natural language data, cost efficiency is usually measured in terms of the number of tokens to be considered.",
        "This measure, assuming uniform costs for all tokens involved, is, from a linguistic perspective at least, intrinsically inadequate and should be replaced by a more adequate cost indicator, viz. the time it takes to manually label selected annotation examples.",
        "We here propose three different approaches to incorporate costs into the AL selection mechanism and evaluate them on the Muc7t corpus, an extension of the Muc7 newspaper corpus that contains such annotation time information.",
        "Our experiments reveal that using a cost-sensitive version of semi-supervised AL, up to 54% of true annotation time can be saved compared to random selection."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Active Learning (AL) is a selective sampling strategy for determining those annotation examples which are particularly informative for classifier training, while discarding those that are already easily predictable for the classifier given previous training experience.",
        "While the efficiency of AL has already been shown for many NLP tasks based on measuring the number of tokens or sentences that are saved in comparison to random sampling (e.g., Engelson and Dagan (1996), Tomanek et al.",
        "(2007) or Settles and Craven (2008)), it is obvious that just counting tokens under the assumption of uniform annotation costs for each token is empirically questionable, from a linguistic perspective, at least.",
        "As an alternative, we here explore annotation costs that incur for AL based on an empirically more plausible cost metric, viz. the time it takes to annotate selected linguistic examples.",
        "We investigate three approaches to incorporate costs into the AL selection mechanism by modifying the standard (fully supervised) mode of AL and a non-standard semi-supervised one according to cost considerations.",
        "The empirical backbone of this comparison is constituted by Muc7t, a reannotation of a part of the Muc7 newspaper corpus that contains annotation time information (Tomanek and Hahn, 2010)."
      ]
    },
    {
      "heading": "2. Active Learning",
      "text": [
        "Unlike random sampling, AL is a selective sampling technique where the learner is in control of the data to be chosen for training.",
        "By design, the intention behind AL is to reduce annotation costs, usually considered as the amount of labeled training material required to achieve a particular target performance of the model.",
        "The latter is yielded by querying labels only for those examples which are assumed to have a high training utility.",
        "In this section, we introduce different AL frameworks the default, fully supervised AL approach (Section 2.1), as well as a semi-supervised variant of it (Section 2.2).",
        "In Section 2.3 we then propose three methods how these approaches to AL can be made cost-sensitive without further modifications.",
        "As we consider AL for the NLP task of Named Entity Recognition (NER), some design decisions have to be made.",
        "Firstly, the selection granularity is set to complete sentences - a reasonable linguistic annotation unit which still allows for fairly precise selection.",
        "Second, a batch of examples instead of a single example is selected per AL iteration to reduce the computational overhead of the sampling process.",
        "We base our approach to AL on Conditional Random Fields (CRFs), which we employ as base learners (Lafferty et al., 2001).",
        "For observation sequences x = (x\\,..., xn) and label sequences y = (yi,..., yn), a linear-chain CRF is defined as token level, we might also obtain the performance of the second best label and calculate the margin between the first and second best label as a confidence score so that the final utility function is obtained by",
        "Algorithm 1 formalizes our AL framework.",
        "Depending on the utility function, the best b examples are selected per round, manually labeled, and then added to the set of labeled data L which feeds the classifier for the next training round.",
        "Y\\ exp ^ XJ/i (y%-i, yi, x, i) Algorithm NER-specific AL Framework",
        "where Ze (x) is the normalization factor, and k feature functions /j(•) with feature weights 0 = (Ai,...,Afc) appear.",
        "The core of any AL approach is a utility function u(p, 0) which estimates the informativeness of each example p, a complete sentence p = (x), drawn from the pool P of all unlabeled examples, for model induction.",
        "For our experiments, we employ two alternative utility functions which have produced the best results in previous experiments (Tomanek, 2010, Chapter 4).",
        "The first utility function is based on the confidence of a CRF model 0 in the predicted label sequence y* which is given by the probability distribution Pe(y* \\x).",
        "The utility function based on this probability boils down so that sentences for which the predicted label sequence y* has a low probability is granted a high utility.",
        "Instead of calculating the model's confidence on the complete sequence, we might alternatively calculate the model's confidence in its predictions on single tokens.",
        "To obtain an overall confidence for the complete sequence, the average over the single token-confidence values can be computed by the marginal probability Pe (yi\\x).",
        "Now that we are calculating the confidence on the",
        "b: number of examples to be selected in each iteration L: set of labeled examples l = (x, y) e Xn x YnP: set of unlabeled examples p = (x) e XnT(L): a learning algorithm u(p,9): utility function",
        "Algorithm:",
        "loop until stopping criterion is met",
        "3. select b examples pi with highest utility from S: B – {pi,... ,pb}, b < m, pi e S",
        "The specification is still not cost-sensitive as the selection of examples depends only on the utility function.",
        "Using uLC will result in a reduction of the number of examples (i.e., sentences) selected irrespective of the sentence length so that a model learns the most from it.",
        "As a result, we observed that the selected sentences are quite long which might even cause higher annotation costs per sentence (Tomanek, 2010, Chapter 4).",
        "As for uma there is at least a slight normalization sensitive to costs since the sum over all token-level utility scores is normalized by the length of the selected sentence.",
        "Tomanek and Hahn (2009) extendeded this standard fully supervised AL framework by a semi-supervised variant (SeSAL).",
        "The selection of sentences is performed in a standard manner, i.e., similarly to the procedure in Algorithm 1.",
        "However, once selected, rather than manually annotating the complete sentence, only (uncertain) subsequences of each selected sentence are manually labeled, while the remaining (certain) ones are automatically annotated using the current version of the classifier.",
        "After the selection of an informative example p = (x) with x = (xi;..., xn), the subsequences x' = (xa,..., xb), 1 < a < b < n, with low local uncertainty have to be identified.",
        "For reasons of simplicity, only sequences of length 1, i.e., single tokens, are considered.",
        "For a token xi from a selected sequence x the model's confidence Ce(y*) in label y* is estimated.",
        "Token-level confidence for a CRF is calculated as the marginal probability so that where y* specifies the label at the respective position of the predicted label sequence y * (the one which is obtained by the Viterbi algorithm).",
        "If Ce (y*) exceeds a confidence threshold t, yi* is assigned as the putatively correct label.",
        "Otherwise, manual annotation of this token is required.",
        "Employing SeSAL, savings of over 80 % of the tokens compared to random sampling are reported by Tomanek and Hahn (2009).",
        "Even when compared to FuSAL, still 60 % of the number of tokens are eliminated.",
        "A crucial question, however, not answered in these experiments, is whether this method actually reduces the overall annotation expenses in time rather than just in the number of tokens.",
        "Also SeSAL does not incorporate labeling costs in the selection process.",
        "In this section, we turn to an extension of FuSAL and SeSAL which incorporates cost sensitivity into the AL selection process (CoSAL).",
        "Three different approaches of CoSAL will be explored.",
        "The challenge we now face is that two contradictory criteria - utility and costs - have to be balanced.",
        "CoSAL can be realized in the most straightforward way by simply constraining the sampling to a particular maximum cost cmax per example.",
        "Therefore, in a preprocessing step all examples p eP for which cost(p) > cmax are removed from P. The unmodified NER-specific AL framework can then be applied.",
        "An obvious shortcoming of Cost-Constrained Sampling (CCS) is that it precludes any form of compensation between utility and costs.",
        "Thus, an exceptionally useful example with a cost factor slightly above cmax will be rejected.",
        "Another critical issue is how to fix cmax.",
        "If chosen too low, the pre-filtering of P results in a much too strong restriction of selection options when only few examples remain inside P. If chosen too high, the cost constraint becomes ineffective.",
        "A general solution to fit different criteria into a single one is by way of linear combination.",
        "If, however, different units of measurement are used, a transformation function for the alignment of benefit, or utility, and costs must be found.",
        "This can be difficult to determine.",
        "In our scenario, benefits measured by utility scores and costs measured in seconds are clearly incommensurable.",
        "As it is not immediately evident how to express utility in monetary terms (or vice versa), we transform utility and cost information into ranks R(u(p, 0)) and R' (cost(p)) instead.",
        "As for utility, higher utility leads to higher ranks.",
        "As for costs, lower costs lead to higher ranks.",
        "The linear rank combination (LRK) is defined as where a is a weighting term.",
        "In a CoSAL scenario, where utility is the primary criterion, a > 0.5 seems a reasonable choice.",
        "Alternatively, as costs and utility are contradictory, allowing equal influence for both criteria, as with a = 0.5, it may be difficult to find appropriate examples in a medium-sized corpus.",
        "Thus, the choice of a depends on size and diversity with respect to combinations of utility and costs within P.",
        "Our third approach to CoSAL is based on the Benefit-Cost Ratio (BCR).",
        "Given equal units of measurement for benefits and costs, the benefit-cost ratio indicates whether a scenario is profitable (ratio > 1).",
        "BCR can also be applied when units are incommensurable and a transformation function is available, as is the case for the combination of utility and cost.",
        "This holds as long as benefit and costs can be expressed in the same units by a linear transformation function, i.e., u(p, 0) = ß • cost(p) + b.",
        "If such a transformation function exists, one can refrain from finding proper values for the above variables b and ß and instead calculate BCR as",
        "Since annotation costs are usually expressed on a linear scale, this is also required for utility, if we want to use BCR.",
        "But when utility is based on model confidence as we do it here, this property gets lost.",
        "Hence a non-linear transformation function is needed to fit the scales of utility and costs.",
        "Assuming a linear relationship between utility and costs, BCR has already been applied by Haertel et al.",
        "(2008) and Settles et al.",
        "(2008).",
        "Our approach provides a crucial extension as we explicitly consider scenarios where such a linear relationship is not given and a non-linear transformation function is required instead.",
        "In a direct comparison of LRK with BCR, LRK may be used when such a transformation function would be needed but is unknown and hard to find.",
        "Choosing LRK over BCR is also motivated by findings in the context of data fusion in information retrieval where Hsu and Taksa (2005) remark that, given incommensurable units and scales, one would do better when ranks rather than the actual scores or values were combined."
      ]
    },
    {
      "heading": "3. Experiments",
      "text": [
        "In the following, we study possible benefits of CoSAL, relative to FuSAL and SeSAL, in the light of real annotation times as a cost measure (instead of the standard, yet inadequate one, viz. the number of tokens being selected).",
        "Such timing data is available in the Muc7t corpus (Tomanek and Hahn, 2010), a re-annotation of the Muc7 corpus containing the ENAMEX types (persons, locations, and organizations) and a time stamp reflecting the time it took annotators to decide on each entity type.",
        "The Muc7t corpus contains 3,113 sentences (76,900 tokens).",
        "The results we report on are averaged over 20 independent runs.",
        "For each run, we split the Muc7t corpus randomly into a pool to select from (90%) and an evaluation set (10%).",
        "AL was started from a random seed set of 20 sentences.",
        "As utility scores to estimate benefits we applied uma and uLC as defined in Section 2.1.",
        "The plots in the following sections depict costs in terms of annotation time (in seconds) relative to annotation quality (expressed via F1-scores).",
        "Learning curves are only shown for early AL iterations.",
        "Later on, in the convergence phase, due to the two conflicting criteria now considered simultaneously, selection options become more and more scarce so that CoSAL necessarily performs sub-optimally.",
        "Preparatory experiments were run to analyze how different parameters affected different CoSAL settings.",
        "For the CCS and LRK experiments, we used the uLC utility function.",
        "For CCS, we tested three cmax values, viz. 7.5, 10, and 15, to determine the maximum performance attainable on Muc7t when only examples below the chosen threshold were included.",
        "Our choices of the maximum were based on the distributions of annotation times over the sentences (see Figure 1) where 7.5s marks the 75% quantile and 15s is just above the 90% quantile.",
        "For 7.5s, we peaked at Fmax = 0.84, for 10s at Fmax = 0.86, and for 15s at Fmax = 0.88.",
        "Figure 2 (top) shows the learning curves of CoSAL with CCS and different cmax values.",
        "With cmax = 15, as could be expected from the boxplot in Figure 1, no difference can be observed compared to cost-insensitive FuSAL.",
        "CCS with lower values for cmax stagnates at the maximum perfor-",
        "parameter test for CCS",
        "mance reported above, but still improves upon cost-insensitive FuSAL in early AL iterations.",
        "At some point in time all economical examples, with costs below cmax but high utility, have been consumed from the corpus.",
        "Even in a corpus much larger than Muc7t this effect will only occur with some delay.",
        "Indeed, any choice of a restrictive value for cmax will cause similar exhaustion effects.",
        "unfortunately, it is unclear how to tune cmax suitably in a real-life annotation scenario where pretests for maximum performance for a particular cmax are not possible.",
        "For further experiments, we chose cmax = 10.",
        "For LRK, we tested three different weights a, viz. 0.5, 0.75, and 0.9.",
        "Figure 2 (bottom) shows their effects on the learning curves.",
        "Similar tendencies as for cmax for CCS can be observed.",
        "With a = 0.9, CoSAL does not fall below default FuSAL, at least in the observed range.",
        "A lower weight of a = 0.",
        "75 results in larger improvements in earlier AL iterations but then falls back to FuSAL and in later AL iterations (not shown here) even below FuSAL.",
        "If the time parameter is granted too much influence, as with a = 0.5, performance even drops to random selection level.",
        "This might also be due to corpus exhaustion.",
        "For further experiments, we chose a = 0.75 because of its potential to improve upon FuSAL in early iterations.",
        "For BCR with uma, we change this utility function to n • uma to compensate for the normaliza-",
        "parameter test for LRK",
        "Figure 2: Different parameter settings for CCS and LRK based on FuSAL with uLC as utility function.",
        "FuSAL: uLC refers to cost-insensitive FuSAL, CCS and LRK to the cost-sensitive versions of FuSAL with the respective parameters.",
        "tion by token length which is otherwise already contained in uma(n is the length of the respective sentence).",
        "For uLC, the preparatory experiments already showed that this utility function does not behave on a linear scale.",
        "This is so because uLC is based on Pe (y\\x) for confidence estimation of the complete label sequence y.",
        "Hence, a uLC score twice as high does not indicate doubled benefit for classifier training.",
        "Thus, we need a non-linear calibration function to transform uLC into a proper utility estimator on a linear scale so that BCR can be applied.",
        "To determine such a non-linear calibration function, the true benefit of an example p would be needed.",
        "In the absence of such information, we consider n • uma as a good approximation.",
        "To identify the relationship between uLC and n • uma, we trained a model on a random subsam-ple from P' c P and used this model to obtain the scores for uLC and n • uma for each example from the test set T. Figure 3 (left) shows a scatter plot of these scores which provides ample evidence that the relationship between uLC and benefit is indeed non-linear.",
        "As calibration function for uLC we propose /(p) = eß'ULc(p).",
        "Experimentally, we determined ß = 20 as a good value.",
        "Figure 3 (right) reveals that eß\"\"Lc(p) is a better utility estimator; the correlation with n • uma is now corr = 0.8959 and the relationship is close to being linear.",
        "In Figure 4, learning curves for BCR with the utility function uLC and the calibrated function eß uLc(p) are compared.",
        "BCR with the uncali-brated utility function uLC fails miserably (the performance falls even below random selection).",
        "This adds credibility to our claim that while uLCmay be appropriate for ranking examples (as for standard, cost-insensitive AL), it is inappropriate for estimating true benefit/utility which is needed when costs are to be incorporated with the BCR method.",
        "BCR with the calibrated utility eß'ULc(p), in contrast, outperforms cost-insensitive FuSAL.",
        "For further experiments with BCR, we either apply n-uMA or eß'ULC(p) as utility functions.",
        "parameter test for BCR",
        "BCR : e/U ULCBCR : uLCFuSAL : uLCRS",
        "We compared all three approaches to CoSAL in the parametrization chosen above for the utility functions uma and uLC.",
        "Learning curves are shown in Figure 5.",
        "Improvements over cost-insensitive AL are only achieved in early AL iterations up to 2,500s (for CoSAL based on uma) or 4,000s (for CoSAL based on uLC) of annotation time.",
        "This exclusiveness of early improvements can be explained by the size of the corpus and, by this, the limited number of good selection options.",
        "Since AL selects with respect to two conflicting criteria, the pool P should be much larger to increase the chance for examples that are favorable with respect to both criteria.",
        "utility function : uMA utility function : uLC",
        "Figure 5: Comparison of CoSAL approaches for the utility functions uma and uLC.",
        "Baseline given by random selection (RS) and standard FuSAL with either uma or uLC.",
        "Improvements for CoSAL based on uLC are generally higher than for uma.",
        "Moreover, cost-insensitive AL based on uLC does not exhibit any normalization where, in contrast, uma is normalized at least to the number of tokens per example.",
        "In CoSAL, both uLC and uma are normalized by costs, which is methodologically a more substantial enhancement for uLC than for uma.",
        "For CoSAL based on uma we cannot proclaim a clear winner among the different approaches.",
        "All three CoSAL approaches improve upon cost-insensitive AL.",
        "For CoSAL based on uLC, LRK performs best, while CCS and BCR perform similarly well.",
        "Given this result, we might prefer LRK or CCS over BCR.",
        "A disadvantage of the first two approaches is that they require corpus-specific parameters which may be difficult to find for a new learning problem for which no data for experimentation is at hand.",
        "Though not the best performer, BCR does not require further parametrization and appears more appropriate for real-life annotation projects - as long as utility is an appropriate estimator for benefit.",
        "CoSAL with BCR has already been studied by Settles et al.",
        "(2008).",
        "They also applied a utility function based on sequence-confidence estimation which presumably, as with our uLC utility function, is not a good benefit estimator.",
        "The fact that Settles et al.",
        "did not explicitly treat this issue might explain why cost-sensitive AL based on BCR often performed worse than cost-insensitive AL in their experiments.",
        "We looked at a cost-sensitive version of SeSAL by applying the cost-sensitive FuSAL approach together with BCR and the transformation function for the utility as discussed above.",
        "On top of this selection, we ran the standard SeSAL approach only tokens below a confidence threshold were selected for annotation.",
        "The following experiments are all based on the uLC utility function (and the transformation function of it).",
        "Figure 6 depicts learning curves for cost-insensitive and cost-sensitive SeSAL and FuSAL which reveal that cost-sensitive SeSAL consid-",
        "Figure 6: Cost-sensitive (BCR variants) vs. cost-insensitive FuSAL and SeSAL with uLC as utility function.",
        "erably outperforms cost-sensitive FuSAL.",
        "Cost-sensitive SeSAL attains a target performance of F=0.85 with only 2806s, while cost-sensitive FuSAL needs 3410s, and random selection consumes over 6060s.",
        "Thus, cost-sensitive SeSAL here reduces true annotation time by about 54 % compared to random selection, whereas cost-sensitive FuSAL reduces annotation time by only 44%."
      ]
    },
    {
      "heading": "4. Related Work",
      "text": [
        "Although the reduction of data acquisition costs that result from human labeling efforts have always been the main driver for AL studies, cost-sensitive AL is a new branch of AL.",
        "In an early study on cost metrics for AL, Becker and Osborne (2005) examined whether AL, while decreasing the sample size on the one hand, on the other hand increased annotation efforts.",
        "For a real-world AL annotation project, they demonstrated that the actual sampling efficiency measure for an AL approach depends on the cost metric being applied.",
        "In a companion paper, Hachey et al.",
        "(2005) studied how sentences selected by AL affected the annotators' performance both in terms of the time needed and the annotation accuracy achieved.",
        "They found that selectively sampled examples are, on the average, more difficult to annotate than randomly sampled ones.",
        "This observation, for the first time, questioned the widespread assumption that all annotation examples can be assigned a uniform cost factor.",
        "Making a standard AL approach cost-sensitive by normalizing utility in terms of annotation time has been proposed before by Haertel et al.",
        "(2008), Settles et al.",
        "(2008), and Donmez and Carbonell (2008).",
        "CoSAL based on the net-benefit (costs subtracted from utility) was proposed by Vijaya-narasimhan and Grauman (2009) for object recognition in images and Kapoor et al.",
        "(2007) for voice message classification."
      ]
    },
    {
      "heading": "5. Conclusions",
      "text": [
        "We investigated three approaches to incorporate the notion of cost into the AL selection mechanism, including a fixed maximal cost budget per example, a linear rank combination to express net-benefit, and a benefit-cost ratio.",
        "The cost metric we applied was the time needed by human coders for annotating particular annotation examples.",
        "Among the three approaches to cost-sensitive AL, we see a slight advantage for benefit cost ratios in real-world settings because they do not require additional corpus-specific parametrization, once a proper calibration function is found.",
        "Another observation is that advantages of the three cost-sensitive AL models over cost-insensitive ones consistently occur only in early iteration rounds - a result we attribute to corpus exhaustion effects since cost-sensitive AL selects for two criteria (utility and cost) and thus requires a extremely large pool to be able to pick up really advantageous examples.",
        "Consequently, applied to real-world annotation settings where the pools may be extremely large, we expect cost-sensitive approaches to be even more effective in terms of the reduction of annotation time.",
        "To be applicable in real-world scenarios, annotation costs which, in our experiments, were directly traceable in the Muc7t corpus have to be estimated since they are not known prior to annotation.",
        "In Tomanek et al.",
        "(2010), we investigated the reading behavior during named entity annotation using eye-tracking technology.",
        "With the insights gained from this study on crucial factors influencing annotation time we were able to induce such a much needed predictive model of annotation costs.",
        "In future work, we plan to incorporate this empirically founded cost model into our approaches to cost-sensitive AL and to investigate whether our positive findings can be reproduced with estimated costs as well."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "This work was partially funded by the EC within the CALBC (FP7-231727) project."
      ]
    }
  ]
}
