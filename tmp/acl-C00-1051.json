{
  "info": {
    "authors": [
      "Takashi Inui",
      "Kentaro Inui"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-1051",
    "title": "Committee-Based Decision Making in Probabiiistic Partial Parsing",
    "url": "https://aclweb.org/anthology/C00-1051",
    "year": 2000
  },
  "references": [
    "acl-A00-2009",
    "acl-A94-1016",
    "acl-E99-1026",
    "acl-P96-1025",
    "acl-P97-1003",
    "acl-P98-1029",
    "acl-P98-1081",
    "acl-W99-0623"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Tins paper explores two directions for the next step beyond the state of the art of statistical parsing: probabilistic partial parsing and committee-based decision making.",
        "Probabilistic partial parsing is a probabilistic extension of the existing notion of partial parsing, which enables fine-grained arbitrary choice on the trade-off between accuracy and coverage.",
        "Committee-based decision making is to combine the outputs from different systems to make a better decision.",
        "While various committee-based techniques for NLP have recently been investigated, they would need to be further extended so as to be applicable to probabilistic partial parsing.",
        "Aiming at tins coupling, tins paper gives a general framework to committee-based decision making, winch consists of a set of weighting functions and a combination function, and discusses how it can be coupled with probabilistic partial parsing.",
        "Our experiments have so far been producing promising results."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "There have been a number of attempts to use statistical techniques to improve parsing performance.",
        "While tins goal has been achieved to a certain degree given the increasing availability of large tree banks, the remaining room for the iinprovement appears to be getting saturated as long as only statistical techniques are taken into account.",
        "This paper explores two directions for the next step beyond the state of the art of statistical parsing: probabilistic partial parsing and committee-based decision making.",
        "Probabilistic partial parsing is a probabilistic extension of the existing notion of partial parsing ( e.g. (Jensen et al., 1993)) where a parser selects as its output only a part of the parse tree that are probabilistically highly reliable.",
        "Tins decision-making scheme enables a fine-grained arbitrary choice on the trade-off between accuracy and coverage.",
        "Such trade-off is hnportant since there are various applications that require reasonably high accuracy even sacrificing coverage.",
        "A typical example is the paraphrasing task embedded in summarization, sentence simplification (e.g. (Carroll et al., 1998)), etc.",
        "Enabling such trade-off choice will make state-of-the-art parsers of wider application.",
        "Partial parsing has also been proven useful for bootstrapping learning.",
        "One may suspect that the realization of partial parsing is a trivial matter in probabilistic parsing just because a probabilistic parser inherently has the notion of \"reliability\" and thus has the trade-off between accuracy and coverage.",
        "However, there has so far been surprisingly little research focusing on tins matter and almost no work that evaluates statistical parsers according to their coverage-accuracy (or recall-precision) curves.",
        "Taking the significance of partial parsing into account, therefore in this paper, we evaluate parsing performance according to coverage-accuracy curves.",
        "Committee-based decision making is to combine the outputs from several different systems (e.g. parsers) to make a better decision.",
        "Recently, there have been various attempts to apply committee-based techniques to NLP tasks such as POS tagging (Halteren et al., 1998; Brill et al., 1998), parsing (Henderson and Brill, 1999), word sense disambiguation (Peder-sen, 2000), machine translation (Frederking and Nirenburg, 1994), and speech recognition (Fis-cus, 1997).",
        "Those works empirically demonstrated that combining different systems often achieved significant improvements over the previous best system.",
        "In order to couple those committee-based",
        "schemes with probabilistic partial parsing, however, one would still need to make a further extension.",
        "Aiming at this coupling, in this paper, we consider a general framework of committee-based decision making that consists of a set of weighting functions and a combination function, and discuss how that framework enables the coupling with probabilistic partial parsing.",
        "To demonstrate how it works, we report the results of our parsing experiments on a Japanese tree bank."
      ]
    },
    {
      "heading": "2 Probabilistic partial parsing",
      "text": []
    },
    {
      "heading": "2.1 Dependency probability",
      "text": [
        "In this paper, we consider the task of deciding the dependency structure of a Japanese input sentence.",
        "Note that, while we restrict our discussion to analysis of Japanese sentences in this paper, what we present below should also be straightforwardly applicable to more wide-ranged tasks such as English dependency analysis just like the problem setting considered by Collins (1.996).",
        "Given an input sentence s as a sequence of Bumetsu-phrases (13Ps)1, 61 62 ... 6,, our task is to identify their inter-BP dependency structure R = {r = , , where r(bi, denotes that bi depends on (or modifies) bi.",
        "Let us consider a depend cn,cy probability (DP), P ki)ls), a probability that r(bi, bi) holds in a given sentence s: Vt. ](r(b bj)ls) ="
      ]
    },
    {
      "heading": "2.2 Estimation of DPs",
      "text": [
        "Some of the state-of-the-art probabilistic language models such as the bottonmp models P (Ris) proposed by Collins (1996) and Fuji° et al.",
        "(1998) directly estimate DPs for a given input, whereas other models such as PCFG-based topdown generation models .P(/?, s) do not (Charniak, 1997; Collins, 1997; Shirai et al., 1998).",
        "If the latter type of models were totally excluded from any committee, our committee-based framework would not work well in practice.",
        "Fortunately, however, even fur such a model, one can still estimate Di's in the following way if the model provides the n-best depenbunsetsu phrase (BP) is a chunk of words consisting of a. content word (noun, Nrerb, adjective, etc.)",
        "accompanied by sonic functional word(s) (particle, auxiliary, etc.).",
        "A Japanese sentence can be analyzed as a sequence of BPs, which constitutes an inter-BP dependency structure dency structure candidates coupled with probabilistic scores.",
        "Let Ri be the i-th best dependency structure (i = 1, , n) of a given input s according to a given model, and let RH be a set of R. Then, 1)(r(61 6.1)18) can be estimated by the following approximation equation:",
        "where PR,,, is the probability mass of R E , and is the probability mass of R E R.H that supports r(bi,ki).",
        "The approximation er",
        "probability mass of all the dependency structure candidates for s (see (Poole, 1993) fbr the proof).",
        "This means that the approximation er1701: is negligible if PR,„ is sufficiently close to PR., winch holds Ibr a reasonably small number n in most cases in practical statistical parsing."
      ]
    },
    {
      "heading": "2.3 Coverage-accuracy curves",
      "text": [
        "We then consider the task of selecting dependency relations whose estimated probability is higher than a certain threshold 0 (0 < a < 1).",
        "When a is set to be higher (closer to 1.0), the accuracy is expected to become higher, while the coverage is expected to become lower, and vice versa.",
        "Bore, coverage C and accuracy A are defined as follows: # of the decided relations",
        "of all Ow relations in the test set # of the correctly decided relations A (3) # of the decided relations Moving the threshold a from 1.0 down toward 0.0, one can obtain a coverage-accuracy curve (C-A curve).",
        "In probabilistic partial parsing, we evaluate the performance of a model according to its CA curve.",
        "A few examples are shown in Figure 1, which_ were obtained in our experiment (see Section 4).",
        "Obviously, Figure 1 shows that model A outperformed the other two.",
        "To summarize a CA curve, we use the 11-point average of accuracy (1.1.-point accuracy, hereafter), where the eleven points are C = 0.5, 0.55, ... , 1..0.",
        "The accuracy of total parsing corresponds to the accuracy of the point in a CA curve where C = 1.0.",
        "We call it total accuracy to distinguish it from 11-point accuracy.",
        "Note that two models with equal achieve",
        "ments in total accuracy may be different in 11- point accuracy.",
        "In fact, we found such cases in our experiments reported below.",
        "Plotting CA curves enable us to make a more fine-grained performance evaluation of a model."
      ]
    },
    {
      "heading": "3 Committee-based probabilistic partial parsing",
      "text": [
        "We consider a general scheme of committee-based probabilistic partial parsing as illustrated in Figure 2.",
        "Here we assume that each committee member Mk (k = , in) provides a DP matrix PA4,,(r ki )1s) (bi, bj E s) for each input s. Those matrices are called input matrices, and are given to the committee as its input.",
        "A committee consists of a set of weighting functions and a combination function.",
        "The role assigned to weighting functions is to standardize input matrices.",
        "The weighting function associated with model Mk transforms an input matrix given by Mk to a weight matrix Wild.",
        "The majority function then combines all tile given weight matrices to produce an output matrix 0, which represents the final decision of the committee.",
        "One can consider various options for both functions."
      ]
    },
    {
      "heading": "3.1 Weighting functions",
      "text": [
        "We have so far considered the following three options.",
        "Simple The simplest option is to do nothing: wf = (4) where wiAP is the (i,:j) element of Wm,.",
        "Normal A bare DP may not be a precise estimation of the actual accuracy.",
        "One can see this by plotting probability-accuracy curves (PA curves) as shown in Figure 3.",
        "Figure 3 shows that model A tends to overestimate DPs, while",
        "model C tends to underestimate DPs.",
        "This means that if A and C give different answers with the same DP, C's answer is more likely to be correct.",
        "Thus, it is not necessarily a good strategy to shnply use given bare DPs in weighted majority.",
        "To avoid tins problem, we consider the following weighting function:",
        "where Am, (p) is the function that returns the expected accuracy of Mk's vote with its dependency probability p, and aiAlk is a normalization factor.",
        "Such a function can be trained by plotting a PA curve for training data.",
        "Note that training data should be shared by all the committee members.",
        "In practice, for training a PA curve, some smoothing technique should be applied to avoid overfitting.",
        "Class The standardization process in the above option Normal can also be seen as an effort for reducing the averaged cross entropy of the model on test data.",
        "Since PA curves tend to defer not only between different models but also between different problem classes, if one incorporates some problem classification into (5), the averaged cross entropy is expected",
        "where Amk c (p) is the PA curve of model Mk only for the problems of class CI), in training data, and trk is a normalization factor.",
        "For problem classification, syntactic/lexical features of bi may be useful."
      ]
    },
    {
      "heading": "3.2 Combining functions",
      "text": [
        "For combination functions, we have so far considered only simple weighted voting, which averages the given weight matrices:",
        "where ok is the (i, j) element of 0.",
        "Note that the committee-based partial parsing framework presented here can be seen as a generalization of the previously proposed voting-based techniques in the following respects:",
        "(a) A committee accepts probabilistically parameterized votes as its input.",
        "(d) A committee accepts multiple voting (i.e. it allow a committee member to vote not only to the best-scored candidate hut also to all other potential candidates).",
        "(c) A. committee provides a means for standardizing original votes.",
        "(b) A committee outputs a probabilistic distribution representing a final decision, which constitutes a CA curve.",
        "For example, none of simple voting techniques for word class tagging proposed by van Hal-toren et al.",
        "(1998) does not accepts multiple voting.",
        "Henderson and Brill (1999) examined constituent voting and naive Bayes classification for parsing, obtaining positive results for each.",
        "Simple constituent voting, however, does not accept parametric votes.",
        "While Naive Bayes seems to partly accept parametric multiple voting, it does not consider either standardization or coverage/accuracy trade-off."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": []
    },
    {
      "heading": "4.1 Settings",
      "text": [
        "We conducted experiments using the following five statistical parsers:",
        "• KANA (Ehara, 1998): a bottom-up model based on maximum entropy estimation.",
        "Since dependency score matrices given by KANA have no probabilistic semantics, we normalized them for each row using a certain function manually tuned for this parser.",
        "• CHAGAKE (Fujio et al., 1998): an extension of the bottom-up model proposed by Collins (Collins, 1996).",
        "• Kanayama's parser (Kanayama et al., 1999): a bottom-up model coupled with an HPSG.",
        "• Shirai's parser (Shirai et al., 1998): a top-down model incorporating lexical collocation statistics.",
        "Equation (1) was used for estimating DPs.",
        "• Peach Pie Parser (Uchimoto et al., 1999): a bottom-up model based on maximum entropy estimation.",
        "Note that these models were developed fully independently of each other, and have significantly different characters (for a comparison of their performance, see Table 1).",
        "In what follows, these models are referred to anonymously.",
        "For the source of the training/test set, we used the Kyoto corpus (ver.2.0) (Kurohashi et al., 1997), which is a collection of Japanese newspaper articles annotated in terms of word boundaries, POS tags, I3P boundaries, and inter-BP dependency relations.",
        "The corpus originally contained 19,956 sentences.",
        "To make the training/test sets, we first removed all the sentences that were rejected by any of the above five parsers (3,146 sentences).",
        "For the remaining 16,810 sentences, we next checked the consistency of the BP boundaries given by the parsers since they had slightly different criteria for BP segmentation from each other.",
        "In this process, we tried to recover as many inconsistent boundaries as possible.",
        "For example, we found there were quite a few cases where a parser recognized a certain word sequence as a single BP, whereas some other parser recognized the same sequence as two BPs.",
        "In such",
        "evaluation.",
        "For closed tests, we used 11,192 sentences (66,536 BPs3) for both training and tests.",
        "For open tests, we conducted fivefold cross-validation on the whole sentence set.",
        "2 In the BP concatenation process described here, quite a few trivial dependency relations between neigh-boring BPs were removed from the test set.",
        "This made our test set slightly more difficult than what it should have been.",
        "3 This is the total number of BPs excluding the rightmost two BPs for each sentence.",
        "Since, in Japanese, a BP always depends on a BP following it, the rightmost BP of a sentence does not depend on any other BP, and the second rightmost BP always depends on the rightmost BP.",
        "Therefore, they were not seen as subjects of evaluation.",
        "For the classification of problems, we manually established the following twelve classes, each of which is defined in terms of a certain morphological pattern of depending BPs:",
        "1. nominal BP with a case marker \"wa (topic)\" 2. nominal BP with a case marker \"no (POS)\" 3. nominal BP with a case marker \"ga (NOM)\" 4. nominal BP with a case marker \"o (ACC)\" 5. nominal BP with a case marker \"ni (DAT)\" 6. nominal BP with a case marker \"de (LOC/.. 7. nominal BP (residue) 8. adnominal verbal I3P 9. verbal BP (residue) 10. adverb 11. adjective 12. residue"
      ]
    },
    {
      "heading": "4.2 Results and discussion",
      "text": [
        "Table 1 shows the total/11-point accuracy of each individual model.",
        "The performance of each model widely ranged from 0.96 down to 0.86 in 11-point accuracy.",
        "Remember that A is the optimal model, and there are two second-best models, B and C, which are closely comparable.",
        "In what follows, we use these achievements as the baseline for evaluating the error reduction achieved by organizing a committee.",
        "The performance of various committees is shown in Figure 4 and 5.",
        "Our primary interest here is whether the weighting functions presented above effectively contribute to error reduction.",
        "According to those two figures, although the contribution of the function Normal were nor very visible, the function Class consistently improved the accuracy.",
        "These results can be a good evidence for the important role of weighting functions in combining parsers.",
        "While we manually built the problem classification in our experiment, automatic classification techniques will also be obviously worth considering.",
        "We then conducted another experiment to examine the effects of multiple voting.",
        "One can straightforwardly simulate a single-voting committee by replacing wij in equation (7) with",
        "The results are shown in Figure 7, which compares the original multi-voting committees and the simulated single-voting committees.",
        "Clearly, in our settings, multiple voting significantly outperformed single voting particularly when the size of a committee is small.",
        "The next issues are whether a committee always outperform its individual members, and if not, what should be considered in organizing a committee.",
        "Figure 4 and 5 show that committees not including the optimal model A achieved extensive improvements, whereas the merit; of organizing connnittees including A is not very visible.",
        "This can be partly attributed to the fact that; the competence of the individual members widely diversed, and A significantly outperforms the other models.",
        "Given the good error reduction achieved by committees containing comparable members such as BC, BD and BCD, however, it; should be reasonable to expect that a committee including A would achieve a significant; improvement if another nearly optimal model was also incorporated.",
        "To empirically prove this assumption, we conducted another experiment, where we add another parser KNP (Kurohashi et; al., 1994) to each committee that appears in Figure 4.",
        "KNP is much closer to model A in total accuracy than the other models (0.8725 in total accuracy).",
        "However, it does not provide DP matrices since it; is designed in a rule-based fashion the current.",
        "version of KNP provides only the best-preferred parse tree for each input; sentence without any scoring annotation.",
        "We thus let KNP to simply vote its total accuracy.",
        "The results are shown in Figure 6.",
        "This time all the committees achieved significant improvmnents, with the maximum error reduction rate up to 31%.",
        "As suggested by the results of this experiment with KNP, our scheme allows a rule-based non-parameixic parser to play in a committee preserving its ability to output parametric DP matrices.",
        "To push the argument further, suppose a, plausible situation where we have an optimal but non-parametric rule-based parser and several suboptimal statistical parsers.",
        "In such a case, our committee-based scheme may be able to organize a committee that can provide DP matrices while preserving the original total accuracy of the rule-based parser.",
        "To see this, we conducted another small experiment, where we combined KNP with each of C and D, both of which are less competent than KNP.",
        "The resulting committees successfully provided reasonable PA curves as shown in Figure 8, while even further improving the original total accuracy of KNP (0.8725 to 0.8868 for CF and 0.8860 for DF).",
        "Furthermore, the committees also gained the 11-point accuracy over C and D (0.9291 to",
        "0.9600 for CF and 0.9266 to 0.9561 for DF).",
        "These results suggest that our committee-based scheme does work even if the most competent member of a committee is rule-based and thus non-parametric."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "This paper presented a general committee-based framework that can be coupled with probabilistic partial parsing.",
        "In this framework, a committee accepts parametric multiple votes, and then standardizes them, and finally provides a probabilistic distribution.",
        "We presented a general method for producing probabilistic multiple votes (i.e. DP matrices), which allows most of the existing probabilistic models for parsing to join a committee.",
        "Our experiments revealed that (a) if more than two comparably competent models are available, it is likely to be worthwhile to combine them, (b) both multiple voting and vote standardization effectively work in committee-based partial parsing, (c) our scheme also allows a non-parametric rule-based parser to make a good contribution.",
        "While our experiments have so far been producing promising results, there seems to be much room left for investigation and improvement."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We would like to express our special thanks to all the creators of the parsers used here for enabling all of this research by providing us their systems.",
        "We would also like to thank the reviewers for their suggestive comments."
      ]
    }
  ]
}
