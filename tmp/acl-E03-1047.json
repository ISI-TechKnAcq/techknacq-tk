{
  "info": {
    "authors": [
      "Yusuke Miyao",
      "Takashi Ninomiya",
      "Jun'ichi Tsujii"
    ],
    "book": "Conference of the European Association for Computational Linguistics",
    "id": "acl-E03-1047",
    "title": "Lexicalized Grammar Acquisition",
    "url": "https://aclweb.org/anthology/E03-1047",
    "year": 2003
  },
  "references": [
    "acl-C88-2121",
    "acl-H94-1020",
    "acl-P00-1058",
    "acl-P02-1043"
  ],
  "sections": [
    {
      "heading": "Jun'ichi Tsujii SORST Japan Science and Technology Corporation, Saitama, Japan Abstract",
      "text": [
        "This paper presents a formalization of automatic grammar acquisition that is based on lexicalized grammar formalisms (e.g. LTAG and HPSG).",
        "We state the conditions for the consistent acquisition of a unique lexicalized grammar from an annotated corpus."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Linguistically motivated and computationally oriented grammar theories take the form of lexicalized grammar formalisms; examples include Lexicalized Tree Adjoining Grammar (LTAG) (Sch-abes et al., 1988), Combinatory Categorial Grammar (Steedman, 2000), and Head-driven Phrase Structure Grammar (HPSG) (Sag and Wasow, 1999).",
        "They have been a great success in terms of linguistic analysis and efficiency in the parsing of real-world texts.",
        "However, such grammars have not generally been considered suitable for the syntactic analysis within practical NLP systems because considerable effort is required to develop and maintain lexicalized grammars that are both robust and provide broad coverage.",
        "One novel approach to grammar development is based on the automatic acquisition of lexicalized grammars from annotated corpora.",
        "Since lexicalized grammars represent grammatical constraints with a few grammar rules and a large number of lexical entries, the rules are quite easy to write but the construction of a lexicon is unrealistic.",
        "The idea in this study is to automatically obtain the lexical entries from an annotated corpus, which will greatly reduce the cost of building the grammar.",
        "The approach has the following advantages.",
        "First, the grammars obtained will be robust because appropriate lexical entries are consistently acquired even for constructions beyond grammar developers' intuition.",
        "Secondly, the grammar developers are simply required to annotate the closed set of the training corpus, where various heuristic and statistical methods are applicable.",
        "Consistency between the grammar rules and the obtained lexical entries is assured independently of the methods of annotation.",
        "Lastly, the validity of the grammar theories is evaluated on real-world texts.",
        "A degree of low coverage by a linguistically motivated grammar does not necessarily reflect inadequacy of the grammar theories; a lack of appropriate lexical entries may also be responsible.",
        "The analysis of obtained grammars gives us grounds for discussing the pros and cons of the theories.",
        "The studies on the extraction of LTAG (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2000) and CCG (Hockenmaier and Steedman, 2002) represent the first attempts at the acquisition of linguistically motivated grammars from annotated corpora.",
        "Those studies are limited to specific formalisms, and can be interpreted as instances of our approach as described in Section 3.",
        "This paper does not describe any concrete algorithms for grammar acquisition that depend on specific grammar formalisms.",
        "The contribution of our work is to formally state the conditions required for the acquisition of lexicalized grammars and to demonstrate that it can be applied to lexicalized grammars other than LTAG and CCG, such as HPSG."
      ]
    },
    {
      "heading": "2 Lexicalized Grammars",
      "text": [
        "In this section, we define the general form of lexicalized grammars including LTAG (Schabes et al., 1988) and HPSG (Sag and Wasow, 1999).",
        "The concepts behind a lexicalized grammar are that i) grammar rules represent general grammatical constructions in the language while ii) lexical entries describe word-specific lexical/syntactic constraints.",
        "Let W be a set of all words and C a set of linguistic representations (e.g. the tree structures of LTAG or typed feature structures of HPSG).",
        "We can formally define a lexicalized grammar in the following way.",
        "Definition 1 (Lexicalized grammar) A lexicalized grammar is a tuple G – (L, R), where L is a lexicon, i.e. L C W x C, and R is a set of grammar rules, i.e. r E R is a partial function: CxC C. In what follows, we assume that all grammar rules are binary for simplicity.",
        "Parsing with a lexicalized grammar is the process of applying grammar rules to lexical entries.",
        "Since we assume that the rules are binary, the history of the process constitutes a binary-branching tree; we define such structures in this paper as constituent structures (Miller, 2000).",
        "The first condition represents inclusion of the top node in the structure, and the second constrains the terminals (words) to a linear order.",
        "The process of parsing is then depicted by a constituent structure labeled with grammar rules, which we call a derivation history.",
        "Definition 3 (Derivation history) Given a sentence w, a derivation history is a tuple T = (T, p), where F is a constituent structure ofw and p is a function: F – >• R. Derivation history T = (F,p) is a well-formed derivation history iff there exists a function £ satisfying the following conditions.",
        "The results of parsing (e.g. derived trees of LTAG and phrasal signs of HPSG) by a lexicalized grammar are outputs of the application of rules according to derivation histories.",
        "Definition 4 (Parse result) Given a sentence w, cs G C is a parse result o/w iff Cg w/or some well-formed derivation history.",
        "Given the above definitions, our task is to obtain lexical entries (w, c) G L from a parsed corpus, i.e., parse results cs G C. The idea is to make derivation histories from a parsed corpus, and reduce the parse results into lexical entries by traversing the derivation histories.",
        "is injective, 3\\c,c\".c' – p(j')(c,c\").",
        "Hence, 3lc,c\".cs => Piccffo- By Definition 3, c => 7.",
        "We thus find that unique c exists for 7.",
        "The theorem shows that we are able to obtain a unique sequence of lexical entries that are consistent with the grammar rules, given the constituent structures and corresponding rule applications.",
        "However, the grammar rules of a lexicalized grammar are not necessarily injective.",
        "For example, Figure 1 shows a situation where the SLASH feature of HPSG causes the same parse result for distinct inputs.",
        "Phrase \"talk about\" has an NP in the SLASH feature, but we cannot determine the origination of the NP.",
        "A similar argument can be made for LTAG on its adjunction rule.",
        "When an auxiliary tree is adjoined into another tree, its spine is melted into the other tree, which produces the same result for distinct inputs.",
        "To enable the acquisition of unique lexical entries even when the grammar rules are not injective, we introduce a further definition that provides a mark which disambiguates the inputs to grammar rales.",
        "This allows us to map non-injective rules into injective rules.",
        "Definition 5 (Pseudo-injective) Grammar rule r £ Ris pseudo-injective when there exists a function p such that rfl – Xc\\, C2-(r(c\\, C2), p(ci, C2)) is an injective function.",
        "We call p. a marking function, and use Rfl to denote a set ofr^.",
        "If all grammar rules are at least pseudo-injective, unique lexical entries are determined.",
        "Theorem 1 is now revised into a more general form.",
        "Theorem 2 (Grammar acquisition (revised)) Given a parse result cs £ C of a sentence w, a marking function p, and a derivation history T of Rfi, lexical entries for w are uniquely determined if all grammar rules r £ R are pseudo-injective functions with respect to p. Proof.",
        "We omit the proof since it is much the same as the proof of Theorem 1.",
        "□ Non-injective grammar rules in lexicalized grammars can often be redefined as pseudo-injective functions by the addition of some information, which depends on grammar theories.",
        "We now discuss grammar-theory-dependent issues.",
        "CG The injective condition is apparently preserved in a simple CG, which is the class of cat-egorial grammars composed of the two reduction rules: Forward Application (FA) and Backward Application (BA).",
        "While these rules take two categories as inputs and output another category, we can regard the rules as taking two derived trees as inputs and outputting a combined tree.",
        "With this insight, we can regard reduction rules as grammar rules, derived trees as parse results, derivations as derivation histories, then Theorem 1 can be applied.",
        "The annotation cost will not be problematic because we only need to annotate FA or BA to the derived trees by using simple heuristic rules.",
        "This argument is also valid for the extraction of CCG.",
        "In order to annotate the other rules defined by CCG (type-raising, composition, and coordination rules), existing work (Hockenmaier and Steedman, 2002) exploits the annotations of traces and coordinations in the Penn Treebank.",
        "LTAG As discussed above, adjoining leads to the situations where the injective condition is violated.",
        "We can make the grammar rules pseudo-injective by determining the lengths of the spines, i.e., defining p as returning the spine length.",
        "Existing studies assume the length as one (Xia, 1999), or determine the length by using heuristic rules (Chen and Vijay-Shanker, 2000; Chiang, 2000).",
        "The above discussion was empirically evaluated by acquiring LTAG grammars from the"
      ]
    },
    {
      "heading": "4 Conclusion",
      "text": [
        "This study has demonstrated the conditions for acquiring lexicalized grammars from annotated corpora.",
        "We proved that a unique lexicalized grammar consistent with the given grammar rules is acquired when derivation histories are given.",
        "Our approach enables the development of lexicalized grammars that are robust and broad-coverage, and also lets us compare various grammar theories with real-world texts.",
        "This study provides a starting point for the application of linguistic grammar theories to real-world NLP systems.",
        "Future work includes an application of our approach to other grammar theories, such as HPSG.",
        "Although annotation of grammar rules (schemata) might be more difficult than LTAG since they have more rules, this will be solved by careful implementation of heuristic annotation rules."
      ]
    }
  ]
}
