{
  "info": {
    "authors": [
      "Junwen Xing",
      "Longyue Wang",
      "Derek F. Wong",
      "Lidia S. Chao",
      "Xiaodong Zeng"
    ],
    "book": "CoNLL",
    "id": "acl-W13-3605",
    "title": "UM-Checker: A Hybrid System for English Grammatical Error Correction",
    "url": "https://aclweb.org/anthology/W13-3605",
    "year": 2013
  },
  "references": [
    "acl-C08-1109",
    "acl-N03-5008",
    "acl-N10-1018",
    "acl-N10-1019",
    "acl-N12-1067",
    "acl-N12-1086",
    "acl-P10-2065",
    "acl-W06-3808",
    "acl-W12-2006",
    "acl-W12-2025",
    "acl-W12-2030",
    "acl-W12-2031",
    "acl-W12-2032",
    "acl-W12-2033",
    "acl-W13-1703",
    "acl-W13-3601"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper describes the NLP2CT Grammatical Error Detection and Correction system for the CoNLL 2013 shared task, with a focus on the errors of article or determiner (ArtOrDet), noun number (Nn), preposition (Prep), verb form (Vform) and subject-verb agreement (SVA).",
        "A hybrid model is adopted for this special task.",
        "The process starts with spell-checking as a preprocessing step to correct any possible erroneous word.",
        "We used a Maximum Entropy classifier together with manually rule-based filters to detect the grammatical errors in English.",
        "A language model based on the Google N-gram corpus was employed to select the best correction candidate from a confusion matrix.",
        "We also explored a graph-based label propagation approach to overcome the sparsity problem in training the model.",
        "Finally, a number of deterministic rules were used to increase the precision and recall.",
        "The proposed model was evaluated on the test set consisting of 50 essays and with about 500 words in each essay.",
        "Our system achieves the",
        "th and 3 rd F1 scores on official test set among all 17 participating teams based on gold-standard edits before and after revision, respectively."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "With the increasing number of people all over the world who study English as their second language1, grammatical errors in writing often occurs due to cultural diversity, language habits, education background, etc.",
        "Thus, there is a substantial and increasing need of using computer 1 A well-known fact is that the most popular language chosen as a first foreign language is English.",
        "techniques to improve the writing ability for second language learners.",
        "Grammatical error correction is the task of automatically detecting and correction erroneous word usage and ill-formed grammatical constructions in text (Dahlmeier et al., 2012).",
        "In recent decades, this special task has gained more attention by some organizations such as the Helping Our Own (HOO) challenge (Dale and Kilgarriff, 2010; Dale et al., 2012).",
        "Although the performance of grammatical error correction systems has been improved, it is still mostly limited to dealing with the determiner and preposition error types with a very low recall and precision.",
        "This year, the CoNLL-2013 shared task extends to include a more comprehensive list of error types, as shown in Table 1.",
        "To take on this challenge, this paper proposes pipeline architecture in combination with several error detection and correction models based on a hybrid approach.",
        "As a preprocessing step we firstly employ a spelling correction to correct the misspelled words.",
        "To correct the grammatical errors, a hybrid system is designed that integrated with Maximum Entropy (ME) classifier, deterministic filter and N-gram language model scorer, each of which is constructed as an individual model.",
        "According to the phenomena of the problems, we use different combinations of the models trained on specific data to tackle the corresponding types of errors.",
        "For instance, Prep and Nn have a strong interrelation with the words (surface) that are preceding and following the active word.",
        "This can be detected and recovered by using a language model.",
        "On the other hand, SVA is more complicated and it is more effective to determine the mistakes by using the linguistic and grammatical rules.",
        "The correction"
      ]
    },
    {
      "heading": "Replacement",
      "text": [
        "The leakage of these (this) confidential information can be a sensitive issue to personal, violation of freedom and breakdown of safety.",
        "Insertion The survey was done by ?",
        "(the) United Nations.",
        "Deletion The air cargo of the (?)",
        "Valujet plane was on fire after the plane had taken off.",
        "Nn Noun number He receives two letter (letters).",
        "Prep Replacement They work under (in) a conductive environment.",
        "Insertion Definitely, there are point of view that agree ?",
        "(with) the technology but also the voices of objection.",
        "Deletion Today, the surveillance technology has become almost manifest to (?)",
        "wherever we go.",
        "components are combined into a pipeline of correction steps to form an end-to-end correction system.",
        "Different types of corrections may interact with each other.",
        "Therefore, only for each focus word in a sentence will pass the filter and predict by the system.",
        "Take the sentence for example, ?The patent applications do not need to be censored.",
        "?, if the word ?applications?",
        "is changed to ?application?",
        "(Nn error) by a correction module, then the following auxiliary verb ?do?",
        "should be revised to ?does?",
        "(SVA error) accordingly.",
        "That is, if a mistake is introduced by a component in the prior step, subsequent analyses are most likely affected negatively.",
        "To avoid the errors propagated into further components, we proposed to deploy the analytical (pipelined) components in the order of Nn, ArtOrDet, Vform, SVA and Prep.",
        "For non-native language learners, over 90% usage of prepositions and articles are correctly used, which makes the errors very sparse (Ro-zovskaya and Roth, 2010c) in a text, and about 10% error is not ?sparse?",
        "by the way.",
        "This factor severely restricts the improvement of data-driven systems.",
        "Different from the previous methods to overcome error sparsity, we explored a graph-based label propagation method that makes use of the prediction on large amount of unlabeled data.",
        "The predicted data are then used to resample our training data.",
        "This semi-supervised method may fix a skewed label distribution in the training set and is helpful to enhance the models.",
        "The paper is organized as follows.",
        "We firstly review and discuss the related work.",
        "The data used to construct the models is described in Section 3.",
        "Section 4 discusses the proposed model based on semi-supervised learning, and the overall hybrid system is given in Section 5.",
        "The methods of grammatical error detection and correction are detailed in Section 6, followed by an evaluation, discussion and a conclusion to end the paper."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "The issues of grammatical error correction have been discussed from different perspectives for several decades.",
        "In this section, we briefly review some related methods.",
        "The use of machine learning methods to tackle this problem has shown a promising performance.",
        "These methods are normally created based on a large corpus of well-formed native English texts (Tetreault and Chodorow 2008; Tetreault et al., 2010) or annotated non-native data (Gamon, 2010; Han et al., 2010).",
        "Although the manually error-tagged text is much more expensive, it has shown improvements over the models trained solely on well-formed native text (Kochmar et al., 2012).",
        "Additionally, both generative and discriminative classifiers were widely used.",
        "Among them, Maximum Entropy was generally used (Rozovskaya and Roth, 2011; Sakaguchi et al., 2012; Quan et al., 2012) and obtained a good result for preposition and article correction using a large feature set.",
        "Naive Bayes",
        "were also applied to recognize or correct the errors in speech or texts (Lynch et al., 2012).",
        "However, only using classifiers always cannot give a satisfied performance.",
        "Thus, grammar rules and probabilistic language model can be used as a simple but effective assistant for correction of spelling (Kantrowitz et al. 2003) and grammatical errors (Dahlmeier et al., 2012; Lynch et al., 2012; Quan et al., 2012; Rozovskaya et al., 2012)."
      ]
    },
    {
      "heading": "3 Data Set",
      "text": [
        "The training data is the NUS Corpus of Learner English (NUCLE) that provided by the National University of Singapore (Dahlmeier et al., 2013).",
        "The NUCLE contains more than one million words (1,400 essays) and has been annotated with error-tags and correction-labels.",
        "There are 27 categories of errors, with 45,106 errors in total.",
        "In this CoNLL-2013 shared task, five types of errors (around 32% of the total errors) are concerned.",
        "Figure 1 shows the statistics information of error types.",
        "the training set.",
        "As the distribution of different errors respects the real environment, there is a serious problem hidden in it.",
        "Roughly estimated, the ratio between the correct and error classes in NUCLE is around 100:1, or even more.",
        "The imbalance problem may be heavily harmful to machine learning methods.",
        "Therefore, researchers (Rozovskaya et al., 2012; Dahlmeier et al., 2012) provided several approaches such as reducing correct instances to deal with error sparsity.",
        "Instead of downsampling the data, we try to up-sample error instances.",
        "Different from UI system (Rozovskaya et al., 2012) which simulates learners to make mistakes artificially, we propose a semi-supervised learning method that makes use of a large amount of unlabeled data which is easy to collect.",
        "In practice, semi-supervised learning requires less human effort and gives higher accuracy in creating a model."
      ]
    },
    {
      "heading": "4 Error Examples Expansion Using Graph-Based Label Propagation",
      "text": [
        "As mentioned before, the corpus contains a low amount of error examples, which results in a high sparsity in the label distribution.",
        "In reality, the balance between the error and correct data is crucial for training a robust grammar detection models.",
        "Our experiment results demonstrate that too many correct data lead to unfavorable error detection rate.",
        "In order to resolve this obstacle, this paper introduces to using external data sources, i.e., a large amount of easily accessible raw texts, to automatically achieve more labeled example for training a stronger model.",
        "This paper employs transductive graph-based semi-supervised learning approach."
      ]
    },
    {
      "heading": "4.1 Graph-Based Label Propagation",
      "text": [
        "Graph-based label propagation is one of the critical subclasses of SSL.",
        "Graph-based label propagation methods have recently shown they can outperform the state-of-the-art in several natural language processing (NLP) tasks, e.g., POS tagging (Subramanya et al., 2010), knowledge acquisition (Talukdar et al., 2008), shallow semantic parsing for unknown predicate (Das and Smith, 2011).",
        "This study uses graph SSL to enrich training data, mainly the examples with incorrect tag, from raw texts.",
        "This approach constructs a k nearest-neighbor (k-nn) similarity graph over the labeled and unlabeled data in the first step.",
        "The vertices in the constructed graph consist of all instances (feature vector) that occur in labeled and unlabeled text, and edge weights between vertices are computed using their Euclidean distance.",
        "Pairs of vertices are connected by weighted edges which encode the degree to which they are expected to have the same label (Zhu, 2003).",
        "In the second step, label propagation operates on the constructed graph.",
        "The primary objective is to propagate labels from a few labeled vertices to the unlabeled ones by optimizing a loss function based on the constraints or properties derived from the graph, e.g. smoothness (Zhu et al., 2003; Subramanya and Bilmes, 2008; Talukdar et al., 2009), or sparsity (Das and Smith, 2012).",
        "This paper uses propagation method (MAD) in (Talukdar et al., 2009)."
      ]
    },
    {
      "heading": "4.2 Implementation",
      "text": [
        "In this paper, the labeled data is taken from NUCLE corpus.",
        "They are regarded as the ?seed?",
        "data, including 93,000 correct and 1,200 incorrect instances.",
        "The unlabeled data is collected from the English side of news magazine corpus (LDC2005T10).",
        "Based on that, a 5-NN similarity graph is constructed.",
        "With the graph and the properties of the labeled data derived from the NUCLE, the MAD algorithm is used to propagate the error-tag (label) from labeled vertices to the unlabeled vertices.",
        "Afterwards, the unlabeled examples with incorrect tag are added into the original training data for training."
      ]
    },
    {
      "heading": "5 System Description",
      "text": [
        "This section describes the details of our system, including preprocessing of training set, confusion set generating, classifier training and language models building.",
        "The grammatical error correction procedure is shown in Figure 2."
      ]
    },
    {
      "heading": "5.1 Preprocessing",
      "text": [
        "As mentioned in Section 3, there is a large amount (68%) of other error types which may result in new errors or confuse the system with wrong information in correction.",
        "In order to make the best use of the corpus, it needs to filter all errors not covered by the CoNLL 2013 shared task, and then generate a separate corpus for each error type.",
        "Therefore, we recovered other irrelevant errors accordingly.",
        "For each error type, we also recover other 4 types of errors, and then we got a pure training data set which only includes one error type.",
        "For the misspelled problem, we used an open source toolkit (JMySpell2) which allows us to use the dictionaries form OpenOffice.",
        "JMySpell"
      ]
    },
    {
      "heading": "2 Available at https://kenai.com/projects/jmyspell.",
      "text": [
        "gives a list of suggestion candidate words, and we select the first one to replace the original word."
      ]
    },
    {
      "heading": "5.2 Confusion Set Generating",
      "text": [
        "Confusion sets include the correction candidates which are used to modify the wrong places of a sentence.",
        "We generated a confusion set for each type of error correction component.",
        "The confusion set for Nn, Vform and SVA was built on Penn Treebank3.",
        "The format can be described as that each prototype word follows all possible combinations with Part-Of-Speech (POS) and variants.",
        "For instance, the format of the word ?look?",
        "in confusion set should looks like ?look",
        "type ?look?",
        "and POS are the constraints for choosing the correct candidate.",
        "In order to quickly find the candidates according to each detected error place, we indexed the confusion set in Lu-cene4 which is another open source toolkit with a high-performance, full-featured text search engine library.",
        "For ArtOrDet and Prep, the confusion sets are manually created because the possible modifications are not so many which are discussed in Section 6.1 and 6.2."
      ]
    },
    {
      "heading": "5.3 Maximum Entropy Classifier",
      "text": [
        "The machine learning algorithm we used to train the detection models is Maximum Entropy (ME), which can classify the data by giving a probability distribution.",
        "It is similar to multiclass logistic regression models, but much more profitable with sparse explanatory feature vectors.",
        "For ME classifier, the feature of text data is suitable for training the model, so we choose it as our detection classifier."
      ]
    },
    {
      "heading": "5.4 N-gram Language Model",
      "text": [
        "The probabilistic language model is constructed on Google Web 1T 5-gram corpus (Brants and Franz, 2006) by using the SRILM toolkit (Stolcke, 2002).",
        "All generated modification candidates are scored by it and only candidates that strictly increase than a threshold can be kept.",
        "The normalized language model score is defined as",
        "in which s is the corrected sentence and |s |is the sentence length in tokens (Dahlmeier et al., 2012)."
      ]
    },
    {
      "heading": "6 Grammatical Error Correction",
      "text": []
    },
    {
      "heading": "6.1 Article and Determiner",
      "text": [
        "The component for ArtOrDet task integrates with the language model and rule-based techniques.",
        "Language models are constructed to select the best candidate from a confusion set of possible article choices {a, the, an, ?",
        "}, given the pre-corrected sentence.",
        "Each Noun Phrase (NP) in the test sentence will be pre-corrected as correction candidates.",
        "However, only using a language model to determine the best correction will often result in a low precision, because a certain amount of correct usages of ArtOrDet are misjudged.",
        "In order to avoid this problem, we proposed a voting method based on multiple language models.",
        "We integrated two separate language models: one was converted from the large Google corpus (general LM) and the other one was constructed from a small in-domain corpus (in-domain LM).",
        "Additionally, the in-domain corpus involves two parts.",
        "One is the training data which has been totally corrected according to the gold answer.",
        "The other one includes the sentences which are similar to the test set.",
        "We extracted them from some well-formed native English corpora such as English News Magazine of LDC2005T106 using term frequency-inverse document frequency (TF-IDF) as the similarity score.",
        "Each document Di is",
        "represented as a vector (wi1, wi2,?, win), and n is the size of the vocabulary.",
        "So wij is calculated as follows: )log( jijij idftfw ??",
        "(2) where tfij is term frequency (TF) of the j-th word in the vocabulary in the document Di, and idfj is the is the inverse document frequency (IDF) of the j-th word calculated.",
        "The similarity between two sentences is then defined as the cosine of the angle between two vectors.",
        "Each candidate sentence will be scored by these two LMs and compared with a threshold.",
        "Only if both of the LMs agree, the modification will be kept.",
        "We believe this method could filter a lot of wrong modification and improve the precision."
      ]
    },
    {
      "heading": "6.2 Preposition",
      "text": [
        "For Prep error type, we used the same method as ArtOrDet.",
        "The only difference is confusion matrix.",
        "Our system corrects the unnecessary, missing and unwanted errors for the five most frequently prepositions which are in, for, to, of and on.",
        "While developing our system, we found that adding more prepositions did not increase performance in our experiments.",
        "Thus the confusion set is {in, for, to, of, on, ?",
        "}."
      ]
    },
    {
      "heading": "6.3 Noun Number",
      "text": [
        "A single noun in the sentence that is hard to distinguish whether it is singular or plural, so we treat a noun phrase as a observe subject.",
        "Our strategy of correcting noun number error is to use a filter contains rule-based and machine learning method.",
        "It can filter a part of nouns that absolutely right, and the rest of nouns will be detected by the language model generated by SRILM7.",
        "The rule-based filter of our system contains several criteria.",
        "It can detect the noun phrase by article, i.e. it can simply find out that the noun is singular which with an article of ?a?",
        "or ?an?.",
        "The determiner and cardinal number also will be taken into consider by the rule-based model such as ?I have three apple.",
        "?, then system can find out the ?apple?",
        "should be ?apples?.",
        "The correct noun will keep the original one, and the incorrect noun will be replaced with a new candidate.",
        "After the first level filtering by the rules, the rest of noun phrases are indeterminacy by system.",
        "Therefore, we use a ME classifier for further filtering.",
        "We use lexical, POS and dependency",
        "parse information as features.",
        "The features are listed in Table 2.",
        "In previous steps, most of the error can be detected, but also it may give a lot of wrong suggests, in order to reduce this situation, we use N-gram language model scorer to evaluate on the candidates and choose the highest probability one.",
        "ple is water which is a good resource and is plentiful.",
        "?"
      ]
    },
    {
      "heading": "6.4 Verb Form",
      "text": [
        "Determining the correct form of a verb in English is complex, involving a relatively wide range of choices.",
        "A verb can have many forms, such as base, gerund, preterite, past participle and so on.",
        "To detect the tense of verb error is much more related to the semantics level than syntax level.",
        "Therefore, it is hard to extract a common feature for training model.",
        "We chose to separate it into several problems and use rule-based model to do the Vform correction.",
        "For auxiliary verbs, there are three categories, one is modal verbs (do, can, may, will, might, should, must, need and dare), the other is the form of ?be?",
        "and ?have?.",
        "In a verb phrase, normally modals precede ?have?",
        "and ?be?, and ?have?",
        "proceed ?be?, then we can get the ordering like this: Modal, Have, Be.",
        "Auxiliary verbs can incorporate with other verbs, and have different combination.",
        "Based on the previous study of the core language engine (Alshawi, 1992), we define the rules that contain the type of verb, which tense of verbs can be used with, and their entries in the lexicon.",
        "For example: (can (aux (modal) (vform pres) (COMPFORM bare)) This means ?can?",
        "is a modal verb, it can be used with a verb that in the present tense, when ?can?",
        "used alone with the main verb should as complement the base (bare) form.",
        "In here, the COMPFORM attribute is the entry condition in the grammar."
      ]
    },
    {
      "heading": "6.5 Subject-Verb Agreement",
      "text": [
        "The basic principle of Subject-Verb Agreement is singular subjects need singular verbs; plural subjects need plural verbs, such as following sentences: My brother is a nutritionist.",
        "My sisters are dancers.",
        "Therefore, the subject of the sentence is the key point.",
        "To decide whether the verb is singular or plural should look into the context and find out the POS of the subject.",
        "We utilize the existing information given by NUCLE to extract the subject of the verb.",
        "For example, the sentence ?Statistics show that the number are continuing to grow with the existing population explosion.?",
        "Figure 3 shows the parse tree of this sentence.",
        "Through Figure 3, the observed words are ?show?",
        "and ?are?, the subjects are ?statistics?",
        "and ?number?",
        "respectively that we can conclude ?statistics?",
        "should use plural verb and ?number?",
        "should use singular verb ?is?",
        "instead of ?are?.",
        "The other features extracted for training are",
        "tics show that the number are continuing to grow with the existing population explosion.?",
        "The purpose of extracting the noun phrase after the observed word is in the situation of the subject is after the verb, such as ?Where are my scissors?",
        "?, ?scissors?",
        "is the subject of this sentence."
      ]
    },
    {
      "heading": "7 Evaluation and Discussion",
      "text": [
        "The evaluation is provided by the organizer and generated by M2 scorer (Dahlmeier & Ng, 2012).",
        "The result consists of precision, recall and F-score.",
        "Our grammatical error correction system has proposed 1,011 edits.",
        "The evaluation result of our system output for the CoNLL-2013 test data is shown in Table 4."
      ]
    },
    {
      "heading": "Results Precision Recall F-score",
      "text": [
        "Revision).",
        "The data in table 5 and 6 are the detailed information for each error type which was calculated by us, the table 5 is the data before revision, and the table 6 is that after revision.",
        "Second column is the amount of the gold edits, and the third column is the amount of our correct edits, and the last column is the percentage of correct edits.",
        "We analyzed the results in detail, and found several critical reasons of causing low recall.",
        "Firstly, the five error types are associated relatively, if one is modified, it may cause a chain reaction, such as the article will affect the noun number, and the noun number will cause the SVA errors.",
        "Some Nn errors still cannot be detected or given a wrong correction by our system, which decreases the precision and recall of SVA.",
        "Another reason is our system does not perform well in Vform and Prep error correction.",
        "In our output, just a few errors have been revised.",
        "This means the quantity of correction rules is not enough that cannot cover all the linguistic phenomena.",
        "For",
        "instance, the situation of missing verb or unnecessary verb cannot be detected.",
        "On the other hand, the hybrid method of our system has filtered some wrong suggestion candidates that improve the precision."
      ]
    },
    {
      "heading": "8 Conclusion",
      "text": [
        "We have presented the hybrid system for English grammatical error correction.",
        "It achieves a 28.9% F1-score on the official test set.",
        "We believe that if we find more appropriate features, our system can still be improved and achieve a better performance."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "The authors are grateful to the Science and Technology Development Fund of Macau and the Research Committee of the University of Macau for the funding support for our research, under the reference No.",
        "017/2009/A and MYRG076(Y1-L2)-FST13-WF.",
        "The authors also wish to thank the anonymous reviewers for many helpful comments as well as Liangye He, Yuchu Lin and Jiaji Zhou who give us a lot of help."
      ]
    }
  ]
}
