{
  "info": {
    "authors": [
      "Guangyou Zhou",
      "Jun Zhao"
    ],
    "book": "ACL",
    "id": "acl-P13-2019",
    "title": "Joint Inference for Heterogeneous Dependency Parsing",
    "url": "https://aclweb.org/anthology/P13-2019",
    "year": 2013
  },
  "references": [
    "acl-C08-1132",
    "acl-C10-1151",
    "acl-D07-1101",
    "acl-D08-1017",
    "acl-D08-1059",
    "acl-D09-1060",
    "acl-D10-1001",
    "acl-D10-1125",
    "acl-D11-1036",
    "acl-E06-1011",
    "acl-E12-1009",
    "acl-N10-1091",
    "acl-P05-1012",
    "acl-P06-2041",
    "acl-P08-1068",
    "acl-P08-1108",
    "acl-P09-1006",
    "acl-P09-1007",
    "acl-P09-1066",
    "acl-P10-1110",
    "acl-P11-1066",
    "acl-P11-1156",
    "acl-P11-2033",
    "acl-P12-1023",
    "acl-P12-1071",
    "acl-P94-1034",
    "acl-W04-1513"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper is concerned with the problem of heterogeneous dependency parsing.",
        "In this paper, we present a novel joint inference scheme, which is able to leverage the consensus information between heterogeneous treebanks in the parsing phase.",
        "Different from stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008), which process the dependency parsing in a pipelined way (e.g., a second level uses the first level outputs), in our method, multiple dependency parsing models are coordinated to exchange consensus information.",
        "We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a).",
        "Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c).",
        "These methods usually rely heavily on the manually annotated treebanks for training the dependency models.",
        "However, annotating syntac-?",
        "(with) ??",
        "(eyes) ??",
        "(cast) ??",
        "(Hongkong ) BA NN VV NR ?",
        "(with) ??",
        "(eyes) ??",
        "(cast) ??",
        "(Hongkong ) p n v ns",
        "tactic structures between CTB (upper) and CDT (below).",
        "CTB is converted into dependency grammar based on the head rules of (Zhang and Clark, 2008).",
        "tic structure, either phrase-based or dependency-based, is both time consuming and labor intensive.",
        "Making full use of the existing manually annotated treebanks would yield substantial savings in data-annotation costs.",
        "In this paper, we present a joint inference scheme for heterogenous dependency parsing.",
        "This scheme is able to leverage consensus information between heterogenous treebanks during the inference phase instead of using individual output in a pipelined way, such as stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008).",
        "The basic idea is very simple: although heterogenous treebanks have different grammar formalisms, they share some consensus information in dependency structures for the same sentence.",
        "For example in Figure 1, the dependency structures actually share some partial agreements for the same sentence, the two words ?eyes?",
        "and ?Hongkong?",
        "depend on ?cast?",
        "in both Chinese Dependency Treebank (CDT) (Liu et al., 2006) and Penn Chinese Treebank (CTB) (Xue et al., 2005).",
        "Therefore, we would like to train the dependency parsers on individual heterogenous treebank and jointly parse the same sentences with consensus information exchanged between them.",
        "The remainder of this paper is divided as fol",
        "erogeneous dependency parsing.",
        "lows.",
        "Section 2 gives a formal description of the joint inference for heterogeneous dependency parsing.",
        "In section 3, we present the experimental results.",
        "Finally, we conclude with ideas for future research."
      ]
    },
    {
      "heading": "2 Our Approach",
      "text": [
        "The general joint inference scheme of heterogeneous dependency parsing is shown in Figure 2.",
        "Here, heterogeneous treebanks refer to two Chinese treebanks: CTB and CDT, therefore we have only two parsers, but the framework is generic enough to integrate more parsers.",
        "For easy explanation of the joint inference scheme, we regard a parser without consensus information as a baseline parser, a parser incorporates consensus information called a joint parser.",
        "Joint inference provides a framework that accommodates and coordinates multiple dependency parsing models.",
        "Similar to Li et al. (2009) and Zhu et al. (2010), the joint inference for heterogeneous dependency parsing consists of four components: (1) Joint Inference Model; (2) Parser Coordination; (3) Joint Inference Features; (4) Parameter Estimation."
      ]
    },
    {
      "heading": "2.1 Joint Inference Model",
      "text": [
        "For a given sentence x, a joint dependency parsing model finds the best dependency parsing tree y?",
        "among the set of possible candidate parses Y(x) based on a scoring function Fs:",
        "Following (Li et al., 2009), we will use dk to denote the kth joint parser, and also use the notation Hk(x) for a list of parse candidates of sentence x determined by dk.",
        "The sth joint parser can be written as:",
        "where Ps(x, y) is the score function of the sth baseline model, and each?k(y,Hk(x)) is a partial consensus score function with respect to dk and is defined over y andHk(x):",
        "where each fk,l(y,Hk(x)) is a feature function based on a consensus measure between y and Hk(x), and ?k,l is the corresponding weight parameter.",
        "Feature index l ranges over all consensus-based features in equation (3)."
      ]
    },
    {
      "heading": "2.2 Parser Coordination",
      "text": [
        "Note that in equation (2), though the baseline score function Ps(x, y) can be computed individually, the case of ?k(y,Hk(x)) is more complicated.",
        "It is not feasible to enumerate all parse candidates for dependency parsing.",
        "In this paper, we use a bootstrapping method to solve this problem.",
        "The basic idea is that we can use baseline models?",
        "n-best output as seeds, and iteratively refine joint models?",
        "n-best output with joint inference.",
        "The joint inference process is shown in Algorithm 1.",
        "Algorithm 1 Joint inference for multiple parsers Step1: For each joint parser dk, perform inference with a baseline model, and memorize all dependency parsing candidates generated during inference in Hk(x); Step2: For each candidate in Hk(x), we extract subtrees and store them inH?k(x).",
        "First, we extract bigram-subtreesthat contain two words.",
        "If two words have a dependency relation, we add these two words as a subtree into H?k(x).Similarly, we can extract trigram-subtrees.",
        "Note that the dependency direction is kept.",
        "Besides, we also store the ?ROOT?",
        "word of each candidate in H?k(x); Step3: Use joint parsers to re-parse the sentence x with the baseline features and joint inference features (see subsection 2.3).",
        "For joint parser dk, consensus-based features of any dependency parsing candidate are computed based on current setting of H?s(x) for all s but k. New dependency parsing candidates generated by dk in re-parsing are cached in H?",
        "?k(x); Step4: Update all Hk(x) with H?",
        "?k(x); Step5: Iterate from Step2 to Step4 until a preset iteration limit is reached.",
        "In Algorithm 1, dependency parsing candidates of different parsers can be mutually improved.",
        "For example, given two parsers d1 and d2 with candidates H1 and H2, improvements on H1 enable d2 to improve H2, and H1 benefits from improved H2, and so on.",
        "We can see that a joint parser does not enlarge the search space of its baseline model, the only change is parse scoring.",
        "By running a complete inference process, joint model can be applied to re-parsing all candidates explored by a parser.",
        "Thus Step3 can be viewed as full-scale candidates reranking because the reranking scope is beyond the limited n-best output currently cached inHk."
      ]
    },
    {
      "heading": "2.3 Joint Inference Features",
      "text": [
        "In this section we introduce the consensus-based feature functions fk,l(y,Hk(x)) introduced in equation (3).",
        "The formulation can be written as:",
        "and P (y?|dk) is the posterior probability of dependency parse y?",
        "parsed by parser dk given sentence x. Il(y, y?)",
        "is a consensus measure defined on y and y?",
        "using different feature functions.",
        "Dependency parsing model P (y?|dk) can be predicted by using the global linear models",
        "(GLMs) (e.g., McDonald et al. (2005); McDonald and Pereira (2006)).",
        "The consensus-based score functions Il(y, y?)",
        "include the following parts: (1) head-modifier dependencies.",
        "Each head-modifier dependency (denoted as ?edge?)",
        "is a tu-ple t =< h,m, h ?",
        "m >, so Iedge(y, y?)",
        "=?",
        "t?y ?",
        "(t, y?).",
        "(2) sibling dependencies: Each sibling dependency (denoted as ?sib?)",
        "is a tuple t =< i, h,m, h ?",
        "i ?",
        "m >, so Isib(y, y?)",
        "=?",
        "t?y ?",
        "(t, y?).",
        "(3) grandparent dependencies: Each grandparent dependency (denoted as ?gp?)",
        "is a tuple t =< h, i,m, h ?",
        "i ?",
        "m >, so Igp(y, y?)",
        "=?",
        "<h,i,m,h?i?m>?y ?",
        "(t, y?).",
        "(4) root feature: This feature (denoted as ?root?)",
        "indicates whether the multiple dependency parsing trees share the same ?ROOT?, so",
        "t ?",
        "y?",
        "and 0 otherwise, feature index l ?",
        "{edge, sib, gp, root} in equation (4).",
        "Note that < h,m, h ?",
        "m > and < m,h,m ?",
        "h > are two different edges.",
        "In our joint model, we extend the baseline features of (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007) by conjoining with the consensus-based features, so that we can learn in which kind of contexts the different parsers agree/disagree.",
        "For the third-order features (e.g., grand-siblings and tri-siblings) described in (Koo et al., 2010), we will discuss it in future work."
      ]
    },
    {
      "heading": "2.4 Parameter Estimation",
      "text": [
        "The parameters are tuned to maximize the dependency parsing performance on the development set, using an algorithm similar to the average per-ceptron algorithm due to its strong performance and fast training (Koo et al., 2008).",
        "Due to limited space, we do not present the details.",
        "For more information, please refer to (Koo et al., 2008)."
      ]
    },
    {
      "heading": "3 Experiments",
      "text": [
        "In this section, we describe the experiments to evaluate our proposed approach by using CTB4 (Xue et al., 2005) and CDT (Liu et al., 2006).",
        "For the former, we adopt a set of head-selection rules (Zhang and Clark, 2008) to convert the phrase structure syntax of treebank into a dependency tree representation.",
        "The standard data split of CTB4 from Wang et al. (2007) is used.",
        "For the latter, we randomly select 2,000 sentences for test set, another 2,000 sentences for development set, and others for training set.",
        "We use two baseline parsers, one trained on CTB4, and another trained on CDT in the experiments.",
        "We choose the n-best size of 16 and the best iteration time of four on the development set since these settings empirically give the best performance.",
        "CTB4 and CDT use two different POS tag sets and transforming from one tag set to another is difficult (Niu et al., 2009).",
        "To overcome this problem, we use Stanford POS Tagger1 to train a universal POS tagger on the People's Daily corpus,2 a large-scale Chinese corpus (approximately 300 thousand sentences and 7 million words) annotated with word segmentation and POS tags.",
        "Then the POS tagger produces a universal layer of POS tags for both the CTB4 and CDT.",
        "Note that the word segmentation standards of these corpora (CTB4, CDT and People's Daily) slightly differs; however, we do not consider this problem and leave it for future research.",
        "The performance of the parsers is evaluated using the following metrics: UAS, DA, and CM, which are defined by (Hall et al., 2006).",
        "All the metrics except CM are calculated as mean scores per word, and punctuation tokens are consistently excluded.",
        "We conduct experiments incrementally to evaluate the joint features used in our first-order and",
        "heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency parser, and then test on CTB4 and CDT using this single model.",
        "Improvements of joint models over baseline models are shown in parentheses.",
        "CTB4 test set using UAS metric.",
        "MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008).",
        "Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data.",
        "?",
        "The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper.",
        "(dep1) only incorporates head-modifier dependency part (McDonald et al., 2005).",
        "The second-order parser (dep2) uses the head-modifier and sibling dependency parts (McDonald and Pereira, 2006), as well as the grandparent dependency part (Carreras, 2007; Koo et al., 2008).",
        "Table 1 shows the experimental results.",
        "As shown in Table 1, we note that adding more joint inference features incrementally, the dependency parsing performance is improved consistently, for both treebanks (CTB4 or CDT).",
        "As a final note, all comparisons between joint models and baseline models in Table 1 are statistically significant.3 Furthermore, we also present a baseline method called ?CTB4 + CDT?",
        "for comparison.",
        "This method first tags both CTB4 and CDT with the universal POS tagger trained on the People's Daily corpus, then simply concatenates the two corpora and trains a dependency parser, and finally tests on CTB4 and CDT using this single model.",
        "The comparisons in Table 1 tell us that very limited information is obtained without consensus features by simply taking a union of the dependencies and their contexts from the two treebanks.",
        "To put our results in perspective, we also compare our second-order joint parser with other best-performing systems.",
        "??",
        "40?",
        "refers to the sentence with the length up to 40 and ?Full?",
        "refers to all the sentences in test set.",
        "The results are shown in Table 2, our approach significantly outperforms many systems evaluated on this data set.",
        "Chen et al. (2009) and Chen et al. (2012) reported a very high accuracy using subtree-based features and dependency language model based features derived from large-scale data.",
        "Our systems did not use such knowledge.",
        "Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance.",
        "We do not present the comparison of our proposed approach 3We use the sign test at the sentence level.",
        "All the comparisons are significant at p < 0.05.",
        "with the state-of-the-art methods on CDT because there is little work conducted on this treebank.",
        "Some researchers conducted experiments on CTB5 with a different data split: files 1-815 and files 1,001-1,136 for training, files 886-931 and 1,148-1,151 for development, files 816-885 and files 1,137-1,147 for testing.",
        "The development and testing sets were also performed using gold-standard assigned POS tags.",
        "We report the experimental results on CTB5 test set in Table 4.",
        "Our results are better than most systems on this data split, except Zhang and Nivre (2011), Li et al. (2012) and Chen et al. (2009)."
      ]
    },
    {
      "heading": "3.1 Additional Results",
      "text": [
        "To obtain further information about how dependency parsers benefit from the joint inference, we conduct an initial experiment on CTB4 and CDT.",
        "From Table 4, we find that out of 355 sentences on the development set of CTB4, 74 sentences benefit from the joint inference, while 26 sentences suffer from it.",
        "For CDT, we also find that out of 2,000 sentences on the development set, 341 sentences benefit from the joint inference, while 97 sentences suffer from it.",
        "Although the overall dependency parsing results is improved, joint inference worsens dependency parsing result for some sentences.",
        "In order to obtain further information about the error sources, it is necessary to investigate why joint inference gives negative results, we will leave it for future work."
      ]
    },
    {
      "heading": "4 Conclusion and Future Work",
      "text": [
        "We proposed a novel framework of joint inference, in which multiple dependency parsing models were coordinated to search for better dependency parses by leveraging the consensus information between heterogeneous treebanks.",
        "Experimental results showed that joint inference significantly outperformed the state-of-the-art baseline models.",
        "There are some ways in which this research could be continued.",
        "First, recall that the joint inference scheme involves an iterative algorithm by using bootstrapping.",
        "Intuitively, there is a lack of formal guarantee.",
        "A natural avenue for further research would be the use of more powerful algorithms that provide certificates of optimality; e.g., dual decomposition that aims to develop decoding algorithms with formal guarantees (Rush et al., 2010).",
        "Second, we would like to combine our heterogeneous treebank annotations into a unified representation in order to make dependency parsing results comparable across different annotation guidelines (e.g., Tsarfaty et al. (2011))."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was supported by the National Natural Science Foundation of China (No.",
        "61070106, No.",
        "61272332 and No.",
        "61202329), the National High Technology Development 863 Program of China (No.",
        "2012AA011102), the National Basic Research Program of China (No.",
        "2012CB316300), We thank the anonymous reviewers and the prior reviewers of ACL-2012 and AAAI-2013 for their insightful comments.",
        "We also thank Dr. Li Cai for providing and preprocessing the data set used in this paper."
      ]
    }
  ]
}
