{
  "info": {
    "authors": [
      "Seonho Kim",
      "Juntae Yoon",
      "Mansuk Song"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-1064",
    "title": "Structural Feature Selection for English-Korean Statistical Machine Translation",
    "url": "https://aclweb.org/anthology/C00-1064",
    "year": 2000
  },
  "references": [
    "acl-H94-1028",
    "acl-J90-2002",
    "acl-J93-2003",
    "acl-J96-1002"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "When aligning texts in very different languages such as Korean and English, structural features beyond word or phrase give useful information.",
        "In this paper, we present a method for selecting structural features of two languages, from which we construct a model that assigns the conditional probabilities to corresponding tag sequences in bilingual English-Korean corpora.",
        "For tag sequence mapping between two languages, we first define a structural feature function which represents statistical properties of empirical distribution of a set of training samples.",
        "The system, based on maximum entropy concept, selects only features that produce high increases in log-likelihood of training samples.",
        "These structurally mapped features are more informative knowledge for statistical machine translation between English and Korean.",
        "Also, the information can help to reduce the parameter space of statistical alignment by eliminating syntactically unlikely alignments."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Aligned texts have been used for derivation of bilingual dictionaries and terminology databases which are useful for machine translation and cross languages information retrieval.",
        "Thus, a. lot of alignment techniques have been suggested at the sentence (Gale et al., 1993), phrase (Shin et al., 1996), noun phrase (Kupiec, 1993), word (Brown et al., 1993; Berger et al., 1996; Melamed, 1997), collocation (Smadja et al., 1996) and terminology level.",
        "Some work has used lexical association measures for word alignments.",
        "However, the association measures could be misled since a word in a source language frequently co-occurs with more than one word in a target language.",
        "In other work, iterative re-estimation techniques have been employed.",
        "They were usually incorporated with the EM algorithm and dynamic programming.",
        "In that case, the probabilities of alignments usually served as parameters in a model of statistical machine translation.",
        "In statistical machine translation, IBM 1--,5 models (Brown et al., 1993) based on the source-channel model have been widely used and revised for many language domains and applications.",
        "It has also shortcoming that it needs much iteration time for parameter estimation and high decoding complexity, however.",
        "Much work has been done to overcome the problem.",
        "Wu (1996) adopted channels that eliminate syntactically unlikely alignments and Wang et al.",
        "(1998) presented a model based on structures of two languages.",
        "Tinmann et al.",
        "(1997) suggested the dynamic programming based search to select the best alignment and preprocessed bilingual texts to remove word order differences.",
        "Sato et al.",
        "(1998) and Och et al.",
        "(1998) proposed a model for learning translation rules with morphological information and word category in order to improve statistical translation.",
        "Furthermore, many researches assumed one-to-one correspondence due to the complexity and computation time of statistical alignments.",
        "Although this assumption turned out to be useful for alignment of close languages such as English and French, it is not applicable to very different languages, in particular, Korean and English where there is rarely close correspondence in order at the word level.",
        "For such languages, even phrase level alignment, not to mention word alignment, does not gives good translation due to structural difference.",
        "Hence, structural features beyond word or phrase should be considered to get better translation between English and Korean.",
        "In addition, the construction of structural bilingual texts would be more informative for extracting linguistic knowledge.",
        "In this paper, we suggest a method for structural mapping of bilingual language on the basis of the maximum entorpy and feature induction framework.",
        "Our model based on POS tag sapience mapping has two advantages: First, it can reduce a lot of parameters in statistical machine translation by eliminating syntactically unlikely alignments.",
        "Second, it can be used as a preprocessor for lexical alignments of bilingual corpora although it can be also exploited by itself for alignment.",
        "In this case, it would serve as the first step of alignment for reducing the parameter space."
      ]
    },
    {
      "heading": "2 Motivation",
      "text": [
        "In order to devise parameters for statistical modeling of translation, we started our research from the IBM model which has been widely used by many researches.",
        "The IBM model is represented with the formula shown in (1)",
        "Here, n is the fertility probability that an English word generates n French words, t is the alignment probability that the English word c generates the French word f , and d is the distortion probability that an English word in a certain position will generate a French word in a certain position.",
        "This formula is one of many ways in which p(f, ale) can be written as the product of a series of conditional probabilities.",
        "In above model, the distortion probability is related with positional preference(word order).",
        "Since Korean is a free order language, the probability is not feasible in English-Korean translation.",
        "Furthermore, the difference between two languages leads to the discordance between words that the one-to-one correspondence between words generally does not keep.",
        "The model (1), however, assumed that an English word can be connected with multiple French words, but that each French word is connected to exactly one English word including the empty word.",
        "In conclusion, many-to-many mappings are not allowed in this model.",
        "According to our experiment, many-to-many mappings exceed 40% in English and Korean lexical alignments.",
        "Only 25.1% of them can he explained by word for word correspondences.",
        "It means that we need a statistical model which can handle phrasal mappings.",
        "In the case of the phrasal mappings, a lot of parameters should be searched even if we restrict the length of word strings.",
        "Moreover, in order to properly estimate parameters we need much larger volume of bilingual aligned text than it in word-for-word modeling.",
        "Even though such a large corpora exist sometimes, they do not come up with the lexical alignments.",
        "For this problem, we here consider syntactic features which are important in determining structures.",
        "A structural feature means here a mapping between tag sequences in bilingual parallel sentences.",
        "If we are concerned with tag sequence alignments, it is possible to estimate statistical parameters in a relatively small size of corpora.",
        "As a result, we can remarkably reduce the problem space for possible lexical alignments, a sort of t probability in (1), which improve the complexity of a statistical machine translation model.",
        "If there are similarities between corresponding tag sequences in two language, the structural features would be easily computed or recognized.",
        "However, a tag sequence in English can be often translated into a completely different tag sequence in Korean as follows.",
        "It means that similarities of tag features between two languages are not kept all the time and it is necessary to get the most likely tag sequence mappings that reflect structural correspondences between two languages.",
        "In this paper, the tag sequence mappings are oh-taind by automatic feature selection based on the maximum entropy model."
      ]
    },
    {
      "heading": "3 Problem Setting",
      "text": [
        "In this chapter, we describe how the features are related to the training data.",
        "Let to be an English tag sequence and tk be a Korean tag sequence.",
        "Let Ts be the set of all possible tag sequence mappings in a aligned sentence, S. We define a feature function (or a feature) as follows:",
        "It indicates co-occurrence information between tags appeared in Ts.",
        "f(te,tk) expresses the information for predicting that; tâ€ž maps into tk.",
        "A feature means a sort of information for predicting something.",
        "In our model, co-occurrence information on the same aligned sentence is used for a feature, while context is used as a feature in most of systems using maximum entropy.",
        "It can be less informative than context.",
        "Hence, we considered an initial supervision and feature selection.",
        "Our model starts with initial seed(active) features for mapping extracted by supervision.",
        "In the next step, feature pool is constructed from training samples from filtering and only features with a large gain to the model are added into active feature set.",
        "The final outputs of our model are the set of active features, their gain values, and conditional probabilities of features which maximize the model.",
        "The results can be embedded in parameters of statistical machine translation and help to construct structural bilingual text.",
        "Most alignment algorithm consists of two steps:",
        "(1) estimate translation probabilities.",
        "(2) use these probabilities to search for most probable alignment path.",
        "Our study is focused on (1), especially the part of tag string alignments.",
        "Next, we will explain the concept of the model.",
        "We are concerned with an optimal statistical model which can generate the training samples.",
        "Namely, our task is to construct a stochastic model that pro",
        "duces output tag sequence Tk, given a tag sequence.",
        "Te.",
        "The problem of interest is to use samples of tagged sentences to observe the behavior of the random process.",
        "The model p estimates the conditional probability that the process will output 4, given tk.",
        "It is chosen out of a set of all allowed probability distributions.",
        "The following steps are employed for our model.",
        "Input: a set L of POS-labeled bilingual aligned sentences.",
        "1.",
        "Make a set .T of correspondence pairs of tag sequences, (t,, tk.)",
        "from a small portion of L by supervision.",
        "2.",
        "Set :F into a set of active features, A.",
        "3.",
        "Maximization of parameters, A of active features by HS (Improved iterative Scaling) algorithm.",
        "4.",
        "Create a feature pool set P of all possible alignments a(tc, tk) from tag sequences of samples.",
        "5.",
        "Filter P using frequency and similarity with A.",
        "6.",
        "Compute the approximate gains of features in P. 7.",
        "Select new features(A1) with a large gain value, and add A.",
        "We began with training samples composed of English-Korean aligned sentence pairs, (e,k).",
        "Since they included long sentences, we broke them into shorter ones.",
        "The length of training sentences was limited to under 14 on the basis of English.",
        "It is reasonable because we are interested in not lexical alignments but tag sequence alignments.",
        "The samples were tagged using brill's tagger and 'Morally' that we implemented as a Korean tagger.",
        "Figure 1. shows the FOS tags we considered.",
        "For simplicity, we adjusted some part of Brill's tag set.",
        "In the supervision step, 700 aligned sentences were used to construct the tag sequences mappings which are referred to as an active feature set A.",
        "As Figure 2 shows, there are several ways in constructing the correspondences.",
        "We chose the third mapping although (1) can be more useful to explain Korean with predicate-argument structure.",
        "Since a subject of a English sentence is always used for a subject form in Korean, we exlcuded a subject case from arguments of a predicate.",
        "For example, 'they' is only used for a subject form, whereas 'me' is used for a object form and a dative form.",
        "In the next step, training events, (4,1k) are constructed to make a feature pool from training samples.",
        "The event consists of a tag string t, of a English",
        "POS-tagged sentence and a tag string tk of the corresponding Korean POS-tagged sentence mid it can be represented with indicator functions fi(4,tk).",
        "For a given sequence, the features were drawn from all adjacent possible pairs and some interrupted pairs.",
        "Only features (tchtki) out of the feature pool that meet the following conditions are extracted.",
        "â€¢ #(tei, tki) > 3, # is count â€¢ there exist tk,â€ž where (tchtkx) in A and the similarity(same tag count) of tki and tk > 0.6",
        "Table 1 shows possible features, for a given aligned sentence , 'take her out â€“ !import:Mr baggeuro derycogara'.",
        "Since the set of the structural features for alignment modeling is vast, we constructed a maximum PNIte entropy model for by the iterative model growing method."
      ]
    },
    {
      "heading": "4 Maximum Entropy",
      "text": [
        "To explain our method, we briefly describe the concept of maximum entropy.",
        "Recently, many approaches based on the maximum entropy model have been applied to natural language processing (l3erger et al., 1994; l3erger et al., 1996; Pietra et al., 1997).",
        "Suppose a model p which assigns a probability to a random variable.",
        "If we don't have any knowledge, a reasonable solution for p is the most uniform distribution.",
        "As some knowledge to estimate the model p are added, the solution space of p are more constrained and the model would be close to the optimal probability model.",
        "For the purpose of getting the optimal probability model, we need to maximize the uniformity under sonic constraints we have.",
        "Here, the constraints are related with features.",
        "A feature, L is usually represented with a binary indicator function.",
        "The importance of a feature, L can be identified by requiring that the model accords with it.",
        "As a constraint, the expected value of fi with respect to time model p(fi) is supposed to be the same as the expected value of fi with respect to empirical distribution in training samples, P(fi).",
        "In sum, the maximum entropy framework finds the model winch has highest entropy(most uniform), given constraints.",
        "It is related to the constrained optimization.",
        "To select a model from a constrained set C of allowed probability distributions, the model E C with maximum entropy II(p) is chosen.",
        "In general, for the constrained optimization problem, Lagrange multipliers of the number of features can be used.",
        "However, it was proved that the model with maximum entropy is equivalent to the model that maximizes the log likelihood of the training samples like (2) if we can assume it as an exponential model.",
        "In (2), the left side is Lagrangian of the conditional entropy and tile right side is maximum log-likelihood.",
        "We use the right side equation of (2) to select for the best model p,.",
        "Since A, cannot be found analytically, we use the following improved iterative scaling algorithm to compute A, of n active features in A in total samples.",
        "1.",
        "Start with Ai = 0 for all i E {1, 2, ... , 2.",
        "Do for each i E {1, 2, ... , : (a) Let .AAi be the solution to the log likelihood (b) Update the value of Ai into Ai +",
        "3.",
        "Stop if not all the Ai have converged, otherwise go to step 2 The exponential model is represented as (3).",
        "Here, Ai is the weight of feature In our model, since only one feature is applied to each pair of x and y, it can be represented as (4) and fi is the feature related with x and y.",
        "where AXi = log"
      ]
    },
    {
      "heading": "5 Feature selection",
      "text": [
        "Only a small subset of features will be employed in a model by selecting useful features from the feature pool P. Let p.,4 be the optimal model constrained by a set of active features A and AU fi be AL.",
        "Let pAfi be the optimal model in the space of probability distribution C(Ali).",
        "The optimal model can be represented as (5).",
        "Here, the optimal model means a maximum entropy model.",
        "The improvement of the model regarding the addition of a single feature fi can be estimated by measuring the difference of maximum log-likelihood between L(pA f,) and L(pA).",
        "We denote the gain of feature fi by (Ati) and it can be represented in (6).",
        "Note that a model pA has a set of parameters A which means weights of features.",
        "The model pAfi contains the parameters and the new parameter a with respect to the feature When adding a new feature to A, the optimal values of all parameters of probability distribution change.",
        "To make the computation of feature selection ftâ€¢actable, we approximate that the addition of a feature affects only the single parameter a, as shown in (5).",
        "The following algorithm is used for computing the gain of the model with respect to We referred to the studies of (Berger et al., 1996; Pietra et al., 1997).",
        "We skip the detailed contents and proofs.",
        "1.",
        "Let 2.",
        "Repeat the following until GAf, (aâ€ž) has con",
        "where a = an-Ft ,",
        "This algorithm is iteratively computed using Net-won's method.",
        "We can recognize the importance of a feature with the gain value.",
        "As mentioned above, it means how much the feature accords with the model.",
        "We viewed the feature as the information that tk and tâ€ž occur together."
      ]
    },
    {
      "heading": "6 Experimental results",
      "text": [
        "The total samples consists of 3,000 aligned sentence pairs of English-Korean, which were extracted from news on the web site of 'Korea Times' and a magazine for English learning.",
        "In the initial step, we manually constucted the correspondences of tag sequences with 700 PUS-tagged sentence pairs.",
        "In the supervision step, we extracted 1,483 correct tag sequence correspondences as shown in Table 2, and it work as active features.",
        "As a feature pool, 3,172 disjoint features of tag sequence mappings were retrieved.",
        "It is very important to make atomic features.",
        "We maximized A of active features with respect to total samples using improved the iterative scaling algorithm.",
        "Figure 3 shows Ai of each feature f(tDEPH-.1J)tk) E A.",
        "There are many correspondence patterns with respect to the Englsh tag string, `13E1)+J.I'.",
        "Note that p(tkite) is computed by the exponential model of (4) and the conditional probability is the same with empirical probability in (7).",
        "Since the value of kylx) shows the maximum likelihood, it is proved that; each A was converged correctly.",
        "number of times of 3; In feature selection step, we chose useful features with the gain threshold of 0.008.",
        "Figure 4 shows some feaures with a large gain.",
        "Among them, tag sequences mapping including `11,13' are erroneous.",
        "It means that position of adverb in Korean is very complicated to handle.",
        "Also, proper noun in English aligned common nouns in Korean",
        "because of tagging errors.",
        "Note that in the case of TN+PPCA2+PPAD+VBMA', it is not an adjacent string but an interrupted string.",
        "It means that a verb in English generally map to a verb taking as argument the accusative and adverbial postposition in Korean.",
        "One way of testing usefulness of our method is to construct structured aligned bilingual sentences.",
        "Table 3 shows lexical alignments using tag sequence alignments drawn from our algorithm for a given sentence, 'you usually have to take regular seating - dangsineun dachero ilbanseoke anjagaman handa' and Figure 5 shows the best lexical alignment of the sentence.",
        "We conducted the experiment on 100 sentences composed of words in length 14 or less and simply chose the most likely paths.",
        "As the result, the accuray was about 71.1%.",
        "It shows that we can partly use the tag sequence alignments for lexical alignments.",
        "We will extend the structural mapping model with consideration to the lexical information.",
        "The parameters, the conditional probabilities about stuctural mappings will be embedded in a statistical model.",
        "Table 4 shows conditional probabilities of some features according to `DT+NN'.",
        "In general, determiner is translated into NULL or adnominal word in Korean."
      ]
    },
    {
      "heading": "7 Conclusion",
      "text": [
        "When aligning English-Korean sentences, the differences of word order and word unit require structural information.",
        "For this reason, we tried structural tag string mapping using maximum entropy modeling and feature selection concept.",
        "We devised a model that generates a English tag string given a Korean tag string.",
        "From initial active structural features, useful features are extended by feature selection.",
        "The retrieved features and parameters can be embedded in statistical machine translation and reduce the complexity of searching.",
        "We showed that they can helpful to construct structured aligned bilingual sentences."
      ]
    }
  ]
}
