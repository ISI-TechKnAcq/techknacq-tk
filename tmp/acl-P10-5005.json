{
  "info": {
    "authors": [
      "Daumé",
      "Hal III"
    ],
    "book": "Tutorial Abstracts of ACL 2010",
    "id": "acl-P10-5005",
    "title": "From Structured Prediction to Inverse Reinforcement Learning",
    "url": "https://aclweb.org/anthology/P10-5005",
    "year": 2010
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Hal Daumé III",
        "me@hal3.name",
        "1 Introduction",
        "Machine learning is all about making predictions; language is full of complex rich structure.",
        "Structured prediction marries these two.",
        "However, structured prediction isn't always enough: sometimes the world throws even more complex data at us, and we need reinforcement learning techniques.",
        "This tutorial is all about the how and the why of structured prediction and inverse reinforcement learning (aka inverse optimal control): participants should walk away comfortable that they could implement many structured prediction and IRL algorithms, and have a sense of which ones might work for which problems."
      ]
    },
    {
      "heading": "2. Content Overview",
      "text": [
        "The first half of the tutorial will cover the \"basics\" of structured prediction: the structured per-ceptron and Magerman's incremental parsing algorithm.",
        "It will then build up to more advanced algorithms that are shockingly reminiscent of these simple approaches: maximum margin techniques and search-based structured prediction.",
        "The second half of the tutorial will ask the question: what happens when our standard assumptions about our data are violated?",
        "This is what leads us into the world of reinforcement learning (the basics of which we'll cover) and then to inverse reinforcement learning and inverse optimal control.",
        "Throughout the tutorial, we will see examples ranging from simple (part of speech tagging, named entity recognition, etc.)",
        "through complex (parsing, machine translation).",
        "The tutorial does not assume attendees know anything about structured prediction or reinforcement learning (though it will hopefully be interesting even to those who know some!",
        "), but does assume some knowledge of simple machine learning (eg., binary classification)."
      ]
    },
    {
      "heading": "3. Tutorial Outline",
      "text": [
        "Part I: Structured prediction - What does it mean to learn?• What is structured prediction?",
        "• Refresher on binary classification",
        "- Linear models for classification - Batch versus stochastic optimization - Linear models for structured prediction - The \"argmax\" problem - From perceptron to margins• From perceptron to structured perceptron",
        "• Search-based structured prediction",
        "- Training classifiers to make parsing decisions",
        "- Searn and generalizations Part II: Inverse reinforcement learning - Markov decision processes - Q learning - Maximum margin planning - Learning to search• Refersher on reinforcement learning",
        "• Inverse optimal control and A* search",
        "• Apprenticeship learning",
        "• Open problems References",
        "See http://www.cs.utah.edu/ ~suresh/mediawiki/index.php/MLRG/ springlO."
      ]
    }
  ]
}
