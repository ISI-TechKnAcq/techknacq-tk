{
  "info": {
    "authors": [
      "Emili Sapena",
      "Lluís Padró",
      "Jordi Turmo"
    ],
    "book": "COLING – POSTERS",
    "id": "acl-C10-2125",
    "title": "A Global Relaxation Labeling Approach to Coreference Resolution",
    "url": "https://aclweb.org/anthology/C10-2125",
    "year": 2010
  },
  "references": [
    "acl-D08-1069",
    "acl-E09-1051",
    "acl-H05-1004",
    "acl-J01-4004",
    "acl-M95-1005",
    "acl-N07-1010",
    "acl-N07-1011",
    "acl-N07-1030",
    "acl-P02-1014",
    "acl-P03-1023",
    "acl-P04-1018",
    "acl-P08-2012",
    "acl-P95-1017",
    "acl-W06-1633"
  ],
  "sections": [
    {
      "text": [
        "Emili Sapena, Llus Padro and Jordi Turmo*",
        "TALP Research Center Universität Politecnica de Catalunya",
        "This paper presents a constraint-based graph partitioning approach to coreference resolution solved by relaxation labeling.",
        "The approach combines the strengths of groupwise classifiers and chain formation methods in one global method.",
        "Experiments show that our approach significantly outperforms systems based on separate classification and chain formation steps, and that it achieves the best results in the state of the art for the same dataset and metrics."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Coreference resolution is a natural language processing task which consists of determining the mentions that refer to the same entity in a text or discourse.",
        "A mention is a noun phrase referring to an entity and includes named entities, definite noun phrases, and pronouns.",
        "For instance, \"Michael Jackson\" and \"the youngest of Jackson 5\" are two mentions referring to the same entity.",
        "A typical machine learning-based coreference resolution system usually consists of two steps: (i) classification, where the system evaluates the coreferentiality of each pair or group of mentions, and (ii) formation of chains, where given the confidence values of the previous classifications the system forms the coreference chains.",
        "Research supported by the Spanish Science and Innovation Ministry, via the KNOW2 project (TIN2009-14715-C04-04) and from the European Community's Seventh Framework Programme (FP7/2007-2013) under Grant Agreement number 247762 (FAUST)",
        "Regarding the classification step, pioneer systems developed were based on pairwise classifiers.",
        "Given a pair of mentions, the process generates a feature vector and feeds it to a classifier.",
        "The resolution is done by considering each mention of the document as anaphor and looking backward until the antecedent is found or the beginning of the document is reached (Aone and Bennett, 1995; McCarthy and Lehnert, 1995; Soon et al., 2001).",
        "A first approach towards groupwise classifiers is the twin-candidate model (Yang et al., 2003).",
        "The model faces the problem as a competition between two candidates to be the antecedent of the anaphor into account.",
        "Each candidate mention is compared with all the others in a round robin contest.",
        "Following the groupwise approach, rankers consider all the possible antecedent mentions at once (Denis and Baldridge, 2008).",
        "Rankers can obtain more accurate results due to a more informed context where all candidate mentions are considered at the same time.",
        "Coreference chains are formed after classification.",
        "Many systems form the chains by joining each positively-classified pair (i.e. single-link) or with simple improvements such as linking an anaphor only to its antecedent with maximum confidence value (Ng and Cardie, 2002).",
        "Some works propose more elaborated methods than single-link for chain formation.",
        "The approaches used are Integer Linear Programming partitioning (Nicolae and Nicolae, 2006), and clustering (Klenner and Ailloud, 2008).",
        "The main advantage of these types of post-processes is the enforcement of transitivity sorting out the contradictions that the previous classification process may introduce.",
        "Although chain formation processes search for global consistency, the lack of contextual information in the classification step is propagated forward.",
        "Few works try to overcome the limitations of keeping classification and chain formation apart.",
        "Luo et al.",
        "(2004) search the most probable path comparing each mention with the partial-entities formed so far using a Bell tree structure.",
        "McCallum and Wellner (2005) propose a graph partitioning cutting by distances, with the peculiarity that distances are learned considering coreferential chains of the labeled data instead of pairs.",
        "Culotta et al.",
        "(2007) combine a groupwise classifier with a clustering process in a First-Order probabilistic model.",
        "The approach presented in this paper follows the same research line of joining group classification and chain formation in the same step.",
        "Concretely, we propose a graph representation of the problem solved by a relaxation labeling process, reducing coreference resolution to a graph partitioning problem given a set of constraints.",
        "In this manner, decisions are taken considering the whole set of mentions, ensuring consistency and avoiding that classification decisions are independently taken.",
        "Our experimental results on the ACE dataset show that our approach outperforms systems based on separate classification and chain formation steps, and that it achieves the best results in the state of the art for the same dataset and metrics.",
        "The paper is organized as follows.",
        "Section 2 describes the graph representation of the task.",
        "Section 3 explains the use of relaxation labeling algorithm and the machine learning process.",
        "Finally, experiments and results are explained in Section 4 before paper is concluded."
      ]
    },
    {
      "heading": "2. Graph Representation",
      "text": [
        "Let G = G(V, E) be an undirected graph where V is a set of vertices and E a set of edges.",
        "Let m = (mi, ...,mn) be the set of mentions of a document with n mentions to resolve.",
        "Each mention mj in the document is represented as a vertex vi G V. An edge eij G E is added to the graph for pairs of vertices (vi, Vj ) representing the possibility that both mentions corefer.",
        "The list of adjacent vertices of a vertex vi is A(vi).",
        "Let C be our set of constraints.",
        "Given a pair of mentions (mi, mj), a subset of constraints Cij ç C restrict the compatibility of both mentions.",
        "Cij is used to compute the weight value of the edge connecting viand Vj.",
        "Let wij G W be the weight of the edge eij:",
        "Wjj = 5Z Afcffc(mj,mj) (1) keCij where fk(•) is a function that evaluates the constraint k. And Ak is the weight associated to the constraint k (Ak and wij can be negative).",
        "In our approach, each vertex (Vi) in the graph is a variable (vi) for the algorithm.",
        "Let Li be the number of different values (labels) that are possible for Vi.",
        "The possible labels of each variable are the partitions that the vertex can be assigned.",
        "Note that the number of partitions (entities) in a document is unknown, but it is at most the number of vertices (mentions), because in a extreme case, each mention in a document could be referring to a different entity.",
        "A vertex with index i can be in the first i partitions (i.e. Li = i).",
        "Each combination of labelings for the graph vertices is a partitioning (Q).",
        "The resolution process searches the partitioning Q* which optimizes the goodness function F(Q, W), which depends on the edge weights W. In this manner, Q* is optimal if:",
        "The next section describes the algorithm used in the resolution process."
      ]
    },
    {
      "heading": "3. Relaxation Labeling",
      "text": [
        "Relaxation labeling (Relax) is a generic name for a family of iterative algorithms which perform function optimization, based on local information.",
        "The algorithm has been widely used to solve NLP problems such as PoS-tagging (Marquez et al., 2000), chunking, knowledge integration, and Semantic Parsing (Atserias, 2006).",
        "Relaxation labeling solves our weighted constraint satisfaction problem dealing with the edge weights.",
        "In this manner, each vertex is assigned to a partition satisfying as many constraints as possible.",
        "To do that, the algorithm assigns a probability for each possible label of each variable.",
        "Let H = (h, h,..., hn) be the weighted labeling to optimize, where each hi is a vector containing the probability distribution of vi, that is: hj = (h\\, h%2,..., hLL).",
        "Given that the resolution process is iterative, the probability for label l of variable vi at time step t is hj (t), or simply hjwhen the time step is not relevant.",
        "The support for a pair variable-label ) expresses how compatible is the assignment of label l to variable vi considering the labels of adjacent variables and the edge weights.",
        "Although several support functions may be used (Torras, 1989), we chose the following one, which defines the support as the sum of the edge weights that relate variable Vi with each adjacent variable Vj multiplied by the weight for the same label l of Vj :",
        "where wij is the edge weight obtained in Equation 1.",
        "In our version of the algorithm, A(vi) is the list of adjacent vertices of Vi but only including the ones with an index k < i. Consequently, the weights only have influence in one direction which is equivalent to using a directed graph.",
        "Although the proposed representation is based on a general undirected graph, preliminary experiments showed that using directed edges yields higher perfomance in this particular problem.",
        "The aim of the algorithm is to find a weighted labeling such that global consistency is maximized.",
        "Maximizing global consistency is defined as maximizing the average support for each variable.",
        "Formally, H* is a consistent labeling if:",
        "Initialize:",
        "Main loop: repeat For each variable vi For each possible label l for vi",
        "Sil = Ej6AK) Wij X hj",
        "End for End for Until no more significant changes",
        "Figure 1: Relaxation labeling algorithm",
        "A partitioning Q is directly obtained from the weighted labeling H assigning to each variable the label with maximum probability.",
        "The supports and the weighted labeling depend on the edge weights (Equation 3).",
        "To satisfy Equation 4 is equivalent to satisfy Equation 2.",
        "Many studies have been done towards the demonstration of the consistency, convergence and cost reduction advantages of the relaxation algorithm (Rosenfeld et al., 1976; Hummel and Zucker, 1987; Pelillo, 1997).",
        "Although some of the conditions required by the formal demonstrations are not fulfilled in our case, the presented algorithm that forces a stop after a number of iterations-has proven useful for practical purposes.",
        "Figure 1 shows the pseudo-code of the relaxation algorithm.",
        "The process updates the weights of the labels in each step until convergence.",
        "The convergence is met when no more significant changes are done in an iteration.",
        "Specifically, when the maximum change in an update step (maxi;l ( | hj (t+1) – hj (t) | )) is lower than a parameter e, a small value (0.001 in our experiments), or a fixed number of iterations is reached (2000 in our experiments).",
        "Finally, the assigned label for a variable is the one with the highest weight.",
        "Figure 2 shows a representation.",
        "Figure 2: Representation of Relax.",
        "The vertices representing mentions are connected by weighted edges eij.",
        "Each vertex has a vector hi of probabilities to belong to different partitions.",
        "The figure shows h, h and h.",
        "The performance of the resolution process depends on the edge weights obtained by a set of weighted constraints (Equation 1).",
        "Any method or combination of methods to generate constraints can be used.",
        "For example, a set of constraints handwritten by linguist experts can be added to another automatically obtained set.",
        "This section explains the automatic constraint generation process carried out in this work, using a set of feature functions and a training corpus.",
        "Marquez et al.",
        "(2000) have successfully used similar processes to acquire constraints for constraint satisfaction algorithms.",
        "Each pair of mentions (mi, mj) in a training document is evaluated by a set of feature functions (Figure 3).",
        "The values returned by these functions form a positive example when the pair of mentions corefer, and a negative one otherwise.",
        "Three specialized models are constructed depending on the type of anaphor mention (mj) of the pair: pronoun, named entity or nominal.",
        "For each specialized model, a decision tree (DT) is generated and a set of rules is extracted with C4.5 rule-learning algorithm (Quin-lan, 1993).",
        "These rules are our set of constraints.",
        "The C4.5rules algorithm generates a set of rules for each path from the learnt tree.",
        "It then generalizes the rules by dropping conditions.",
        "The weight assigned to a constraint (Ak) is its",
        "DIST: Distance between mi and mj in sentences: number DIST_MEN: Distance between mi and mj in mentions: number APPOSITIVE: One mention is in apposition with the other: y,n I/JJN_QUOTES: mi/j is in quotes or inside a NP or a sentence in quotes: y,n I/J-FIRST: mi/j is the first mention in the sentence: y,n_",
        "I/J_DEF_NP: mi/j is a definitive NP: y,n I/J_DEM_NP: mi/j is a demonstrative NP: y,n I/JJNDEF_NP: mi/j is an indefinite NP: y,n STR_MATCH: String matching of mi and mj : y,n PRO-STR: Both are pronouns and their strings match: y,n PN_STR: Both are proper names and their strings match: y,n NONPRCLSTR: String matching like in Soon et al.",
        "(2001) and mentions are not pronouns: y,n HEAD-MATCH: String matching of NP heads: y,n_",
        "NUMBER: The number of both mentions match: y,n,u GENDER: The gender of both mentions match: y,n,u",
        "AGREEMENT: Gender and number of both mentions match: y,n,u",
        "I/J_THIRD_PERSON: mi/j is 3rd person: y,n",
        "PROPER_NAME: Both mentions are proper names: y,n,u",
        "I/JLPERSON: mi/j is a person (pronoun or proper name in a list): y,n",
        "ANIMACY: Animacy of both mentions match (persons, objects): y,n",
        "I/J_REFLEXIVE: mi/j- is a reflexive pronoun: y,n",
        "NESTED: One mention is included in the other: y,n MAXIMALNP: Both mentions have the same NP parent or they are nested: y,n",
        "I/J_MAXIMALNP: mi/j is not included in any other mention: y,n",
        "I/JJEMBEDDED: mi/j is a noun and is not a maximal NP: y,n",
        "BINDING: Conditions B and C of binding theory: y,n",
        "SEMCLASS: Semantic class of both mentions match: y,n,u",
        "ALIAS: One mention is an alias of the other: y,n,u (only entities, else unknown)",
        "Figure 3: Feature functions used precision over the training data (Pk), but shifted to be zero-centered: Ak = Pk – 0.5.",
        "Analyzing the errors of development experiments, we have found two main error patterns that can be solved by a pruning process.",
        "First, the contribution of the edge weights for the resolution depends on the size of the document.",
        "And second, many weak edge weights may sum up to produce a bias in the wrong direction.",
        "The weight of an edge depends on the weights assigned for the constraints which apply to a pair of mentions according to Equation 1.",
        "Each vertex is adjacent to all the other vertices.",
        "This produces that the larger the number of adjacencies, the smaller the influence of a constraint is.",
        "A consequence is that resolution for large and short documents has different results.",
        "Many works have to deal with similar problems, specially the ones looking backward for antecedents.",
        "The larger the document, the more possible antecedents the system has to classify.",
        "This problem is usually solved looking for antecedents in a window of few sentences, which entails an evident limitation of recall.",
        "Regarding the weak edge weights, it is notable that some kind of mention pairs are very weakly informative.",
        "For example, the pairs (pronoun, pronoun).",
        "Many stories have a few main characters which monopolize the pronouns of the document.",
        "This produces many positive training examples for pairs of pronouns matching in gender and person, which may lead the algorithm to produce large coreferential chains joining all these mentions even for stories where there are many different characters.",
        "For example, we have found in the results of some documents a huge corefer-ence chain including every pronoun \"he\".",
        "This is because a pair of mentions (\"he\", \"he\") is usually linked with a small positive weight.",
        "Although the highest adjacent edge weight of a \"he\" mention may link with the correct antecedent, the sum of several edge weights linking the mention with other \"he\" causes the problem.",
        "A pruning process is perfomed solving both problems and reducing computational costs from O(n) to O(n).",
        "For each vertex's adjacency list A(vi), only a maximum of N edges remain and the others are pruned.",
        "Concretely, the N/2 edges with largest positive weight and the N/2 with largest negative weight.",
        "The value of N is empirically chosen by maximizing performances over training data.",
        "On the one hand, the pruning forces the maximum adjacency to be constant and the contribution of the edge weights does not depend on the size of the document.",
        "On the other hand, most edges of the less informative pairs are discarded avoiding further confusion.",
        "There are no limitations in distance or other restrictions which may cause a loss of recall.",
        "The initial state of the vertices define the a priori probabilities for each vertex to be in each partition.",
        "There are several possible initial states.",
        "In the case where no prior information is available, a random or uniformly distributed state is commonly used.",
        "However, a well-informed initial state should drive faster the relaxation process to a better solution.",
        "This section describes the well-informed initial state chosen in our approach and the random one.",
        "Both are compared in the experiments (Section 4.2).",
        "The well-informed initial state favors the creation of new chains.",
        "Variable vi has Li = i possible values while variable vi+1 has Li + 1.",
        "The probability distribution of vi+1 is equiprobable for values from 1 to Li but it is the double for the probability to start a new chain Li + 1.",
        "Pronouns do not follow this distribution but a totally equiprobable one, given that they are usually anaphoric.",
        "This configuration enables the resolution process to determine as singletons the mentions for which little evidence is available.",
        "This small difference between initial probability weights is also introduced in order to avoid exceptional cases where all support values contribute with the same value.",
        "The random initial state is also used in our experiments to test that our proposed configuration is better-informed than random.",
        "Given the equiprobability state, we add a random value to each probability to be in a partition:",
        "where eil is a random value 2L – eil – 2L.",
        "These little random differences may help the algorithm to avoid local minima.",
        "The vertices of the graph would usually be placed in the same order as the mentions are found in the document (chronological).",
        "In this manner, vi corresponds to mi.",
        "However, as suggested by Luo (2007), there is no need to generate the model following that order.",
        "In our approach, the first variables have a lower number of possible labels.",
        "Moreover, an error in the first variables has more influence on the performance than an error in the later ones.",
        "Placing named entities at the beginning is reasonably to expect that is helpful for the algorithm, given that named entities are usually the most informative mentions.",
        "Figure 4: Statistics about ACE-phase02",
        "Suppose we have three mentions appearing in this order somewhere in a document: \"A. Smith\", \"he\", \"Alice Smith\".",
        "For proximity, mention \"he\" may tend to link with \"A. Smith\".",
        "Then, the third mention \"Alice Smith\" clearly is the whole name of \"A. Smith\" but the gender with \"he\" does not agree.",
        "Given that our implementation acts like a directed graph only looking backward (see Section 3), mention \"he\" won't change its tendency and it may cause a split in the \"Alice Smith\" coref-erence chain.",
        "However, having named entities in first place and pronouns at the end, enables the mention \"he\" to determine that \"A. Smith\" and \"Alice Smith\" having the same label are not good antecedents.",
        "Reordering only affects on the number of possible labels of the variables and the list of adjacencies A(vi ).",
        "The chronological order of the document is taken into account by the constraints regardless of the graph representation.",
        "Our experiments confirm (Section 4) that placing first named entity mentions, then nominal mentions and finally the pronouns, the precision increases considerably.",
        "Inside of each of these groups, the order is the same order of the document."
      ]
    },
    {
      "heading": "4. Experiments and Results",
      "text": [
        "We evaluate our approach to coreference resolution using ACE-phase02 corpus, which is composed of three sections: Broadcast News (BNEWS), Newswire (NWIRE) and Newspaper (NPAPER).",
        "Each section is in turn composed of a training set and a test set.",
        "Figure 4 shows some statistics about this corpus.",
        "In our experiments, we consider the true mentions of ACE.",
        "This is because our focus is on evaluating pairwise approach versus the graph partitioning approach and also comparing them to some state-of-the-art approaches which also use true mentions.",
        "Moreover, details on mention identifier systems and their performances are rarely published by the systems based on automatic identification of mentions and it difficults the comparison.",
        "To evaluate our system we use CEAF (Luo, 2005) and B (Bagga and Baldwin, 1998).",
        "CEAF is computed based on the best one-to-one map between key coreference chains and response ones.",
        "We use the mention-based similarity metric which counts the number of common mentions shared by key coreference chains and response ones.",
        "As we are using true mentions for the experiments, precision, recall and F1 are the same value and only F1 is shown.",
        "B scorer is used for comparison reasons.",
        "B algorithm looks at the presence/absence of mentions for each entity in the system output.",
        "Precision and recall numbers are computed for each mention, and the average gives the final precision and recall numbers.",
        "MUC scorer (Vilain et al., 1995) is not used in our experiments.",
        "Although it has been widely used in the state of the art, we consider the newer metrics have overcome some MUC limitations (Bagga and Baldwin, 1998; Luo, 2005; Klenner and Ailloud, 2008; Denis and Baldridge, 2008).",
        "Our preprocessing pipeline consists of FreeLing (Atserias et al., 2006) for sentence splitting and tokenization, SVMTool (Gimenez and Marquez, 2004) for part of speech tagging and BIO (Surdeanu et al., 2005) for named entity recognition and classification.",
        "No lemmatization neither syntactic analysis are used.",
        "The baseline developed in our work is based on Soon et al.",
        "(2001) with the improvements of Ng and Cardie (2002), which uses a Decision Tree (DT).",
        "Many research works use the same references in order to evaluate possible improvements done by their new models or by the incorporation of new features.",
        "The features used in the baseline are the same than those used in our proposed system (Figure 3).",
        "However, some features are noisy and many others have redundancy which causes low performances using DTs.",
        "In order to select the best set",
        "Tokens",
        "Mentions",
        "Entities",
        "bnews train",
        "66627",
        "9937",
        "4408",
        "bnews test",
        "17463",
        "2579",
        "1040",
        "npaper train",
        "68970",
        "11283",
        "4163",
        "npaper test",
        "17404",
        "2483",
        "942",
        "nwire train",
        "70832",
        "10693",
        "4297",
        "nwire test",
        "16772",
        "2608",
        "1137",
        "Table 1: Results ACE-phase02.",
        "Comparing baselines based on Deeision Trees.",
        "Table 2: Results on documents shorter than 200 mentions of ACE-phase02 of features a Hill Climbing proeess has been performed doing a fivefold eross-validation over the training eorpus.",
        "A similar feature selection pro-eess has been done by Hoste (2005).",
        "The Hill Climbing proeess starts using the whole set of features.",
        "A eross-validation is done (un)masking eaeh feature.",
        "The (un)masked feature with more improvement is (added to) removed from the set.",
        "The proeess is repeated until an iteration without improvements is reaehed.",
        "Note that this optimization proeess is biased by the metrie used to evaluate eaeh feature eombi-nation.",
        "We use CEAF in our experiments, whieh eneourages preeision and eonsisteney.",
        "The seeond baseline developed forms the eoref-erenee ehains given the output of the pair elassi-fieation of the first baseline.",
        "A set of binary variables (xij ) symbolize whether pairs of mentions (mi; mj) eorefer (xij- = 1) or not (xij = 0).",
        "An objeetive function is defined as follows:",
        "where Pcij is the eonfidenee value of mentions mi and mj to eorefer obtained by the pair elas-sifier.",
        "The minimization of the objeetive function is done by Integer Linear Programming (ILP) in a similar way to (Klenner, 2007; Denis and Baldridge, 2007; Finkel and Manning, 2008).",
        "In order to keep eonsisteney in the results, whieh is the goal of this post-process, a set of triangular eonstraints is required.",
        "For eaeh three mentions with indexes i < j < k the eorresponding variables have to satisfy three eonstraints:",
        "* xik ^ xij + xjk",
        "This implies that this model needs, for a doe-ument with n mentions, ^n(n – 1) variables and 2n(n – 1)(n – 2) eonstraints to assure eonsis-teney.",
        "This is an important limitation with a view to sealability.",
        "In our experiments only documents shorter than 200 mentions ean be solved by this baseline due to its eomputational eost.",
        "Four experiments have been done in order to evaluate our proposed approaeh.",
        "This seetion de-seribes and analyzes the results of eaeh experiment.",
        "Finally, our performanees are eompared with the state of the art.",
        "The first experiment eompares the perfor-manees of our baselines (Table 1).",
        "\"DT\" is the system based on Deeision Tree using all the features of Figure 3 and \"DT+Hill\" is a DT using the features seleeted by the Hill Climbing proeess (Section 4.1.1).",
        "There is a signifieant improvement in the performanees (5.1 points with CEAF, 5.3 with B) after the automatie feature selection proeess is done.",
        "bnews | npaper | nwire",
        "Global",
        "Metrie:",
        "CEAF",
        "CEAF",
        "B",
        "Model",
        "Fi",
        "Fi",
        "Fi",
        "Fi",
        "P",
        "R",
        "Fi",
        "DT",
        "60.6",
        "57.8",
        "60.5",
        "59.7",
        "61.0",
        "74.1",
        "66.9",
        "DT Hill",
        "67.8",
        "61.6",
        "65.0",
        "64.8",
        "74.7",
        "69.8",
        "72.2",
        "bnews | npaper | nwire",
        "Global",
        "Metrie:",
        "CEAF",
        "CEAF",
        "Model",
        "Fi",
        "Fi",
        "Fi",
        "Fi",
        "P",
        "R",
        "Fi",
        "DT",
        "60.6",
        "59.5",
        "64.7",
        "61.7",
        "63.3",
        "74.7",
        "68.5",
        "DT + ILP",
        "62.8",
        "60.3",
        "63.7",
        "62.5",
        "72.4",
        "69.2",
        "70.7",
        "DT Hill",
        "67.8",
        "63.2",
        "67.2",
        "66.5",
        "76.8",
        "71.0",
        "73.8",
        "DT Hill + ILP",
        "67.6",
        "63.5",
        "66.7",
        "66.3",
        "80.0",
        "68.3",
        "73.7",
        "Relax",
        "69.5",
        "68.3",
        "73.0",
        "70.4",
        "86.5",
        "67.9",
        "76.1",
        "Table 3: Results ACE-phase02.",
        "In the seeond experiment the ILP ehain formation proeess is applied using the output of both DTs.",
        "Results are shown in Table 2.",
        "Note that ILP only applies to documents shorter than 200 mentions due to its exeessive eomputational eost (Section 4.1.2).",
        "Results for Relax applied to the same documents are also ineluded for eomparison.",
        "ILP forees eonsisteney of the results produeing an in-erease in preeision seore with B metrie in both eases.",
        "However, \"DT+Hill\" has been optimized for CEAF metrie whieh eneourages preeision and eonsisteney.",
        "For this, a post-proeess foreing eon-sisteney seems unneeessary for a elassifier already optimized.",
        "Relax signifieantly outperforms all the baselines.",
        "The third experiment shows the improvements aehieved by the use of pruning and reordering teehniques (Sections 3.2 and 3.4).",
        "Table 3 shows the results.",
        "Pruning improves performanees with both metries.",
        "B preeision is deereased but the global Fi is inereased due to a eonsiderably improvement of reeall.",
        "Reordering reeovers the pre-eision lost by the pruning without loosing reeall, whieh aehieves the best performanees of 69.7 with CEAF and 74.9 with B.",
        "The fourth experiment evaluates the influenee of the initial state.",
        "A eomparison is done with the proposed initial state (Section 3.3) and the random one.",
        "The results shown in Table 3 for random initial state are the average of 3 exeeutions.",
        "The system ealled \"Relax random IS\" is using the same values for pruning and reordering teehniques than the best result of previous experiment: \"Relax pruning & reorder\".",
        "As expeeted, results with a well-informed initial state outperform the random ones.",
        "Finally, Relax performanees are eompared with the best seores we have found using the same eor-pora and metries.",
        "We eompare our approaeh with speeialized Rankers -groupwise elassifier-, and a system using ILP not only foreing eonsisteney but also using information about anaphorieity and named entities.",
        "Relax outperforms both systems with both metries (Table 3)."
      ]
    },
    {
      "heading": "5. Conclusion",
      "text": [
        "The approaeh for eoreferenee resolution presented in this paper is a eonstraint-based graph partitioning solved by relaxation labeling.",
        "The deeision to join or not a set of mentions in the same entity is taken eonsidering always the whole set of previous mentions like in groupwise elassifiers.",
        "Contrarily to the approaehes where variables are the linkage of eaeh pair of mentions, in this model eonsisteney is implieitly foreed.",
        "Moreover, the influenee of the partial results of the other mentions at the same time avoids that deeisions are independently taken.",
        "The eapaeity to easily ineorporate eonstraints from different sourees and using different knowledge is also remarkable.",
        "This flexibility gives a great poteneial to the approaeh.",
        "Anaphorieity filtering is not needed given that the neeessary knowledge ean be also introdueed by eonstraints.",
        "In addition, three teeniques to improve results have been presented: reordering, pruning and feature selection by Hill Climbing.",
        "The experiments eonfirm their utility.",
        "The experimental results elearly outperform the baselines with separate elassifieation and ehain formaiton.",
        "The approaeh also outperforms others in the state of the art using same eorpora and metries.",
        "bnews | npaper | nwire",
        "Global",
        "Metrie:",
        "CEAF",
        "CEAF",
        "B",
        "Model",
        "F1",
        "F1",
        "F1",
        "F1",
        "P",
        "R",
        "F1",
        "Relax",
        "67.3",
        "64.4",
        "69.5",
        "67.2",
        "88.4",
        "62.7",
        "73.3",
        "Relax pruning",
        "68.6",
        "65.2",
        "70.1",
        "68.0",
        "82.3",
        "66.9",
        "73.8",
        "Relax pruning & reorder",
        "69.5",
        "67.3",
        "72.1",
        "69.7",
        "85.3",
        "66.8",
        "74.9",
        "Relax random IS",
        "68.2",
        "66.1",
        "71.0",
        "68.5",
        "83.5",
        "66.7",
        "74.2",
        "MaxEnt+ILP (Denis, 2007)",
        "-",
        "-",
        "-",
        "66.2",
        "81.4",
        "65.6",
        "72.7",
        "Rankers (Denis, 2007)",
        "65.7",
        "65.3",
        "68.1",
        "67.0",
        "79.8",
        "66.8",
        "72.7"
      ]
    }
  ]
}
