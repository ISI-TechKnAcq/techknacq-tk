{
  "info": {
    "authors": [
      "Mikiko Nishikimi",
      "Hideyuki Nakashima",
      "Hitoshi Matsubara"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C92-2106",
    "title": "Language Acquisition as Learning",
    "url": "https://aclweb.org/anthology/C92-2106",
    "year": 1992
  },
  "references": [],
  "sections": [
    {
      "heading": "LANGUAGE ACQUISITION AS LEARNING",
      "text": []
    },
    {
      "heading": "Abstract",
      "text": [
        "Chomsky's proposition that language is handled by a language-specific faculty needs more justification.",
        "In language acquisition in particular, it is still in question whether the faculty is necessary or not.",
        "We succeeded in explaining one constraint on language acquisition in terms of a general learning mechanism.",
        "This paper describes a machine learning system Rhea applied to the domain of language acquisition and shows that Rhea can learn the tendency which children confronting new words seem to have."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Chomsky proposed that language is handled by a language specific faculty, lint this proposition has not been verified, especially in the area of language acquisition.",
        "Although lierwick[I] showed the existence of a special mechanism sufficient for the learning of syntax, there is still a question of whether or not the mechanism is necessary.",
        "Furthermore, his model does not explain acquisition of semantics or concepts.",
        "These were simply presupposed.",
        "We started front a general learning mechanism and succeeded in explaining a constraint on language acquisition.",
        "Children learning their first language face and solve a big problem of induction.",
        "They find out how words are used and related to other words from limited information at a surprisingly rapid rate.",
        "In the field of developmental psychology, many kinds of constraints have been proposed to account for this phenomenon.",
        "Most of these constraints comp front the view that assumes a specific framework for language acquisition, but there is another view: language as an extension of other intellectual faculties, and its acquisition as one result of the universal learning process that leads to our acquisition of intellect.",
        "We want to explain the children's ability in terms of the latter view.",
        "Thus, we stake machine learning system, Rhea, which accepts n-tuple inputs consisting of instances from n-domains (one front each domain) and creates the rules t hat delimit the possible combinations.",
        "This framework is very general, and yet if we choose outer-worlds and linguistic descriptions for them as two Mimi domains, it can be seen as a language acquisition system without language-specific constraints.",
        "- In this paper.",
        "we describe the machi nelearning system Rites and its application to the domain of language acquisition.",
        "We show that without a priori information about how outer-worlds are organized, Rhea can learn the \"setting for new words\", which children confronting new words seem to possess.",
        "The point is how the model acquires and formalizes the \"meaning\" of an expression.",
        "To achieve this autonomously, Rhea has its own rep, resentation language for outer-worlds.",
        "If one linguistic expression is repeatedly given along with different outer-worlds, it builds up one common representation for all the outer-worlds.",
        "This internal representation that has a one to-ono correspondence to a linguistic expression is regarded as the \"meaning\" of the expression in our model.",
        "2 Constraints In order to elucidate the children's rapid acquisition of vocabulary.",
        "constraints oil the possible hypotheses about Ilie meanings of linguistic expressions have been postulated.",
        "Glarh[2] proposes the principle of contrast whereby every two forms contrast in meaning, and Marlon:oi[:I] suggests a stronger assumption of taxonomic epitomization.",
        "The assumption of taxonomic organization confines children to assuming that a word given with au unknown object refers to a taxonomic class of the object.",
        "As ostensive definition is the only way to acquire early vocabulary, the assumption reduces the possible search space of meaning.",
        "With this assumption, if you see someone point to an unfamiliar object and say a word, you can presume that Ilus word is either the label of tho object or the label of one of I lie categories it belongs to and can forget about the possibility of the word's referring to one of its at tributes or",
        "its relation to other objects.",
        "Children seem to consider the assumption of taxonomic organization.",
        "Markman's experiment shows that civet' though they are liable to consider thematic relations in domains other than language acquisition, children hearing a new word attend to taxonomic relations.",
        "This tendency is called the \"setting for new words\".",
        "It is not clear, however, if such constraints are innate or not, or more essentially if they can he derived from restrictions t hat any intelligent system should observe.",
        "One way to clarify this point is to examine whether the model that does not contain the constraint can acquire it during the learning process."
      ]
    },
    {
      "heading": "3 An overview of Rhea",
      "text": []
    },
    {
      "heading": "3.1 Rhea as a machine learning system",
      "text": [
        "Fig.1 illustrates Rhea's learning process in two different domains, .4 and 13.",
        "The system's task is to find general rules that predict which instance from Domain A can appear with a certain instance from 11, and vice versa.",
        "Rhea accepts as input a pair of instances = (a, //).",
        "One instance is from Domain A and the other from Domain 13.",
        "One pair is given at a time.",
        "Rhea.",
        "is equipped with an internal representation language for each domain, DA and DB, and has predefined methods to extend the representation languages ill case of need.",
        "Similarities, generalization operations and specialization operations are defined upon each language.",
        "Rhea represents an input pair using these languages and their extensions, and makes an internal representation D(1) = (DA( a), DB(b)), which is a pair of a representation of Domain A instance and that of a Domain 11 instance.",
        "More than one possible internal representation may exist for one input, hut the one found first is stored.",
        "When representations ale accumulated, Rhea is able to find out rules.",
        "It first sorts internal representations into classes based on similarities.",
        "Classes may or may not overlap.",
        "'Ilion Rhea generalizes representations of each class.",
        "This process of classification and generalization is done on demand.",
        "When a partial input a (an instance from Domain A) is given and its counterpart 11 (from Domain 8) is to lie predicted, the model first classifies the partial input into a class A' using the information about a, makes the generalization of Domain 11 part of all the other representations in class A' and expects one of its specializations to be b's representation DR(b).",
        "The model Prins classes so that representations in each class share some characteristics.",
        "Two internal representations, (1)„.1(ai), DH(bi)) and (I) A(a2),D8(1(2)), belong to the same class if Dn(ai) and DA( a2 ) are similar in the criterion defined in the representation language DA.",
        "and DB(b1) and Dii(b..2) are also similar in the criterion defined in Dtr.",
        "Ill the extreme case, if DA(ai ) equals DA(02), then 143(1,1) must equal 1)R(1,2) and vice versa, which means that when two instances from one domain are represented as the same, instances from the other domain that appear with them must also have the same internal representation."
      ]
    },
    {
      "heading": "3.2 Rhea as a language acquisition model",
      "text": [
        "Rhea, when applied to the domain of outer-worlds S and the domain of linguistic expressions I, that describe t he outer-worlds, call be regarded as a language acquisition model.",
        "In these domains, Rhea learns the followings:",
        "1.",
        "Extensions of the representation language of linguistic expressions 2.",
        "Internal representations of linguistic expressions DL(11).",
        "D1.",
        "(1„) 3.",
        "Extensions of the representation language of outer-worlds Ds 4.",
        "Internal represent at ions of outer-worlds Ds(si ) Classification of inputs which respectively can be seen as 1.",
        "Syntactic rules 2.",
        "Structures of linguistic expressions 3.",
        "Concepts that delineate meanings 4.",
        "Meanings of linguistic expressions derived from outer-worlds",
        "Fig.2 shows the configuration of the lang,nage acquisition model, Rhea.",
        "Ii receives a pair of one scene and a linguistic expression that describes the scene.",
        "An expression is a sequence of words and contains no structural information.",
        "A scene is the equivalent of sensory input from outer-worlds.",
        "Fig.3 shows an example of a scene.",
        "A scene is a sequence of snapshots which are fists of assertions that become true or false at the time when the snapshots have been taken.",
        "Each assertion expresses a relation between two terms.",
        "The terms may be objects, attributes or values, which cannot be distinguished byRhea.",
        "l'he parser makes the internal representa•-(ions of linguistic expressions, and the filter finder makes those of scenes.",
        "The elaseofieV divides representations into classes and makes rules.",
        "Since two inputs represented as the same in one domain must have the same representation in I he other domain, there may be no synonyms or polysemants, which means that the model has \"the principle of contrast\" implanted from the beginning"
      ]
    },
    {
      "heading": "4 Internal representations of inputs",
      "text": [
        "The internal representation of an input is a pair of internal representations of the input's constituents, which is a pair of one alive/v-( and one filter."
      ]
    },
    {
      "heading": "4.1 Internal representation of linguistic expressions",
      "text": [
        "The internal representation of a linguistic expression is tine syntactic structure of the expression.",
        "For example, a linguistic expression \"Kitty ate pancakes\" is internally represented as a. straehm",
        "The first element in the list specifies the name of tini class the structure belongs to and the rest are its constituents.",
        "Each constituent in turn has its class name and constituents.",
        "The representation language DI, at the beginning contains suppositions that one input expression forms one structure and ran be described with a phrase structure grafil WM', The model accepts a new input expression provided that it can be described by adding at most one new rule.",
        "When known rules cannot parse an expression, Rhea parses it front the bottom to up and front t he top to down simultaneously and makes partial structures.",
        "If tlwy can be combined into one structure by adding one rule, Rhea adds the rule to the memory as an extension of DI,.",
        "If otw rule cannot connect all of them, the model backtracks to find another parsing or abandons the input.",
        "Rhea sets the class or an unknown word considering the scene given with the word.",
        "When some ride predicts the class of the word and the scene presented with the word can be given an internal representation similar to those of other words in the class, the word is added to the predicted class.",
        "If not, a new category is assigned to the word."
      ]
    },
    {
      "heading": "4.2 Internal representation of scenes",
      "text": [
        "1\\11 internal represent at ion of a scene provides the semantics of t he linguistic expression that comes",
        "with the scene.",
        "Linguistic expressions change or control the listeners' interpretations of the outer-world, and make speakers and listeners share one focus of attention (hereinafter, FOAL In order to model this process, a scene is internally represented as a procedure that converts the scene into an FOA.",
        "We call this procedure a finer.",
        "As stated before, a scene is a sequence of lists of assertions, and so is an FOA.",
        "FOAs must contain at least one non-variable assertion because there must exist non-variable FOAs to be shared among speakers and listeners.",
        "If a filter applied to scene a yields a non-variable sequence of lists of assertions, the filter is valid for s. Any valid filter for scene .s can be a representation of the scene.",
        "For example.",
        "a scene that contains someone eating pancakes may be internally represented in several ways.",
        "A procedure that focuses the listeners' attention on pancakes and yields pancakes as an FOA is valid for the scene, and one that stresses the eating action can also be an internal representation of the scene.",
        "However, scenes which appeared with the same expression must have the same filter because there may be no polysemants.",
        "Fig.",
        "4 shows the relationship among filters, scenes and FOAs.",
        "Since the FOAs derived by filter f from scene al and scene s2 both contain some objects, the filter is valid for both scenes.",
        "Thus two scenes that appear with linguistic expression I are represented by the filter.",
        "Filters are mappings front scenes to FOAs.",
        "Rhea has 32 parameterized simple mappings as its representation language ns at the start.",
        "It combines mappings and searches a given scene for values to instantiate parameters.",
        "We call these parameterized mappings filltr-primitives and instantiated mappings fatt•-elements.",
        "For instance, among the possible combinations of filter-primitives is the one (snap-remove not-include *variable*) which removes assertions that do not contain a certain term from a snapshot.",
        "When a scene is given, the model selects one of the terms .in the scene, namely $location, to substitute for *variable* and makes a filter-element (snap-remove not-include $location) which extracts assertions t hat contain the term $looat ion from a snapshot in the scene.",
        "A filter is it sequence of one or more filter-elements.",
        "Filter-elements in the sequence are applied to a scene one by one and the result becomes the FOA."
      ]
    },
    {
      "heading": "4.2.2 Acquisition of filters",
      "text": [
        "Rhea shapes filters through trial and error.",
        "Whenever a new scene is given with an expression, the filter that seems to correspond to the expression is tested for its validity for the new scene, and Rhea then elaborates or corrects the filter depending on I he result.",
        "When the new input (1,․) is given, the model creates DL(/), which is the representation of I by the language D1„ and searches through the memory for a representation that has the form (1) L(1), f), where f is an internal representation of an instance from Domain S. If there is no representation of the form (DLLO, f), I is regarded as a TWIN expression and Rhea builds a candidate for filter f. The Candidate consists of one filter-element made by selecting one filter-primitive randomly and substituting terms in the given scene a for parameters of the filter-primitive.",
        "If the candidate is valid for scene a, it is used as an internal representation of the scene.",
        "If it is not, another candidate is created and tested.",
        "As there must be no synonyms, a filter must be different front those of other expressions.",
        "If Rhea already knows the linguistic expression 1, that is, if the representation of the form (DL(1), f) is in the memory of [tea, it checks the validity of filter f for scene ,s. Rhea elaborates valid filters and corrects invalid ones.",
        "Elaboration is to make filters more specific by adding conditions.",
        "Rhea may either insert one randomly selected filter-element into the existing filter or replace one filter-element by a more specific one.",
        "For each input, the model can add only one condition, so learning proceeds gradually.",
        "'ffie new filter must he different from the filters of other expressions and must extract an FOA which is different from the one derived by the old filter.",
        "If Rhea cannot elaborate the filter to make up a new one, it keeps the 01(1 one.",
        "Correction of a filter is done by deleting conditions.",
        "Rhea keeps a revision counler R for every internal representation.",
        "It is the number of successive scenes from which the filter cannot extract an FOA and Rhea cannot correct it.",
        "To correct a filter, Rhea may remove j filter-elements, replace parameters of k' filter-elements with other values extracted from scene .s or replace 1 filter-elements with more general ones.",
        "The number of changes j k 1, however, must not exceed the value of the revision counter.",
        "When the correction succeeds, Rhea sets the revision counter to zero.",
        "If the filter cannot be made valid for scene a within the allowed number of changes, Rhea keeps it and increments the revision counter by ODD.",
        "5 Classification and generalization of input Rhea divides internal representations into classes.",
        "A class contains representations that have both similar structures and similar filters.",
        "As classes may overlap, an internal representation can be a member of two or more classes."
      ]
    },
    {
      "heading": "5.1 Similarity of structures",
      "text": [
        "Two structures are similar if they are in interchangeable positions within bigger structures.",
        "For example, having two structures: Sl: (Sentence (Categoryl 'yellow') (Category2 `pancake')) S2: (Sentence (Categoryl 'red')",
        "may trigger the making of a class that contains two representations whose structures are (Category2 'pancake') and (Category3 `raspberries') respectively.",
        "These structures are similar because they both have one Categoryl as their sister class and form members of the Sentence class."
      ]
    },
    {
      "heading": "5.2 Similarity of filters",
      "text": [
        "Filters are lists of filter-elements.",
        "Two filters are similar when they can be generalized into the same non-null and non-variable list.",
        "Rhea has the following generalization dropping down conditions) operations.",
        "1. deletion 01' transformation into a variable of a filter-element at a specified position in the list 2. deletion or transformation into a variable of filter-elements between those that match certain patterns",
        "transformation into a variable of a part of a. filter-element at a specified position in the list If a sequence of operations is applied to a set of filters and yields a cominon and non-trivial result, tie internal representations that have those filters can form one class.",
        "For example, all internal representation with a lilt ((F x y) (G v)) and another representation whose filter is x z)) may belong to t he same class because t he non t ri vial generalization of the two filters ((F x *variable)) exists.",
        "5.3 How classes can be used As described in subsection 3.1, a class constrains its members to a certain form of representation.",
        "There are two ways for the model to use this restriction.",
        "One way is based on the class-instance relations among representations.",
        "We can demarcate the search space for the meaning of the expression if its class is known.",
        "Rhea, ill need of finding the filter paired wit h a structure, first determines the class of the structure, generalizes all the filters of members of the class and expects that t he filter in question is one of the specializations of I he generalized filters.",
        "Specialization is done by substit ming values for variables in the generalized filter or adding one or more filter-elements to the filter.",
        "The other way utilizes hilt a-relationships of relationships among representations.",
        "The struct ores define whole-part relationships among themselves.",
        "Representations of a class are expected to share some characteristics of these relationships.",
        "We call guess the meaning of a sentence that was never heard before.",
        "This happens when we know all the constituent words and how their meanings contribute to the meaning of t he whole sentence.",
        "When a new linguistic expression is given and represented in a structure, R !ma can accelerate the search for Ole filter paired with it if the filters of its constituents are known.",
        "It first identifies the structure's class, and then makes one rule for each member of the class that explains how the filter of the member is broken down into the",
        "filters of its constituents.",
        "It then generalizes all these rules and expects that a specialization of the generalized rule applies to the structure in question.",
        "Therefore, Rhea puts the filter of its constituents into the general rule and composes a candidate for the filter of the whole structure.",
        "The model can limit the search space for the filter to specializations of the candidate."
      ]
    },
    {
      "heading": "6 Experiment: one-word sentence",
      "text": [
        "We test the model to see whether it can acquire the \"setting\" for new words given as one-word sentences.",
        "An input scene is selected from 48 possibilities that we have prepared.",
        "The lexicon has 32 words, but not every word can describe a given scene, thus for each scene we made a list of words that can be used to describe it.",
        "Linguistic expressions are randomly composed using the words in the list and the grammar shown in Table 1,1 and are restricted to no more than a length of three words.",
        "These <n>, <p>, <v> and <a> roughly correspond to nouns, proper-nouns, verbs and adjectives.",
        "After 432 pairs were input, Rhea divided :32 words into three, unconnected classes: Class], Class2 and Class3.",
        "In the internal representations of two or three-word sentences, they were 'English translations of terminal symbols in Table I are: <n> ::= \"leg\" I \"head\" I \"duck\" I \"sweets\" I \"cup\" I \"mouth\" I \"glass\" I \"coffee\" I \"plate\" I \"spoon\" I \"food\" I \"table\" I \"arm\" I \"living thing\" I \"cat\" I \"pancake\" I \"milk\" I \"eye\" <v> ::= \"to exist\" I \"to move\" 1\"to touch\" I \"to eat\" I \"not to exist\"",
        "further divided into subclasses, but here for simplicity, we concentrate on the classes made to express one-word sentences.",
        "Class] contained one <v> word \"aru\" (to exist), Class2 contained another <v> word \"nai\" (not to exist ) and all other 30 words were classified into the last class.",
        "Class3.",
        "Rhea learned that the word in Class is associated with a filter that extracts assertions that become t rue at the time of utterance, and t he filters of the word in Class2 extracts only assertions that become false at utterance.",
        "Fig.5 shows the generalized filter of Class3.",
        "It makes parameterized modifications to scenes.",
        "The first filter-element (subseq 0 0) extracts changes at the time of utterance, (snap-count all) counts how many times each term appears in the snapshot and (snap-sort all maxcount) changes order of assertions in the snapshot so that assertions that contains the term that appears more frequently come earlier.",
        "The last filter-element (map snap-remove not-include *variable*) has a variable and Rhea.",
        "has to select a term from the snapshot to substitute for it.",
        "The substituted filter-element extracts assertions that contain the term.",
        "As the assertions in the snapshot are thus sorted, the term that appears most frequently is selected first, and the filter that focuses on the term is tested for its validity first.",
        "As for the relationship between a one-word sentence and its only constituent word, Rhea conjectured that the filter of the syntnnee is the same' as that of the word.",
        "In short, Rhea acquired the general filter for a group of one-word sentences and it extracts such assertions that describe a term that appears most frequently in the snapshot at the time of utterance.",
        "As Rhea backtracks, assertions with the next most frequent term are extracted.",
        "Scenes have more labels for an object than labels for its attributes because each assertion expresses a relation between two terms and an object label appears in all the assertions about its attributes.",
        "Therefore when the model is given a one-word sentence whose roust it tient word does not belong to classes of words of existence/nonAcres existence, it first assumes the sentence to refer to the label for an object in the scene.",
        "If the label is already known, the model then backtracks to refer to the label for its most salient attribute or a label for another object.",
        "This is what children with the \"setting for new words\" would do facing a new one-word sentence."
      ]
    },
    {
      "heading": "7 Discussion",
      "text": []
    },
    {
      "heading": "7.1 Semantic concepts and input",
      "text": [
        "Other acquisition models that cover semantic acquisition are the system of Takagi et.",
        "al, [4], which accepts a sentence and visual input, Bill's language acquisition model[5] and Selfridge's CHILD[6].",
        "However these models assume semantic concepts from the start, and t heir task is to associate linguistic entities with them.",
        "These systems, which receive a semantic concept to be associated with a linguistic expression as direct input, cannot 'misunderstand the meaning of a linguistic expression and cannot shed light on the difficulty of learning the meaning of a certain expression.",
        "We do not assume semantic concepts in representing scenes given to Rhea.",
        "We formalize concepts as functions from the direct input to FOAs.",
        "They must be formed and tested in accordance with expressions and other concepts.",
        "We equipped the model with filter-primitives, which arc moans of establishing the concepts.",
        "We have designed filter-primitives to become equivalents of human abilities of recognition.",
        "Filter-primitives are given from the beginning because human beings have the ability to focus their attention on objects, attributes or changes when they begin language acquisition.",
        "Rhea can select a parameter from scenes and make CODE rate filter-elements just like any child coming to distinguish important features in its world.",
        "Therefore, our formalization of concepts and its acquisition process is a more realistic one."
      ]
    },
    {
      "heading": "7.2 Acquisition of a constraint",
      "text": [
        "The principle of contrast is derived from the general constraint on how a class should be formed to make useful predictions, and as shown in section 6, Rhea has no language-specific constraints but yet can acquire the \"setting for new words\", because its filter-primitives and classification criteria can reproduce the tendency that was contained in the input pairs.",
        "In our experiment, the one-word sentences given to Rhea were often taxonomic terms or attributes of any objects in the scene and Rhea learned that the best conjecture is that tlict one-word sentence presented with unknown objects refers to a taxonomic term of the most frequently described object.",
        "If we give a label for the biggest object in the scene whenever Rhea meets a scene with multiple objects that are not yet labeled, Rhea will make a filter of a category that sorts objects by size and extracts the first one.",
        "Our claim is that children can also acquire the \"setting for the new words\" from a few inputs of one-word sentences, and that it need not to be set a priori.",
        "8 Conclusion This paper has described Rhea, the model of language acquisition, which uses very general acquisition procedure.",
        "We assume neither semantic concepts nor syntactic rules a priori.",
        "Instead, we have equipped the model with the general framework to create the rules that delimit the possible combinations of the in pat.",
        "We applied the model to the domains of outer-worlds and linguistic descriptions of them.",
        "The system successfully made concepts that are consistent with given inputs.",
        "Thy experiment showed that it reproduced the \"setting for the new words,\" a. human tendency in language] acquisition, without language-specific constraints or informal ion about how outer-worlds are organized."
      ]
    }
  ]
}
