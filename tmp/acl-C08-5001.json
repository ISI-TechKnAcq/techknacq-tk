{
  "info": {
    "authors": [
      "Liang Huang"
    ],
    "book": "COLING – Tutorials",
    "id": "acl-C08-5001",
    "title": "Advanced Dynamic Programming in Semiring and Hypergraph Frameworks",
    "url": "https://aclweb.org/anthology/C08-5001",
    "year": 2008
  },
  "references": [
    "acl-D07-1104",
    "acl-H05-1036",
    "acl-J02-3001",
    "acl-J03-1006",
    "acl-N03-1016",
    "acl-N04-1014",
    "acl-N06-1040",
    "acl-P03-1021",
    "acl-P05-1012",
    "acl-P05-1022",
    "acl-W05-1506"
  ],
  "sections": [
    {
      "text": [
        "Dynamic Programming (DP) is an important class of algorithms widely used in many areas of speech and language processing.",
        "Recently there have been a series of work trying to formalize many instances of DP algorithms under algebraic and graph-theoretic frameworks.",
        "This tutorial surveys two such frameworks, namely semirings and directed hypergraphs, and draws connections between them.",
        "We formalize two particular types of DP algorithms under each of these frameworks: the Viterbi-style topological algorithms and the Dijkstra-style best-first algorithms.",
        "Wherever relevant, we also discuss typical applications of these algorithms in Natural Language Processing."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Many algorithms in speech and language processing can be viewed as instances of dynamic programming (DP) (Bellman, 1957).",
        "The basic idea of DP is to solve a bigger problem by divide-and-conquer, but also reuses the solutions of overlapping subproblems to avoid recalculation.",
        "The simplest such example is a Fibonacci series, where each F(n) is used twice (if cached).",
        "The correctness of a DP algorithm is ensured by the optimal substructure property, which informally says that an optimal solution must contain optimal subsolutions for subproblems.",
        "We will formalize this property as an algebraic concept of monotonicity in Section 2.",
        "* Survey paper to accompany the COLING 2008 tutorial on dynamic programming.",
        "The material presented here is based on the author's candidacy exam report at the University of Pennsylvania.",
        "I would like to thank Fernando Pereira for detailed comments on an earlier version of this survey.",
        "This work was supported by NSF ITR EIA-0205456.",
        "Table 1: The structure of this paper: a two dimensional classification of dynamic programming algorithms, based on search space (rows) and propogation ordering (columns).",
        "Corresponding section numbers are in parentheses.",
        "This report surveys a two-dimensional classification of DP algorithms (see Table 1): we first study two types of search spaces (rows): the semiring framework (Mohri, 2002) when the underlying representation is a directed graph as in finite-state machines, and the hypergraph framework (Gallo et al., 1993) when the search space is hierarchically branching as in context-free grammars; then, under each of these frameworks, we study two important types of DP algorithms (columns) with contrasting order of visiting nodes: the Viterbi style topological-order algorithms (Viterbi, 1967), and the Dijkstra-Knuth style best-first algorithms (Dijkstra, 1959; Knuth, 1977).",
        "This survey focuses on optimization problems where one aims to find the best solution of a problem (e.g. shortest path or highest probability derivation) but other problems will also be discussed."
      ]
    },
    {
      "heading": "2. Semirings",
      "text": [
        "The definitions in this section follow Kuich and Salomaa (1986) and Mohri (2002).",
        "Definition 1.",
        "A monoid is a triple (A, <g>, 1) where <g> is a closed associative binary operator on the set A, and 1 is the identity element for <g>, i.e., for all fleA,o®l = l®a = a.",
        "A monoid is commutative if <g> is commutative.",
        "1.",
        "(A, ©, 0) is a commutative monoid.",
        "2.",
        "(A, <g>, 1) is a monoid.",
        "(aeb)®c = (a®c)e(b(g)c), c®(aeb) = (c®a)e(c®b).",
        "4.",
        "0 is an annihilator for <g>: for all a in A, 0 <g> a = a <g> 0 = 0.",
        "search space \\ ordering",
        "topological-order",
        "best-first",
        "graph + semirings (2) hypergraph + weight functions (4)",
        "Viterbi (3.1) Gen. Viterbi (5.1)",
        "Dijkstra/A* (3.2) Knuth/A* (5.2)",
        "Definition 3.",
        "A semiring (A, ©, <g>, 0,1) is commutative if its multiplicative operator <g> is commutative.",
        "For example, all the semirings in Table 2 are commutative.",
        "Definition 4.",
        "A semiring (A,©,®, 0,1) is idempotent if for all a in A, a © a = a.",
        "Idempotence leads to a comparison between elements of the semiring.",
        "Lemma 1.",
        "Let (A, ©, <g>, 0,1) be an idempotent semiring, then the relation < denned by is a partial ordering over A, called the natural order over A.",
        "However, for optimization problems, a partial order is often not enough since we need to compare arbitrary pair of values, which requires a total ordering over A.",
        "Definition 5.",
        "An idempotent semiring (A, ©, <g>, 0,1) is totally-ordered if its natural order is a total ordering.",
        "An important property of semirings when dealing with optimization problems is monotonicity, which justifies the optimal subproblem property in dynamic programming (Cormen et al., 2001) that the computation can be factored (into smaller problems).",
        "Definition 6.",
        "Let K = (A, ©, <g>, 0,1) be a semiring, and < a partial ordering over A.",
        "We say K is monotonic if for all a,b,c e A Lemma 2.",
        "Let (A,©,®, 0,1) be an idempotent semiring, then its natural order is monotonic.",
        "Semiring",
        "Set",
        "©",
        "®",
        "Ö",
        "Ï",
        "intuition/application",
        "Boolean",
        "{0,1}",
        "V",
        "A",
        "0",
        "1",
        "logical deduction, recognition",
        "Viterbi",
        "[0,1]",
        "max",
        "x",
        "0",
        "1",
        "prob, of the best derivation",
        "Inside",
        "R+ U {+00}",
        "+",
        "x",
        "0",
        "1",
        "prob, of a string",
        "Real",
        "RU {+00}",
        "min",
        "+",
        "+00",
        "0",
        "shortest-distance",
        "Tropical",
        "R+ U {+00}",
        "min",
        "+",
        "+00",
        "0",
        "with non-negative weights",
        "Counting",
        "N",
        "+",
        "x",
        "0",
        "1",
        "number of paths",
        "In the following section, we mainly focus on totally-ordered semirings (whose natural order is monotonic).",
        "Another (optional) property is superiority which corresponds to the non-negative weights restriction in shortest-path problems.",
        "When superiority holds, we can explore the vertices in a best-first order as in the Dijkstra algorithm (see Section 3.2).",
        "Definition 7.",
        "Let K = (A, ©, <g>, 0,1) be a semiring, and < a partial ordering over A.",
        "We say K is superior if for all a, b e A a < a (gib, b < a (gib.",
        "Intuitively speaking, superiority means the combination of two elements always gets worse (than each of the two inputs).",
        "In shortest-path problems, if you traverse an edge, you always get worse cost (longer path).",
        "In Table 2, the Boolean, Viterbi, and Tropical semirings are superior while the Real semiring is not.",
        "Lemma 3.",
        "Let (A, ©, (gi, 0,1) be a superior semiring with a partial order < over A, then for all a g A 1 < a < 0.",
        "Proof.",
        "For all a g A, we have l<l®a = aby superiority and 1 being the identity of <g>; on the other hand, we have a<0®a = 0by superiority and 0 being the annihilator of <g>.",
        "□",
        "This property, called negative boundedness in (Mohri, 2002), intuitively illustrates the direction of optimization from 0, the initial value, towards as close as possible to 1, the best possible value."
      ]
    },
    {
      "heading": "3. Dynamic Programming on Graphs",
      "text": [
        "Following Mohri (2002), we next identify the common part shared between these two algorithms as the generic shortest-path problem in graphs.",
        "Definition 8.",
        "A (directed) graph is a pair G = (V,E) where V is the set of vertices and E the set of edges.",
        "A weighted (directed) graph is a graph G = (V, E) with a mapping w : E i – > A that assigns each edge a weight from the semiring (A, ©, <g>, 0,1).",
        "Definition 9.",
        "The backward-star BS(v) of a vertex v is the set of incoming edges and the forward-star FS(v) the set of outgoing edges.",
        "Definition 10.",
        "A path it in a graph G is a sequence of consecutive edges, i.e. 7r = eie2 • • • where e» and ej+i are connected with a vertex.",
        "We define the weight (or cos£) of path tt to be",
        "We denote P(v) to be the set of all paths from a given source vertex s to vertex v. In the remainder of the section we only consider single-source shortest-path problems.",
        "Definition 11.",
        "The best weight 5(v) of a vertex f is the weight of the best path from the source stoti:",
        "For each vertex v, the current estimate of the best weight is denoted by d(v), which is initialized in the following procedure:",
        "procedure Initialize^, s) for each vertex v / s do d(v) <- 0",
        "The goal of a shortest-path algorithm is to repeatedly update d(v) for each vertex v to some better value (based on the comparison ©) so that eventually d(v) will converge to S(v), a state we call fixed.",
        "For example, the generic update along an incoming edge e = (u, v) for vertex v is",
        "Notice that we are using the current estimate of u to update v, so if later on d(u) is updated we have to update d(v) as well.",
        "This introduces the problem of cyclic updates, which might cause great inefficiency.",
        "To alleviate this problem, in the algorithms presented below, we will not trigger the update until u is fixed, so that the u – > v update happens at most once.",
        "In many NLP applications, the underlying graph exhibits some special structural properties which lead to faster algorithms.",
        "Perhaps the most common of such properties is acyclicity, as in Hidden Markov Models (HMMs).",
        "For acyclic graphs, we can use the Viterbi (1967) Algorithm which simply consists of two steps:"
      ]
    },
    {
      "heading": "1.. topological sort",
      "text": [
        "2. visit each vertex in the topological ordering and do updates",
        "The pseudo-code of the Viterbi algorithm is presented in Algorithm 1.",
        "Algorithm 1 Viterbi Algorithm.",
        "1: procedure Viterbi(G, w, s) 2: topologically sort the vertices of G 3: Initialize^, s)",
        "4: for each vertex v in topological order do 5: for each edge e = (u, v) in BS(v) do",
        "The correctness of this algorithm (that d(v) = 5(v) for all v after execution) can be easily proved by an induction on the topologically sorted sequence of vertices.",
        "Basically, at the end of the outer-loop, d(v) is fixed to be S(v).",
        "This algorithm is widely used in the literature and there have been some alternative implementions.",
        "Variant 1.",
        "If we replace the backward-star BS(v) in line 5 by the forward-star FS(v) and modify the update accordingly, this procedure still works (see Algorithm 2 for pseudo-code).",
        "We refer to this variant the forward-update version of Algorithm l. The correctness can be proved by a similar induction (that at the beginning of the outer-loop, d(v) is fixed to be S(v)).",
        "Algorithm 2 Forward update version of Algorithm 1.",
        "1: procedure Viterbi-Forward(G, w, s) 2: topologically sort the vertices of G 3: Initialize^, s)",
        "4: for each vertex v in topological order do 5: for each edge e = (v,u) in FS(v) do",
        "Variant 2.",
        "Another popular implemention is memoized recursion (Cormen et al., 2001), which starts from a target vertex t and invokes recursion on sub-problems in a top-down fashion.",
        "Solved sub-problems are memoized to avoid duplicate calculation.",
        "The running time of the Viterbi algorithm, regardless of which implemention, is 0(V + E) because each edge is visited exactly once.",
        "It is important to notice that this algorithm works for all semirings as long as the graph is a DAG, although for non-total-order semirings the semantics of 5(v) is no longer \"best\" weight since there is no comparison.",
        "See Mohri (2002) for details.",
        "Example 1 (Counting).",
        "Count the number of paths between the source vertex s and the target vertex t in a DAG.",
        "Solution Use the counting semiring (Table 2).",
        "Example 2 (Longest Path).",
        "Compute the longest (worst cost) paths from the source vertex s in a DAG.",
        "Solution Use the semiring (R U { – oo}, max, +, – oo, 0).",
        "Example 3 (HMM Tagging).",
        "See Manning and Schütze (1999, Chap.",
        "10).",
        "The well-known Dijkstra (1959) algorithm can also be viewed as dynamic programming, since it is based on optimal substructure property, and also utilizes the overlapping of sub-problems.",
        "Unlike Viterbi, this algorithm does not require the structural property of acyclicity; instead, it requires the algebraic property of superiority of the semiring to ensure the correctness of best-first exploration.",
        "Algorithm 3 Dijkstra Algorithm.",
        "1: procedure Dijkstra(G, w, s) 2: Initialize^, s)",
        "3: Q < – V[G] > prioritized by d-values 6: for each edge e = (v,u) in FS(v) do 8: DeCREASE-Key(Q, u)",
        "The time complexity of Dijkstra Algorithm is 0((E + V) log V) with a binary heap, or 0(E + V log V) with a Fibonacci heap (Cormen et al., 2001).",
        "Since Fibonacci heap has an excessively high constant overhead, it is rarely used in real applications and we will focus on the more popular binary heap case below.",
        "For problems that satisfy both acyclicity and superiority, which include many applications in NLP such as HMM tagging, both Dijkstra and Viterbi can apply (Nederhof, 2003).",
        "So which one is better in this case?",
        "From the above analysis, the complexity 0((V + E) log V) of Dijkstra look inferior to Viterbi's 0(V + E) (due to the overhead for maintaining the priority queue), but keep in mind that we can quit as long as the solution for the target vertex t is found, at which time we can ensure the current solution for the target vertex is already optimal.",
        "So the real running time of Dijkstra depends on how early the target vertex is popped from the queue, or how good is the solution of the target vertex compared to those of other vertices, and whether this early termination is worthwhile with respect to the priority queue overhead.",
        "More formally, suppose the complete solution is ranked rth among V vertices, and we prefer Dijkstra to be faster, i.e., then we have as the condition to favor Dijkstra to Viterbi.",
        "However, in many real-world applications (especially AI search, NLP parsing, etc.",
        "), often times the complete solution (a full parse tree, or a source-sink path) ranks very low among all vertices (Eq.",
        "4 does not hold), so normally the direct use of Dijkstra does not bring speed up as opposed to Viterbi.",
        "To alleviate this problem, there is a popular technique named A* (Hart et al., 1968) described below.",
        "We prioritize the queue using a combination of the known cost d(v) from the source vertex, and an estimate h(v) of the (future) cost from v to the target t:",
        "where P(v, t) is the set of paths from v to t. In case where the estimate h(v) is admissible, namely, no worse than the true future cost h(v), we can prove that the optimality of d(t) when t is extracted still holds.",
        "Our hope is that ranks higher among d(v) ® h(v) and can be popped sooner.",
        "The Dijkstra Algorithm is a special case of the A* Algorithm where h(v) = 1 for all v."
      ]
    },
    {
      "heading": "4. Hypergraphs",
      "text": [
        "Hypergraphs, as a generalization of graphs, have been extensively studied since 1970s as a powerful tool for modeling many problems in Discrete Mathematics.",
        "In this report, we use directed hypergraphs (Gallo et al., 1993) to abstract a hierarchically branching search space for dynamic programming, where we solve a big problem by dividing it into (more than one) sub-problems.",
        "Classical examples of these problems include matrix-chain multiplication, optimal polygon triangulation, and optimal binary search tree (Cormen et al., 2001).",
        "Definition 12.",
        "A (directed) hypergraph is a pair H = (V,E) with a set R, where V is the set of vertices, E is the set of hyperedges, and R is the set of weights.",
        "Each hyperedge e e E is a triple e = (T(e), h(e), fe), where h(e) G V is its head vertex and T(e) e V* is an ordered list of tail vertices.",
        "fe is a weight function from RlT(e)l to R.",
        "Note that our definition differs slightly from the classical definitions of Gallo et al.",
        "(1993) and Nielsen et al.",
        "(2005) where the tails are sets rather than ordered lists.",
        "In other words, we allow multiple occurrences of the same vertex in a tail and there is an ordering among the components.",
        "We also allow the head vertex to appear in the tail creating a self-loop which is ruled out in (Nielsen et al., 2005).",
        "Definition 13.",
        "We denote |e| = |T(e)| to be the arity of the hyperedge.",
        "If |e| = 0, then /e() e R is a constant (/e is a nullary function) and we call h(e) a source vertex.",
        "We define the arity of a hypergraph to be the maximum arity of its hyperedges.",
        "A hyperedge of arity one degenerates into an edge, and a hypergraph of arity one is standard graph.",
        "Similar to the case of graphs, in many applications presented below, there is also a distinguished vertex t e V called target vertex.",
        "We can adapt the notions of backward-and forward-star to hypergraphs.",
        "BThe arity of e is different from its cardinality denned in (Gallo et al., 1993; Nielsen et al., 2005) which is \\T(e)\\ + 1.",
        "Definition 14.",
        "The backward-star BS(v) of a vertex v is the set of incoming hyperedges {e £ E \\ h{e) = v}.",
        "The in-degree of v is \\BS(v)\\.",
        "The forward-star FS(v) of a vertex v is the set of outgoing hyperedges {e <E E \\ v <E T(e)}.",
        "The out-degree of t> is \\FS(v)\\.",
        "Definition 15.",
        "The graph projection of a hypergraph if = (V, i?,i, R) is a directed graph G = (V, E') where",
        "A hypergraph H is acyclic if its graph projection G is acyclic; then a topological ordering of ii is an ordering of V that is a topological ordering in G.",
        "We also extend the concepts of monotonicity and superiority from semirings to hypergraphs.",
        "Definition 16.",
        "A function / : Rm i – > R is monotonic with regarding to ^, if for alH g \\..m (aj < a'i) f(ai, ■■■ ,ai,--- , am) ■< f(ai, • • • , a-, • • • , am).",
        "Definition 17.",
        "A hypergraph H is monotonic if there is a total ordering ^ on R such that every weight function / in H is monotonic with regarding to ^.",
        "We can borrow the additive operator © from semiring to define a comparison operator",
        "In this paper we will assume this monotonicity, which corresponds to the optimal substructure property in dynamic programming (Cormen et al., 2001).",
        "Definition 18.",
        "A function / : Rm i – > R is superior if the result of function application is worse than each of its argument:",
        "A hypergraph H is superior if every weight function / in H is superior.",
        "E' = {(u,v) | 3e g BS(v), s.t.",
        "u g T(e)}.",
        "To do optimization we need to extend the notion of paths in graphs to hy-pergraphs.",
        "This is, however, not straightforward due to the assymmetry of the head and the tail in a hyperedge and there have been multiple proposals in the literature.",
        "Here we follow the recursive definition of derivations in (Huang and Chiang, 2005).",
        "See Section 6 for the alternative notion of hyperpaths.",
        "Definition 19.",
        "A derivation D of a vertex v in a hypergraph H, its size \\D\\ and its weight w(D) are recursively defined as follows:",
        "• If e g BS(v) with |e| =0, then D = (e, e) is a derivation of v, its size \\D\\ = 1, and its weight w(D) = /e().",
        "The ordering on weights in R induces an ordering on derivations: D < D' iffw(D) r< w(D').",
        "We denote S>(v) to be the set of derivations of v and extend the best weight in definition 11 to hypergraph:",
        "Definition 20.",
        "The best weight 5(v) of a vertex v is the weight of the best derivation of v:",
        "Hypergraphs are closely related to other formalisms like AND/OR graphs, context-free grammars, and deductive systems (Shieber et al., 1995; Neder-hof, 2003).",
        "In an AND/OR graph, the OR-nodes correspond to vertices in a hypergraph and the AND-nodes, which links several OR-nodes to another OR-node, correspond to a hyperedge.",
        "Similarly, in context-free grammars, nonterminals are vertices and productions are hyperedges; in deductive systems, items are vertices and instantied deductions are hyperedges.",
        "Table 3 summarizes these correspondences.",
        "Obviously one can construct a corresponding hypergraph for any given AND/OR graph, context-free grammar, or deductive system.",
        "However, the hypergraph formulation provides greater v is a source vertex modeling flexibility than the weighted deductive systems of Nederhof (2003): in the former we can have a separate weight function for each hyperedge, where as in the latter, the weight function is defined for a deductive (template) rule which corresponds to many hyperedges."
      ]
    },
    {
      "heading": "5. Dynamic Programming on Hypergraphs",
      "text": [
        "Since hypergraphs with weight functions are generalizations of graphs with semirings, we can extend the algorithms in Section 3 to the hypergraph case.",
        "The Viterbi Algorithm (Section 3.1) can be adapted to acyclic hypergraphs almost without modification (see Algorithm 4 for pseudo-code).",
        "Algorithm 4 Generalized Viterbi Algorithm, l: procedure General-ViTERBi(if) 2: topologically sort the vertices of H",
        "3: iNITIALIZE(if) 4: for each vertex v in topological order do 5: for each hyperedge e in BS(v) do",
        "The correctness of this algorithm can be proved by a similar induction.",
        "Its time complexity is 0(V + E) since every hyperedge is visited exactly once (assuming the arity of the hypergraph is a constant).",
        "The forward-update version of this algorithm, however, is not as trivial as the graph case.",
        "This is because the tail of a hyperedge now contains several vertices and thus the forward-and backward-stars are no longer symmetric.",
        "The naive adaption would end up visiting a hyperedge many times.",
        "To ensure that a hyperedge e is fired only when all of its tail vertices have been fixed to their best weights, we maintain a counter r[e] of the remaining vertices yet to be fixed (line 5) and fires the update rule for e when r[e] =0 (line 9).",
        "This method is also used in the Knuth algorithm (Section 5.2).",
        "hypergraph",
        "AND/OR graph",
        "context-free grammar",
        "deductive system",
        "vertex",
        "OR-node",
        "symbol",
        "item",
        "source-vertex",
        "leaf OR-node",
        "terminal",
        "axiom",
        "target-vertex",
        "root OR-node",
        "start symbol",
        "goal item",
        "hyperedge",
        "AND-node",
        "production",
        "instantiated deduction",
        "/",
        "V – > U\\ U2",
        "v,\\ : a v,2 '■ b",
        "({ui,u2},v, f)",
        "v : f(a,b)",
        "Algorithm 5 Forward update version of Algorithm 4.",
        "1: procedure General-Viterbi-Forward (if) 2: topologically sort the vertices of H",
        "3: iNITIALIZE(ii) 4: for each hyperedge e do 5: r[e] < – |e| i> counter of remaining tails to be fixed 6: for each vertex v in topological order do 7: for each hyperedge e in FS(v) do 9: if r[e] == 0 then i> all tails have been fixed",
        "The most widely used algorithm for parsing in NLP, the CKY algorithm (Kasami, 1965), is a specific instance of the Viterbi algorithm for hyper-graphs.",
        "The CKY algorithm takes a context-free grammar G in Chomsky Normal Form (CNF) and essentially intersects G with a DFA D representing the input sentence to be parsed.",
        "The resulting search space by this intersection is an acyclic hypergraph whose vertices are items like (X, i, j) and whose hyperedges are instantiated deductive steps like ({(Y,i, k)(Z, k,j)}, (X, i,j), /) for alH < k < j if there is a production X – > YZ.",
        "The weight function / is simply /(a,b) = a®b®w{X -»■ YZ).",
        "The Chomsky Normal Form ensures acyclicity of the hypergraph but there are multiple topological orderings which result in different variants of the CKY algorithm, e.g., bottom-up CKY, left-to-right CKY, and right-to-left CKY, etc.",
        "Knuth (1977) generalizes the Dijkstra algorithm to what he calls the grammar problem, which essentially corresponds to the search problem in a monotonic superior hypergraph (see Table 3).",
        "However, he does not provide",
        "4: for each hyperedge e do",
        "an efficient implementation nor analysis of complexity.",
        "Graehl and Knight (2004) present an implementation that runs in time 0(VlogV + E) using the method described in Algorithm 5 to ensure that every hyperedge is visited only once (assuming the priority queue is implemented as a Fibonaaci heap; for binary heap, it runs in 0((V + E) \\ogV)).",
        "Algorithm 6 Knuth Algorithm.",
        "1: procedure Knuth(_£T)",
        "3: Q < – V[H] > prioritized by d-values",
        "8: for each edge e in FS(v) do",
        "We can also extend the A* idea to hypergraphs to speed up the Knuth Algorithm.",
        "A specific case of this algorithm is the A* parsing of Klein and Manning (2003) where they achieve significant speed up using carefully designed heuristic functions.",
        "More formally, we first need to extend the concept of (exact) outside cost from Eq.",
        "5:",
        "where S>(v,t) is the set of (partial) derivations using n as a leaf node.",
        "This outside cost can be computed from top-down following the inverse topological order: for each vertex v, for each incoming hyperedge e = ({«i, • • •, u\\e\\},v, fe) g BS(v), we update ct{ui) © = fe{d{u\\)... d(ui-{), a(v),d(ui+i)... d(u\\e\\)) for each i.",
        "Basically we replace d(ui) by a(v) for each i.",
        "In case weight functions are composed of semiring operations, as in shortest paths (+) or probabilistic grammars (x), this definition makes sense, but for general weight functions there should be some formal requirements to make the definition sound.",
        "However, this topic is beyond the scope of this paper."
      ]
    },
    {
      "heading": "6. Extensions and Discussions",
      "text": [
        "In most of the above we focus on optimization problems where one aims to find the best solution.",
        "Here we consider two extensions of this scheme: non-optimization problems where the goal is often to compute the summation or closure, and k-best problems where one also searches for the 2nd, 3rd, through fcth-best solutions.",
        "Both extensions have many applications in NLP.",
        "For the former, algorithms based on the Inside semiring (Table 1), including the forward-backward algorithm (Baum, 1972) and Inside-Outside algorithm (Baker, 1979; Lari and Young, 1990) are widely used for unsupervised training with the EM algorithm (Dempster et al., 1977).",
        "For the latter, since NLP is often a pipeline of several modules, where the 1-best solution from one module might not be the best input for the next module, and one prefers to postpone disambiguation by propogating a fc-best list of candidates (Collins, 2000; Gildea and Jurafsky, 2002; Charniak and Johnson, 2005; Huang and Chiang, 2005).",
        "The fc-best list is also frequently used in discriminative learning to approximate the whole set of candidates which is usually exponentially large (Och, 2003; McDonald et al., 2005).",
        "We know that in optimization problems, the criteria for using dynamic programming is monotonicity (definitions 6 and 16).",
        "But in non-optimization problems, since there is no comparison, this criteria is no longer applicable.",
        "Then when can we apply dynamic programming to a non-optimization problem?",
        "Cormen et al. (1990) develop a more general criteria of closed semiring where © is idempotent and infinite sums are well-defined and present a more sophisticated algorithm that can be proved to work for all closed semirings.",
        "This definition is still not general enough since many non-optimization semirings including the Inside semiring are not even idempotent.",
        "Mohri (2002) solves this problem by a slightly different definition of closedness which does not assume idempotence.",
        "His generic single-source algorithm subsumes many classical algorithms like Dijkstra, Bellman-Ford (Bellman, 1958), and Viterbi as specific instances.",
        "It remains an open problem how to extend the closedness definition to the case of weight functions in hypergraphs.",
        "The straightforward extension from 1-best to fc-best is to simply replace the old semiring (A,©,®, 0,1) by its fc-best version (Ak, ©fc, ®fc, 0k, lk) where each element is now a vector of length k, with the ith component represent the ith-best value.",
        "Since © is a comparison, we can define ©fc to be the top-fc elements of the 2k elements from the two vectors, and ®fc the top-fc elements of the k elements from the crossproduct of two vectors:",
        "where ®'k returns the ordered list of the top-fc elements in a set.",
        "A similar construction is obvious for the weight functions in hypergraphs.",
        "Now we can reuse the 1-best Viterbi Algorithm to solve the fc-best problem in a generic way, as is done in (Mohri, 2002).",
        "However, some more sophisticated techniques that breaks the modularity of semirings results in much faster fc-best algorithms.",
        "For example, the Recursive Enumeration Algorithm (REA) (Jimenez and Marzal, 1999) uses a lazy computation method on top of the Viterbi algorithm to efficiently compute the ith-best solution based on the 1st, 2nd, (i – l)th solutions.",
        "A simple fc-best Dijkstra algorithm is described in (Mohri and Riley, 2002).",
        "For the hypergraph case, the REA algorithm has been adapted for fc-best derivations (Jimenez and Marzal, 2000; Huang and Chiang, 2005).",
        "Applications of this algorithm include fc-best parsing (McDonald et al., 2005; Mohri and Roark, 2006) and machine translation (Chiang, 2007).",
        "It is also implemented as part of Dyna (Eisner et al., 2005), a generic langauge for dynamic programming.",
        "The fc-best extension of the Knuth Algorithm is studied by Huang (2005).",
        "A separate problem, fc-shortest hyperpaths, has been studied by Nielsen et al.",
        "(2005).",
        "Eppstein (2001) compiles an annotated bibliography for fc-shortest-path and other related fc-best problems."
      ]
    },
    {
      "heading": "7. Conclusion",
      "text": [
        "This report surveys two frameworks for formalizing dynamic programming and presents two important classes of DP algorithms under these frameworks.",
        "We focused on 1-best optimization problems but also discussed other scenarios like non-optimization problems and fc-best solutions.",
        "We believe that a better understanding of the theoretical foundations of DP is benefitial for NLP researchers."
      ]
    }
  ]
}
