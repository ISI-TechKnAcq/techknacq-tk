{
  "info": {
    "authors": [
      "Arjen Poutsma"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C00-2092",
    "title": "Data-Oriented Translation",
    "url": "https://aclweb.org/anthology/C00-2092",
    "year": 2000
  },
  "references": [
    "acl-C90-3001",
    "acl-C90-3045",
    "acl-C96-2215",
    "acl-J90-2002"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In this article, we present a statistical approach to machine translation that is based on Data-Oriented Parsing: Data-Oriented Translation (DOT).",
        "In DOT, we use linked subtree pairs for creating a derivation of a source sentence.",
        "Each linked subtree pair has a certain probability, and consists of two trees: one in the source language and one in the target language.",
        "When a derivation has been formed with these subtree pairs, we can create a translation from this derivation.",
        "Since there are typically many different derivations of the same sentence in the source language, there can be as many different translations for it.",
        "The probability of a translation can be calculated as the total probability of all the derivations that form this translation.",
        "We give the computational aspects for this model, show that we can convert each subtree pair into a productive rewrite rule, and that the most probable translation can be computed by means of Monte Carlo disambiguation.",
        "Finally, we discuss some pilot experiments with the Verbmobil corpus."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The Data-Oriented Parsing model has been presented as a promising paradigm for natural language processing (Scha, 1990; Bod, 1995; Bod, 1998).",
        "It has been shown that DOP has the ability to locate syntactic and semantic dependencies, both of which are quite important for machine translation.",
        "We hope that, by basing our model on DOP, we can inherit these advantages, thus obtaining a new and interesting way to perform machine translation.",
        "In section 2, we describe this novel model by identifying its parameters.",
        "In section 3, we describe its computational aspects; in section 4, we discuss some pilot experiments with this model; and finally, in section 5, we give some issues open for future research."
      ]
    },
    {
      "heading": "2 The Data-Oriented Translation Model",
      "text": [
        "In this section, we will give the instantiation of a model that uses DOP for MT purposes, which we will call Data-Oriented Translation (DOT).1 This model is largely based on DOP1 (Bod, 1998, chapt.",
        "2).",
        "In DOT, we use linked subtree pairs as combinational fragments.2 Each linked subtree pair has a certain probability, and consists of a tree in the source language and a tree in the target language.",
        "By combining these fragments to form an an analysis of the source sentence, we automatically generate a translation, i.e. we form a derivation of both source sentence and target sentence.",
        "Since there are typically many different derivations which contain the same source sentence, there can be equally many different translations for it.",
        "The probability of a translation can be calculated as the total probability of all the derivations that form this translation.",
        "The model presented here is capable of translating between two languages only.",
        "This limitation is by no means a property of the model itself, but is chosen for simplicity and readability reasons only.",
        "The following parameters should be specified for a DOP-like approach to MT:",
        "1. the representations of sentences that are assumed, 2. the fragments of these representations that can be used for generating new representations, 3. the operator that is used to combine the fragments to form a translation, and",
        "This is actually the second instantiation of such a framework.",
        "The original model (Poutsma, 1998; Poutsma, 2000) had a major flaw, which resulted in translations that were simply incorrect, as pointed out by Way (1999).",
        "4. the model that is used for determining the probability of a target sentence given a source sentence.",
        "In the explanation that follows, we will use a subscript s to denote an element of the source language, and a subscript t to denote one of the target language."
      ]
    },
    {
      "heading": "2.1 Representations",
      "text": [
        "In DOT, we basically use the same utterance-analysis as in DOP1 (i.e. syntactically labeled phrase structure trees).",
        "To allow for translation capabilities in this model, we will use pairs of trees that incorporate semantic information.",
        "The amount of semantic information need not be very detailed, since all we are interested in is semantic equivalence.",
        "Two trees Ti and T2 are said to be semantic equivalents (denoted as T1 T2) iff T1 can be replaced with T2 without loss of meaning.",
        "We can now introduce the notion of links: a link symbolizes a semantic equivalence between two trees, or part of trees.",
        "It can occur at any level in the tree structure, except for the terminal leve1.3 The representation used in DOT is a 3-tuple (Ts, Ti,o), where Ts is a tree in the source language, T is a tree in the target language, and (I) is a function that maps between semantic equivalent parts in both trees.",
        "In the rest of this article, we will refer to this 3-tuple as the pair (7's, Ti).",
        "Because of the semantic equivalence, a link must exist at the top level of the tree pair (Ti,Ti).",
        "Figure 1. shows an example of two linked trees, the links are depicted graphically as dashed lines."
      ]
    },
    {
      "heading": "2.2 Fragments",
      "text": [
        "Likewise, we will use linked subtrees as our fragments.",
        "Given a pair of linked trees (T„ T1), a linked subtree pair of (Tr, T) consists of two connected and linked subgraphs (4,4) of (7:„ 7;) such that:",
        "1. for every pair of linked nodes in (ts,tt), it holds that: (a) both nodes in (4,4) have either zero daughter nodes, or (b) both nodes have all the daughter nodes of the corresponding nodes in (Ts, 7'1) and 2. every non-linked node in either t,, (or tt) has all the daughter nodes of the corresponding node in Ts (T), and 3. both ts and tt consist of more than one node.",
        "This definition has a number of consequences.",
        "First of all, it is more restrictive than the DOP1 definition for subtrees, thus resulting in a smaller or equal amount of subtrees per tree.",
        "Secondly, it defines a possible pair of linked subtrees.",
        "Typically, there are many pairs of linked subtrees for each set of linked trees.",
        "Thirdly, the linked tree pair itself is also a valid linked subtree pair.",
        "Finally, according to this definition, all the linked subtree pairs are semantic equivalents, since the semantic daughter nodes of the original tree are removed or retained simultaneously (clause 1).",
        "The nodes for which a semantic equivalent does not exist are always retained (clause 2).",
        "We can now define the bag of linked subtree pairs, which we will use as a grammar.",
        "Given a corpus of linked trees C, the bag of linked subtree pairs of C is the bag in which linked subtree pairs occur exactly as often as they can be identified in C.4 Figure 2 show the bag of linked subtree pairs for the linked tree pair (Tx ,T1) ."
      ]
    },
    {
      "heading": "2.3 Composition operator",
      "text": [
        "In DOT, we use the leftmost substitution operator for forming combinations of grammar rules.",
        "The composition of the linked tree pair (4,4) and",
        "(u, tit), written as (tc,tt) 0 (us, at), is defined iff the label of the leftmost nonterminal linked frontier node and the label of its linked counterpart are identical to the labels of the root nodes of (u•, If this composition is defined, it yields a copy of (',„ti), in which a copy of us has been substituted on ts's leftmost nonterminal linked frontier node, and a copy of ut has been substituted on the node's linked counterpart.",
        "The composition operation is illustrated in figure 3.",
        "Given a bag of linked subtree pairs B, a sequence of compositions (ts „ 0 • • • 0 (t„ , tiN), with (ts„tii) E 13 yielding a tree pair (Ts, 7',) without nonterminal leaves is called a derivation D of (7', 7;)."
      ]
    },
    {
      "heading": "2.4 Probability calculation",
      "text": [
        "To compute the probability of the target composition, we make the same statistical assumptions as in DOP1 with regard to independence and representation of the subtrees (Sod, 1998, p. 16).",
        "The probability of selecting a subtree pair (f,, tt) is calculated by dividing the frequency of the subtree pair in the bag by the number of subtrees that have the same root node labels in this bag.",
        "In other words, let.",
        "(1,,tf)1 be the number of times the subtree pair (ts,0 occurs in the bag of subtree pairs, and r(t) be the root node categories of t, then the probability assigned to (1,,t1) is",
        "Given the assumptions that all subtree pairs are independent, the probability of a derivation",
        "The translation generated by a derivation is equal to the sentence yielded by the target trees of the derivation.",
        "Typically, a translation can be generated by a large number of different derivations, each of which has its own probability.",
        "Therefore, the probability of a translation ws w, is the sum of the probabilities of its derivations:",
        "The justification of this last equation is quite trivial.",
        "As in any statistical MT system, we wish to choose the target sentence wt so as to maximize P(wtlws) (Brown et al., 1990, p. 79).",
        "If we take the sum over all possible derivations that were formed from Iv, and derive wt, we can rewrite this as equation 4, as seen below.",
        "Since both w , and wt are contained in D(„,,,„,), we can remove them both and arrive at equation 5, which as we maximize over wt--is equivalent to equation 3 above."
      ]
    },
    {
      "heading": "3 Computational Aspects",
      "text": [
        "When translating using the DOT model, we can distinguish between three computational stages:",
        "1. parsing: the formation of a derivation forest, 2. translation: the transfer of the derivation forest from the source language to the target language, 3. disambiguation: the selection of the most probable translation from the derivation forest."
      ]
    },
    {
      "heading": "3.1 Parsing",
      "text": [
        "In DOT, every subtree pair (4,0 can be seen as a productive rewrite rule: (root(ts), root(4)) -+ (frontier(ts), frontier(4)), where all linkage in the frontier nodes is retained.",
        "The linked non-terminals in the yield constitute the symbol pairs to which new rules (subtree pairs) are applied.",
        "For instance, the rightmost subtree pair in figure 3 can be rewritten as",
        "This rule can then be combined with rules that have the root pair (NP,NP), and so on.",
        "If we only consider the left-side part of this rule, we can use algorithms that exist for context-free grammars, so that we can parse a sentence of n words with a time complexity which is polynomial in n. These algorithms give as output a chart-like derivation forest (Sima'an et al., 1994), which contains the tree pairs of all the derivations that can be formed."
      ]
    },
    {
      "heading": "3.2 Translation",
      "text": [
        "Since every tree pair in the derivation forest contains a tree for the target language, the translation of this forest is trivial."
      ]
    },
    {
      "heading": "3.3 Disambiguation",
      "text": [
        "In order to select the most probable translation, it is not efficient to compare all translations, since there can be exponentially many of them.",
        "Furthermore, it has been shown that the Viterbi algorithm cannot be used to make the most probable selection from a DOP-like derivation forest (Sima'an, 1996).",
        "Instead, we use a random selection method to generate derivations from the target derivation forest, otherwise known as Monte Carlo sampling (Bod, 1998, p. 46-49).",
        "In this method, the random choices of derivations are based on the probabilities of the underlying subderivations.",
        "If we generate a large number of samples, we can estimate the most probable translation as the translation which results most often.",
        "The most probable translation can be estimated as accurately as desired by making the number of random samples sufficiently large."
      ]
    },
    {
      "heading": "4 Pilot Experiments",
      "text": [
        "In order to test the DOT-model, we did some pilot experiments with a small part of the Verbmobil corpus.",
        "This corpus consists of transliterated spoken appointment dialogues in German, English,",
        "and Japanese.",
        "We only used the German and English datasets, which were aligned at sentence level, and syntactically annotated using different annotation schemes.5 Naturally, the tree pairs in the corpus did not contain any links, so in order to make it useful for DOT – we had to analyze each tree pair, and place links where necessary.",
        "We also corrected tree pairs that were not aligned correctly.",
        "Figure 4 shows an example of a corrected and linked tree from our correction of the Verbmobil corpus.",
        "We used a blind testing method, dividing the 266 trees of our corpus into an 85% training set of 226 tree pairs, and a 15% test set of 40 tree pairs.",
        "We carried out three experiments, in both directions, each using a different split of training and test set.",
        "The 226 training set tree pairs were converted into fragments (i.e. subtree pairs), and were enriched with their corpus probabilities.",
        "The 40 sentences from the test set served as input sentences: they were translated with the fragments from the training set using a bottom-up chart parser, and disambiguated by the Monte Carlo algorithm.",
        "The most probable translations were estimated from probability distributions of 1500 sampled derivations, which accounts for a standard deviation 6 < 0.013.",
        "Finally, we compared the resulting translations with the original translation as given in the test set.",
        "We also fed the test sentences into another MT-system: AltaVista's Babelfish, which is based on Systran.6"
      ]
    },
    {
      "heading": "4.1 Evaluation",
      "text": [
        "In a manner similar to (Brown et al., 1990, p. 83), we assigned each of the resulting sentences a category according to the following criteria.",
        "If the produced sentence was exactly the same as the actual Verbmobil translation, we assigned it the exact category.",
        "If it was a legitimate translation of the source sentence but in different words, we assigned it the alternate category.",
        "If it made sense as a sentence, but could not be interpreted as a valid translation of the source sentence, we assigned it the wrong category.",
        "If the translation only yielded a part of the source sentence, we assigned it the partial category: either partial exact if it was a part of the actual Verbmobil translation, or partial alternate if it was part of an alternate translation.",
        "Finally, if no translation",
        "was given, we assigned it the none category.",
        "The results we obtained from Systran were also evaluated using this procedure.",
        "Figure 5 gives some classification examples.",
        "The method of evaluation is very strict: even if our model generated a translation that had a better quality than the given Verbmobil translation, we still assigned it the (partial) alternate category.",
        "This can be seen in the second example in figure 5."
      ]
    },
    {
      "heading": "4.2 Results",
      "text": [
        "The results that we obtained can be seen in table 1 and 2.",
        "In both our experiments, the number of exact translations was somewhat higher than Sys-tran's, but Systran excelled at the number of alternate translations.",
        "This can be explained by the fact that Systran has a much larger lexicon, thus allowing it to form much more alternate translations.",
        "While it is meaningless to compare results obtained from different corpora, it may be interesting to note that Brown et al.",
        "(1990) report a 5% exact match in experiments with the Hansard corpus, indicating that an exact match is very hard to achieve.",
        "The number of ungrammatical translations in our",
        "English to German experiment were much higher than Systran's (32% versus Systran's 19%); vice-versa it was much lower (13% versus Systran's 21%).",
        "Since the German grammar is more complex than the English grammar, this result could be expected.",
        "It is simpler to map a complex grammar to a simpler than vice-versa.",
        "The partial translations, which are quite useful for forming the basis of a post-edited, manual translation, varied around 38% in our English to German experiments, and around 55% when translating from German to English.",
        "Systran is incapable of forming partial translations.",
        "As can be seen from the tables, we experimented with the maximum depth of the tree pairs used.",
        "We expected that the performance of the model would increase when we used deeper subtree pairs, since deeper structures allow for more complex structures, and therefore better translations.",
        "Our experiments showed, however, that there was very little increase of performance as we increased the maximum tree depth.",
        "A possible explanation is that the trees in our corpus contained a lot of lexical context (i.e. terminals) at very small tree depths.",
        "Instead of varying the maximum tree depth, we should experiment with varying the maximum tree width.",
        "We plan to perform such experiments in the future."
      ]
    },
    {
      "heading": "5 Future work",
      "text": [
        "Though the findings presented in this article cover the most important issues regarding DOT, there are still some topics open for future research.",
        "As we stated in the previous section, we wish to see whether DOT's performance increases as we vary the maximum width of a tree.",
        "In the experiments it became clear that DOT lacks a large lexicon, thus resulting in less alternate translations than Systran.",
        "By using an external lexicon, we can form a part-of-speech sequences from the source sentence, and use this sequence as input for DOT.",
        "The resulting target part-of-speech sequence can then be reformed into a target sentence.",
        "The experiments discussed in this article are pilot experiments, and do not account for much.",
        "In order to find more about DOT and its (dis)abilities, more experiments on larger corpora are required."
      ]
    },
    {
      "heading": "6 Conclusion",
      "text": [
        "In this article, we have presented a new approach to machine translation: the Data-Oriented Translation model.",
        "This method uses linked subtree pairs for creating a derivation of a sentence.",
        "Each subtree-pair consists of two trees: one in the source language and one in the target language.",
        "Using these subtree pairs, we can form a derivation of a given source sentence, which can then be used to form a target sentence.",
        "The probability of a translation can",
        "then be calculated as the total probability of all the derivations that form this translation.",
        "The computational aspects of DOT have been discussed, where we introduced a way to reform each subtree pair into a productive rewrite rule so that well-known parsing algorithms can be used.",
        "We determine the best translation by Monte Carlo sampling.",
        "We have discussed the results of some pilot experiments with a part of the Verbmobil corpus, and showed a method of evaluating them.",
        "The evaluation showed that DOT produces less correct translation than Systran, but also less incorrect translations.",
        "We expected to see an increase in performance as we increased the depth of subtree pairs used, but this was not the case.",
        "Finally, we supplied some topics which are open for future research."
      ]
    }
  ]
}
