{
  "info": {
    "authors": [
      "Kazuaki Maeda",
      "Steven Bird",
      "Xiaoyi Ma",
      "Haejoong Lee"
    ],
    "book": "Human Language Technology Conference",
    "id": "acl-H01-1005",
    "title": "The Annotation Graph Toolkit: Software Components for Building Linguistic Annotation Tools",
    "url": "https://aclweb.org/anthology/H01-1005",
    "year": 2001
  },
  "references": [],
  "sections": [
    {
      "heading": "ABSTRACT",
      "text": [
        "Annotation graphs provide an efficient and expressive data model for linguistic annotations of time-series data.",
        "This paper reports progress on a complete software infrastructure supporting the rapid development of tools for transcribing and annotating time-series data.",
        "This general-purpose infrastructure uses annotation graphs as the underlying model, and allows developers to quickly create special-purpose annotation tools using common components.",
        "An application programming interface, an I/O library, and graphical user interfaces are described.",
        "Our experience has shown us that it is a straightforward task to create new special-purpose annotation tools based on this general-purpose infrastructure."
      ]
    },
    {
      "heading": "Keywords",
      "text": []
    },
    {
      "heading": "1. INTRODUCTION",
      "text": [
        "Annotation graphs (AGs) provide an efficient and expressive data model for linguistic annotations of time-series data [2].",
        "This paper reports progress on a complete software infrastructure supporting the rapid development of tools for transcribing and annotating time-series data.",
        "This general-purpose infrastructure uses annotation graphs as the underlying model, and allows developers to quickly create special-purpose annotation tools using common components.",
        "This work is being done in cooperation with the developers of other widely used annotation systems, Transcriber and Emu [1, 3].",
        "The infrastructure is being used in the development of a series of annotation tools at the Linguistic Data Consortium.",
        "Several such tools are shown in the paper: one for dialogue annotation, one for telephone conversation transcription, and one for interlinear transcription aligned to speech.",
        "This paper will cover the following points: the application programming interfaces for manipulating annotation graph data and importing data from other formats; the model of inter-component communication which permits easy reuse of software components; and the design of the graphical user interfaces, which have been tailored to be maximally ergonomic for the tasks.",
        "The project homepage is: [http://www.ldc.upenn.edu/ AG/].",
        "The software tools and software components described in this paper are available through a CVS repository linked from this homepage."
      ]
    },
    {
      "heading": "2. ARCHITECTURE 2.1 General Architecture",
      "text": [
        "Existing annotation tools are based on a two level model (Figure 1 Top).",
        "The systems we demonstrate are based around a three level model, in which annotation graphs provide a logical level independent of application and physical levels (Figure 1 Bottom).",
        "The application level represents special-purpose tools built on top of the general-purpose infrastructure at the logical level.",
        "The system is built from several components which instantiate this model.",
        "Figure 2 shows the architecture of the tools currently being developed.",
        "Annotation tools, such as the ones discussed below, must provide graphical user interface components for signal visualization and annotation.",
        "The communication between components is handled through an extensible event language.",
        "An application programming interface for annotation graphs (AG-API) has been developed to support well-formed operations on annotation graphs.",
        "This permits applications to abstract away from file format issues, and deal with annotations purely at the logical level."
      ]
    },
    {
      "heading": "2.2 The Annotation Graph API",
      "text": [
        "The complete IDL definition of the AG-API is provided in the appendix (also online).",
        "Here we describe a few salient features of the API.",
        "The API provides access to internal objects (signals, anchors, annotations etc) using identifiers.",
        "Identifiers are strings which contain internal structure.",
        "For example, an AG identifier is qualified with an AGSet identifier: AGSetId:AGId.",
        "Annotations and anchors are doubly qualified: AGSetId:AGId:AnnotationId, AGSetId:AGId:AnchorId.",
        "Thus, it is possible to determine from any given identifiers, its membership in the overall data structure.",
        "The functioning of the API will now be illustrated with a series of examples.",
        "Suppose we have already constructed an AG and now wish to create a new anchor.",
        "We might have the following API call: CreateAnchor( \"agSet12:ag5\", 15.234, \"sec\" ); This call would construct a new anchor object and return its identifier: agSet12 : ag5 :anchor34.",
        "Alternatively, if we already .",
        "have an anchor identifier that we wish to use for this new anchor (e.g. because we are reading previously created annotation data from a file and do not wish to assign new identifiers), then we could have the following API call: CreateAnchor( \"agset12:ag5:anchor34\", 15.234, \"sec\" ); This call will return agset12: ag5:anchor34.",
        "Once a pair of anchors have been created it is possible to create an annotation which spans them:",
        "This call will construct an annotation object and return an identifier for it, e.g. agSet12: ag5:annotation41.",
        "We can now add features to this annotation:",
        "The implementation maintains indexes on all the features, and also on the temporal information and graph structure, permitting efficient search using a family of functions such as:"
      ]
    },
    {
      "heading": "2.3 A File I/O Library",
      "text": [
        "A file I/O library (AG-FIO) to support creation and export of AG data has been developed.",
        "This will eventually handle all widely used annotation formats.",
        "Formats currently supported by the AG-FIO library include the TIMIT, BU, Treebank, AIF (ATLAS Interchange Format), Switchboard and BAS Partitur formats."
      ]
    },
    {
      "heading": "2.4 Inter-component Communication",
      "text": [
        "Figure 3 shows the structure of an annotation tool in terms of components and their intercommunications.",
        "The main program is typically a small script which sets up the widgets and provides callback functions to handle widget events.",
        "In this example there are four other components which are reused by several annotation tools.",
        "The AG and AG-FIO components have already been described.",
        "The waveform display component (of which there may be multiple instances) receives instructions to pan and zoom, to play a segment of audio data, and so on.",
        "The transcription editor is an annotation component which is specialized for",
        "a particular coding task.",
        "Most tool customization is accomplished by substituting for this component.",
        "Both GUI components and the main program support a common API for transmitting and receiving events.",
        "For example, GUI components have a notion of a “current region” – the timespan which is currently in focus.",
        "A waveform component can change an annotation component’s idea of the current region by sending a SetRegion event (Figure 4).",
        "The same event can also be used in the reverse direction.",
        "The main program routes the events between GUI components, calling the AG-API to update the internal representation as needed.",
        "With this communication mechanism, it is a straightforward task to add new commands, specific to the annotation task."
      ]
    },
    {
      "heading": "2.5 Reuse of Software Components",
      "text": [
        "The architecture described in this paper allows rapid development of special-purpose annotation tools using common components.",
        "In particular, our model of inter-component communication facilitates reuse of software components.",
        "The annotation tools described in the next section are not intended for general purpose annotation/transcription tasks; the goal is not to create an “emacs for linguistic annotation”.",
        "Instead, they are special-purpose tools based on the general purpose infrastructure.",
        "These GUI components can be modified or replaced when building new special-purpose tools."
      ]
    },
    {
      "heading": "3. GRAPHICAL USER INTERFACES",
      "text": []
    },
    {
      "heading": "3.1 A Spreadsheet Component",
      "text": [
        "The first of the annotation/transcription editor components we describe is a spreadsheet component.",
        "In this section, we show two tools that use the spreadsheet component: a dialogue annotation tool and a telephone conversation transcription tool.",
        "Dialogue annotation consists of assigning a field-structured record to each utterance in each speaker turn.",
        "A key challenge is to handle overlapping speaker turns and back-channel cues without disrupting the structure of individual speaker contributions.",
        "The tool solves these problems and permits annotations to be aligned to a (multi-channel) recording.",
        "The records are displayed in a spreadsheet.",
        "Clicking on a row of the spreadsheet causes the corresponding extent of audio signal to be highlighted.",
        "As an extended recording is played back, annotated sections are highlighted (both waveform and spreadsheet displays).",
        "Figure 5 shows the tool with a section of the TRAINS/DAMSL corpus [4].",
        "Figure 6 shows another tool designed for transcribing telephone conversations.",
        "This latter tool is a version of the dialogue annotation tool, with the columns changed to accommodate the needed fields: in this case, speaker turns and transcriptions.",
        "Both of these tools are for two-channel audio files.",
        "The audio channel corresponding to the highlighted annotation in the spreadsheet is also highlighted."
      ]
    },
    {
      "heading": "3.2 An Interlinear Transcription Component",
      "text": [
        "Interlinear text is a kind of text in which each word is annotated with phonological, morphological and syntactic information (displayed under the word) and each sentence is annotated with a free translation.",
        "Our tool permits interlinear transcription aligned to a primary audio signal, for greater accuracy and accountability.",
        "Whole words and sub-parts of words can be easily aligned with the audio.",
        "Clicking on a piece of the annotation causes the corresponding extent of audio signal to be highlighted.",
        "As an extended recording is played back, annotated sections are highlighted (both waveform and interlinear text displays).",
        "The following screenshot shows the tool with some interlinear text from Mawu (a Manding language of the Ivory Coast, West Africa)."
      ]
    },
    {
      "heading": "3.3 A Waveform Display Component",
      "text": [
        "The tools described above utilize WaveSurfer and Snack developed by K˚are Sj¨olander and Jonas Beskow [7, 8].",
        "WaveSurfer allows developers to specify event callbacks through a plug-in architecture.",
        "We have developed a plug-in for WaveSurfer that enables the inter-component communication described in this paper.",
        "In addition to waveforms, it is also possible to show spectrograms and pitch contours of a speech file if the given annotation task requires phonetic analysis of the speech data."
      ]
    },
    {
      "heading": "4. FUTURE WORK",
      "text": []
    },
    {
      "heading": "4.1 More GUI Components",
      "text": [
        "In addition to the software components discussed in this paper, we plan to develop more components to support various annotation tasks.",
        "For example, a video component is being developed, and it will have an associated editor for gestural coding.",
        "GUI components for Conversation Analysis (CA) [6] and CHAT [5] are also planned."
      ]
    },
    {
      "heading": "4.2 An Annotation Graph Server",
      "text": [
        "We are presently designing a client-side component which presents the same AG-API to the annotation tool, but translates all calls",
        "typedef string MimeClass; // the MIME class typedef string MimeType; // the MIME type typedef string Encoding; // the signal encoding typedef string Unit; // the unit for offsets typedef string AnnotationRef; // an annotation reference typedef float Offset; // the offset into a signal"
      ]
    },
    {
      "heading": "4.3 Timeline for Development",
      "text": [
        "A general distribution (Version 1.0) of the tools is planned for the early summer, 2001.",
        "Additional components and various improvements will be added to future releases.",
        "Source code will be available through a source code distribution service, SourceForge ([http://sourceforge.net/projects/agtk/]).Further schedule for updates will be posted on our web site: [http: //www.ldc.upenn.edu/AG/]."
      ]
    },
    {
      "heading": "5. CONCLUSION",
      "text": [
        "This paper has described a comprehensive infrastructure for developing annotation tools based on annotation graphs.",
        "Our experience has shown us that it is a simple matter to construct new special-purpose annotation tools using high-level software components.",
        "The tools can be quickly created and deployed, and replaced by new versions as annotation tasks evolve.",
        "The components and tools reported here are all being made available under an open source license."
      ]
    },
    {
      "heading": "6. ACKNOWLEDGMENT",
      "text": [
        "This material is based upon work supported by the National Science Foundation under Grant No.",
        "9978056 and 9983258."
      ]
    },
    {
      "heading": "7. REFERENCES",
      "text": []
    }
  ]
}
