{
  "info": {
    "authors": [
      "Keisuke Sakaguchi",
      "Yuki Arase",
      "Mamoru Komachi"
    ],
    "book": "ACL",
    "id": "acl-P13-2043",
    "title": "Discriminative Approach to Fill-in-the-Blank Quiz Generation for Language Learners",
    "url": "https://aclweb.org/anthology/P13-2043",
    "year": 2013
  },
  "references": [
    "acl-D11-1010",
    "acl-W05-0201",
    "acl-W05-0203",
    "acl-W05-0210"
  ],
  "sections": [
    {
      "text": [
        "where (a) blaming is the answer and (b) accusing is a distractor.",
        "There are previous studies on distractor generation for automatic fill-in-the-blank quiz generation (Mitkov et al., 2006).",
        "Hoshino and Nakagawa (2005) randomly selected distractors from words in the same document.",
        "Sumita et al. (2005) used an English thesaurus to generate distractors.",
        "Liu et al.",
        "(2005) collected distractor candidates that are close to the answer in terms of word-frequency, and ranked them by an association/collocation measure between the candidate and surrounding words in a given context.",
        "Dahlmeier and Ng (2011) generated candidates for collocation error correction for English as a Second Language (ESL) writing using paraphrasing with native language (L1) pivoting technique.",
        "This method takes an sentence containing a collocation error as input and translates it into L1, and then translate it back to English to generate correction candidates.",
        "Although the purpose is different, the technique is also applicable for distractor generation.",
        "To our best knowledge, there have not been studies that fully employed actual errors made by ESL learners for distractor generation.",
        "In this paper, we propose automated distractor generation methods using a large-scale ESL corpus with a discriminative model.",
        "We focus on semantically confusing distractors that measure learners?",
        "competence to distinguish word-sense and select an appropriate word.",
        "We especially target verbs, because verbs are difficult for language learners to use correctly (Leacock et al., 2010).",
        "Our proposed methods use discriminative models238",
        "and error tags (Replacement, Deletion and Insertion).",
        "trained on error patterns extracted from an ESL corpus, and can generate exclusive distractors with taking context of a given sentence into consideration.",
        "We conduct human evaluation using 3 native and 23 non-native speakers of English.",
        "The result shows that 98.3% of distractors generated by our methods are reliable.",
        "Furthermore, the non-native speakers?",
        "performance on quiz generated by our method has about 0.76 of correlation coefficient with their TOEIC scores, which shows that distractors generated by our methods satisfy validity.",
        "Contributions of this paper are twofold; (1) we present methods for generating reliable and valid distractors, (2) we also demonstrate the effectiveness of ESL corpus and discriminative models on distractor generation."
      ]
    },
    {
      "heading": "2 Proposed Method",
      "text": [
        "To generate distractors, we first need to decide which word to be blanked.",
        "We then generate candidates of distractors and rank them based on a certain criterion to select distractors to output.",
        "In this section, we propose our methods for extracting target words from ESL corpus and selecting distractors by a discriminative model that considers long-distance context of a given sentence."
      ]
    },
    {
      "heading": "2.1 Error-Correction Pair Extraction",
      "text": [
        "We use the Lang-8 Corpus of Learner English3 as a large-scale ESL corpus, which consists of 1.2M sentence correction pairs.",
        "For generating semantic distractors, we regard a correction as a target and the misused word as one of the distractor candidates.",
        "In the Lang-8 corpus, there is no clue to align the original and corrected words.",
        "In addition, words may be deleted and inserted in the corrected sentence, which makes the alignment difficult.",
        "Therefore, we detect word deletion, insertion, and replacement by dynamic programming4.",
        "We com",
        "tracted from a sentence: Each side, government and opposition, is *accusing/blaming the other for the political crisis, and for the violence.",
        "pare a corrected sentence against its original sentence, and when word insertion and deletion errors are identified, we put a spaceholder (Figure 2).",
        "We then extract error-correction (i.e. replacement) pairs by comparing trigrams around the replacement in the original and corrected sentences, for considering surrounding context of the target.",
        "These error-correction pairs are a mixture of grammatical mistakes, spelling errors, and semantic confusions.",
        "Therefore, we identify pairs due to semantic confusion; we exclude grammatical error corrections by eliminating pairs whose error and correction have different part-of-speech (POS)5, and exclude spelling error corrections based on edit-distance.",
        "As a result, we extract 689 unique verbs (lemma) and 3,885 correction pairs in total.",
        "Using the error-correction pairs, we calculate conditional probabilities P (we|wc), which represent how probable that ESL learners misuse the word wc as we.",
        "Based on the probabilities, we compute a confusion matrix.",
        "The confusion matrix can generate distractors reflecting error patterns of ESL learners.",
        "Given a sentence, we identify verbs appearing in the confusion matrix and make them blank, then outputs distractor candidates that have high confusion probability.",
        "We rank the candidates by a generative model to consider the surrounding context (e.g. N-gram).",
        "We refer to this generative method as Confusion-matrix Method (CFM)."
      ]
    },
    {
      "heading": "2.2 Discriminative Model for Distractor Generation and Selection",
      "text": [
        "To generate distractors that considers long-distance context and reflects detailed syntactic information of the sentence, we train multiple classifiers for each target word using error-correction pairs extracted from ESL corpus.",
        "A classifier for 5Because the Lang-8 corpus does not have POS tags, we assign POS by the NLTK (http://nltk.org/) toolkit.239 a target word takes a sentence (in which the target word appears) as an input and outputs a verb as the best distractor given the context using following features: 5-gram (?1 and ?2 words of the target) lemmas and dependency type with the target child (lemma).",
        "The dependent is normalized when it is a pronoun, date, time, or number (e.g. he ?",
        "#PRP#) to avoid making feature space sparse.",
        "Table 1 shows an example of features and a class label for the classifier of a target verb (blame).",
        "These classifiers are based on a discriminative model: Support Vector Machine (SVM)6 (Vapnik, 1995).",
        "We propose two methods for training the classifiers.",
        "First, we directly use the corrected sentences in the Lang-8 corpus.",
        "As shown in Table 1, we use the 5-gram and dependency features7, and use the original word (misused word by ESL learners) as a class.",
        "We refer to this method as DiscESL.",
        "Second, we train classifiers with an ESL-simulated native corpus, because (1) the number of sentences containing a certain error-correction pair is still limited in the ESL corpus and (2) corrected sentences are still difficult to parse correctly due to inherent noise in the Lang-8 corpus.",
        "Specifically, we use articles collected from Voice of America (VOA) Learning English8, which consist of 270k sentences.",
        "For each target in a given sentence, we artificially change the target into an incorrect word according to the error probabilities obtained from the learners confusion matrix explained in Section 2.2.",
        "In order to collect a sufficient amount of training data, we generate 100 samples for each training sentence in which the target word is replaced into an erroneous word.",
        "We refer to this method as DiscSimESL9."
      ]
    },
    {
      "heading": "3 Evaluation with Native-Speakers",
      "text": [
        "In this experiment, we evaluate the reliability of generated distractors.",
        "The authors asked the help of 3 native speakers of English (1 male and 2 females, majoring computer science) from an author's graduate school.",
        "We provide each participant a gift card of $30 as a compensation when completing the task.",
        "tive model with ESL corpus, DiscSimESL: Discriminative model with simulated ESL corpus) and baseline (THM: Thesaurus Method, RTM: Roundtrip Method).",
        "In order to compare distractors generated by different methods, we ask participants to solve the generated fill-in-the-blank quiz presented in Figure 1.",
        "Each quiz has 3 options: (a) only word A is correct, (b) only word B is correct, (c) both are correct.",
        "The source sentences to generate a quiz are collected from VOA, which are not included in the training dataset of the DiscSimESL.",
        "We generate 50 quizzes using different sentences per each method to avoid showing the same sentence multiple times to participants.",
        "We randomly ordered the quizzes generated by different methods for fair comparison.",
        "We compare the proposed methods to two baselines implementing previous studies: Thesaurus-based Method (THM) and Roundtrip Translation Method (RTM).",
        "Table 2 shows a summary of each method.",
        "The THM is based on (Sumita et al., 2005) and extract distractor candidates from synonyms of the target extracted from WordNet10.",
        "The RTM is based on (Dahlmeier and Ng, 2011) and extracts distractor candidates from roundtrip (pivoting) translation lexicon constructed from the WIT3 corpus (Cettolo et al., 2012)11, which covers a wide variety of topics.",
        "We build English-Japanese and Japanese-English word-based translation tables using GIZA++ (IBM Model4).",
        "In this dictionary, the target word is translated into Japanese words and they are translated back to English as distractor candidates.",
        "To consider (local) context, the candidates generated by the THM, RTM, and CFM are re-ranked by 5-gram language",
        "with a 95% confidence interval and inter-rater agreement statistics ?.",
        "model score trained on Google 1T Web Corpus (Brants and Franz, 2006) with IRSTLM toolkit12.",
        "As an evaluation metric, we compute the ratio of appropriate distractors (RAD) by the following equation: RAD = NAD/NALL, where NALL is the total number of quizzes and NAD is the number of quizzes on which more than or equal to 2 participants agree by selecting the correct answer.",
        "When at least 2 participants select the option (c) (both options are correct), we determine the distractor as inappropriate.",
        "We also compute the average of inter-rater agreement ?",
        "among all participants for each method.",
        "Table 3 shows the results of the first experiment; RAD with a 95% confidence interval and inter-rater agreement ?.",
        "All of our proposed methods outperform baselines regarding RAD with high inter-rater agreement.",
        "In particular, DiscSimESL achieves 9.0% and 4.7% higher RAD than THM and RTM, respectively.",
        "These results show that the effectiveness of using ESL corpus to generate reliable distractors.",
        "With respect to ?, our discriminative models achieve from 0.12 to 0.2 higher agreement than baselines, indicating that the discriminative models can generate sound distractors more effectively than generative models.",
        "The lower ?",
        "on generative models may be because the distractors are semantically too close to the target (correct answer) as following examples: The coalition has *published/issued a report saying that ... .",
        "As a result, the quiz from generative models is not reliable since both published and issued are correct."
      ]
    },
    {
      "heading": "4 Evaluation with ESL Learners",
      "text": [
        "In this experiment, we evaluate the validity of generated distractors regarding ESL learners?",
        "profi",
        "ticipants?",
        "TOEIC scores, (2) the average percentage of correct answer (Corr), incorrect answer of distractor (Dist), and incorrect answer that both are correct (Both) chosen by participants, and (3) standard deviation (Std) of Corr.",
        "males and 8 females) are participated.",
        "All the participants, who have taken at least 8 years of English education, self-report proficiency levels as the TOEIC scores from 380 to 99013.",
        "All the participants are graduate students majoring in science related courses.",
        "We call for participants by emailing to a graduate school.",
        "We provide each participant a gift card of $10 as a compensation when completing the task.",
        "We ask participants to solve 20 quizzes per each method in the same manner as Section 3.",
        "To evaluate validity of distractors, we use only reliable quizzes accepted in Section 3.",
        "Namely, we exclude quizzes whose options are both correct.",
        "We evaluate correlation between learners?",
        "accuracy for the generated quizzes and the TOEIC score.",
        "Table 4 represents the results; the highest corre-13The official score range of the TOEIC is from 10 to 990.241 lation coefficient r and standard deviation on DiscSimESL shows that its distractors achieve best validity.",
        "Figure 3 depicts the correlations between the participants?",
        "TOEIC scores and accuracy (i.e.",
        "Corr.)",
        "on THM and DiscSimESL.",
        "It illustrates that DiscSimESL achieves higher level of positive correlation than THM.",
        "Table 4 also shows high percentage of choosing ?",
        "(c) both are correct?",
        "on DiscSimESL, which indicates that distractors generated from DiscSimESL are difficult to distinguish for ESL learners but not for native speakers as a following example: ..., she found herself on stage ... *playing/performing a number one hit.",
        "A relatively lower correlation coefficient on DiscESLmay be caused by inherent noise on parsing the Lang-8 corpus and domain difference from quiz sentences (VOA)."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "We have presented methods that automatically generate semantic distractors of a fill-in-the-blank quiz for ESL learners.",
        "The proposed methods employ discriminative models trained using error patterns extracted from ESL corpus and can generate reliable distractors by taking context of a given sentence into consideration.",
        "The human evaluation shows that 98.3% of distractors are reliable when generated by our method (DiscSimESL).",
        "The results also demonstrate 0.76 of correlation coefficient to their TOEIC scores, indicating that the distractors have better validity than previous methods.",
        "As future work, we plan to extend our methods for other POS, such as adjective and noun.",
        "Moreover, we will take ESL learners?",
        "proficiency into account for generating distractors of appropriate levels for different learners."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was supported by the Microsoft Research Collaborative Research (CORE) Projects.",
        "We are grateful to Yangyang Xi for granting permission to use text from Lang-8 and Takuya Fujino for his error pair extraction algorithm.",
        "We would also thank anonymous reviewers for valuable comments and suggestions."
      ]
    }
  ]
}
