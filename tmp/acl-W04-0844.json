{
  "info": {
    "authors": [
      "Roberto Navigli",
      "Paola Velardi"
    ],
    "book": "SENSEVAL International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",
    "id": "acl-W04-0844",
    "title": "Structural Semantic Interconnection: A Knowledge-Based Approach to Word Sense Disambiguation",
    "url": "https://aclweb.org/anthology/W04-0844",
    "year": 2004
  },
  "references": [],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "In this paper we describe the SSI algorithm, a structural pattern matching algorithm for WSD.",
        "The algorithm has been applied to the gloss disambiguation task of Senseval-3."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Our approach to WSD lies in the structural pattern recognition framework.",
        "Structural or syntactic pattern recognition (Bunke and Sanfeliu, 1990) has proven to be effective when the objects to be classified contain an inherent, identifiable organization, such as image data and time-series data.",
        "For these objects, a representation based on a flat ctor f atures uses ss of information that negatively impacts on classification performances.",
        "Word senses clearly fall under the category of objects that are better described through a set of structured features.",
        "The classification task in a structural pattern recognition system is implemented through the use of grammars that embody precise criteria to discriminate among different classes.",
        "Learning a structure for the objects to be classified is often a major problem in many application areas of structural pattern recognition.",
        "In the field of computational linguistics, however, several efforts have been made in the past years to produce large lexical knowledge bases and annotated resources, offering an ideal starting point for constructing structured representations of word senses.",
        "2 Building structural representations of word senses We build a structural representation of word senses using a variety of knowledge sources, i.e. WordNet, Domain Labels (Magnini and Cavaglia, 2000), annotated corpora like SemCor and LDC"
      ]
    },
    {
      "heading": "Paola VELARDI",
      "text": [
        "Dipartimento di Informatica, Università di Roma La Sapienza Via Salaria, 113 - 00198 Roma, Italy velardi@di.uniroma1.it generate labeled directed graphs (digraphs) representations of word senses.",
        "We call these semantic graphs, since they represent alternative conceptualizations for a lexical item.",
        "Figure 1 shows an example of the semantic graph generated for senses #1 of market, where nodes represent concepts (WordNet synsets), and edges are semantic relations.",
        "In each graph, we include only nodes with a maximum distance of 3 from the central node, as suggested by the dashed oval in Figure 1.",
        "This distance has been experimentally established.",
        "All the used semantic relations are explicitly encoded in WordNet, except for three relations named topic, gloss and domain, extracted respectively from annotated corpora, sense definitions and domain labels."
      ]
    },
    {
      "heading": "3 Summary description of the SSI algorithm",
      "text": [
        "The SSI algorithm consists of an initialization step and an iterative step.",
        "In a generic iteration of the algorithm the input is a list of co-occurring terms T = [ t1, , tn ] and a list of associated senses I = [St1,..., Stn ], i.e. the semantic interpretation of T, where Sti 2 is either the chosen sense for ti (i.e., the result of a previous 2 Note that with V we refer interchangeably to the semantic graph associated with a sense or to the sense name.",
        "disambiguation step) or the empty set (i.e., the term is not yet disambiguated).",
        "A set of pending terms is also maintained, P = { |ti I Sti = 0 }.",
        "I is named the semantic context of T and is used, at each step, to disambiguate new terms in P. The algorithm works in an iterative way, so that at each stage either at least one term is removed from P (i.e., at least a pending term is disambiguated) or the procedure stops because no more terms can be disambiguated.",
        "The output is the updated list I of senses associated with the input terms T. Initially, the list I includes the senses of monosemous terms in T. If no monosemous terms are found, the algorithm makes an initial guess based on the most probable sense of the less ambiguous term.",
        "The initialisation policy is adjusted depending upon the specific WSD task considered.",
        "Section 5 describes the policy adopted for the task of gloss disambiguation in WordNet.",
        "During a generic iteration, the algorithm selects those terms t in P showing an interconnection between at least one sense S of t and one or more senses in I.",
        "The likelihood for a sense S of being the correct interpretation of t, given the semantic context I, is estimated by the function fI : CxT – > 91, where C is the set of all the concepts in the ontology O, defined as follows:",
        "where Senses(t) is the subset of concepts C in O associated with the term t, and",
        "i.e. a function (p) of the weights (w) of each path connecting S with S, where S and S are represented by semantic graphs.",
        "A semantic path een between two senses S and S', S – > e2S1 – >... e – >n_1 Sn_1 – >S', is represented by a sequence of edge labels e1 • e2•...• en .",
        "A proper choice for both p and p may be the sum function (or the average sum function).",
        "A context-free grammar G = (E, N, SG, PG) encodes all the meaningful semantic patterns.",
        "The terminal symbols (E) are edge labels, while the non-terminal symbols (N) encode (sub)paths between concepts; SG is the start symbol of G and PG the set of its productions.",
        "We associate a weight with each production A – > a in PG, where A e N and a e (N u E) * , i.e. a is a sequence of terminal and non-terminal symbols.",
        "If the sequence of edge labels e1 • e2 • ... • en belongs to L(G), the language generated by the grammar, and provided that G is not ambiguous, then w(e1•e2• ... • en) is given by the sum of the weights of the productions applied in the derivation SG =>+ e1 • e2 • ... • en .",
        "The grammar G is described in the next section.",
        "Finally, the algorithm selects arg max fI (S, t) as"
      ]
    },
    {
      "heading": "Se C",
      "text": [
        "the most likely interpretation of t and updates the list I with the chosen concept.",
        "A threshold can be applied to f(S,t) to improve the robustness of systems choices.",
        "At the end of a generic iteration, a number of terms is disambiguated and each of them is removed from the set of pending terms P. The algorithm stops with output I when no sense S can be found for the remaining terms in P such that fI (S, t) > 0, that is, P cannot be further reduced.",
        "In each iteration, interconnections can only be found between the sense of a pending term t and the senses disambiguated during the previous iteration.",
        "A special case of input for the SSI algorithm is given by I=[0,0, ...,0], that is when no initial semantic context is available (there are no monosemous words in T).",
        "In this case, an initialization policy selects a term t e T and the execution is forked into as many processes as the number of senses of t."
      ]
    },
    {
      "heading": "4 The grammar",
      "text": [
        "The grammar G has the purpose of describing meaningful interconnecting patterns among semantic graphs representing conceptualisations in O.",
        "We define a pattern as a sequence of consecutive semantic relations e1• e2 •...• en where ei e E, the set of terminal symbols, i.e. the vocabulary of conceptual relations in O.",
        "Two relations ei ei+1 are consecutive if the edges labelled with ei and ei+1 are incoming and/or outgoing from the same concept node, that is �(S)-, <_(S)-,�(S)<, <-(S)� .",
        "A meaningful pattern between two senses S and S is a sequence",
        "In its current version, the grammar G has been defined manually, inspecting the intersecting patterns automatically extracted from pairs of manually disambiguated word senses co-occurring in different domains.",
        "Some of the rules in G are inspired by previous work on the eXtended WordNet project described in (Milhalcea and Moldovan, 2001).",
        "The terminal symbols ei are the conceptual relations extracted from WordNet and other on-line lexical-semantic resources, as described in Section 2.",
        "by the sum of the weights of the productions applied in the derivation SG =>' e1 • e2 • .. .",
        "• en.",
        "These weights have been learned using a perceptron model, trained with standard word sense disambiguation data, such as the SemCor corpus.",
        "Examples of the rules in G are provided in the subsequent Section 5.",
        "5 Application of the SSI algorithm to the disambiguation of WordNet glosses For the gloss disambiguation task, the SSI algorithm is initialized as follows: In step 1, the list I includes the synset S whose gloss we wish to disambiguate, and the list P includes all the terms in the gloss and in the gloss of the hyperonym of S. Words in the hyperonyms gloss are useful o augment the context available for disambiguation.",
        "In the following, we present a sample execution of the SSI algorithm for the gloss disambiguation task applied to sense #1 of retrospective: an exhibition of a representative selection of an artists ife workFor this task the algorithm uses a context enriched with the definition of the synset hyperonym, i.e. art exhibition#]: an exhibition of art objects (paintings or statues) Initially we have:",
        "At first, I is enriched with the senses of monosemous words in the definition of retrospective#1 and its hyperonym:",
        "since statue and artist are monosemous terms in WordNet.",
        "During the first iteration, the algorithm finds three matching paths4:",
        "During the second iteration, a hyponymy/holonymy path (rule S2) is found: painting#] (painting is a kind of art)which leads to:",
        "The third iteration finds a co-occurrence (topic rule) path between artist#] and sense 12 of life (biography, life history):",
        "The algorithm stops because no additional matches are found.",
        "The chosen senses concerning terms contained in the hyperonyms gloss were of help during disambiguation, but are now discarded.",
        "Thus we have:"
      ]
    },
    {
      "heading": "6 Evaluation",
      "text": [
        "The SSI algorithm is currently tailored for noun disambiguation.",
        "Additional semantic knowledge and ad-hoc rules would be needed to detect semantic patterns centered on concepts associated to verbs.",
        "Current research is directed towards integrating in semantic graphs information from FrameNet and VerbNet, but the main problem is harmonizing these knowledge bases with WordNets enses and elations nventory.",
        "A second problem of SSI, when applied to unrestricted WSD tasks, is that it is designed to disambiguate with high precision, possibly low recall.",
        "In many interesting applications of WSD, especially in information retrieval, improved document access may be obtained even when only few words in a query are disambiguated, but the disambiguation precision needs to be well over the 70% threshold.",
        "Supporting experiments are described in (Navigli and Velardi, 2003).",
        "The results obtained by our system in Senseval3 reflect these limitations (see Figure 2).",
        "The main run, named OntoLearn, uses a threshold to select only those senses with a weight",
        "over a given threshold.",
        "OntoLearnEx uses a non-greedy version of the SSI algorithm.",
        "Again, a threshold is used to accepts or reject sense choices.",
        "Finally, OntoLearnB uses the first senseheuristics to elect a sense, very since aa sense choice is below the threshold (or no patterns are found for a given word).",
        "Table 1 shows the precision and recall of OntoLearn main run by syntactic category.",
        "It shows that, as expected, the SSI algorithm is currently tuned for noun disambiguation.",
        "The official Senseval-3 evaluation has been performed against a set of so called golden glossesproduced by Dan Moldovan nd ts group5.",
        "This test set however had several problems, that we partly detected and submitted to the organisers.",
        "Besides some technical errors in the data set (presence of WordNet 1.7 and 2.0 senses, missing glosses, etc.)",
        "there are sense-tagging inconsistencies that are very evident.",
        "For example, one of our highest performing sense tagging rules in SSI is the direct hyperonymy path.",
        "This rule reads as follows: if the word wj appears in the gloss of a synset Si, and if one of the synsets of wj, Sj, is the direct hyperonym of Si, then, select Sj as the correct sense for wj",
        "therefore we select sense #5 of patronage, while Moldovans goldensense is #1 #1.",
        "We do not intend to dispute whether the questionable nse signment e ne provided in the golden gloss or rather the hyperonym selected by the WordNet lexicographers.",
        "In any case, the detected patterns show a clear inconsistency in the data.",
        "These patterns (313) have been submitted to the organisers, who then decided to remove them from the data set."
      ]
    },
    {
      "heading": "7 Conclusion",
      "text": [
        "The interesting feature of the SSI algorithm, unlike many co-occurrence based and statistical approaches to WSD, is a justification (i.e. a set of semantic patterns) to support a sense choice.",
        "Furthermore, each sense choice has a weight representing the confidence of the system in its output.",
        "Therefore SSI can be tuned for high precision (possibly low recall), an asset that we consider more realistic for practical WSD applications.",
        "Currently, the system is tuned for noun disambiguation, since we build structural representations of word senses using lexical knowledge bases that are considerably richer for nouns.",
        "Extending semantic graphs associated to verbs and adding appropriate interconnection rules implies harmonizing WordNet and available lexical resources for verbs, e.g. FrameNet and VerbNet.",
        "This extension is in progress."
      ]
    }
  ]
}
