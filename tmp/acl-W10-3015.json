{
  "info": {
    "authors": [
      "Huiwei Zhou",
      "Xiaoyan Li",
      "Degen Huang",
      "Zezhong Li",
      "Yuansheng Yang"
    ],
    "book": "Proceedings of the Fourteenth Conference on Computational Natural Language Learning",
    "id": "acl-W10-3015",
    "title": "Exploiting Multi-Features to Detect Hedges and their Scope in Biomedical Texts",
    "url": "https://aclweb.org/anthology/W10-3015",
    "year": 2010
  },
  "references": [
    "acl-P03-1054",
    "acl-P07-1125",
    "acl-P08-1033",
    "acl-P09-2044",
    "acl-W03-0404",
    "acl-W09-1304"
  ],
  "sections": [
    {
      "text": [
        "Exploiting Multi-Features to Detect Hedges and Their Scope in",
        "Biomedical Texts",
        "Huiwei Zhou, Xiaoyan Li, Degen Huang, Zezhong Li, Yuansheng Yang",
        "Dalian University of Technology Dalian, Liaoning, China",
        "(zhouhuiwei, huangdg, yangys)@dlut.edu.cn",
        "2lixiaoyan@mail.dlut.edu.cn",
        "In this paper, we present a machine learning approach that detects hedge cues and their scope in biomedical texts.",
        "Identifying hedged information in texts is a kind of semantic filtering of texts and it is important since it could extract speculative information from factual information.",
        "In order to deal with the semantic analysis problem, various evidential features are proposed and integrated through a Conditional Random Fields (CRFs) model.",
        "Hedge cues that appear in the training dataset are regarded as keywords and employed as an important feature in hedge cue identification system.",
        "For the scope finding, we construct a CRF-based system and a syntactic pattern-based system, and compare their performances.",
        "Experiments using test data from CoNLL-2010 shared task show that our proposed method is robust.",
        "F-score of the biological hedge detection task and scope finding task achieves 86.32% and 54.18% in in-domain evaluations respectively."
      ]
    },
    {
      "heading": "1.. Introduction",
      "text": [
        "Identifying sentences in natural language texts which contain unreliable or uncertain information is an increasingly important task of information extraction since the extracted information that falls in the scope of hedge cues cannot be presented as factual information.",
        "Szarvas et al.",
        "(2008) report that 17.69% of the sentences in the abstracts section of the BioScope corpus and 22.29% of the sentences in the full papers section contain hedge cues.",
        "Light et al.",
        "(2004) estimate that 11% of sentences in MEDLINE abstracts contain speculative fragments.",
        "Szarvas (2008) reports that 32.41% of gene names mentioned in the hedge classification dataset described in Medlock and Briscoe (2007) appear in a speculative sentence.",
        "Many Wikipedia articles contain a specific weasel tag which mark sentences as non-factual (Ganter and Strube, 2009) .",
        "There are some Natural Language Processing (NLP) researches that demonstrate the benefit of hedge detection experimentally in several subjects, such as the ICD-9-CM coding of radiology reports and gene named Entity Extraction (Szarvas, 2008), question answering systems (Riloff et al., 2003), information extraction from biomedical texts (Medlock and",
        "Briscoe, 2007).",
        "2010) \"Learning to detect hedges and their scope in natural language text\" proposed two tasks related to speculation research.",
        "Task 1 aimed to identify sentences containing uncertainty and Task 2 aimed to resolve the in-sentence scope of hedge cues.",
        "We participated in both tasks.",
        "In this paper, a machine learning system is constructed to detect sentences in texts which contain uncertain or unreliable information and to find the scope of hedge cues.",
        "The system works in two phases: in the first phase uncertain sentences are detected, and in the second phase in-sentence scopes of hedge cues are found.",
        "In the uncertain information detecting phase, hedge cues play an important role.",
        "The sentences that contain at least one hedge cue are considered as uncertain, while sentences without cues are considered as factual.",
        "Therefore, the task of uncertain information detection can be converted into the task of hedge cue identification.",
        "Hedge cues that appear in the training dataset are collected and used as keywords to find hedges.",
        "Furthermore, the detected keywords are employed as an important feature in hedge cue identification system.",
        "In addition to keywords, various evidential features are proposed and integrated through a machine learning model.",
        "Finding the scope of a hedge cue is to determine at sentence level which words are affected by the hedge cue.",
        "In the scope finding phase, we construct a machine learning-based system and a syntactic pattern-based system, and compare their performances.",
        "For the learning algorithm, Conditional random fields (CRFs) is adopted relying on its flexible feature designs and good performance in sequence labeling problems as described in Lafferty et al.",
        "(2001).",
        "The main idea of CRFs is to estimate a conditional probability distribution over label sequences, rather than over local directed label sequences as with Hidden Markov Models (Baum and Petrie, 1966) and Maximum Entropy Markov Models (McCallum et al., 2000).",
        "Evaluation is carried out on the CoNLL-2010 shared task (Farkas et al., 2010) dataset in which sentences containing uncertain information are annotated.",
        "For the task of detecting uncertain information, uncertain cues are annotated.",
        "And for the task of finding scopes of hedge cues, hedge cues and their scope are annotated as shown in sentence (a): hedge cue indicate that, and its scope indicate that dhtt is widely expressed at low levels during all stages of Drosophila development are annotated.",
        "type=\"speculation\">indicate that</cue> dhtt is widely expressed at low levels during all stages of Drosophila development</xcope>."
      ]
    },
    {
      "heading": "2.. Related Work",
      "text": [
        "In the past few years, a number of studies on hedge detection from NLP perspective have been proposed.",
        "Elkin et al.",
        "(2005) exploited handcrafted rule-based negation/uncertainty detection modules to detect the negation or uncertainty information.",
        "However, their detection modules were hard to develop due to the lack of standard corpora that used for evaluating the automatic detection and scope resolution.",
        "Szarvas et al.",
        "(2008) constructed a corpus annotated for negations, speculations and their linguistic scopes.",
        "It provides a common resource for the training, testing and comparison of biomedical NLP systems.",
        "Medlock and Briscoe (2007) proposed an automatic classification of hedging in biomedical texts using weakly supervised machine learning.",
        "They started with a very limited amount of annotator-labeled seed data.",
        "Then they iterated and acquired more training seeds without much manual intervention.",
        "The best classifier using their model achieved 0.76 precision/recall break-even-point (BEP).",
        "Further, Medlock (2008) illuminated the hedge identification task including annotation guidelines, theoretical analysis and discussion.",
        "He argued for separation of the acquisition and classification phases in semi-supervised machine learning method and presented a probabilistic acquisition model.",
        "In probabilistic model he assumed bigrams and single terms as features based on the intuition that many hedge cues are bigrams and single terms and achieves a peak performance of around 0.82",
        "BEP.",
        "Morante and Daelemans (2009) presented a meta-learning system that finds the scope of hedge cues in biomedical texts.",
        "The system worked in two phases: in the first phase hedge cues are identified, and in the second phase the full scopes of these hedge cues are found.",
        "The performance of the system is tested on three subcorpora of the BioScope corpus.",
        "In the hedge finding phase, the system achieves an F-score of 84.77% in the abstracts subcorpus.",
        "In the scope finding phase, the system with predicted hedge cues achieves an F-score of 78.54% in the abstracts subcorpus.",
        "The research on detecting uncertain information is not restricted to analyze biomedical documents.",
        "Ganter and Strube (2009) investigated Wikipedia as a source of training data for the automatic hedge detection using word frequency measures and syntactic patterns.",
        "They showed that the syntactic patterns worked better when using the manually annotated test data, word frequency and distance to the weasel tag was sufficient when using Wikipedia weasel tags themselves."
      ]
    },
    {
      "heading": "3.. Identifying Hedge Cues",
      "text": [
        "Previous studies (Light et al., 2004) showed that the detection of hedging could be solved effectively by looking for specific keywords which were useful for deciding whether a sentence was speculative.",
        "Szarvas (2008) reduces the number of keyword candidates without excluding helpful keywords for hedge classification.",
        "Here we also use a simple keyword-based hedge cue detection method.",
        "In order to recall as many hedge cues as possible, all hedge cues that appear in the training dataset are used as keywords.",
        "Hedge cues are represented by one or more tokens.",
        "The list of all hedge cues in the training dataset is comprised of 143 cues.",
        "90 hedge cues are unigrams, 24 hedge cues are bigrams, and the others are trigrams, four-grams and five-grams.",
        "Besides, hedge cues that appear in the training dataset and their synonyms in WordNet are also selected as keywords for hedge cue detection.",
        "The complete list of them contains 438 keywords, 359 of which are unigrams.",
        "Many tokens appear in different grams cues, such as possibility appears in five-grams cue cannot rule out the possibility, four-gram cue cannot exclude the possibility, trigrams cue raise the possibility and unigram cue possibility.",
        "To find the complete cues, keywords are matched through a maximum matching method (MM) (Liu et al., 1994).",
        "For example, though indicate and indicate that are both in keywords list, indicate that is extracted as a keyword in sentence (a) through MM.",
        "Candidate cues are extracted based on keywords list in keyword-based hedge cue detection stage.",
        "But the hedge cue is extremely ambiguous, so CRFs are applied to correct the false identification results that occurred in the keyword-based hedge cue detection stage.",
        "The extracted hedge cues are used as one feature for CRFs-based hedge cue detection.",
        "A CRF identifying model is generated by applying a CRF tool to hedge cue labeled sequences.",
        "Firstly, hedge cue labeled sentences are transformed into a set of tokenized word sequences with IOB2 labels:",
        "B-cue Current token is the beginning of a hedge cue I-cue Current token is inside of a hedge cue O Current token is outside of any hedge",
        "For sentence (a) the system assigns the B-cue tag to indicate, the I-cue tag to that and the O tag to the rest of tokens as shown in Figure 1.",
        "The hedge cues that are found by keyword-based method is also given IOB2 labels feature as shown in Figure1.",
        "Figure 1 : Example of Cues labels and Keywords labels Feature",
        "Diverse features including keyword feature are employed to our CRF-based hedge cue detection system.",
        "(1) Word Features is the first word to the left, Word (1) is the first word to the right, etc.",
        "(2) Stem Features",
        "The motivation for stemming in hedge identification is that distinct morphological forms of hedge cues are used to convey the same semantics (Medlock, 2008).",
        "In our method, GENIA Tagger (Tsuruoka et al., 2005) is applied to get stem features.",
        "Stem(-1) is the first stem to the left, Stem (1) is the first stem to the right, etc.",
        "(3) Part-Of-Speech Features",
        "Since most of hedge cues in the training dataset are verbs, auxiliaries, adjectives and adverbs.",
        "Therefore, Part-of-Speech (POS) may provide useful evidence about the hedge cues and their boundaries.",
        "GENIA Tagger is also used to generate this feature.",
        "the first POS to the left, POS (1) is the first POS to the right, etc.",
        "(4) Chunk Features",
        "Some hedge cues are chunks consisting of more than one token.",
        "Chunk features may contribute to the hedge cue boundaries.",
        "We use GENIA Tagger to get chunk features for each token.",
        "The (1) Word Features (2) Stem Features (3) Part-Of-Speech Features (4) Chunk Features chunk features include unigram, bigram, and trigram types, listed as follows:",
        "Text",
        "Keyword Labels Feature",
        "Cue Labels",
        "these",
        "O",
        "O",
        "data",
        "O",
        "O",
        "indicate",
        "B",
        "B-cue",
        "that",
        "I",
        "I-cue",
        "dhtt",
        "O",
        "O",
        "is",
        "O",
        "O",
        "where Chunk (0) is the chunk label for the current word, Chunk (-1) is the chunk label for the first word to the left , Chunk (1) is the chunk label for the first word to the right, etc.",
        "(5) Keyword Features",
        "Keyword labels feature is an important feature.",
        "where Keyword (0) is the current keyword label, Keywords (-1) is the keyword label for the first keyword to the left, Keywords (1) is the keyword label for the first keyword to the right, etc.",
        "Feature sets can be easily redefined by changing the window size n. The relationship of the window size and the F-score observed in our experiments will be reported in Section 5."
      ]
    },
    {
      "heading": "4.. Hedge Scope Finding",
      "text": [
        "In this task, a CRFs classifier is applied to predict for all the tokens in the sentence whether a token is the first token of the scope sequence (F-scope), the last token of the scope sequence (L-scope), or neither (None).",
        "For sentence (a) in Section 1, the classifier assigns F-scope to indicate, L-scope to benchmarks, and None to the rest of the tokens.",
        "Only sentences that assigned cues in the first phase are selected for hedge scope finding.",
        "Besides, a syntactic pattern-based system is constructed, and compared with the CRF-based system.",
        "The features that used in CRF-based hedge cue detection systems are also used for scope finding except for the keyword features.",
        "The features are:",
        "The chunk features include unigram, bigram, and trigram types, listed as follows:",
        "(5) Hedge cues Features Hedge cues labels that are doped out in Task 1 are selected as an important feature.",
        "where Hedge cues (0) is the cue label for the current word, Hedge cues (-1) is the cue label for the first word to the left , Hedge cues (1) is the cue label for the first word to the right, etc.",
        "The scope of the sequence must be consistent with the hedge cues.",
        "That means that the number of the F-scope and L-scope must be the same with the hedge cues.",
        "However, sometimes their number predicted by classifier is not same.",
        "Therefore, we need to process the output of the classifier to get the complete sequence of the scope.",
        "The following post processing rules are adapted.",
        "• If the number of F-scope, L-scope and hedge cue is the same, the sequence will start at the token predicted as F-scope, and end at the token predicted as L-scope.",
        "• If one token has been predicted as F-scope and none has been predicted as L-scope, the sequence will start at the token predicted as F-scope and end at the end of the sentence.",
        "Since when marking the scopes of keywords, linguists always extend the scope to the biggest syntactic unit possible.",
        "• If one token has been predicted as L-scope and none has been predicted as F-scope, the sequence will start at the hedge cue and end at the token predicted as L-scope.",
        "Since scopes must contain their cues.",
        "• If one token has been predicted as F-scope and more than one has been predicted as L-scope, the sequence will end at the first token predicted as L-scope.",
        "Statistics from prediction on CoNLL-2010 Shared Task evaluation data show that 20 sentences are in this case.",
        "And the scope of 6 sentences extends to the first L-scope, and the scope of 3 sentences end at the last L-scope, the others are predicted mistakenly.",
        "Our system prediction and gold-standard annotation are shown in sentence (b1) and (b2) respectively.",
        "(b1) our system annotation:",
        "dRas85DV12 <xcope id=\"X3.64.1\"><cue ref= \"X3.64.1 \" type=\"speculation\">may</cue> be more potent than dEGFRX</xcope> because dRas85DV12 can activate endogenous PI3K signaling</xcope> [16].",
        "(b2) gold-standard annotation:",
        "type=\"speculation\">may</cue> be more potent than dEGFRX</xcope> because dRas85DV12 can activate endogenous PI3K signaling [16].",
        "• If one token has been predicted as L-scope and more than one has been predicted as F-scope, the sequence will start at the first token predicted as F-scope.",
        "• If an L-scope is predicted before an F-scope, the sequence will start at the token predicted as F-scope, and finished at the end of the sentence.",
        "Hedge scopes usually can be determined on the basis of syntactic patterns dependent on the cue.",
        "Therefore, a syntactic pattern-based system is also implemented for hedge scope finding.",
        "When the sentence is predicted as uncertain, the toolkit of Stanford Parser (Klein and Manning, 2003) is utilized to parse the sentence into a syntactic tree, which can release a lot of information about the grammatical structure of sentences that is beneficial for the finding of hedge scope.",
        "For sentence (c) the Stanford Parser gives the syntactic tree as showed in Figure 2.",
        "(c) This <xcope id=\"X*.",
        "*.",
        "*\"><cue ref=\"X*.",
        "*.",
        "*\" type=\"speculation\"> may </cue> represent a viral illness</xcope>.",
        "It is obvious to see from the syntactic tree, all the words of the parsed sentence concentrate at the places of leaves.",
        "We use the following rules to find the scope.",
        "• If the tag of the word is \"B-cue\", it is predicted as F-scope.",
        "• If the POS of the hedge cue is verbs and auxiliaries, the L-scope is signed at the end of the clause.",
        "• If the POS of the hedge cue is attributive",
        "adjectives, the L-scope is signed at the following noun phrase.",
        "• If the POS of the hedge cue is prepositions, the L-scope is signed at the following noun phrase.",
        "• If none of the above rules apply, the scope of a hedge cue starts with the hedge cue and ends at the following clause.",
        "represent DT JJ NN a viral illness"
      ]
    },
    {
      "heading": "5.. Experiments and Discussion",
      "text": [
        "We evaluate our method using CoNLL-2010 shared task dataset.",
        "The evaluation of uncertain information detection task is carried out using the sentence-level F-score of the uncertainty class.",
        "As mentioned in Section 1, Task 1 is converted into the task of hedge cues identification.",
        "Sentences can be classified as certain or uncertain according to the presence or absence of a few hedge cues within the sentences.",
        "In task of finding in-sentence scopes of hedge cues, a scope is correct if all the tokens in the sentence have been assigned the correct scope class for a specific hedge signal.",
        "In the CoNLL-2010 Shared Task 1, our in-domain system obtained the F-score of 85.77%.",
        "Sentence-level results of in-domain systems under the condition n=3 (window size) are summarized in Table 1.",
        "System",
        "Prec.",
        "Recall",
        "F-score",
        "Keyword-based",
        "41.15",
        "99.24",
        "58.18",
        "CRF-based system (without keyword features)",
        "88.66",
        "80.13",
        "84.18",
        "CRF-based system + keyword features",
        "86.21",
        "84.68",
        "85.44",
        "CRF-based system",
        "86.49",
        "85.06",
        "85.77",
        "The keyword-based system extracts hedge cues through maximum matching method (MM).",
        "As can be seen in Table 1, the system achieves a high recall (99.24%).",
        "This can be explained that almost all of the hedge cues in the test dataset are in the keywords list.",
        "However, it also brings about the low precision since not all potential speculative keywords convey real speculation.",
        "So the keyword-based method can be combined with our CRF-based method to get better performance.",
        "All the CRF-based systems in Table 1 significantly outperform the keyword-based system, since the multi-features achieve a high precision.",
        "And the result with keyword features is better than the result without it.",
        "The keyword features improve the performance by recalling 39 true positives.",
        "In addition, further improvement is achieved by using Maximum Matching method (MM).",
        "In the test dataset, there should be a few hedge cues not in the training dataset.",
        "And the additional resources besides the manually labeled data are allowed for in-domain predictions.",
        "Therefore, the synonyms of the keywords can be used for in-domain systems.",
        "The synonyms of the keywords are added to the keywords list, and are expected to improve detecting performance.",
        "The synonyms are obtained from WordNet.",
        "Table 2 shows the relationship between the window size and the sentence-level results.",
        "This table shows the results with and without synonyms.",
        "Generally, the results with synonyms are better than the results without them.",
        "With respect to window size, the wider the window size, the better precision can be achieved.",
        "However, large window size leads to low recall which is probably because of data sparse.",
        "The best F-score 86.32 is obtained when the window size is +/-4.",
        "in-domain system obtained the F-score of 44.42%.",
        "Table 3 shows the scope finding results.",
        "For in-domain scope finding system, we use the hedge cues extracted by the submitted CRF-based in-domain system (the best result 85.77 in Table 1).",
        "The result of the syntactic pattern-based system is not ideal probably due to the syntactic parsing errors and limited annotation rules.",
        "Through analyzing the false of our scope finding system, we found that many of our false scope were caused by such scope as sentence (d1) shows.",
        "Our CRF-based system signed the L-scope to the end of sentence mistakenly.",
        "The incorrectly annotation of our system and gold-standard annotation are shown in sentence (d1) and (d2) respectively.",
        "So an additional rule is added to our CRF-based system to correct the L-scope.",
        "The rule is:",
        "• If one token has been predicted as L-scope, and if the previous token is \")\", or \"]\", the L-scope will be modified just before the paired token \"(\" or \"[\".",
        "(d1) The incorrectly predicted version:",
        "type=\"speculation\">presumed</cue> to be pathogenic</xcope> (85).",
        "(d2) Gold-standard annotation:",
        "pathogenic (85) </xcope>.",
        "+ keyword features + MM",
        "3",
        "without synonyms",
        "86.49",
        "85.06",
        "85.77",
        "with synonyms",
        "86.69",
        "84.94",
        "85.81",
        "4",
        "without synonyms",
        "86.34",
        "84.81",
        "85.57",
        "with synonyms",
        "87.21",
        "85.44",
        "86.32",
        "System",
        "Prec.",
        "Recall",
        "F-score",
        "syntactic pattern-based",
        "44.31",
        "42.59",
        "43.45",
        "CRF-based",
        "45.32",
        "43.56",
        "44.42",
        "Window size",
        "Synonym",
        "s",
        "Prec.",
        "Recall",
        "F-score",
        "1",
        "without synonyms",
        "85.27",
        "86.46",
        "85.86",
        "with",
        "85.66",
        "86.20",
        "85.93",
        "synonyms",
        "2",
        "without synonyms",
        "86.35",
        "85.70",
        "86.02",
        "with",
        "86.14",
        "84.94",
        "85.53",
        "F-score is reached to 51.83 by combining this additional rule with the submitted CRF-based in-domain system as shown in Table 4.",
        "Several best results of Task 1 are exploited to investigate the relationship between the window size and the scope finding results.",
        "From the results of Table 5, we can see that the case of n=4 gives the best precision, recall and F-score.",
        "And the case of n=2 and the case of n=3 based on the same task 1 system have a very similar score.",
        "With respect to the different systems of Task 1, in principle, the higher the F-score of Task 1, the better the performance of Task 2 can be expected.",
        "However, the result is somewhat different from the expectation.",
        "The best F-score of Task 2 is obtained under the case F-score (task 1) =86.02.",
        "This indicates that it is not certain that Task 2 system based on the best Task 1 result gives the best scope finding performance.",
        "In the case that scopes longer than n (window size) words, the relevant cue will thus not fall into the +/-n word window of the L-scope and all hedge cue features will be O tag.",
        "The hedge cue features will be useless for detecting L-scopes.",
        "Taking into account the importance of hedge cue features, the following additional features are also incorporated to capture hedge cue features.",
        "• Distance to the closest preceding hedge cue",
        "• Distance to the closest following hedge cue",
        "• Stem of the closest preceding hedge cue",
        "• Stem of the closest following hedge cue",
        "• POS of the closest preceding hedge cue",
        "• POS of the closest following hedge cue",
        "Table 6 shows the results when the additional hedge cue features are used.",
        "The results with additional hedge cue feature set are constantly better than the results without them.",
        "In most of cases, the improvement is significant.",
        "The best F-score 54.18% is achieved under the case F-score (task 1) =86.02 and n=4.",
        "Table 6: Scope finding results relative to the results of Task 1 and window size with additional cue features",
        "The upper-bound results of CRF-based system assuming gold-standard annotation of hedge cues are show in Table 7.",
        "A comparative character analysis of syntactic pattern-based method and CRF-based method will be interesting, which can provide insights leading to better methods in the future."
      ]
    },
    {
      "heading": "6.. Conclusion",
      "text": [
        "In this paper, we have exploited various useful features evident to detect hedge cues and their scope in biomedical texts.",
        "For hedge detection task, keyword-based system is integrated with CRF-based system by introducing keyword features to CRF-based system.",
        "Our experimental results show that the proposed method improves the performance of CRF-based system by the additional keyword features.",
        "Our system has achieved a state of the art F-score 86.32% on the sentence-level evaluation.",
        "For scope finding task, two different systems are established: CRF-based and syntactic pattern-based system.",
        "CRF-based system outperforms syntactic pattern-based system due to its evidential features.",
        "TP",
        "FP",
        "FN",
        "Prec.",
        "Recall",
        "F-score",
        "525",
        "468",
        "508",
        "52.87",
        "50.82",
        "51.83",
        "F-score",
        "Window",
        "Prec.",
        "Recall",
        "F-score",
        "(Task 1)",
        "size",
        "86.32",
        "4",
        "54.73",
        "52.08",
        "53.37",
        "3",
        "54.22",
        "51.60",
        "52.88",
        "2",
        "53.41",
        "50.82",
        "52.08",
        "86.02",
        "4",
        "55.35",
        "53.05",
        "54.18",
        "3",
        "54.75",
        "52.47",
        "53.58",
        "2",
        "53.94",
        "51.69",
        "52.79",
        "85.86",
        "4",
        "54.49",
        "52.86",
        "53.66",
        "3",
        "53.79",
        "52.18",
        "52.97",
        "2",
        "53.09",
        "51.50",
        "52.29",
        "F-score",
        "Window",
        "Prec.",
        "Recall",
        "F-score",
        "(Task 1)",
        "size",
        "86.32",
        "4",
        "54.32",
        "51.69",
        "52.98",
        "3",
        "52.59",
        "50.05",
        "51.29",
        "2",
        "52.90",
        "50.34",
        "51.59",
        "86.02",
        "4",
        "54.85",
        "52.57",
        "53.68",
        "3",
        "53.13",
        "50.92",
        "52.00",
        "2",
        "53.13",
        "50.92",
        "52.00",
        "85.86",
        "4",
        "54.19",
        "52.57",
        "53.37",
        "3",
        "52.50",
        "50.92",
        "51.70",
        "2",
        "52.50",
        "50.92",
        "51.70",
        "TP",
        "FP",
        "FN",
        "Prec.",
        "Recall",
        "F-score",
        "618",
        "427",
        "415",
        "59.14",
        "59.83",
        "59.48",
        "In the near future, we will improve the hedge cue detection performance by investigating more implicit information of potential keywords.",
        "On the other hand, we will study on how to improve scope finding performance by integrating CRF-based and syntactic pattern-based scope finding systems."
      ]
    }
  ]
}
