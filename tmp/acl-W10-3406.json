{
  "info": {
    "authors": [
      "Nicolas Béchet",
      "Mathieu Roche"
    ],
    "book": "Proceedings of the 2nd Workshop on Cognitive Aspects of the Lexicon",
    "id": "acl-W10-3406",
    "title": "How to Expand Dictionaries by Web-Mining Techniques",
    "url": "https://aclweb.org/anthology/W10-3406",
    "year": 2010
  },
  "references": [
    "acl-P08-1052",
    "acl-P84-1004"
  ],
  "sections": [
    {
      "text": [
        "How to Expand Dictionaries with Web-Mining Techniques",
        "LIRMM, UMR 5506, CNRS, Univ.",
        "Montpellier 2",
        "bechet@lirmm.fr",
        "LIRMM, UMR 5506, CNRS,",
        "Univ.",
        "Montpellier 2",
        "mroche@lirmm.fr",
        "This paper presents an approach to enrich conceptual classes based on the Web.",
        "To test our approach, we first build conceptual classes using syntactic and semantic information provided by a corpus.",
        "The concepts can be the input of a dictionary.",
        "Our web-mining approach deals with a cognitive process which simulates human reasoning based on the enumeration principle.",
        "The experiments reveal the interest of our approach by adding new relevant terms to existing conceptual classes."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "111usl gCUCiai U",
        "the Aristotelian approach to a concept, and con'esrosiersoabbaih, 1984).",
        "in a domain such as ours, i.e.",
        "ontology building, semantic webs, and computational linguistics, it seems appropriate to stick to tion) on common semantic features.",
        "The choice of the features and how the knowledge is gathered depend on criteria we will explain below.",
        "in this paper, we deal with the building of conceptual classes, which can be defined as gathering semantically close terms.",
        "First, we suggest building specific conceptual classes by focusing on knowledge extracted from corpora.",
        "Conceptual classes are shaped by the study of syntactic dependencies between corpus terms (as described in section 2).",
        "Dependencies tackle relations such as Verb/Subject, Noun/Noun Phrase Complements, Verb/Object, Verb/Complements, and sometimes Sentence Head/Complements.",
        "in this paper, we focus on the Verb/Object dependency because it is representative of a field.",
        "For instance, in computer science, the verb 'to load' takes as objects, nouns of the conceptual class software (L'Homme, 1998).",
        "This feature also extends to 'download' or 'upload', which have the same verbal root.",
        "inuuiiuuai analysis lu ai^qun",
        "or ontological knowledge from textual data (e.g (Bourigault and Lame, 2002) for law, (Naza-renko et al., 2001; Weeds et al., 2005) for medicine).",
        "using a vvcu scaiuu engine",
        "terms (section 3).",
        "in section 4, experiments con ducted on real data enable us to validate our ap proach."
      ]
    },
    {
      "heading": "2. Building Conceptual Classes 2.1 Principle",
      "text": [
        "sy uiac ut section.",
        "Concepts have several definitions; one of the",
        "Corpora are rich sources of terminological information that can be mined.",
        "A terminology extraction of this kind is similar to a Harris-like distributional analysis (Harris, 1968) and many works in the literature have been the subject of",
        "After building conceptual classes (section 2), we describe an approach to expand concepts by to discover sider it as a set of knowledge (gathered informain our approach, a class can be defined as a gathering of terms with a common field.",
        "in this paper, we focus on objects of verbs judged to be semantically close by using a measure.",
        "These objects are thus considered as instances of conceptual classes.",
        "The first step in building conceptual classes consists in extracting Verb/Object relations as explained in the following",
        "NLP applica-",
        "L1UL15.",
        "nuwcvci, LUC lUllUWlilg lllClilUU",
        "used for any other language, provided a reliable in our case,",
        "Assumption of Semantic Closeness.",
        "The underlying linguistic hypothesis is the following: Verbs with a significant number of common objects are semantically close.",
        "To measure closeness, the ASiUM score (Faure and Nedellec, 1999; Faure, 2000) is used (see figure 1).",
        "This type of work is similar to distributional analysis approaches such as that of (Bourigault and Lame, 2002).",
        "As explained in the introduction, the measure considers two verbs to be close if they have a significant number of common features (objects).",
        "Let p and q be verbs with their respective pi,...,pn and qi,...,qm objects.",
        "NbOCp(qi) is the number of occurrences of q objects from q that are also objects of p (common objects).",
        "NbO(qi) is the number of occurrences of qi objects of q verb.",
        "The Asium measure is then:",
        "i^NbOCjqf)",
        "we Where logAsium(x) is equal to:",
        "Therefore, conceptual classes instances are the common objects of close verbs, according to the ASiUM proximity measure.",
        "The following section describes the acquisition of new terms starting with a list of terms/concepts obtained with the global process summarized in this section and detailed in (Béchet et al., 2008)."
      ]
    },
    {
      "heading": "3. Expanding conceptual classes",
      "text": [
        "The aim of this approach is to provide new candidates for a given concept.",
        "it is based on enumeration on the Web of terms that are semantically close.",
        "For instance, with a query (string) \"bicycle, car, and\", we can find other vehicles.",
        "We propose to use the Web to acquire new candidates.",
        "This kind of method uses information regarding the \"popularity\" of the web and is independent of a particular corpus.",
        "Our method of acquisition is quite similar to that of (Nakov and Hearst, 2008).",
        "These authors propose to query the Web using the Google search engine to characterize the semantic relation between a pair of nouns.",
        "The Google star operator among others, is used to that end.",
        "(Na-kov and Hearst, 2008) refer to the study of (Lin and Pantel, 2001) who used a Web mining approach to discover inference rules missed by humans.",
        "y t/iusc vi",
        "concepts",
        "Our corpora are in French since our team is mostly devoted to French-based use the SYGFRAN parser developed by (Chauché, 1984).",
        "As an example, in the French sentence \"Thierry Dusautoir brandissant le drapeau tricolore sur la pelouse de Cardiff après la victoire. \"",
        "(translation: 'Thierry Dusautoir brandishing the three colored flag on Cardiff lawn after the victory'), there is a verb-object syntactic relation: \"verb: brandir (to brandish), object: drapeau (flag)\", which is a good candidate for retrieval.",
        "The second step of the building process corresponds to the gathering of common objects related to semantically close verbs.",
        "To apply our method, we first consider the common objects of semantically which are instances of reference (e.g. vehicle).",
        "Let N concepts Ci£{], N} and their respective instances Ij(Ci).",
        "For each concept Ci, we submit to a search engine the following queries: \"WQ, Ijb(Q, and\" and \"Ija(C), Ijb(C), or\" with jA and jB e{1, NblnstanceC} andjA f jB.",
        "The search engine returns a set of results from which we extract new candidate instances of a concept.",
        "For example, if we consider the query: \"bicycle, car, and\", one page returned by a search engine gives the following text:",
        "Listen here for the Great Commuter Race (17/11/05) between bicycle, car and bus, as part of...",
        "<v cauuiuaies",
        "cepts.",
        "The process can be repeated.",
        "in order to",
        "The quality of the extracted terms can be validated by an expert, or automatically by using the Web to check if the extracted candidates (see section 3.1) are relevant.",
        "The principle is to consider a relevant term if it is often present with the terms of the original conceptual class (kernel of words).",
        "Thus, our aim is to validate a term \"in the context\".",
        "From that point of view, our method is close to that of (Turney, 2001), which queries the Web via the AltaVista search engine to determine appropriate synonyms for a given term.",
        "Like (Turney, 2001), we consider that information concerning the number of pages returned by the queries can give an indication of the relevance of a term.",
        "Thus, we submit to a search engine different strings (using citation marks).",
        "A query consists of the new candidate and both terms of the concept.",
        "Formally, our approach can be defined as follows.",
        "Let N concepts Ci £ {1, N}, their respective instances Ij(Ci) and the new candidates for a concept Ci, Na £ {h NbNi(Ci)}.",
        "For each Ci, each new candidate Nik is sent as a query to a Web search engine.",
        "in practice the three terms are separated either by a comma or the word \"or\" or \"and\" .",
        "For each query, the search engine returns a number of results (i.e. number of web pages).",
        "Then, the sum of these results is calculated using all possible combinations of \"or\", \"and\", or of the three words (words of the kernel plus candidate",
        "Note that the commas are automatically removed by the search engines.",
        "word to enrich it).",
        "Below is an example with the kernel words \"car\", \"bicycle\" and the candidate \"bus\" to test (using Yahoo):",
        "• and so forth",
        "Global result: 71 + 268 + 208...",
        "The filtering of candidates consists in selecting the k first candidates by class (i.e. with the highest sum), they are added as new instances of the initial concept.",
        "We can reiterate the acquisition approach by including these new terms.",
        "The acquisition/filtering process can be repeated several times.",
        "CUUUUCLi",
        "proach."
      ]
    },
    {
      "heading": "4. Experiments",
      "text": [
        "We used a French corpus from the Yahoo site (http://fr.news.yahoo.com/) composed of 8,948 news items (16.5 MB) from newspapers.",
        "Experiments were performed on 60,000 syntactic relations (Béchet et al., 2008; Béchet et al., 2009) to build original conceptual classes.",
        "We manually selected five concepts (see Figure 2).",
        "instances of these concepts are the common objects of verbs defining the concept (see section 2.2).",
        "in the next section, we present experiments",
        "Having identified the relevant features in the result returned (in bold in our example), we add the term \"bus\" to the initial concept \"vehicle\".",
        "in y determine which candidates relevant, the candidates are filtered as shown the following section.",
        "d to evaluate the quality of our ap-",
        "Concepte",
        "Organiame ■ Administration",
        "Fonction",
        "Objet?",
        "symboliques",
        "SenlinUftl",
        "HBni featallfln de protestation",
        "(Civil Sexvice)",
        "(WW*.}",
        "(symbols;",
        "(□rarest",
        "parquet {pruSGCVtioa}",
        "négociateur",
        "drapeau (fias)",
        "mécontentement",
        "proteslalion",
        "mai rte (city hs)S)",
        "einlast* (ÏJi'mvnaAe^",
        "llaur",
        "(1 lower]",
        "souhall fm&h)",
        "grlncêtrienL",
        "fgflrfc?",
        "gendarme {placeman)",
        "ecriveiri",
        "fmler)",
        ":■:::(:■:::■;■ ispcctoff",
        "déceplim",
        "indgnejian (indignation)",
        "préfecture",
        "fprçfççtt.>re)",
        "oral sur (public speaker)",
        "cesaocof d (cft5Qgr?emer7t)",
        "émotion (emotion}",
        "pümpiör",
        "(fifßtnan)",
        "dtelr (oasiœ)",
        "remous (Srtfà)",
        "aN.u.",
        "toiu",
        "émoi",
        "/CÛrïlrNOr/Stf,:",
        "panique (panic)",
        "Therefore, we only keep the nouns, after applying a PoS (Part of Speech) tagger, the TreeTag-ger (Schmid, 1995).",
        "After these post-treatments, we manually validate the new terms using three experts.",
        "We compute the precision of our approach to each expert.",
        "The average is calculated to define the quality of the terms.",
        "Precision is defined as follows.",
        "Precision = Number of relevant terms given by our system Number of terms given by our system",
        "in the next section, we present the evaluation of our method.",
        "Experimental results",
        "Table 1 gives the results of the term acquisition method (i.e. for each acquisition step, we apply our approach to filter candidate terms).",
        "For each step, the table lists the degree of precision obtained after expertise:",
        "• All candidates.",
        "We calculate the precision before the filtering step.",
        "• Filtered candidates.",
        "After applying the automatic filtering by selecting k terms per class, we calculate the precision obtained.",
        "Note that the automatic filtering (see section 3.2) reduces the number of terms proposed, and thus reduces the re-call.",
        "Terms number (without filter)",
        "filtering approach).",
        "iiie iccaii is uui caicuiaieu vised context it is difficult",
        "Finally Table 1 shows the number of terms generated by the acquisition system.",
        "These results show that a significant number of terms can be generated (i.e. 103 words).",
        "For example, for the concept 'feeling', using the initial terms given in figure 1, we obtained the following eight French terms (in two steps): \"hor(horror), satisfaction (depression), faiblesse (weakness), tristesse (sadness), désenchantement (disenchantment), folie (madness), fatalisme (fatalism)\".",
        "This approach is appropriate to produce new relevant terms to enrich conceptual classes, in particular when we select the first terms (k = 4) returned by the filtering system.",
        "in a future work, we plan to test other values of the automatic filtering.",
        "The precision obtained in the first two steps was high (i.e. 0.69 to 0.83).",
        "The third step returned lower scores; noise was introduced because we were too \"far\" from the initial kernel words."
      ]
    },
    {
      "heading": "5. Conclusion and Future Work",
      "text": [
        "This paper describes an approach for conceptual enrichment classes based on the Web.",
        "We apply the \"enumeration\" principle to find new terms using Web search engines.",
        "This approach has the advantage of being less dependent on the corpus.",
        "Note that as the use of the Web requires validation of candidates, we propose an automatic filtering method to select relevant terms to add to the concept.",
        "in a future work, we plan to use other statistical web measures (e.g. Mutual information, Dice measure, and so forth) to automatically validate terms.",
        ", déprime",
        "to estimate."
      ]
    }
  ]
}
