{
  "info": {
    "authors": [
      "Masatoshi Tsuchiya",
      "Shoko Endo",
      "Seiichi Nakagawa"
    ],
    "book": "Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration (NEWS 2009)",
    "id": "acl-W09-3534",
    "title": "Analysis and Robust Extraction of Changing Named Entities",
    "url": "https://aclweb.org/anthology/W09-3534",
    "year": 2009
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Masatoshi Tsuchiyat Shoko Endo* Seiichi Nakagawa*",
        "^Information and Media Center / *Department of Information and Computer Sciences,",
        "This paper focuses on the change of named entities over time and its influence on the performance of the named entity tagger.",
        "First, we analyze Japanese named entities which appear in Mainichi Newspaper articles published in 1995, 1996, 1997, 1998 and 2005.",
        "This analysis reveals that the number of named entity types and the number of named entity tokens are almost steady over time and that 70 ~ 80% of named entity types in a certain year occur in the articles published either in its succeeding year or in its preceding year.",
        "These facts lead that 20 ~ 30% of named entity types are replaced with new ones every year.",
        "The experiment against these texts shows that our proposing semi-supervised method which combines a small annotated corpus and a large unannotated corpus for training works robustly although the traditional supervised method is fragile against the change of name entity distribution."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "It is widely agreed that extraction of named entity (henceforth, denoted as NE) is an important subtask for various NLP applications, such as information retrieval, machine translation, information extraction and natural language understanding.",
        "Several conferences like Message Understanding Conference(Grishman and Sundheim, 1996) and the IREX workshop (Sekine and Eriguchi, 2000) were conducted to encourage researchers of NE extraction and to provide its common evaluation basis.",
        "In Japanese NE extraction, it is quite common to apply morphological analysis as preprocessing stage which segments a sentence into a sequence of morphemes.",
        "After that, either a pattern matcher based on hand-crafted rules or a statistical chun-ker is employed to extract NEs from a sequence of morphemes.",
        "Various machine learning approaches such as maximum entropy(Uchimoto et al., 2000), decision list(Sassano and Utsuro, 2000; Isozaki, 2001), and Support Vector Machine(Yamada et al., 2002; Isozaki and Kazawa, 2002) were investigated for extracting NEs.",
        "These researches show that machine learning approaches are more promising than approaches based on hand-crafted rules if a large corpus whose NEs are properly annotated is available as training data.",
        "However, it is difficult to obtain an enough corpus in the real world because of the increasing number of NE types and the increasing time gap between the training corpus and the test corpus.",
        "There is the increasing number of NE types like personal names and company names in the real world.",
        "For example, a large database of organization names(Nichigai Associates, 2007) already contains 171,708 types and is still increasing.",
        "Because annotation work is quite expensive, the annotated corpus may become obsolete in a short period of time.",
        "Both of two factors expands the difference of NE distribution between the training corpus and the test corpus, and it may decrease the performance of the NE tagger as shown in (Mota and Grishman, 2008).",
        "Therefore, a robust method to extract NEs which do not occur or occur few times in a training corpus is necessary.",
        "This paper focuses on the change of NEs over time and its influence on the performance of the NE tagger.",
        "First, we annotate NEs in Mainichi Newspaper articles published in 1996, 1997, 1998 and 2005, and analyze NEs which appear in these texts and an existing corpus.",
        "It consists of Mainichi Newspaper articles published in 1995, thus, we get an annotated corpus that spans 10 years.",
        "This analysis reveals that the number of NE types and the number of NE tokens are almost steady over time and that that 70 ~ 80% of NE types in a certain year occur in the articles published either in its succeeding year or in its preceding year.",
        "These facts lead that 20 ~ 30% of named entity types are replaced with new ones every year.",
        "The experiment against these corpora shows that the traditional supervised method is fragile against the change of NE types and that our proposing semi-supervised method which combines a small annotated corpus and a large unannotated corpus for training is robust against the change of NE types."
      ]
    },
    {
      "heading": "2. Analysis of Changing Named Entities",
      "text": [
        "The task of NE extraction of the IREX workshop (Sekine and Eriguchi, 2000) is to recognize eight NE categories in Table 1.",
        "The organizer of the IREX workshop provided a training corpus (henceforth, denoted as IREX corpus), which consists of 1,174 Mainichi Newspaper articles published from January 1st 1995 to 10th which include 18,677 NEs.",
        "In the Japanese language, no other corpora whose NEs are annotated are publicly available as far as we know.",
        "Thus, IREX corpus is referred as a golden sample of NE distribution in this paper.",
        "The most homogeneous texts which are written in different days are desirable, to explore the influence of the text time frame on NE distribution.",
        "Because IREX corpus is referred as a golden sample in this paper, Mainichi Newspaper articles written in different years than IREX corpus is suitable.",
        "Thus, ordinal days of June and October in 1996, 1997, 1998 and 2005 are randomly selected as sampling days.",
        "Because annotating work is too expensive for us to annotate all articles published in sampling days, thirty percent of them are only annotated.",
        "Each article of Mainichi Newspaper belongs into 16 categories like front page articles, international stories, economical stories, political stories, editorial columns, and human interest stories.",
        "Because these categories may influence to NE distribution, it is important to keep the proportion of categories in the sampled texts to the proportion in the whole newspaper, in order to investigate NE distribution over the whole newspaper.",
        "Therefore, thirty percent articles of each category published at sampling days are randomly selected and annotated in accordance with the IREX regulation.",
        "NE Categories",
        "Frequency (%)",
        "ARTIFACT",
        "747",
        "(4.0)",
        "DATE",
        "3567",
        "(19.1)",
        "LOCATION",
        "5463",
        "(29.2)",
        "MONEY",
        "390",
        "(2.1)",
        "ORGANIZATION",
        "3676",
        "(19.7)",
        "PERCENT",
        "492",
        "(2.6)",
        "PERSON",
        "3840",
        "(20.6)",
        "TIME",
        "502",
        "(2.7)",
        "Total",
        "18677",
        "Published date of",
        "Published year of unannotated corpus U lish date is January 1st to 10th in 1995) is corresponding to IREX corpus, and other columns are corresponding to articles annotated by ourselves.",
        "Table 2 illustrates that the normalized number of NEtypes and the normalized numberofNEtokens are almost steady over time.",
        "Figure 1 shows the distributions of NE categories for sampling texts and that there is no significant difference between them.",
        "We also investigate the relation of the time gap between texts and NE types which appear in these texts.",
        "The overlap ratio of NE types between the annotated corpus A published in the year Ya and the annotated corpus B published in the year Ybwas defined in (Mota and Grishman, 2008) as follows",
        "type.overlap(A, B) = ^RTB ,",
        "where Ta and TB are lists of NE types which appear in A and B respectively.",
        "However, it is impossible to compute reliable type-overlap in our research because enough annotated texts are unavailable.",
        "As an alternative of type-overlap, the overlap ratio of NE types between the annotated corpus A and the unannotated corpus U published in the year Yjj is defined as follows where 5(s,U) is the binary function to indicate whether the string s occurs in the string U or not.",
        "Table 3 shows string .ratio values of annotated texts.",
        "It shows that 70 – 80% of Ta appear in the preceding year of Ya, and that 70 – 80% of Ta appear in the succeeding year of Ya.",
        "Figure 2 shows the relation between the time gap Yj – Ya and stringjratio(A,U).",
        "Suppose that all NEs are independent and equivalent on their occurrence probability and that stringjratio(A, U) is equal to 0.8 when the time gap Yj – Ya is equal to one.",
        "When the time gap Yjji – Ya is equal to two years, although this assumption leads that string.ratio(A, U') will be equal to 0.64, stringjratio(A, U') in Figure 2 is greater than 0.7.",
        "This suggests that NEs are not equivalent on their occurrence probability.",
        "And more, Table 4 shows that the longer time span of the annotated text increases the number of NE types.",
        "These facts lead that some NEs are shortlived and superseded by other new NEs."
      ]
    },
    {
      "heading": "3. Robust Extraction of Changing Named Entities",
      "text": [
        "It is infeasible to prepare a large annotated corpus which covers all increasing NEs.",
        "A semi-supervised learning approach which combines a small annotated corpus and a large unannotated corpus for training is promising to cope this problem.",
        "(Miller et al., 2004) proposed the method using classes which are assigned to words based on the class language model built from a large unannotated corpus.",
        "(Ando and Zhang, 2005) pro(Values in brackets are rates of increase comparing to 1995.)",
        "posed the method using thousands of automatically generated auxiliary classification problems on an unannotated corpus.",
        "(?)",
        "proposed the semi-supervised discriminative model whose potential function can treat both an annotated corpus and an unannotated corpus.",
        "Published date",
        "1995",
        "1996",
        "1997",
        "1998",
        "2005",
        "Jan. 1~10",
        "Jun.",
        "5",
        "Oct. 15",
        "Jun.",
        "10",
        "Oct. 7",
        "Jun.",
        "8",
        "Oct. 21",
        "Jun.",
        "23",
        "Oct. 12",
        "# of articles",
        "1174",
        "120",
        "133",
        "106",
        "117",
        "96",
        "126",
        "90",
        "99",
        "# of characters",
        "407SS1",
        "60790",
        "53625",
        "46653",
        "50362",
        "51006",
        "67744",
        "49038",
        "44344",
        "# of NE types",
        "6979",
        "1446",
        "1656",
        "1276",
        "1350",
        "1190",
        "1226",
        "1230",
        "1113",
        "# of NE tokens",
        "18677",
        "2519",
        "2652",
        "2145",
        "2403",
        "2126",
        "2052",
        "1902",
        "2007",
        "# of NE types / # of characters",
        "0.0171",
        "0.0238",
        "0.0309",
        "0.0274",
        "0.0268",
        "0.0233",
        "0.0181",
        "0.0251",
        "0.0251",
        "# of NE tokens / # of characters",
        "0.0458",
        "0.0414",
        "0.0495",
        "0.0460",
        "0.0477",
        "0.0417",
        "0.0303",
        "0.0388",
        "0.0453",
        "annotated corpus A",
        "1993",
        "1994",
        "1995",
        "1996",
        "1997",
        "1998",
        "1999",
        "Jan. 1-10(1995)",
        "73.2%",
        "78.6%",
        " – ",
        "74.4%",
        "65.0%",
        "64.4%",
        "63.3%",
        "Jun.",
        "6, Oct. 15 (1996)",
        "67.2%",
        "71.7%",
        "72.2%",
        " – ",
        "77.3%",
        "76.0%",
        "75.1%",
        "Jun.",
        "6, Oct. 7 (1997)",
        "71.2%",
        "73.4%",
        "74.4%",
        "78.6%",
        " – ",
        "80.8%",
        "78.6%",
        "Jun.",
        "8, Oct. 21 (1998)",
        "72.5%",
        "74.6%",
        "76.2%",
        "79.7%",
        "82.7%",
        " – ",
        "84.0%",
        "Jun.",
        "23, Oct. 12 (2005)",
        "62.3%",
        "64.1%",
        "66.8%",
        "68.7%",
        "71.2%",
        "72.9%",
        "73.8%",
        "In this paper, the method proposed by (Tsuchiya et al., 2008) is employed, because its implementation is quite easy.",
        "It consists of two steps.",
        "The first step is to assign the most similar and familiar morpheme to each unfamiliar morpheme based on their context vectors calculated from a large unannotated corpus.",
        "The second step is to employ Conditional Random Fields(CRF)(Lafferty et al., 2001) using both features of original morphemes and features of similar morphemes.",
        "This section gives the detail of this method.",
        "It is quite common that the task of extracting Japanese NEs from a sentence is formalized as a chunking problem against a sequence of morphemes.",
        "For representing proper chunks, we employ IOB2 representation, one of representations which have been studied well in various chunking tasks of NLP (Tjong Kim Sang, 1999).",
        "This representation uses the following three labels.",
        "B Current token is the beginning of a chunk.",
        "I Current token is a middle or the end of a chunk consisting of more than one token.",
        "O Current token is outside of any chunk.",
        "Actually, we prepare the 16 derived labels from the label B and the label I for eight NE categories, in order to distinguish them.",
        "When the task of extracting Japanese NEs from a sentence is formalized as a chunking problem of a sequence of morphemes, the segmentation boundary problem arises as widely known.",
        "For example, the NE definition of IREX tells that a Chinese character \"M (bei)\" must be extracted as an NE means America from a morpheme \"MM (hou-bei)\" which means visiting America.",
        "A naive chunker using a morpheme as a chunking unit cannot extract such a kind of NEs.",
        "In order to cope this problem, (Uchimoto et al., 2000) proposed employing translation rules to modify problematic morphemes, and (Asahara and Matsumoto, 2003; Nakano and Hirai, 2004) formalized the task ofex-tracting NEs as a chunking problem of a sequence of characters instead of a sequence of morphemes.",
        "In this paper, we keep the naive formalization, because it is still enough to analyze the influence of the text time frame.",
        "1995",
        "1995-1996",
        "1995-1997",
        "1995-1998",
        "1995-2005",
        "ARTIFACT DATE LOCATION MONEY",
        "ORGANIZATION PERCENT PERSON TIME",
        "541 (1.00)",
        "950(1.00) 1403 (1.00)",
        "301 (1.00) 1487 (1.00)",
        "249 (1.00) 1842(1.00)",
        "206(1.00)",
        "743 (1.37) 1147 (1.21) 1914 (1.36)",
        "492 (1.63) 1890 (1.27)",
        "319 (1.28) 2540 (1.38)",
        "257 (1.25)",
        "862 (1.59) 1326 (1.40) 2214(1.58)",
        "570 (1.89) 2280 (1.53)",
        "353 (1.42) 3175 (1.72)",
        "291 (1.41)",
        "1025 (1.89) 1461 (1.54) 2495 (1.78)",
        "656(2.18) 2566(1.73)",
        "401 (1.61) 3683 (2.00)",
        "314(1.52)",
        "1169 (2.16) 1583 (1.67) 2692(1.92)",
        "749 (2.49) 2893 (1.95)",
        "443 (1.78) 4243 (2.30)",
        "332(1.61)",
        "Total",
        "6979 (1.00)",
        "9302 (1.33)",
        "11071 (1.59)",
        "12601 (1.81)",
        "14104 (2.02)",
        "Morpheme Feature",
        "Similar Morpheme Feature",
        "Character",
        "Type Feature",
        "Chunk Label",
        "(English translation)",
        "POS",
        "(English translation)",
        "POS",
        "^0 (kyou)",
        "(today)",
        "Noun-Adverbial",
        "^0 (kyou)",
        "(today)",
        "Noun-Adverbial",
        "<i",
        "G, G, G, G, G)",
        "O",
        "D (no)",
        "gen",
        "Particle",
        "D (no)",
        "gen",
        "Particle",
        "<G",
        "1, G, G, G, g)",
        "O",
        "ftfà (Ishikari)",
        "(Ishikari)",
        "Noun-Proper",
        "HÉ (Kantou)",
        "(Kantou)",
        "Noun-Proper",
        "(1",
        "G, G, G, G, g)",
        "B-LOCATION",
        "¥W (heiya)",
        "(plain)",
        "Noun-Generic",
        "¥W (heiya)",
        "(plain)",
        "Noun-Generic",
        "(1",
        "G, G, G, G, g)",
        "I-LOCATION",
        "D (no)",
        "gen",
        "Particle",
        "D (no)",
        "gen",
        "Particle",
        "(G",
        "1, G, G, G, g)",
        "O",
        "(tenki)",
        "(weather)",
        "Noun-Generic",
        "(tenki)",
        "(weather)",
        "Noun-Generic",
        "(1",
        "G, G, G, G, g)",
        "O",
        "i (ha)",
        "top",
        "Particle",
        "i (ha)",
        "top",
        "Particle",
        "(G",
        "1, G, G, G, g)",
        "O",
        "Hftl (hare)",
        "(fine)",
        "Noun-Generic",
        "Hftl (hare)",
        "(fine)",
        "Noun-Generic",
        "(1",
        "1, G, G, G, g)",
        "O",
        "A context vector Vm of a morpheme m is a vector consisting of frequencies of all possible unigrams and bigrams, where M = {m0, m1,... ,mN} is a set of all morphemes of the unannotated corpus, f (mi, mj) is a frequency that a sequence of a morpheme miand a morpheme mj occurs in the unannotated corpus, and f (mi, mj, mk) is a frequency that a sequence of morphemes mi, mj and mk occurs in the unannotated corpus.",
        "Suppose an unfamiliar morpheme mu £ M n Mp, where Mp is a set of familiar morphemes that occur frequently in the annotated corpus.",
        "The most similar morpheme mhu to the morpheme mumeasured with their context vectors is given by the following equation, where sim(Vi, Vj) is a similarity function between context vectors.",
        "In this paper, the cosine function is employed as it.",
        "The feature set Fi at i-th position is defined as a tuple of the morpheme feature MF(mi) of the i-th morpheme mi, the similar morpheme feature SF (mi), and the character type feature CF (mi).",
        "The morpheme feature MF(mi) is a pair of the surface string and the part-of-speech of mi.",
        "The similar morpheme feature SF(mi) is defined as if mi e M n MFotherwise where mi is the most similar and familiar morpheme to mi given by Eqn.",
        "1.",
        "The character type feature CF(mi) is a set of six binary flags to indicate that the surface string of mi contains a Chinese character, a hiragana character, a katakana",
        " – > Chunking Direction – > Feature set Fi_2 Fi_i Fi Fm Fi+2 Chunk label ci_2 ci_1 Yci character, an English alphabet, a number and an other character respectively.",
        "When we identify the chunk label ci for the ith morpheme mi, the surrounding five feature sets Fi_2, Fi_i, Fi, Fi+i, Fi+2 and the preceding two chunk labels ci_2, ci_i are referred as shown in Figure 4.",
        "Figure 3 shows an example of training instance of the proposed method for the sentence \"^~B (kyou) © (no) ^B¥f (Ishikari) ^0 (heiya) © (no) ;^xt (tenki) It (ha) Hftl (hare)\" which means \"It is fine at Ishikari-plain, today\".",
        "(Kantou)\" is assigned as the most similar and familiar morpheme to \"^B^f (Ishikari)\" which is unfamiliar in the training corpus.",
        "Figure 5 compares performances of the proposed method and the baseline method over the test texts which were published in 1996, 1997, 1998 and 2005.",
        "The proposed method combines a small annotated corpus and a large unannotated corpus as already described.",
        "This experiment refers IREX corpus as a small annotated corpus, and refers Mainichi Newspaper articles published from 1993 to the preceding year of the test text published year as a large unannotated corpus.",
        "For example, when the test text was published in 1998, Mainichi Newspaper articles published from 1993 to 1997 are used.",
        "The baseline method is trained from IREX corpus with CRF.",
        "But, it uses only MF and CF as features, and does not use SF.",
        "Figure 5 illustrates two points: (1) the proposed method outperforms the baseline method consistently, (2) the baseline method is fragile to changing of test texts.",
        "Figure 6 shows the relation between the performance of the proposed method and the size of unannotated corpus against the test corpus published in 2005.",
        "It reveals that that increasing unan-notated corpus size improves the performance of the proposed method."
      ]
    },
    {
      "heading": "4. Conclusion",
      "text": [
        "In this paper, we explored the change of NE distribution over time and its influence on the performance of the NE tagger.",
        "First, we annotated Mainichi Newspaper articles published in 1996, 1997, 1998 and 2005, and analyzed NEs which appear in these texts and IREX corpus which consists of Mainichi Newspaper articles published in 1995.",
        "This analysis illustrated that the number of NE types and the number of NE tokens are almost steady over time, and that 70 – 80% of NE types seen in a certain year occur in the texts published either in its succeeding year or in its preceding year.",
        "The experiment against these texts showed that our proposing semi-supervised NE tagger works robustly although the traditional supervised NE tagger is fragile against the change of NE types.",
        "Based on the results described in this paper, we will investigate the relation between the performance of NE tagger and the similarity of its training corpus and its test corpus."
      ]
    }
  ]
}
