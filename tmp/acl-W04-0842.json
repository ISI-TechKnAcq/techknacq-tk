{
  "info": {
    "authors": [
      "Antonio Molina",
      "Ferran Pla",
      "Encarna Segarra"
    ],
    "book": "SENSEVAL International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",
    "id": "acl-W04-0842",
    "title": "WSD System Based on Specialized Hidden Markov Model (Upv-Shmm-Eaw)",
    "url": "https://aclweb.org/anthology/W04-0842",
    "year": 2004
  },
  "references": [
    "acl-W97-0811"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We present a supervised approach to Word Sense Disambiguation (WSD) based on Specialized Hidden Markov Models.",
        "We used as training data the Semcor corpus and the test data set provided by Senseval 2 competition and as dictionary the Word-net 1.6.",
        "We evaluated our system on the English all-word task of the Senseval-3 competition."
      ]
    },
    {
      "heading": "1 Description of the WSD System",
      "text": [
        "We consider WSD to be a tagging problem (Molina et al., 2002a).",
        "The tagging process can be formulated as a maximization problem using the Hidden Markov Model (HMM) formalism.",
        "Let O be the set of output tags considered, and I, the input vocabulary of the application.",
        "Given an input sentence, I = i 1, ... , iT, where i j E I, the tagging process consists of finding the sequence of tags (O = o1, ... , oT, where oj E O) of maximum probability on the model, that is:",
        "Due to the fact that the probability P(I) is a constant that can be ignored in the maximization process, the problem is reduced to maximize the numerator of equation 1.",
        "To solve this equation, the Markov assumptions should be made in order to simplify the problem.",
        "For a first-order HMM, the problem is reduced to solve the following equation:",
        "The parameters of equation 2 can be represented as a first-order HMM where each state corresponds to an output tag oj, P(oj1oj_1) represent the transition probabilities between states and P(ij1oj) represent the probability of emission of input symbols, ij, in every state, oj.",
        "The parameters of this model are estimated by maximum likelihood from semantic annotated corpora using an appropriate smoothing method (linear interpolation in our work).",
        "Different kinds of available linguistic information can be useful to solve WSD.",
        "The training corpus we used provides as input features: words (W), lemmas (L) and the corresponding POS tags (P); and it also provides as output tags the WordNet senses.",
        "WordNet senses can be represented by a sense key which has the form lemma%lex sense.",
        "The high number of different sense keys and the scarce annotated training data make difficult the estimation of the models.",
        "In order to alleviate this sparness problem we considered the lex sense field (S) of the sense key associated to each lemma as the semantic tag.",
        "This assumption reduces the size of the output tag set and it does not lead to any loss of information because we can obtain the sense key by concatenating the lemma to the output tag.",
        "Therefore, in our system the input vocabulary is I = W x L x P, and the output vocabulary is O = S. In order to incorporate this kind of information to the model we used Specialized HMM (SHMM) (Molina et al., 2002b).",
        "This technique has been successfully applied to other disambiguation tasks such as part-of-speech tagging (Pla and Molina, 2004) and shallow parsing (Molina and Pla, 2002).",
        "Other HMM-based approaches have also been applied to WSD.",
        "In (Segond et al., 1997), they estimated a bigram model of ambiguity classes from the SemCor corpus for the task of disambiguating the semantic categories corresponding to the lexicographer level.",
        "These semantic categories are codified into the lex sense field.",
        "A second-order HMM was used in (Loupy et al., 1998) in a two-step strategy.",
        "First, they determined the semantic category associated to a word.",
        "Then, they assigned the most probable sense according to the word and the semantic category.",
        "A SHMM consists of changing the topology of the HMM in order to get a more accurate model",
        "which includes more information.",
        "This is done by means of an initial step previous to the learning process.",
        "It consists of the redefinition of the input vocabulary and the output tags.",
        "This redefinition is done by means of two processes which transform the training set: the selection process, which is applied to the input vocabulary, and the specialization process, which redefines the output tags."
      ]
    },
    {
      "heading": "1.1 Selection process",
      "text": [
        "The aim of the selection process is to choose which input features are relevant to the task.",
        "This process applies a determined selection criterion to I that produces a new input vocabulary (�I).",
        "This new vocabulary consists of the concatenation of the relevant input features selected.",
        "Taking into account the input vocabulary I = W x L x P, some selection criteria could be as follows: to consider only the word (wi), to consider only the lemma (li), to consider the concatenation of the word and its POS' (wi • pi), and to consider the concatenation of the lemma and its POS (li • pi).",
        "Moreover, different criteria can be applied depending on the kind of word (e.g. distinguishing content and non-content words).",
        "For example, for the input word interest, which has an entry in WordNet and whose lemma and POS are interest and NN (common noun) respectively, the input considered could be interest•1.",
        "For a non-content word, such as the article a, we could consider only its lemma a as input."
      ]
    },
    {
      "heading": "1.2 Specialization process",
      "text": [
        "The specialization process allows for the codification of certain information into the context (that is, into the states of the model).",
        "It consists of redefining the output tag set by adding information from the input.",
        "This redefinition produces some changes in the model topology, in order to allow the model to better capture some contextual restrictions and to get a more accurate model.",
        "The application of a specialization criterion to O produces a new output tag set (6), whose elements are the result of the concatenation of some relevant input features to the original output tags.",
        "Taking into account that the POS input feature is already codified in the lex sense field, only words or lemmas can be considered in the specialization process (wi• lex sensei or li• lex sensei).",
        "This specialization can be total or partial depending on whether we specialize the model with all the elements of a feature or only with a subset of them.",
        "'We mapped the POS tags to the following tags: 1 for nouns, 2 for verbs, 3 for adjectives and 4 for adverbs.",
        "For instance, the input token interest•1 is tagged with the semantic tag 1:09:00:: in the training data set.",
        "If we estimate that the lemma interest should specialize the model, then the semantic tag is redefined as interest•1: 09: 00::.",
        "Non-content words, that share the same output tag (the symbol notag in our system), could be also considered to specialize the model.",
        "For example, for the word a, the specialized output tag associated could be a•notag."
      ]
    },
    {
      "heading": "1.3 System scheme",
      "text": [
        "The disambiguation process is presented in (Figure 1).",
        "First, the original input sentence (I) is processed in order to select its relevant features, providing the input sentence (�I).",
        "Then, the semantic tagging is carried out through the Viterbi algorithm using the estimated SHMM.",
        "WordNet is used to know all the possible semantic tags associated to an input word.",
        "If the input word is unknown for the model (i.e., the word has not been seen in the training data set) the system takes the first sense provided by WordNet.",
        "The learning process of a SHMM is similar to the learning of a basic HMM.",
        "The only difference is that SHMM are based on an appropriate definition of the input information to the learning process.",
        "This information consists of the input features (words, lemmas and POS tags) and the output tag set (senses) provided by the training corpus.",
        "A SHMM is built according to the following steps (see Figure 2):",
        "1.",
        "To define which available input information is relevant to the task (selection criterion).",
        "2.",
        "To define which input features are relevant to redefine or specialize the output tag set (specialization criterion).",
        "3.",
        "To apply the chosen criteria to the original training data set to produce a new one.",
        "4.",
        "To learn a model from the new training data set.",
        "5.",
        "To disambiguate a development data set using that model.",
        "6.",
        "To evaluate the output of the WSD system in order to compare the behavior of the selected criteria on the development set.",
        "These steps are done using different combinations of input features in order to determine the best selection criterion and the best total specialization criterion.",
        "Once these criteria are determined, some partial specializations are tested in order to improve the performance of the model."
      ]
    },
    {
      "heading": "2 Experimental Work",
      "text": [
        "We used as training data the part of the SemCor corpus which is semantically annotated and supervised for nouns, verbs, adjectives and adverbs (that is, the files contained in the Brown1 and the Brown2 folders of SemCor corpus), and the test data set provided by Senseval-2.",
        "We used 10% of the training corpus as a development data set in order to determine the best selection and specialization criteria.",
        "In the experiments, we used WordNet 1.6 as a dictionary which supplies all the possible semantic senses for a given word.",
        "Our system disambiguated all the polysemic lemmas, that is, the coverage of our system was 100% (therefore, precision and recall were the same).",
        "For unknown words (words that did not appear in the training data set), we assigned the first sense in WordNet.",
        "The best selection criterion determined from the experimental work on the development set is as follows: if a word wi has a sense in WordNet we concatenate the lemma (li) and the POS (pi) associated to the word (wi) as input vocabulary.",
        "For non-content words, we only consider their lemma (li) as input.",
        "The best specialization criterion consisted of selecting the lemmas whose frequency in the training data set was higher than a certain threshold (other specialization criteria could have been chosen, but frequency criterion usually worked well in other tasks as we reported in (Molina and Pla, 2002)).",
        "In order to determine which threshold maximized the performance of the model, we conducted a tuning experiment on the development set.",
        "The best performance was obtained using the lemmas whose frequency was higher than 20 (about 1,600 lemmas).",
        "The performance of our system on the Senseval 3 data test set was 60.9% of precision and recall."
      ]
    },
    {
      "heading": "3 Concluding remarks",
      "text": [
        "In our WSD system, the choice of the best specialization criterion is based on the results of the system on the development set.",
        "The tuning experiments included totally specialized models, which is equivalent to consider the sense keys as the output vocabulary, non-specialized models, which is equivalent to consider the lex senses as the output vocabulary, and partially specialized models using different sets of lemmas.",
        "For the best specialization criterion, we have not studied the linguistic characteristics of the different groups of synsets associated to the same lex sense for non-specialized output tags.",
        "We think that we could improve our WSD system through a more adequate definition of the selection and specialization criteria.",
        "This definition could be done using semantic knowledge about the domain of the task."
      ]
    },
    {
      "heading": "4 Acknowledgments",
      "text": [
        "This work has been supported by the Spanish research projects CICYT TIC2003-07158-C04-03 and TIC2003-08681-C02-02."
      ]
    }
  ]
}
