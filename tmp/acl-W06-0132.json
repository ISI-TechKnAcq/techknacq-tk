{
  "info": {
    "authors": [
      "Yuanyong Feng",
      "Le Sun",
      "Yuanhua Lv"
    ],
    "book": "SIGHAN Workshop on Chinese Language Processing",
    "id": "acl-W06-0132",
    "title": "Chinese Word Segmentation and Named Entity Recognition Based on Conditional Random Fields Models",
    "url": "https://aclweb.org/anthology/W06-0132",
    "year": 2006
  },
  "references": [],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper mainly describes a Chinese named entity recognition (NER) system NER@ISCAS, which integrates text, part-of-speech and a small-vocabulary-character-lists feature for MSRA NER open track under the framework of Conditional Random Fields (CRFs) model.",
        "The techniques used for the close NER and word segmentation tracks are also presented."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The system NER@ISCAS is designed under the Conditional Random Fields (CRFs.",
        "Lafferty et al., 2001) framework.",
        "It integrates multiple features based on single Chinese character or space separated ASCII words.",
        "The early designed system (Feng et al., 2005) is used for the MSRA NER open track this year.",
        "The output of an external part-of-speech tagging tool and some carefully collected small-scale-character-lists are used as outer knowledge.",
        "The close word segmentation and named entity recognition tracks are also based on this system by some adjustments.",
        "The remaining of this paper is organized as follows.",
        "Section 2 introduces Conditional Random Fields model.",
        "Section 3 presents the details of our system on Chinese NER integrating multiple features.",
        "Section 4 describes the features extraction for close track.",
        "Section 5 gives the evaluation results.",
        "We end our paper with some conclusions and future works."
      ]
    },
    {
      "heading": "2 Conditional Random Fields Model",
      "text": [
        "Conditional random fields are undirected graphical models for calculating the conditional probability for output vertices based on input ones.",
        "While sharing the same exponential form with maximum entropy models, they have more efficient procedures for complete, non-greedy finite-state inference and training.",
        "Given an observation sequence o=<o1, o2, ..., oT>, linear-chain CRFs model based on the assumption of first order Markov chains defines the corresponding state sequence s' probability as follows (Lafferty et al., 2001):",
        "Where A is the model parameter set, Zo is the normalization factor over all state sequences, fk is an arbitrary feature function, and Ak is the learned feature weight.",
        "A feature function defines its value to be 0 in most cases, and to be 1 in some designated cases.",
        "For example, the value of a feature named “MAYBE-SURNAME” is 1 if and only if st-1 is OTHER, st is PER, and the t-th character in o is a common-surname.",
        "The inference and training procedures of CRFs can be derived directly from those equivalences in HMM.",
        "For instance, the forward variable αt(si) defines the probability that state at time t being si at time t given the observation sequence o.",
        "Assumed that we know the probabilities of each possible value si for the beginning state α0(si), then we have",
        "In similar ways, we can obtain the backward variables and Baum-Welch algorithm."
      ]
    },
    {
      "heading": "3 Chinese NER Using CRFs Model Integrating Multiple Features for Open Track",
      "text": [
        "In our system the text feature, part-of-speech (POS) feature, and small-vocabulary-character-lists (SVCL) feature are combined under a unified CRFs framework.",
        "Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 181–184, Sydney, July 2006. c�2006 Association for Computational Linguistics The text feature includes single Chinese character, some continuous digits or letters.",
        "POS feature is an important feature which carries some syntactic information.",
        "Our POS tag set follows the criterion of modern Chinese corpora construction (Yu, 1999), which contains 39 tags.",
        "The last feature is based on lists.",
        "We first list all digits and English letters in Chinese.",
        "Then most frequently used character feature in Chinese NER are collected, including 100 single character surnames, 100 location tail characters, and 40 organization tail characters.",
        "The total number of these items in our lists is less than 600.",
        "The lists altogether make up a list feature (SVCL).",
        "Some examples of this list are given in Table 1.",
        "Each token is presented by its feature vector, which is combined by these features we just discussed.",
        "Once all token feature (Maybe including context features) values are determined, an observation sequence is feed into the model.",
        "Each token state is a combination of the type of the named entity it belongs to and the boundary type it locates within.",
        "The entity types are person name (PER), location name (LOC), organization name (ORG), date expression (DAT), time expression (TIM), numeric expression (NUM), and not named entity (OTH).",
        "The boundary types are simply Beginning, Inside, and Outside (BIO)."
      ]
    },
    {
      "heading": "4 Feature Extraction for Close Tracks",
      "text": [
        "In close tracks, only character and word list features which are extracted from training data are applied for word segmentation.",
        "In NER track we also include a named entity list extracted from the training data.",
        "To extract the list feature, we simply search each text string among the list items in maximum length forward way.",
        "Taking the word segmentation task for instance, when a text string c1c2...cn is given, we tag each character into a BIO-WL style.",
        "If cici+1...cj matches an item I of length j-i+1 and no other item I’ of length k (k>j-i+1) in the list matches cici+1 ... cj ... ck+i-1, then the characters are tagged as follows: ci ci+1 ... cj B-WL I-WL ... I-WL If no item in the list matches head subpart of the string, then ci is tagged as 0.",
        "The tagging operation iterates on the remaining part until all characters are tagged."
      ]
    },
    {
      "heading": "5 Evaluation 5.1 Results",
      "text": [
        "The system for our MSRA NER open track submission has some bugs and was trained on a much smaller training data set than the full set the organizer provided.",
        "The results are very low, see Table 2:",
        "When we fixed the bug and retrained on the full training corpus, the result comes out to be as follows:",
        "All the submissions on close tracks are trained on 80% of the training corpora, the remaining 20% parts are used for development.",
        "The results are shown in Table 4 and Table 5:",
        "The reason for low measure on MSRA NER track exists in that we chose a much smaller training data file encoded in CP936 (about 7% of the full data set).",
        "This file may be an incomplete output when the organizer transfers from another encoding scheme."
      ]
    },
    {
      "heading": "5.2 Errors from NER Track",
      "text": [
        "The NER errors in our system are mainly as follows:",
        "• Abbreviations",
        "Abbreviations are very common among the errors.",
        "Among them, a significant part of abbreviations are mentioned before their corresponding full names.",
        "Some common abbreviations has no corresponding full names appeared in document.",
        "Here are some examples: R1: }�0ri�KFHWUJ � �k A A �,[171 C��1 C�����fff.j ORG ] [�kr7 GPE].",
        "[�� GPE]&*M5ii T HA�...",
        "In current system, the recognition is fully depended on the linear-chain CRFs model, which is heavily based on local window observation features; no abbreviation list or special abbreviation",
        "recognition involved.",
        "Because lack of constraint checking on distant entity mentions, the system fails to catch the interaction among similar text fragments cross sentences.",
        "• Concatenated Names",
        "For many reasons, Chinese names in titles and some sentences, especially in news, are not separated.",
        "The system often fails to judge the right boundaries and the reasonable type classification.",
        "For example:",
        "• Hints",
        "Though it helps to recognize an entity at most cases, the small-vocabulary-list hint feature may recommend a wrong decision sometimes.",
        "For instance, common surname character “T-” in the following sentence is wrongly labeled when no word segmentation information given: R: [�ea LOC] a [T- �WT����� WT PER] K: [�ea LOC] a T-[�WT����� WT PER] Other errors of this type may result from failing to identify verbs and prepositions, such as: R: [rP�rP� RC rP�RCk5+�0 ORG ] k 1 R iW1... nr-[RCk5 ORG ] k 1OM ��...",
        "• Other Types:",
        "R: 1JJMff Eh _.",
        "'Wft ��OM#4Eito K:��JMff [ Eh�_.",
        "'Wft PER]��OM#4E ito R: 11 i#VU1_4 Q A k 1��",
        "K: Sri __H14 [ Q LOCI [M LOCI 0 ��"
      ]
    },
    {
      "heading": "6 Conclusions and Future Work",
      "text": [
        "We mainly described a Chinese named entity recognition system NER@ISCAS, which integrates text, part-of-speech and a small-vocabulary-character-lists feature for MSRA NER open track under the framework of Conditional Random Fields (CRFs) model.",
        "Although it provides a unified framework to integrate multiple flexible features, and to achieve global optimization on input text sequence, the popular linear chained Conditional Random Fields model often fails to catch semantic relations among reoccurred mentions and adjoining entities in a catenation structure.",
        "The situations containing exact reoccurrence and shortened occurrence enlighten us to take more effort on feature engineering or post processing on abbreviations / recurrence recognition.",
        "Another effort may be poured on the common patterns, such as paraphrase, counting, and constraints on Chinese person name lengths.",
        "From current point of view, enriching the hint lists is also desirable."
      ]
    },
    {
      "heading": "Acknowledgment",
      "text": [
        "This work is supported by the National Science Fund of China under contract 60203007."
      ]
    }
  ]
}
