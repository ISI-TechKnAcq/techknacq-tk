{
  "info": {
    "authors": [
      "Miao Chen"
    ],
    "book": "NAACL",
    "id": "acl-N12-2008",
    "title": "Using Ontology-based Approaches to Representing Speech Transcripts for Automated Speech Scoring",
    "url": "https://aclweb.org/anthology/N12-2008",
    "year": 2012
  },
  "references": [],
  "sections": [
    {
      "text": [
        "Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41?47, Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics Using Ontology-based Approaches to Representing Speech Transcripts for Automated Speech Scoring Miao Chen School of Information Studies Syracuse University Syracuse, NY 13244, USA mchen14@Syr.edu Abstract This paper presents a thesis proposal on approaches to automatically scoring non-native speech from second language tests.",
        "Current speech scoring systems assess speech by primarily using acoustic features such as fluency and pronunciation; however content features are barely involved.",
        "Motivated by this limita-tion, the study aims to investigate the use of content features in speech scoring systems.",
        "For content features, a central question is how speech content can be represented in appropriate means to facilitate automated speech scoring.",
        "The study proposes using ontology-based representation to perform concept level representation on speech transcripts, and furthermore the content features computed from ontology-based representation may facilitate speech scoring.",
        "One baseline and two ontolo-gy-based representations are compared in ex-periments.",
        "Preliminary results show that ontology-based representation slightly improves performance of one content feature for automated scoring over the baseline system."
      ]
    },
    {
      "heading": "1 Introduction With increasing number of language learners taking second language tests, the resulting responses add a huge burden to testing agencies, and thus automated scoring has become a necessity for efficiency and objectivity. Speaking, an important aspect for assessing second language speakers? proficiency, is selected as the context of the study.",
      "text": [
        "The general goal is to investigate new approaches to automatic scoring of second language speech.",
        "When giving a speaking test in computer-mediated environment, test-takers?",
        "responses are typically recorded as speech files.",
        "These files can be considered to contain two layers: sound and text.",
        "The sound is about the acoustic side of speech, whose features have been used to assess speaking proficiency in existing automated speech-scoring systems (Dodigovic, 2009; Zechner et al., 2009).",
        "However, the text side, which is about the content of speech, is by far not well addressed in scoring systems, mainly due to the imperfect performance of automatic speech recognizer systems.",
        "As content is an integral part of speech, adding content features to existing scoring systems may further enhance system performance, and thus this study aims to examine the use of content features in speech scoring systems.",
        "In order to acquire speech content, speech files need to be transcribed to text files, by human or Automatic Speech Recognition (ASR).",
        "The resulted text files, namely, speech transcripts, are to be processed to extract content features.",
        "Moreover, representation of text content (e.g. in vectors) is important because it is the prerequisite for computing content features and building speech scoring models.",
        "Therefore this study focuses on representing content of speech transcripts to facilitate automatic scoring of speech.",
        "Speech transcripts can be seen as a special type of text documents, and therefore document representation approaches shed light on representation of speech transcripts, such as Salton et al. (1975),",
        "Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a).",
        "On the other hand, written essays, the output of writing section of second language test, share great similarity with speech tran-scripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali & Burstein (2006), and Larkey & Croft (2003).",
        "Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector.",
        "These approaches exhibit two challenges: 1) meaningfulness of representation units.",
        "For example, synonymous words represent similar meaning and thus should be grouped as one representation unit.",
        "2) unknown terms.",
        "Since words or latent variables in the vector are from training corpus, if an unknown term occurs in the testing corpus then it is difficult to determine the importance of the term in the training corpus because there is no prior knowledge of it in the training corpus.",
        "Ontology concepts, representation units at the concept level, have been less employed in content representation.",
        "Hotho et al. (2003a) claim that ontology concepts can help reveal concepts and semantics in documents, and thus we hypothesize ontology-based representation may facilitate obtaining better content features for speech scoring.",
        "Ontologies can also complement the abovemen-tioned shortcomings of statistical and corpus based representations by providing meaningful representation units and reasoning power between con-cepts.",
        "The study compares baseline (statistical and corpus based) and ontology-based approaches.",
        "The criterion is representing the same speech transcripts using these approaches, computing content features based on the representations, and comparing performance of content features in predicting speaking proficiency.",
        "2 Related Work This section reviews work related to representation of speech transcripts, including document repre-sentation, essay scoring, and ontology-based representation in text processing.",
        "Document representation has been an important topic in research areas such as natural language processing, information retrieval, and text mining, in which a number of representation approaches have been proposed.",
        "The most common practice of text document representation is the Bag-Of-Words (BOW) ap-proach, illustrated in Salton et al. (1975).",
        "The basic idea is that a document can be represented as a vector of words, with each dimension of the vector standing for one single word.",
        "Besides using explicit words from documents, latent variables derived from document mining can be used for document representation as well, such as the Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) approaches.",
        "The representation units are latent concepts or topics and the documents are projected to the semantic space constructed from the latent concepts or topics (Deerwester et al., 1990; Blei, 2012).",
        "An important purpose of using the latent variables is to reduce dimensions in document representation and place documents in a more compact space.",
        "Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998).",
        "In the area of automatic essay scoring, essay content are represented to facilitate the scoring.",
        "The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali & Burstein, 2006) and the experimental system in Larkey & Croft (2003).",
        "Representation in the BETSY system (Bayesian Essay Test Scoring System) also involves words, such as frequency of content words, along with specific phrases (Dikli, 2006).",
        "The exemplar system employing LSA representation is the Intelligent Essay Assessor system, which performs LSA on training essays and then projects essays to the vector space of latent concepts (Landauer et al., 2003).",
        "Besides representation approaches, content feature computing in essay scoring is useful to content scoring of speech because they share great simi-larity.",
        "Content features can be derived by computing cosine similarity between essay vectors, such as in e-rater (Attali & Burstein, 2006) and Intelligent Essay Assessor (Landauer et al., 2003).",
        "The e-rater content feature computing is adopted in this study to compute content features of speech tran-scripts.",
        "As mentioned in section 1, ontologies can be used to complement the challenges of statistical",
        "uments are most similar to the test document as the feature value.",
        "The cos.w4 feature.",
        "This feature computes content similarity between the test document and the highest level training documents in vector space.",
        "Since score 4 is the highest level in our data set of spoken responses, we compute the cosine similarity between the test vector and the score level 4 vector as the feature value.",
        "Given a speech transcript from the test set, we first convert it to a vector using one of the representation approaches, and then compute the max.cos and cos.w4 feature values as its content features.",
        "3.4 Evaluation Representation approaches are evaluated based on their performance in predicting speaking proficiency of test takers.",
        "More specifically, a representation approach generates a vector representation using specific representation units (e.g. words, concepts); for each test transcript, two content features are computed based on the vector representa-tion; Pearson correlation r is computed between each content feature and speaking proficiency to indicate the predictiveness of the content feature resulting from a specific representation.",
        "Higher correlation indicates higher predictiveness on speaking proficiency.",
        "Lastly, we compare content feature correlations of different representation ap-proaches.",
        "We consider that the higher the correlation is, the better the representation approach is.",
        "4 Experiment Results In the preliminary stage, the BOW (baseline), ONTO-WordNet and OntoReason-WordNet (ex-perimental) approaches are implemented.",
        "Mean-while parameters are optimized to acquire the best parameter setup for each approach.",
        "Since the speech files are transcribed by both human and ASR, same experiments are run on both data sets to compare representation performance on different transcriptions.",
        "The correlations of the two content features to speaking proficiency are computed for each representation.",
        "Tables 2 and 3 show correlations of the max.cos and cos.w4 features respec-tively: For the max.cos feature, the average correlation of the ONTO-WordNet approach outperforms the BOW baseline slightly but the correlation drops dramatically when using the OntoReason-WordNet approach, for both the human and ASR transcripts.",
        "For the cos.w4 feature, the average correlation of the ONTO-WordNet approach outperforms the BOW, and the OntoReason-WordNet further outperforms the ONTO-WordNet approach, for both the human and ASR transcripts.",
        "It shows some evidence that ontology-based representation can improve performance of both content features; the ontology-based reasoning increases performance of the cos.w4 feature but decreases the max.cos feature correlation.",
        "Comparing the performance on human vs. ASR transcripts, the features extracted from the human transcripts exhibit better average correlations than the corresponding features from the ASR tran-scripts.",
        "The results also show that the correlation difference between human and ASR transcripts is moderate.",
        "It may indicate that the representation approaches can be employed on ASR transcripts to further automate the speech scoring process.",
        "Prompt Hum, BOW Hum, ONTO-WordNet Hum, Onto-Reason-WordNet ASR, BOW ASR, ONTO-WordNet ASR, Onto-Reason-WordNet A 0.320 0.333 0.038 0.293 0.286 0.014 B 0.348 0.352 0.350 0.308 0.338 0.339 C 0.366 0.373 0.074 0.396 0.386 0.106 D 0.343 0.323 0.265 0.309 0.309 0.265 Average 0.344 0.345 0.182 0.327 0.330 0.181 Table 2.",
        "Correlations between the max.cos feature and speaking proficiency (Hum=using human transcriptions; ASR=using ASR hypotheses).",
        "Prompt Hum, BOW Hum, ONTO-WordNet Hum, Onto-Reason-WordNet ASR, BOW ASR, ONTO-WordNet ASR, Onto-Reason-WordNet A 0.427 0.429 0.434 0.409 0.416 0.411 B 0.295 0.303 0.327 0.259 0.278 0.292 C 0.352 0.385 0.402 0.338 0.366 0.380 D 0.368 0.385 0.389 0.360 0.379 0.374 Average 0.361 0.376 0.388 0.342 0.360 0.364 Table 3.",
        "Correlations between the cos.w4 feature and speaking proficiency (Hum=using human transcriptions; ASR=using ASR hypotheses) 5 Future Work For future work, we will implement one more baseline (LSA) and two more ontology-based approaches (ONTO-Wikipedia and OntoReason-Wikipedia) and analyze their performance.",
        "Latent semantic analysis (LSA).",
        "LSA decomposes a term-by-document matrix generated from training transcripts to three sub-matrices.",
        "Then given a test transcript, documents can be projected to the latent semantic space based on the three sub-matrices.",
        "The rank k parameter needs to be decided as a parameter for dimensionality reduction purpose by tuning it on the training data.",
        "Using Wikipedia as another case for ontology, two more experimental approaches will be imple-mented, one for ontology-based representation and the other for ontology-based reasoning.",
        "ONTO-Wikipedia.",
        "Wikipedia concepts can be identified in transcripts in two ways: 1) directly find concepts in text window of 5 words; 2) convert a transcript in vectors of Wikipedia concepts using the Explicit Semantic Analysis method, which associates words to Wikipedia concepts and represents arbitrary text using the word-concept associations (Gabrilovich and Markovitch, 2007).",
        "OntoReason-Wikpedia.",
        "The concept similarity between Wikipedia concepts is obtained by computing the cosine similarity of the text description of the concepts.",
        "The reasoning method of the unknown concept follows the one mentioned in the OntoReason-WordNet approach.",
        "We will compute content features based on these new representations and evaluate the performance according to feature correlations.",
        "The current results examine effects of using the Word-Net ontology on predicting speaking proficiency, and these new experiments will answer whether the other type of ontology, Wikipedia, has positive effect in speaking proficiency prediction.",
        "We will also compare the effects of using different ontologies for ontology-based representations.",
        "The study has implications on effects of different speech transcript representations in predicting speaking proficiency.",
        "Since content features are less well explored in automatic speech scoring compared to acoustic features, it also contributes to the understanding of the use and effects of content features in speech scoring.",
        "Acknowledgments The author would like to than Drs.",
        "Klaus Zech-ner and Jian Qin for their tremendous help and support on the dissertation study.",
        "References Arguello, J., Elsas, J. L., Callan, J., & Carbonell, J. G. (2008).",
        "Document representation and query expansion models for blog recommendation.",
        "Proceedings of the Second International Conference on Weblogs and Social Media (ICWSM 2008).",
        "Attali, Y., & Burstein, J.",
        "(2006).",
        "Automated essay scoring with e-rater?",
        "V. 2.",
        "The Journal of Technology, Learning and Assessment, 4(3).",
        "Blei, D. (2012).",
        "Introduction to probabilistic topic mod-els.",
        "Communications of the ACM, 77-84.",
        "Bloehdorn, S., & Hotho, A.",
        "(2004).",
        "Boosting for text classification with semantic features.",
        "Workshop on mining for and from the semantic web at the 10th ACM SIGKDD conference on knowledge discovery and data mining (KDD 2004).",
        "Burstein, J.",
        "(2003).",
        "The E-rater?",
        "scoring engine: Automated essay scoring with natural language pro-cessing.",
        "In M. D. Shermis, Burstein, J.C.",
        "(Ed.",
        "), Automated essay scoring: A cross-disciplinary perspective (pp.",
        "113-121).",
        "Mahwah, NJ: Lawrence Erl-baum Associates, Inc. Chen, L., Tokuda, N., & Nagai, A.",
        "(2003).",
        "A new differential LSI space-based probabilistic document classifier.",
        "Information Processing Letters, 88(5), 203-212.",
        "Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990).",
        "Indexing by latent"
      ]
    }
  ]
}
