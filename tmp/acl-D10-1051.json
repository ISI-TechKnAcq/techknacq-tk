{
  "info": {
    "authors": [
      "Erica Greene",
      "Tugba Bodrumlu",
      "Kevin Knight"
    ],
    "book": "EMNLP",
    "id": "acl-D10-1051",
    "title": "Automatic Analysis of Rhythmic Poetry with Applications to Generation and Translation",
    "url": "https://aclweb.org/anthology/D10-1051",
    "year": 2010
  },
  "references": [
    "acl-C08-1048",
    "acl-J93-2003",
    "acl-P05-1074",
    "acl-P07-2045",
    "acl-W09-2005"
  ],
  "sections": [
    {
      "text": [
        "Haverford College 370 Lancaster Ave. Haverford, PA 19041",
        "Tugba Bodrumlu Kevin Knight",
        "of Computer Science Information Sciences Institute Univ.",
        "of Southern California Univ.",
        "of Southern California Los Angeles, CA 90089 4676 Admiralty Way",
        "bodrumlu@cs .",
        "use .",
        "edu Marina del Rey, CA 90292",
        "We employ statistical methods to analyze, generate, and translate rhythmic poetry.",
        "We first apply unsupervised learning to reveal word-stress patterns in a corpus of raw poetry.",
        "We then use these word-stress patterns, in addition to rhyme and discourse models, to generate English love poetry.",
        "Finally, we translate Italian poetry into English, choosing target realizations that conform to desired rhythmic patterns."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "When it comes to generating creative language (poems, stories, jokes, etc), people have massive advantages over machines:",
        "• people can construct grammatical, sensible utterances,",
        "• people have a wide range of topics to talk about, and",
        "• people experience joy and heart-break.",
        "On the other hand, machines have some minor advantages:",
        "• a machine can easily come up with a five-syllable word that starts with p and rhymes with early, and",
        "• a machine can analyze very large online text repositories of human works and maintain these in memory.",
        "In this paper we concentrate on statistical methods applied to the analysis, generation, and translation of poetry.",
        "By analysis, we mean extracting patterns from existing online poetry corpora.",
        "We use these patterns to generate new poems and translate existing poems.",
        "When translating, we render target text in a rhythmic scheme determined by the user.",
        "statistical methods, although there is a long way to go.",
        "One difficulty has been the evaluation of machine-generated poetry – this continues to be a difficulty in the present paper.",
        "Less research effort has been spent on poetry analysis and poetry translation, which we tackle here."
      ]
    },
    {
      "heading": "2. Terms",
      "text": [
        "Meter refers to the rhythmic beat ofpoetic textwhen read aloud.",
        "Iambic is a common meter that sounds like da-DUM da-DUM da-DUM, etc.",
        "Each da-DUM is called a foot.",
        "Anapest meter sounds like da-da-DUMda-da-DUMda-da-DUM, etc.",
        "Trimeter refers to a line with three feet, pentameter to a line with five feet, etc.",
        "Examples include:",
        "• a VE-ry NAS-ty CUT (iambic trimeter)",
        "• shall I com-PARE thee TO a SUM-mer's DAY?",
        "(iambic pentameter)",
        "• twas the NIGHT before CHRIST-mas and ALL through the HOUSE (anapest tetrameter)",
        "Classical English sonnets are poems most often composed of 14 lines ofiambic pentameter."
      ]
    },
    {
      "heading": "3. Analysis",
      "text": [
        "We focus on English rhythmic poetry.",
        "We define the following analysis task: given poetic lines in a known meter (such as sonnets written in iambic pentameter), assign a syllable-stress pattern to each word in each line.",
        "Making such decisions is part of the larger task of reading poetry aloud.",
        "Later in the paper, we will employ the concrete statistical tables from analysis to the problems of poetry generation and translation.",
        "We create a test set consisting of 70 lines from Shakespeare's sonnets, which are written in iambic pentameter.",
        "Here is an input line annotated with gold output.",
        "shall i compare thee to a summers day",
        "S refers to an unstressed syllable, and S* refers to a stressed syllable.",
        "One of the authors created goldstandard output by listening to Internet recordings of the 70 lines and marking words according to the speaker's stress.",
        "The task evaluation consists ofper-word accuracy (how many words are assigned the correct stress pattern) and per-line accuracy (how many lines have all words analyzed perfectly).",
        "This would seem simple enough, if we are armed with something like the CMU pronunciation dictionary: we look up syllable-stress patterns for each word token and lay these down on top of the sequence S S* S S* S S* S S* S S*.",
        "However, there are difficulties:",
        "• The test data contains many words that are unknown to the CMU dictionary.",
        "• Even when all words are known, many lines do not seem to contain 10 syllables.",
        "Some lines contain eleven words.",
        "• Spoken recordings include stress reversals, such as poin-TING instead ofPOIN-ting.",
        "• Archaic pronunciations abound, such as PROV-ed (two syllables) instead of PROVED (one syllable).",
        "• In usage, syllables are often subtracted (PRISner instead of PRIS-o-ner), added (SOV-e-reign instead of SOV-reign), or merged.",
        "• Some one-syllable words are mostly stressed, and others mostly unstressed, but the dictio-",
        "Figure 1 : Finite-state transducer (FST) for mapping sequences of English words (e) onto sequences of S* and S symbols (m), representing stressed and unstressed syllables.",
        "nary provides no guidance.",
        "When we generate rhythmic text, it is important to use one-syllable words properly.",
        "For example, we would be happy for an iambic generator to output big thoughts are not quite here, but not quite big thoughts are not here.",
        "Therefore, we take a different tack and apply unsupervised learning to acquire word-stress patterns directly from raw poetry, without relying on a dictionary.",
        "This method easily ports to other languages, where dictionaries may not exist and where morphology is a severe complication.",
        "It may also be used for dead languages.",
        "For raw data, we start with all Shakespeare sonnets (17,134 word tokens).",
        "Because our learning is unsupervised, we do not mind including our 70-line test set in this data (open testing).",
        "Figures 1 and 2 show a finite-state transducer (FST) that converts sequences of English words to sequences of S* and S symbols.",
        "The FST's transitions initially map each English word onto all output sub-sequences of lengths 1 to 4 (i.e., S, S*, S-S, S-S*, S*-S, S*-S*, S-S-S, .",
        ".",
        ". )",
        "plus the sequences S-S*-S-S*-S and S*-S-S*-S-S*.",
        "Initial probabilities are set to 1/32.",
        "The FST's main loop allows it to process a sequence ofword tokens.",
        "Ifthe same word appears twice in a sequence, then it may receive two different pronunciations, since the mapping is probabilistic.",
        "However, a token's syllable/stress pattern is chosen independently of other tokens in the sequence; we look at relaxing this assumption later.",
        "We next use finite-state EM training to train the machine on input/output sequences such as these:",
        "from fairest creatures we desire increase S S* S S* S S* S S* S S* but thou contracted to thine own bright eyes S S* S S* S S* S S* S S*",
        "Figure 2: An efficient FST implementing P(m|e).",
        "This machine maps sequences of English words onto sequences of S* and S symbols, representing stressed and unstressed syllables.",
        "Initially every vocabulary word has 32 transitions, each with probability 1/32.",
        "After EM training, far fewer transitions remain.",
        "Figure 3: An FST that accepts any of four input meters and deterministically normalizes its input to strict iambic pentameter.",
        "We call this FST norm.",
        "Figure 4: FST cascade that encodes a loose interpretation of iambic pentameter.",
        "The norm FST accepts any of four near-iambic-pentameter sequences and normalizes them into strict iambic pentameter.",
        "Note that the output sequences are all the same, representing our belief that each line should be read as iambic pentameter.",
        "After we train the FST, we can use Viterbi decoding to recover the highest-probability alignments, e.g.:",
        "Note that the first example contains an error – the words fairest and creatures should each be read with two syllables.",
        "There are many such errors.",
        "We next improve the system in two ways: more data and better modeling.",
        "First, we augment the Shakespeare sonnets with data from the website sonnets.org, increasing the number of word tokens from 17,134 to 235,463.",
        "The sonnets.org data is noisier, because it contains some non-iambic-pentameter poetry, but overall we find that alignments improve, e.g.:",
        "from fairest creatures we desire increase",
        "Second, we loosen our model.",
        "When we listen to recordings, we discover that not all lines are read S S* S S* S S* S S* S S*.",
        "Indeed, some lines in our data contain eleven words – these are unexplainable by the EM training system.",
        "We also observe that poets often use the word mother (S* S) at the beginnings and ends of lines, where it theoretically should not appear.",
        "Two well-known variations explain these facts.",
        "One is optional inversion of the first foot (S S* – S* S).",
        "Second is the optional addition of an eleventh unstressed syllable (the feminine ending).",
        "These variations yield four possible syllable-stress sequences:",
        "We want to offer EM the freedom to analyze lines into any of these four variations.",
        "We therefore construct a second FST (Figure 3), norm, which maps all four sequences onto the canonical pattern S S* in a cascade (Figure 4), and we train the whole cascade on the same input/output sequences as before.",
        "Because norm has no trainable parameters, we wind up training only the lexical mapping parameters.",
        "Viterbi decoding through the two-step cascade now reveals EM's proposed internal meter analysis as well as token mappings, e.g.:",
        "Figure 5 shows accuracy results on the 70-line test corpus mentioned at the beginning of this section.",
        "Over 94% of word tokens are assigned a syllable-stress pattern that matches the pattern transcribed from audio.",
        "Over 81% of whole lines are also scanned correctly.",
        "The upper limit for whole-line scanning under our constraints is 88.6%, because 11.4% of gold outputs do not match any of the four patterns we allow.",
        "We further obtain a probabilistic table of word mappings that we can use for generation and translation tasks.",
        "Figure 6 shows a portion of this table.",
        "Note that P(S S* | mother) has a very small probability of 0.02.",
        "We would incorrectly learn a much higher value if we did not loosen the iambic pentameter model, as many mother tokens occur lineinitial and line-final.",
        "Training data",
        "Training tokens",
        "Test token accuracy",
        "Test line accuracy",
        "Shakespeare",
        "17,134",
        "82.3%",
        "55.7%",
        "sonnets.org",
        "235,463",
        "94.2%",
        "81.4%",
        "to",
        "be",
        "or",
        "not",
        "to",
        "be",
        "that",
        "is",
        "the",
        "question",
        "I",
        "I",
        "I",
        "I",
        "I",
        "I",
        "I",
        "I",
        "I",
        "/\\",
        "S",
        "S*",
        "S",
        "S*",
        "S",
        "S*",
        "S",
        "S*",
        "S",
        "S* S",
        "S",
        "S*",
        "S",
        "S*",
        "S",
        "S*",
        "S",
        "S*",
        "S",
        "S*",
        "Figure 7 shows which one-syllable words are more often stressed (or unstressed) in iambic pentameter poetry.",
        "Function words and possessives tend to be unstressed, while content words tend to be stressed, though many words are used both ways.",
        "This useful information is not available in typical pronunciation dictionaries.",
        "Alignment errors still occur, especially in noisy portions of the data that are not actually written in iambic pentameter, but also in clean portions, e.g.:",
        "the perfect ceremony of loves rite",
        "The word ceremony only occurs this once in the data, so it is willing to accept any stress pattern.",
        "While rite is correctly analyzed elsewhere as a one-syllable word, loves prefers S*, and this overwhelms the one-syllable preference for rite.",
        "We can blame our tokenizer for this, as it conflates loves and love's, despite the fact that these words have different stress probabilities."
      ]
    },
    {
      "heading": "4. Generation",
      "text": [
        "P(m) is a user-supplied model of desired meters – normally it deterministically generates a single string of S* and S symbols.",
        "(The user also supplies a rhyme scheme – see below).",
        "P(e|m) is the reverse of Section 3's P(m|e), being a model of word selection.",
        "Its generative story is: (1) probabilistically select n tokens (n = 1 to 5) from the input, (2) probabilistically select a word w that realizes that n-token sequence, and (3) recurse until the input is consumed.",
        "Instead of asking how a given word is likely to be pronounced (e.g., S or S*), we now ask how a given stress-pattern (e.g., S or S*) is likely to be realized.",
        "This model is trained with the same method described in Section 3 and is augmented with the CMU pronunciation dictionary.",
        "Finally, P(e) is a word-trigram model built from a 10,000-line corpus of 105 English love poems.",
        "We select the first line of our poem from the FST cascade's 100,000-best list, or by hand.",
        "To generate each subsequent line, we modify the cascade and run it again.",
        "The first modification is to incorporate a discourse model.",
        "From our poetry corpus, we estimate a word's unigram probability given the words on the previous line, via IBM Model 1 (Brown et al., 1993).",
        "We modify P(e) by interpolating in these probabilities.",
        "Second, we check if any previous line",
        "P (S*",
        "S S*",
        "I altitude)",
        "=",
        "1 .",
        "00",
        "P (S*",
        "S I",
        "creatures)",
        "=",
        "1 .00",
        "P(S*",
        "S I",
        "pointed)",
        "=",
        "0 .95",
        "P(S",
        "S* I",
        "pointed)",
        "=",
        "0 .05",
        "P(S*",
        "S",
        "I prisoner)",
        "=",
        "0 .",
        "74",
        "P(S*",
        "S S*",
        "I prisoner)",
        "=",
        "0.26",
        "P(S*",
        "SI",
        "mother)",
        "=",
        "0 .95",
        "P(S*",
        "I",
        "mother)",
        "=",
        "0 .",
        "03",
        "P(S",
        "S* I",
        "mother)",
        "=",
        "0 .",
        "02",
        "P(m)",
        " – > m – >",
        "P(e m)",
        "^e^",
        "P(e)",
        "word",
        "P(S* 1 word)",
        "P(S 1 word)",
        "a",
        "0.04",
        "0.96",
        "the",
        "0.06",
        "0.94",
        "their",
        "0.09",
        "0.91",
        "mens",
        "0.10",
        "0.90",
        "thy",
        "0.10",
        "0.90",
        "be",
        "0.48",
        "0.52",
        "me",
        "0.49",
        "0.51",
        "quick",
        "0.50",
        "0.50",
        "split",
        "0.50",
        "0.50",
        "just",
        "0.51",
        "0.49",
        "food",
        "0.90",
        "0.10",
        "near",
        "0.90",
        "0.10",
        "raised",
        "0.91",
        "0.09",
        "dog",
        "0.93",
        "0.07",
        "thought",
        "0.95",
        "0.05",
        "The women of the night Again and all the way Like a mouse in the white Not the heart of the day.",
        "Of the bed to trust me Around her twists the string But i will not tell thee Fire changes everything.",
        "A son of the right hand confines His uncle could have broken in Towards the high bank and the pines Upon the eyes and i have been",
        "Into one of her hundred year old",
        "Or the house in a house in a cold",
        "The first time she met him",
        "Like a mouse in the dim",
        "For me to the moon and when i told",
        "Into one of them some years before His own man or the house in a more The moon and when the day Into one of the way",
        "With the breath from the first time she swore",
        "wi, w2, ...wn needs to be rhymed with, according to the user-supplied scheme.",
        "If so, we build an additional FST that accepts only strings whose final word rhymes with wn.",
        "This is a reasonable approach, though it will not, for example, rhyme ...tar me with ...army.",
        "We say two non-identical words rhyme if their phoneme strings share a common suffix that includes the last stressed vowel."
      ]
    },
    {
      "heading": "5. Translation",
      "text": [
        "Automatically generated poetry can sound good when read aloud, but it often has a \"nonsense\" feel to it.",
        "According to (Gervas, 2010), creative-language researchers interested in realization and surface language statistics (\"how to say\") have tended to gravitate to poetry generation, while researchers interested in characters, goals, and storyline (\"what to say\") have tended to gravitate to prose story generation.",
        "Translation provides one way to tie things together.",
        "The source language provides the input (\"what to say\"), and the target language can be shaped to desired specifications (\"how to say\").",
        "For example, we may want to translate Italian sonnets into fluent English iambic pentameter.",
        "This is certainly a difficult task for people, and one which is generally assumed to be impossible for computers.",
        "Here we investigate translating Dante's Divine Comedy (DC) from Italian into English by machine.",
        "The poem begins:",
        "nel mezzo del cammin di nostra vita mi ritrovai per una selva oscura che la via diritta era smarrita.",
        "DC is a long sequence of such three-line stanzas (tercets).",
        "The meter in Italian is hendecasyl-labic, which has ten syllables and ensures three beats.",
        "Dante's Italian rhyme scheme is: ABA, BCB, CDC, etc, meaning that lines 2, 4, and 6 rhyme with each other; lines 5, 7, and 9 rhyme with each other, and so forth.",
        "There is also internal rhyme (e.g., diritta/smarrita).",
        "Because DC has been translated many times into English, we have examples of good outputs.",
        "Some translations target iambic pentameter, but even the most respected translations give up on rhyme, since English is much harder to rhyme than Italian.",
        "Longfellow's translation begins:",
        "midway upon the journey of our life i found myself within a forest dark for the straightforward pathway had been lost.",
        "We arrange the translation problem as a cascade ofWFSTs, as shown in Figure 10.",
        "We call our Italian input i.",
        "In lieu of the first WFST, we use the statistical phrase-based machine translation (PBMT) system Moses (Koehn et al., 2007), which generates a target-language lattice with paths scored by P(e| i).",
        "We send this lattice through the same P(m| e) device we trained in Section 3.",
        "Finally, we filter the resulting syllable sequences with a strict, single-path, deterministic iambic pentameter acceptor, P(m).",
        "Our nel mezzo del cammin di nostra vita mi ritrovai per una selva oscura che la via diritta era smarrita.",
        "P(e|i)",
        "P(m e)",
        " – > m – >",
        "P(m)",
        "Parallel Italian/English Data",
        "Figure 11 : Data for Italian/English statistical translation.",
        "finite-state toolkit's top-k paths represent the translations with the highest product of scores P(e|i) • P(m|e) • P(m).",
        "In general, the P(e|i) and P(m|e) models fight each other in ranking candidate outputs.",
        "In experiments, we find that the P(e|i) preference is sometimes so strong that the P(m| e) model is pushed into using a low-probability word-to-stress mapping.",
        "This creates output lines that do not scan easily.",
        "We solve this problem by assigning a higher weight to the P(m| e) model.",
        "Figure 11 shows the data we used to train the PBMT system.",
        "The vast majority of parallel Italian/English poetry is DC itself, for which we have four English translations.",
        "We break DC up into DC-train, DC-tune, and DC-test.",
        "We augment our target language model with English poetry collected from many sources.",
        "We also add Europarl data, which Original: Phrase-based translation (PBMT):",
        "midway in the journey of our life i found myself within a forest dark for the straight way was lost.",
        "PBMT + meter model:",
        "midway upon the journey of our life",
        "i found myself within a forest dark for the straightforward pathway had been lost.",
        "Figure 12: Automatic translation of lines from Dante's Divine Comedy.",
        "In this test-on-train scenario, the machine reproduces lines from human translations it has seen.",
        "is out of domain, but which reduces the unknown word-token rate in DC-test from 9% to 6%, and the unknown word-type rate from 22% to 13%.",
        "We first experiment in a test-on-train scenario, where we translate parts of DC that are in our training set.",
        "This is a normal scenario in human poetry translation, where people have access to previous translations.",
        "Figure 12 shows how we translate the first lines of DC, first using only PBMT, then using the full system.",
        "When we use the full system, we not only get an output string, but also the system's intended scan, e.g.:",
        "The machine's translation here is the same as Longfellow's, which is in the training data.",
        "In other cases, we observe the machine combining existing translations, e.g.:",
        "i: bedi la bestia per cu io mi volsi",
        "I5: behold the beast that made me turn aside",
        "H1: BEHOLD THE BEAST for which i have turned back",
        "H2: you see the beast THAT MADE ME TURN ASIDE",
        "H3: see the beast that forced me to turn back",
        "H4: look at the beast that drove me to turn back",
        "I5 refs to the machine's iambic pentameter translaOriginal: Phrase-based translation (PBMT):",
        "Collection",
        "Word count (English)",
        "DC-train",
        "400,670",
        "Il Fiore",
        "25,995",
        "Detto Damare",
        "2,483",
        "Egloghe",
        "3,120",
        "Misc.",
        "557",
        "Europarl",
        "32,780,960",
        "English Language Model Data",
        "Collection",
        "Word count (English)",
        "DC-train",
        "400,670",
        "poemhunter.com poetry, eserver.",
        "org poetrymountain.com",
        "686,714",
        "poetry archive.",
        "org",
        "58,739",
        "everypoet.com",
        "574,322",
        "sonnets.org",
        "166,465",
        "Europarl",
        "32,780,960",
        "Tune and Blind Test Data (4 reference)",
        "Collection",
        "Word count (Italian)",
        "DC-tune",
        "7,674",
        "DC-test",
        "2,861",
        "tion, while H1-4 refer to human translations.",
        "The machine also creates new translations:",
        "i: diro de laltre cose chi vho scorte I5: i shall explain the other things i saw",
        "H1: speak will i of the other things i saw there",
        "H2: ill also tell THE OTHER THINGS I SAW",
        "H3: i will recount the other things i saw",
        "H4: i here will tell the other things i saw",
        "We can further change the target meter to anything we desire.",
        "To obtain iambic tetrameter (4-beat) translations, we delete the last two transitions of the P(m) model.",
        "We then get:",
        "I4: in our life the journey way i found myself deep on dark wood that lost straightforward pathway had.",
        "ah how to say the what is hard this forest savage rough and stern the very thought renews the fear.",
        "Translations and scans are uneven, but we have significant flexibility.",
        "We can even request translations that avoid the English letter A, by adding a filter to the end of the FST cascade, obtaining:",
        "I5: in midst upon the journey of our life i found myself within the wood obscure <fail>",
        "To steer clear of the adjective dark in the second line, the system switches from forest to wood, so obtain a proper scan.",
        "The third line fails because all paths through the translation lattice contain an A somewhere.",
        "Translating blind-test data proves to be more difficult.",
        "We hold out Canto XXXI of DC's Paradiso section for testing.",
        "Figure 13 shows a portion of the translation results.",
        "The MT system handles unknown Italian words by passing them through to the output.",
        "The P(m| e) meter model cannot process those words, accounting for the I5 failure rate.",
        "Here, we get a first look at statistical MT translating poetry into rhythmic structures – as with all MT, there are successes and problems, and certainly more to do."
      ]
    },
    {
      "heading": "6. Future Work",
      "text": [
        "We plan to release all our of data in useful, processed form.",
        "Below we list directions for future research.",
        "In general, we see many interesting paths to pursue.",
        "Analysis.",
        "Proper use of one-syllable words remains tricky.",
        "Lines coming out of generation in forma dunque di Candida rosa mi si mostrava la milizia santa che nel suo sangue cristo fece sposa ma laltra che volando vede e canta la gloria di colui che la nnamora e la bonta' che la fece cotanta Human translation:",
        "in fashion then as of a snow white rose displayed itself to me the saintly host whom christ in his own blood had made his bride but the other host that flying sees and sings the glory of him who doth enamour it and the goodness that created it so noble in the form so rose Candida i now was shown the militia holy that in his blood christ did bride but the other that flying sees and sings the glory of him that the nnamora and the goodness that the made cotanta PBMT + meter model:",
        "i now was shown the holy soldiery that in his blood he married jesus christ but flying sees and sings the other which <fail> and translation do not always scan naturally when read aloud by a person.",
        "We trace such errors to the fact that our lexical probabilities are context-independent.",
        "For example, we have:",
        "When we look at Viterbi alignments from the analysis task, we see that when off is preceded by the word far, the probabilities reverse dramatically:",
        "Similarly, the probability of stressing at is 40% in general, but this increases to 91% when the next word is the.",
        "Developing a model with context-dependent probabilities may be useful not only for improving generation and translation, but also for improving poetry analysis itself, as measured by an-laysis task accuracy.",
        "Other potential improvements include the use of prior knowledge, for example, taking word length and spelling into account, and exploiting incomplete pronunciation dictionary information.",
        "Generation.",
        "Evaluation is a big open problem for automatic poetry generation – even evaluating human poetry is difficult.",
        "Previous suggestions for automatic generation include acceptance for publication in some established venue, or passing the Turing test, i.e., confounding judges attempts to distinguish machine poetry from human poetry.",
        "The Turing test is currently difficult to pass with medium-sized Western poetry.",
        "Translation.",
        "The advantage of translation over generation is that the source text provides a coherent sequence of propositions and images, allowing the machine to focus on \"how to say\" instead of \"what to say.\"",
        "However, translation output lattices offer limited material to work with, and as we dig deeper into those lattices, we encounter increasingly disflu-ent ways to string together renderings of the source substrings.",
        "An appealing future direction is to combine translation and generation.",
        "Rather than translating the source text, a program may instead use the source text for inspiration.",
        "Such a hybrid translation/generation program would not be bound to translate every word, but rather it could more freely combine lexical material from its translation tables with other grammatical and lexical resources.",
        "Interestingly, human translators sometimes work this way when they translate poetry – many excellent works have been produced by people with very little knowledge of the source language.",
        "Paraphrasing.",
        "Recently, e – f translation tables have been composed with f – e tables, to make e – e tables that can paraphrase English into English (Bannard and Callison-Burch, 2005).",
        "This makes it possible to consider statistical translation of English prose into English poetry."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "This work was partially supported by NSF grant IIS0904684."
      ]
    }
  ]
}
