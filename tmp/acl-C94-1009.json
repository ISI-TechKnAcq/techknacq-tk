{
  "info": {
    "authors": [
      "Akira Kumano",
      "Hideki Hirakawa"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C94-1009",
    "title": "Building an MT Dictionary from Parallel Texts Based on Linguistic and Statistical Information",
    "url": "https://aclweb.org/anthology/C94-1009",
    "year": 1994
  },
  "references": [
    "acl-J93-1004",
    "acl-P91-1017",
    "acl-P91-1022",
    "acl-P93-1002",
    "acl-P93-1003",
    "acl-P93-1004"
  ],
  "sections": [
    {
      "heading": "BUILDING AN MT DICTIONARY FROM PARALLEL TEXTS BASED ON LINGUISTIC AND STATISTICAL INFORMATION",
      "text": []
    },
    {
      "heading": "Abstract",
      "text": [
        "A method for generating a machine translation (MT) dictionary from parallel texts is described.",
        "This method utilizes both statistical information and linguistic information to obtain corresponding words or phrases in parallel texts.",
        "By combining these two types of information, translation pairs which cannot be obtained by a linguistic-based method can be extracted.",
        "Over 70% accurate translations of compound nouns and over 50% of unknown words are obtained as the first candidate from small Japanese/English parallel texts containing severe distortions."
      ]
    },
    {
      "heading": "1 INTRODUCTION",
      "text": [
        "Parallel texts (corpora) are useful resources for acquiring a variety of linguistic knowledge (Dangan, 1991; Matsumoto, 1993), especially for machine translation systems which inherently require customizations.",
        "Translation dictionaries are, needless to say, the most basic and powerful knowledge source for improving and customizing translation systems.",
        "Our research interest lies in automatic generation of translation dictionaries from parallel texts.",
        "In this perspective, finding corresponding words or phrases in bilingual texts will be the fundamental factor for accurate translation.",
        "Statistics-based processing has proven to he very powerful for aligning sentences and words in parallel corpora (Brown, 1991; Gale, 1993; Chen, 1993).",
        "Kupiec proposes an algorithm for finding noun phrases in bilingual corpora (Kupiec, 1993).",
        "In this algorithm, noun-phrase candidates are extracted from tagged and aligned parallel texts using a noun phrase recognizer and the correspondences of these noun phrases are calculated based on the EM algorithm.",
        "Accuracy of around 90% has been attained for the hundred highest ranking correspondences.",
        "Statistics based processing is effective when a relatively large amount of parallel texts is available, i.e. when high frequencies are obtained.",
        "On the other hand, existing linguistic knowledge can be used for finding corresponding words or phrases in parallel texts.",
        "For example, possible tar get expressions for a source expression provided by a translation system (linguistic knowledge source) can be a key in searching the corresponding expressions in a corpus (Nogami, 1991; Katoh, 1993).",
        "Yamamoto (1993) proposes a method for generating a translation dictionary from Japanese/English parallel texts.",
        "In this method, English and Japanese compound noun phrases are extracted from parallel texts and their correspondences are searched by matching their possible translations generated by the existing translation dictionary.",
        "However, acquirable noun phrases are limited by the linguistic generative power of the translation dictionary.",
        "Furthermore, this method utilizes no sentence alignment information which can reduce errors in finding noun phrase correspondences.",
        "This paper proposes a new method for generating an MT dictionary from parallel texts.",
        "It utilizes both statistical and linguistic information to obtain corresponding words or phrases in parallel texts.",
        "By combining these two types of information, translation pairs which cannot be obtained by the above linguistic-based method can be extracted, and a highly accurate translation dictionary is generated from relatively small parallel texts."
      ]
    },
    {
      "heading": "2 APPROACH TO BUILDING AN MT DICTIONARY",
      "text": [
        "Our goal in building an MT dictionary from parallel texts is to develop a robust method which enables highly accurate extraction of translation pairs from a relatively small amount of parallel texts as well as from parallel texts containing severe distortions.",
        "In real-world applications, generally it is extremely difficult especially for MT users to obtain a large amount of high quality parallel texts of one specific domain.",
        "If source and target languages do not belong to the same linguistic family, like Japanese and English, the situation becomes grave.",
        "As one typical example of MT dictionary compilation, we have selected Japanese and English patent documents which contain many state-of-the-art technical terms.",
        "Although these, documents are not cul76"
      ]
    },
    {
      "heading": "Japanese Text [English Text",
      "text": [
        "The translation candidates are evaluated to obtain the best one, unit extraction turally biased, in many cases, the organization between Japanese and English greatly differs and extensive changes are made in translating from Japanese to English text and vice versa.",
        "Hence, the difficulty of word extraction from patents.",
        "To solve this problem, we explored the appropriate integration method considering the use of linguistic information and statistical information to this end.",
        "Linguistic information is useful in making an intelligent judgment about correspondence between two languages even from partial texts because of its lexical, syntactic, and semantic knowledge; statistical information is characterized by its robustness against noise because it can transform many actual examples into an abstract form.",
        "Below is the flow of our method illustrated in Fig. 1:",
        "(1) Unit Extraction: Parts of documents (\"units\") are extracted from both Japanese and English texts.",
        "(2) Unit Mapping: Each Japanese unit is mapped into English units.",
        "(3) Term Extraction; Japanese term candidates are extracted by the NP recognizer.",
        "(4) Translation Candidate Generation: English translation candidates for Japanese terms are extracted from English units.",
        "(5) English Translation Estimation:",
        "The subsequent sections show the details of each processing."
      ]
    },
    {
      "heading": "3 FORMING UNIT CORRESPONDENCES",
      "text": [
        "The plausible bythat parallel sentences contain corresponding linguistic expressions is the major premise in Kupiec (1993).",
        "This type of information should be widely used.",
        "The problem is that the alignment method based on the sentence bead model (Brown, 1991) is not applicable to patent documents clue to their sevem distortions in document structures and sentence correspondences.",
        "Consequently, we have introduced a concept called \"unit\" which corresponds to a part of sentence and adopted a new method to extract corresponding units by using linguistic knowledge as a primary source of information."
      ]
    },
    {
      "heading": "3.1 Extraction of Units",
      "text": [
        "First, units are extracted from parallel texts.",
        "The unit corresponds to sentences or phrases in the text.",
        "Terms which should be extracted can be found within a unit.",
        "The rest of words in the unit is called contextual information for the extracted term.",
        "The size of units determines the effectiveness of the succeeding unit mapping process.",
        "For example, if we set noun phrases (entry words in a dictionary) as a unit, no contextual information is available, and thus the probability that corresponding relations hold decreases.",
        "lit our present implementation, we set sentences as a unit for the first approximation."
      ]
    },
    {
      "heading": "3.2 Mapping of Units",
      "text": [
        "Next, the unit mapping process creates a conesponding unit table from Japanese and English units.",
        "This table stoics the correspondence relationship between units and its likelihood.The hood is calculated based on the linguistic information in an MT bilingual dictionary.",
        "Our unit inapping algorithm is given below:",
        "(1) Let 3 be a set of all content words in the JapalleSe unit JU.",
        "(rn is the number of words) =LIPIn/ (2) Let E be a set of all content words in the English unit EU.",
        "(n is the number of words) E,En} (3) A. is the num her of Ji's whose translation candi-term"
      ]
    },
    {
      "heading": "4 GENERATING TRANSLATION CANDIDATES",
      "text": []
    },
    {
      "heading": "4.1 Extraction of Japanese Terms",
      "text": [
        "Errors in the extraction of terms and phrases from parallel texts eventually lead to a failure in acquiring the correct term/phrase correspondences.",
        "In Kupiec (1993) and Yamamoto (1993), term and phrase extraction is applied to both of parallel texts.",
        "In contrast, we extract from units only Japanese terms, thereby reducing the errors caused by term/phrase recognizer.",
        "Japanese NP's can be recognized more accurately than English NP's because Japanese has considerably less multi-category words.",
        "In the current implementation, the following two types of term candidates arc extracted by the NP recognizer:"
      ]
    },
    {
      "heading": "4.2 Finding Translation Candidates",
      "text": [
        "Generation of English translation candidates for a Japanese term is essentially based on the following hypothesis: Hypothesis 1 The English translation of an extracted term in a Japanese unit is contained in the English corresponding unit.",
        "Now an arbitrary word sequence in corresponding units can be a translation candidate of the Japanese term.",
        "We extract English translation candidates in two steps: Step 1: Select English corresponding units.",
        "Step 2: Extract n-gram data from the units.",
        "Step 1: When the extracted term appears in N Japanese units, NxM English units will be stored in the corresponding unit table with their correspondence likelihood.",
        "The N highest corresponding units within NxM combinations are extracted.",
        "When N is less than M, the M highest combinations are selected.",
        "Suppose that the correct English translation of the Japanese term JW is EW, and that the number of Japanese units in which JW appears is FJU(.IW) N).",
        "From Hypothesis 1 that the translation is contained in the corresponding units EIJI , EU2 ..... EUF fumy), EW would be a word sequence which often appears in corresponding units.",
        "In order to get such EW, we use n-gram data.",
        "The frequency of each n-gram (1n IC 2 x (the number of component words in JW)) data in M(JW) English units is calculated and then EW candidates are ranked by the frequency as EWCI, EWC2,... EWC.. Because EWC with a low frequency in the corresponding units is unlikely to be the correct translation, the data with a frequency less FJU(JW) thanare heuristically excluded from the",
        "candidates.",
        "The data containing be verb and the data which starts or ends with a preposition or an article are also excluded from the candidates."
      ]
    },
    {
      "heading": "5 ESTIMATING ENGLISH TRANSLATIONS",
      "text": [
        "The translation likelihood (TL) of one translation candidate EWCi for the term JW is defined as: TL(JW, EWCi) = F(TLS(JW, EWCi), TLL(JW, EWCi)) where ns(Jw, EWCi) is \"Translation Likelihood based on Statistical information,\" and TLL(JW, EWCi) \"Translation Likelihood based on Linguistic information.\""
      ]
    },
    {
      "heading": "5.1 Statistical Information",
      "text": [
        "TLS(JW, EWCi) is the frequency score based on the statistical information from Hypothesis 1 that a word which appears as often in the corresponding units as JW in Japanese units is more likely to be EW.",
        "It is quantitatively defined as the probability in which the translation candidate appears in the corresponding units.",
        "That is,",
        "where EEU(EWCi) is the number of corresponding units in which EWCi appears."
      ]
    },
    {
      "heading": "5.2 Linguistic Information",
      "text": [
        "TEL(IW, EWCi) is the word similarity score based on the accuracy of the correspondence term JW and the translation candidate EWCi obtained by using linguistic information in the MT bilingual dictionary.",
        "Suppose one translation candidate of term JW=wji , wj2,... wjk is EWCrwei , we2,... we/.",
        "Then we use the following hypothesis."
      ]
    },
    {
      "heading": "Hypothesis 2",
      "text": [
        "(a) If the length of EWCi is close to the length of JW, JW and EWCi are likely to correspond each other.",
        "(b) JW and EWCi with more word translation correspondences are likely to correspond each other.",
        "Under this hypothesis, the following correspondence relation (1) is the best.",
        "Term JW and translation candidate EWCi have the same length k(-1), and all of their component words correspond in the dictionary.",
        "wjir--wei indicates that we is included in wji's translation candidates in the MT bilingual dictionary.",
        "(1) wj1we1, wi2wc2'wikwek",
        "More generally, the relation of each word (wj) in term JW and each word (we) in translation candidate EWCi is classified into the following four classes:",
        "ii) shows a pair whose correspondence is not described in the bilingual dictionary.",
        "iii) and iv) indicate that the corresponding word for wj or we is missing.",
        "In iii), JW is longer than EWCi; and vice versa in iv).",
        "In order to estimate correspondence between JW and EWCi, i) and ii) are scored by similarity to the virtual translation which holds the relation (1).",
        "When the number of words is the same, score Q (constant) is given.",
        "aQ (a>0) is added to Q when there is a translation relation to reflect higher reliability of i).",
        "Therefore, Q-(aQ-(1-(a)Q is given to the word pair of i), and Q to the word pair of ii).",
        "Now since we disregard the word order of a term, JW and EWCi are represented as sets of words: Jwwj2-.",
        "wikwil' wj2\".. wid EWCi wei , we2,... we/ = (wei , we2,...",
        "The number of words with a lexical correspondence relation in wj and we, the number of words in wj without a relation and the number of words in we without a relation are counted as x, y, z respectively.",
        "That is, x y = k and x i z= 1.",
        "By definition, TI.L(JW, EWCi) < 1.",
        "The value of a is determined as 2 by evaluating sample translation pairs.",
        "Followings are the TLL's of three EWC's for JW:t -'y }').-/:it which consists of four component words (k=4); \"% (=open),\" \"V 'y"
      ]
    },
    {
      "heading": "5.3 Combination of Statistical and Linguistic Information",
      "text": [
        "We define the translation likelihood /I(JW, 11WCi) as below: TE(JW, EWCi) in TLS(IW, EWCi) n TLE(JW, EWCi) in n Examining the value with the ratio ram constant, a low value of nsow, Ewcd ill affects the total score, especially when the frequency",
        "FJU(JW) is 5 or less.",
        "This shows that TLS(JW, EWCi) should be much weighed for JW's which appear often, but not for SW's with a low frequency.",
        "Therefore we tentatively define f3 = Wm as a function of frequency FJU(JW), because 13 should be higher when FJU(JW) is low.",
        "where r is a possible minimum frequency, and s is limit of 13 as the word frequency is high enough.",
        "Values p=4, q=1, r=1, and s=0.5 are used in the following experiments.",
        "By introducing p, F is rewritten as: F(TLS(JW, EWCi), TLL(JW, EWCi)) - TLS(JW, EWCi) + p TLL(JW, EWCi) 1 +f3 In case {FJU(.1W)}q is equal to or less than r, 13 is meaningless.",
        "For such JW's, TL(JW, EWCi) is redefined as simply: TL(.1W, EWCi) TLL(JW, EWCi).",
        "Finally the translation candidate EWCi with the largest value of TL(JW, EWCi) is assumed to be the correct English translation.",
        "Table 1 shows the translation candidates for JW: Y t.with the best three TL's.",
        "Its frequency in Japanese text is M(JW) = 19 (13",
        "are listed in Fig. 2.",
        "Table 2 shows the ranking of the correctly estimated translation pairs in seven sample texts.",
        "The upper row shows the average of seven individual texts; the lower shows the result using all seven texts in one time.",
        "The translation of over 70% of compound nouns is obtained as the first candidate, and over 80% in the top three.",
        "The result for unknown words is 54.0% and 65.0%.",
        "Though the accuracy for the unknown words is relatively low, the estimation has been impossible for Yamamoto (1993).",
        "Here, the terms whose correct translations are not found in English texts are excepted from evaluation.",
        "Such data occur when human experts give a noun translation for Japanese verbal noun term which is translated as a verb in the actual text.",
        "The ratio of this kind of translation pairs is about 3%.",
        "The rate of the correct data is calculated by the ratio of the total occurrences.",
        "The accuracy for the average of unknown words is 52.4% in the top three.",
        "The result using all texts is significantly better than the average because the statistical information is the major factor in the current implementation.",
        "Use of more linguistic information such as in Dangan (1991) and Matsumoto (1993) would improve the total performance.",
        "Linguistic information has proven effective to estimate translations of low-frequency terms.",
        "Of terms which appeared only once in a Japanese text, 215 translations are obtained correctly as the first candidate from 327 terms (65.7%) in seven texts.",
        "The fourth example of compound nouns in Fig. 2 shows the advantage of statistical information because the correct translation was obtained in spite of the wrong word segmentation.",
        "The Japanese term really consists of three words Pr 7 A , 7 F 1, A A ), each of which corresponds to \"column,\" \"address\" and \"strobe\" respectively.",
        "But word segmentation output four words ().1 7 A , 7 FL-A, 1.,-I) because \":;< 1.",
        "11.",
        "1\" is unknown and ''"
      ]
    },
    {
      "heading": "7 CONCLUSION",
      "text": [
        "An MT dictionary has been generated from Japanese and English parallel texts.",
        "The method proposed in this paper assumes unit correspondence and utilizes linguistic information in an MT bilingual dictionary as well as statistical information, namely, word frequency, to estimate the English translation, Over 70% accurate translations for compound nouns are obtained as the first candidate from small (about 300 sentences) Japanese/1Mglish parallel texts (patent specifications) containing severe distortions.",
        "The accuracy of the first translation candidates for unknown words, which cannot be obtained by a linguistic-based method, is over 50%.",
        "The current implementation shows promising results for a difficult target (patent texts) despite relatively simple linguistic knowledge.",
        "The overall performance will be unproved by using more linguistic knowledge and optimizing parameters calculated by statistical information."
      ]
    }
  ]
}
