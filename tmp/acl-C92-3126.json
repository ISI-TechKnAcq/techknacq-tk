{
  "info": {
    "authors": [
      "Rens Bod"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C92-3126",
    "title": "A Computational Model of Language Performance: Data Oriented Parsing",
    "url": "https://aclweb.org/anthology/C92-3126",
    "year": 1992
  },
  "references": [
    "acl-E91-1004"
  ],
  "sections": [
    {
      "text": [
        "The Synthesis of Syntax and Statistics The idea that a synthesis between syntactic and statistical approaches could be useful has incidentally been proposed before, but has not been worked out very well so far.",
        "The only technical elaboration of this idea that exists at the moment, the notion of a probabilistic grammar, is of a rather simplistic nature.",
        "A probabilistic grammar is simply a juxtaposition of the most fundamental syntactic notion and the most fundamental statistical notion: it is an \"old-fashioned\" context free grammar, that describes syntactic structures by means of a set of abstract rewrite rules that are now provided with probabilities that correspond to the application probabilities of the rules (see e.g. [Jelinek 1990]).",
        "As long as a probabilistic grammar only assigns probabilities to individual rewrite rules, the grammar cannot account for all statistical properties of a language corpus.",
        "It is, for instance, not possible to indicate how the probability of syntactic structures or lexical items depends on their syntactic/lexical context.",
        "As a consequence of this, it is not possible to recognize frequent phrases and figures of speech as such - a disappointing property, for one would prefer that such phrases and figures of speech would get a high priority in the ranking of the possible syntactic analyses of a sentence.",
        "Some improvements can be made by applying the Markov-approach to rewrite rules, as is found in the work of [Salomaa 19691 and [Magerman 1991].",
        "Nevertheless, any approach which tics probabilities to rewrite rules will never be able to acconunodate all statistical dependencies.",
        "Optimal statistical estimations can only be achieved if the statistics are applied to different kinds of units than rewrite rules.",
        "It is interesting to note that also in the field of theoretical linguistics the necessity to use other kinds of structural units has been put forward.",
        "The clearest articulation of this idea is found in the work of [Fillmore 1988].",
        "From a linguistic point of view that emphasizes the syntactic complexities caused by idiomatic and semi-idiomatic expressions, Fillmore et al.",
        "arrive at the proposal to describe language not by means of a set of rewrite rules, but by means of a set of constructions.",
        "A construction is a tree-structure: a fragment of a constituent-structure that can comprise more than one level.",
        "This tree is labeled with syntactic, semantic and pragmatic categories and feature-values.",
        "Lexical items can be specified as part of a construction.",
        "Constructions can be idiomatic in nature: the meaning of a larger constituent can be specified without being constructed from the meanings of its sub-constituents.",
        "Fillmore's ideas still show the influence of the tradition of formal grammars: the constructions are schemata, and the combinatorics of putting the constructions together looks very much like a context free grammar.",
        "But the way in which Fillmore generalizes the notion of grammar resolves the problems we found in the current statistical grammars: if a construction-grammar is combined with statistical notions it is perhaps possible to represent all statistical information.",
        "This is one of the central ideas behind our approach.",
        "A New Approach: Data Oriented Parsing The starting-point of our approach is the idea indicated above, that when a human language user analyzes sentences, there is a strong preference for the recognition of sentences, constituents and patterns that occurred before in the experience of the language user.",
        "There is a statistical component in language processing that prefers more frequent structures and interpretations to less frequently perceived alternatives.",
        "The information we ideally would like to use in order to model the language performance of a natural language user, comprises therefore an enumeration of all lexical items and syntactic/semantic structures ever experienced by the language user, with their frequency of occurrence.",
        "In practice this means: a very large corpus of sentences with their syntactic analyses and semantic interpretations.",
        "Every sentence comprises a large number of constructions: not only the whole sentence and all its constituents, but also the patterns that can be abstracted from the analyzed sentence by introducing 'free variables' for lexical elements or complex constituents.",
        "Parsing then does not happen by applying grammatical rules to the input sentence, but by constructing an optimal analogy between the input sentence and as many corpus sentences as possible.",
        "Sometimes the system shall need to abstract away from most of the properties of the trees in the corpus, and sometimes a part of die input is found literally in the corpus, and can be treated as one unit in the parsing process.",
        "Thus the system tries to combine constructions from the corpus so as to reconstruct the input sentence as 'well' as possible.",
        "The preferred parse out of all parses of the input sentence is obtained by maximizing the conditional probability of a parse given the sentence.",
        "Finally, the preferred parse is added to the corpus, bringing it into a new 'state'.",
        "To illustrate the basic idea, consider the following extremely simple example.",
        "Assume that the whole corpus consists of only the following two trees: Then the input sentence who opened coling92 in Nantes in July can be analyzed as an S by combining the following constructions from die corpus:",
        "The events tnot mutually exclusive, since constructions can overlap, and can include other constructions.",
        "The formula for the joint probability of events E1 is given by:",
        "We will use Bayes decomposition formula to derive the conditional probability of Ti given s. Let Ti and Tj be parses of s; the conditional probability of Ti given s, is then given by:",
        "A parse Ti of a with maximal conditional probability P(Tds) is called a preferred parse of S.",
        "Several different implementations of DOP are possible.",
        "In [Scholtes 1992] a neural net implementation of DOP is proposed.",
        "Here we will show that conventional rule based parsing strategies can be applied to DOP, by converting constructions into rules.",
        "A construction can be seen as a production rule, where the leftliand-side of the rule is constituted by the root of the construction and the righthand-side is constituted by the leaves of the construction.",
        "The only extra condition is that of every such rule its corresponding construction should be remembered in order to generate a parse-tree for the input string (by composing the constructions that correspond to the rules that are applied).",
        "For a construction 4 the corresponding production rule is given by root(t)leaves(t) In order to calculate the prefen-ed parse of an input string by maximizing the conditional probability, all parses with all possible tuples of constructions must be generated, which becomes highly inefficient.",
        "Often we are not interested in all parses of an ambiguous input string, neither in their exact probabilities, but only in which parse is the preferred parse.",
        "Thus we would like to have a strategy that estimates the top of the probability hierarchy of parses.",
        "This can be achieved by using Monte Carlo techniques (see e.g. [Hammersley 1964]): we estimate the preferred parse by taking random samples from the space of possibilities.",
        "This will give us a more effective approach than exhaustively calculating the probabilities.",
        "Although DOP has not yet been tested thoroughly2, we can already predict some of its capabilities.",
        "In 1)0P, the probability of a parse depends on all tuples of constructions that generate that parse.",
        "The more different ways in which a parse can be generated, the higher its probability.",
        "This implies that a parse which can (also) be generated by relatively large constructions is favoured over a parse which can only be generated by relatively small constructions.",
        "This means that prepositional phrase attachments and figures of speech can be processed adequately by II0P.",
        "As to the problem of hinguage acquisition, this might seem problematic for DOP: with an already analyzed corpus, only adult language behaviour can be simulated.",
        "The problem of language acquisition is in our perspective the problem of the acquisition of an initial corpus, in which non-linguistic input and pragmatics should play an important role.",
        "An additional remark should be devoted here to formal grammars and disambiguation.",
        "Much work has been done to extend rule-based grammars with selectional restrictions such that the explosion of ambiguities is constrained considerably.",
        "Ilowever, to represent semantic and pragmatic constraints is a very expensive task.",
        "No one has ever succeeded in doing so except in relatively small grammars.",
        "Furthermore, a basic question remains as to whether it is possible to formally encode all of the syntactic, semantic and pragmatic information needed for disambiguation.",
        "In DOP, the additional information that one can draw from a corpus of hand-marked structural annotations is that one can bypass the necessity for modelling world knowledge, since this will automatically enter into the disambiguation of structures by hand.",
        "Extracting constructions from these structures, and combining them in the most probable way, taking into account all possible statistical dependencies between them, preserves this world knowledge in the best possible way.",
        "In conclusion, it may be interesting to note that our idea of using past language experiences instead of rules, has much in common with Stich's ideas about language ((Stich 19711).",
        "In Stich's view, judgements of grammaticality are not determined by applying a precompiled set of grammar rules, but rather have the character of a perceptual judgement on the question to what extent the judged sentence 'looks like' the sentences the language user has in his head as examples of grammaticality.",
        "The concrete language experiences of the past of a language user determine how a new utterance is processed; there is no evidence for the assumption that past language experiences are generalized into a consistent theory that defines the",
        "This paper fonnalizes the model for natural language introduced in [Sella 1990].",
        "Since that article is written in I)utch, we will translate some parts of it more or less literally in this introduction.",
        "According to Sella, the current tradition of language processing systems is based on linguistically motivated competence models of natural languages.",
        "The problems that these systems run into, suggest die necessity of a more performance oriented model of language processing, that takes into account the statistical properties of real language use.",
        "Therefore Scha proposes a system that makes use of an annotated corpus.",
        "Analyzing a new input means that the system attempts to find the most probable way to reconstruct the input out of fragments that already exist in the corpus.",
        "The problems with competence grammars that are mentioned in Scha's article, include the explosion of ambiguities, the fact that human judgements on granunaticality are not stable, that competence grammars do not account for language change, and that no existing rule-based grammar gives a descriptively adequate characterization of an actual language.",
        "According to Scha, the development of a formal grammar for natural language gets more difficult as die grammar gets larger.",
        "When the number of phenomena one has already taken into account gets larger, the number of interactions that must be considered when one tries to introduce an account of a new phenomenon grows accordingly.",
        "As to die problem of ambiguity, it has turned out that as soon as a formal grammar characterizes a non-trivial part of a natural language, almost every input sentence of reasonable length gets an unmanageably large number of different structural analyses (and The author wishes to thank his colleagues at the Department of Computational Linguistics of the University of Amsterdam for many fruitful discussions, and, in particular, Remko Martin van den Berg, Kwee Tjoe Liong and Frederik Sornsen for valuable comments on earlier versions of this paper.",
        "semantic.al interpretations).'",
        "This is problematic since most of these interpretations are not perceived as possible by a human language user, while there are no systematic reasons to exclude them on syntactic or semantic grounds.",
        "Often it is just a matter of relative implausibility: the only reason why a certain interpretation of a sentence is not perceived, is that another interpretation is much more plausible."
      ]
    },
    {
      "heading": "Competence and Performance",
      "text": [
        "'the limitations of the current language processing systems are not suprising: they are die direct consequence of the fact that these systems implement Chomsky's notion of a competence grammar.",
        "The formal grammars that constitute the subject-matter of theoretical linguistics, aim at characterizing the competence of the language user.",
        "But the preferences language users have in the case of ambiguous sentences, are paradigm instances of performance phenomena.",
        "In order to build effective language processing systems we must implement performance-grammars, rather than competence grammars.",
        "These performance gramnuus should not only contain infomiation on the structural possibilities of the general language system, but also on details of actual language use in a language community, and of die language experiences of an individual, which cause this individual to have certain expectations on what kinds of utterances are going to occur, and what structures and interpretations these utterances are going to have.",
        "There is an alternative linguistic tradition that has always focused on the concrete details of actual language use: die statistical tradition.",
        "In this approach, syntactic structure is usually ignored; only 'superficial' statistical properties of a large corpus are described: the probability that a certain word is followed by a certain other word, the probability that a certain sequence of two words is followed by a certain word, etc.",
        "(Markovchains, see e.g. [Bahl 1983]).",
        "This approach has performed succesfully in certain practical tasks, such as selecting the most probable sentence from the outputs of a speech recognition component.",
        "It will be clear that this approach is not suitable for many other tasks, because no notion of syntactic MAMA= is used.",
        "And there are statistical dependencies within the sentences of a corpus, that can extend over an arbitrarily long sequence of words; this is ignored by the Markov-approach.",
        "The challenge is now to develop a theory of language processing that does justice to the statistical as well as to the structural aspects of language.",
        "I In [Martin 1979] it is reported that their puser generated 455 different parses for the sentence \"List the sales of products produced in 1973 with the products produced in 1972\".",
        "ACIIS DE COUNG-92, NAnrrEs, 23-28 AO&I' 19921155PROC.",
        "OF COLING-92, NAN l'ES, AUG. 23-28, 1992 granunaticality and the structure of new utterances univocally."
      ]
    },
    {
      "heading": "References",
      "text": [
        "[Bahl 1983]: Bahl, L., Jelinek, F. and Mercer, R., 'A Maxinium Likelihood Approach to Continuous Speech Recognition', in: IFF:F Transactions on Pattern Analysis and Machine Intelligence, Vol.",
        "PAMI-5, No.2.",
        "[Fillmore 1988] Fillmore, C., Kay, P. and O'Connor, M., 'Regularity and idiomaticity in grammatical constructions: the case of let alone', Language 64, p. 501-538.",
        "[Hammersley 1964]: Hauunersley, J.M.",
        "and Handscomb, D.C., Monte Carlo Methods, Chapman and Hall, London.",
        "[Harris 1966]: Harris, B., Theory of Probability, Addison-Wesley, Reading (Mass).",
        "[Jelinck 1990]: Jelinek, F., Lafferty, J.D.",
        "and Mercer, RI,., Basic Methods of Probabilistic Context Free Grammars, Yorktown Heights: IBM RC 16374 (#72684).",
        "[Magennan 1991]: Magerman, D. and Marcus, M., 'Pearl: A Probabilistic Chart Parsee,in: Proceedings of the European Chapter of the ACT 91, Berlin.",
        "[Martin 1979]: Martin, W.A., Preliminary analysis of a breadth-first parsing algorithm: Theoretical and experimental results (Technical Report No.",
        "lit-261).",
        "MIT LCS.",
        "[SaJomaa 1969]: Salomaa, A., 'Probabilistic and weighted grammars', in: Information and control 15, p. 529-544, [Scha 1990]: Scha, R., 'Language Theory and Language Technology; Competence and Performance' (in Dutch), in: Q.A.M.",
        "de Kort 8c G.L.J.",
        "Leerdani (eds.",
        "), Computertoepassingen in de Neerlandistiek, Almere: Landelijke Vereniging van Neerlandici.",
        "(LVVNjaarboek) [Scholtes 1992]: Scholtes, J. C. and Bloembergen, S., The Design of a Neural Data-Oriented Parsing (DOP) System', Proceedings of the International Joint Conference on Neural Networks 1992, Baltimore.",
        "[Stich 19711: Stich, SP., 'What every speaker knows', in: Philosophical Review 80, p.476-496.",
        "Acres DE COL1NG-92, NANrre,s, 23-28 Aarr 1992859 PROC.",
        "OF COL1NG-92, NANTes, AUG. 23-28, 1992 The ModelTg/N VPPP In order to come to formal definitions of parse and preferred parse we first specify some basic notions."
      ]
    },
    {
      "heading": "Labels",
      "text": [
        "We distinguish between the set of lexical labels L and the set of non-lexical labels N. Lexical labels represent words.",
        "Non-lexical labels represent syntactic and/or semantic and/or pragmatic information, depending on the kind of corpus being used.",
        "We write / for LuAl.",
        "String Given a set of labels /, a string is an n-tuple of elements of(Li,Lit) c Z.",
        "An input string is an n-tuple of elements of L:c 1\".",
        "A concatenation * can be defined on strings as usual: (a,...,b,cd).",
        "Tree Given a set of labels Z, the set of trees is defined as the smallest set Tree such that (1)if Lei, then (1())e7'ree (2)if Lei, th...,t,,ETree, then (1,4i ,taciree For a set of trees Tree over a set of labels Z, we define a function root: Tree--4 and a function leaves: Tree-4114 by for n_0, rool((L,(11,...,4))) for n>0, le.aves(041,...,4))) leaves(0)....*leavesaid for n=0, leavesaL,O)).= (L)",
        "An input string can have several parses and every such parse can be generated by several different combinations of constructions from the corpus.",
        "What we are interested in, is, given an input string s, flue probability that arbitrary combinations of constructions from the corpus generate a certain parse Ti of s. 'thus we are interested in the conditional probability of a parse I', given s, with as probability space the set of constructions of trees in the corpus.",
        "let Ti be it parse of input string s, and suppose that Ti can exhaustively be generated by k tuples of Tuplesth,C) = (Ontint), constructions: (12/,,(2a2,), , Ora-Audi.",
        "Then Ti occurs iff (t11,Ow) or (t1,t252) or .... or (tkb...,tknk) occur, and (t1,1,timid mons iff t51 and /b2 and .... Pr he Acres us COL1NG-92, NANrEs, 23-28 noCr 1992857 Puoc.",
        "oe COI ,ING-92, NAN I ES, AUG. 23-28, 1992"
      ]
    }
  ]
}
