{
  "info": {
    "authors": [
      "Ge Xu",
      "Xinfan Meng",
      "Houfeng Wang"
    ],
    "book": "COLING",
    "id": "acl-C10-1136",
    "title": "Build Chinese Emotion Lexicons Using a Graph-based Algorithm and Multiple Resources",
    "url": "https://aclweb.org/anthology/C10-1136",
    "year": 2010
  },
  "references": [
    "acl-E09-1077",
    "acl-P02-1053",
    "acl-W06-3808",
    "acl-W09-3001",
    "acl-W97-0313"
  ],
  "sections": [
    {
      "text": [
        "Build Chinese Emotion Lexicons Using A Graph-based Algorithm and Multiple Resources",
        "Ge Xu, Xinfan Meng, Houfeng Wang",
        "Key Laboratory of Computational Linguistics (Peking University), Ministry of Education Institute of Computational Linguistics, Peking University {xuge, mxf, wanghf}@pku.edu.cn",
        "For sentiment analysis, lexicons play an important role in many related tasks.",
        "In this paper, aiming to build Chinese emotion lexicons for public use, we adopted a graph-based algorithm which ranks words according to a few seed emotion words.",
        "The ranking algorithm exploits the similarity between words, and uses multiple similarity metrics which can be derived from dictionaries, unlabeled corpora or heuristic rules.",
        "To evaluate the adopted algorithm and resources, two independent judges were asked to label the top words of ranking list.",
        "It is observed that noise is almost unavoidable due to imprecise similarity metrics between words.",
        "So, to guarantee the quality of emotion lexicons, we use an iterative feedback to combine manual labeling and the automatic ranking algorithm above.",
        "We also compared our newly constructed Chinese emotion lexicons (happiness, anger, sadness, fear and surprise) with existing counterparts, and related analysis is offered."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Emotion lexicons have a great impact on the results of related tasks.",
        "With high-quality emotion lexicons, systems using simple methods can achieve competitive performance.",
        "However, to manually build an emotion lexicon is time-consuming.",
        "Many research works in building lexicons use automatic methods to assist the building procedure.",
        "Such works commonly rank words by the similarities to a set of seed words, then those words with high ranking scores are more likely to be added to the final lexicons or used as additional seed words.",
        "For Chinese, emotion lexicons are scarce resources.",
        "We can get a small set of emotion words from semantic dictionary (such as CCD, HowNet, synonym dictionaries) or directly from related papers (Xu and Tao, 2003) (Chen et al.",
        ", 2009), but it is often not sufficient for practical systems.",
        "Xu et al.",
        "(2008) constructed a large-scale emotion ontology dictionary, but it is not publicly available yet.",
        "In this paper, we adopted a graph-based algorithm to automatically rank words according to a few seed words.",
        "Similarity between words can be utilized and multiple resources are used to boost performance.",
        "Combining manual labeling with automatic ranking through an iterative feedback framework, we can produce high-quality emotion lexicons.",
        "Our experiments focused on Chinese, but the method is applicable to any other language as long as suitable resources exist.",
        "The remainder of this paper is organized as follows.",
        "In Section 2, related works are introduced.",
        "In Section 3, we describe a graph-based algorithm and how to incorporate multiple resources.",
        "Section 4 gives the details of applying the algorithm on five emotions and shows how to evaluate the results.",
        "Section 5 focuses on how to build and evaluate emotion lexicons, linguistic consideration and instruction for identifying emotions are also included.",
        "Finally, conclusion is made in Section 6."
      ]
    },
    {
      "heading": "2. Related work",
      "text": []
    },
    {
      "heading": "3. Our method",
      "text": [
        "Riloff and Shepherd (1997) presented a corpus-based method that can be used to build semantic lexicons for specific categories.",
        "The input to the system is a small set of seed words for a category and a representative text corpus.",
        "The output is a ranked list of words that are associated with the category.",
        "An approach proposed by (Tur-ney, 2002) for the construction of polarity started with a few positive and negative seeds, then used a similarity method (pointwise mutual information) to grow this seed list from web corpus.",
        "Our experiments are similar with these works, but we use a different ranking method and incorporate multiple resources.",
        "To perform rating inference on reviews, Goldberg and Zhu (2006) created a graph on both labeled and unlabeled reviews, and then solved an optimization problem to obtain a smooth rating function over the whole graph.",
        "Rao and Ravichandran (2009) used three semi-supervised methods in polarity lexicon induction based on WordNet, and compared them with corpus-based methods.",
        "Encouraging results show methods using similarity between words can improve the performance.",
        "Wan and Xiao (2009) presented a method to use two types of similarity between sentences for document summarization, namely similarity within a document and similarity between documents.",
        "The ranking method in our paper is similar to the ones used in above three papers, which fully exploit the relationship between any pair of sample points (both labeled and unlabeled).",
        "When only limited labeled data are available, such method achieves significantly better predictive accuracy over other methods that ignore the unlabeled examples during training.",
        "Xu et al.",
        "(2008) at first formed a taxonomy for emotions, under which an affective lexicon ontology exploiting various resources was constructed.",
        "The framework of ontology is filled by the combination of manual classification and automatic methods.",
        "To our best knowledge, this affective lexicon ontology is the largest Chinese emotion-oriented dictionary.",
        "For our experiments, we chose the graph-based algorithm in (Zhou et al.",
        ", 2004) which is transduc-tive learning and formulated as follows:",
        "Given apoint set x = {x1;xl, xl+1, ...,xn}, the first l points xi(i < l) are labeled and the remaining points xu (l + 1 < u < n) unlabeled.",
        "The goal is to rank the unlabeled points.",
        "Let F denotes an n-dimensional vector whose elements correspond to ranking scores on the data set x.",
        "Define another n-dimensional vector Y with Y = 1 if xi is labeled and Y = 0 otherwise.",
        "Y denotes the initial label assignment.",
        "The iterative algorithm is shown in the following:",
        "Algorithm 1 A graph-based algorithm 1.",
        "Construct the weight matrix W and set Wii to zero to avoid self-reinforcement.",
        "W is domain-dependent.",
        "2.",
        "Construct the similarity matrix S = D1/2WD1/2 using symmetric normalization.",
        "D is a diagonal matrix with Dii = Ej Wij.",
        "3.",
        "Iterate F(t + 1) = aSF(t) + (1 - a)Y until convergence, where a is a parameter in (0, 1), and F(0) = Y.",
        "We clamp labeled points to 1 after each iteration.",
        "4.",
        "Let F * denote F (t) when the iteration converges.",
        "In our experiments, labeled points are seed emotion words, Sij denotes the similarity between ith word and jth word.",
        "In an iteration, each word absorbs label information from other words.",
        "More similar two words are, more influence they have on each other.",
        "The label information (initially from seed emotion words) will propagate along S. The final output F * contains ranking scores for all words, and a score indicates how similar the corresponding word is to the seed emotion words.",
        "The implementation of the iterative algorithm is theoretically simple, which only involves basic matrix operation.",
        "Compared with methods which do not exploit the relationship between samples, experiments showing advantages of graph-based learning methods can be found in (Rao and Ravichandran, 2009),(Goldberg and 2009),(Zhu and Ghahramani, 2002) etc.",
        "When labeled data are scarce, such graph-based transduc-tive learning methods are especially useful.",
        "For building the emotion lexicons, we are faced with lots of resources, such as semantic dictionaries, labeled or unlabeled corpora, and some linguistic experiences which can be presented as heuristic rules.",
        "Naturally we want to use these resources together, thus boosting the final performance.",
        "In graph-base setting, such resources can be used to construct the emotion-oriented similarity between words, and similarities will be represented by matrices.",
        "The schemes to fuse similarity matrices are presented in (Sindhwani et al.",
        ", 2005), (Zhou and Burges, 2007), (Wan and Xiao, 2009) and (Tong et al.",
        ", 2005) etc.",
        "In our paper, not aiming at comparing different fusion schemes, we used a linear fusion scheme to fuse different similarities matrices from different resources.",
        "The scheme is actually a convex combination of matrices, with weights specified empirically.",
        "The fusion of different similarity matrices falls in the domain of multi-view learning.",
        "A well-known multi-view learning method is Co-Training, which uses two views (two resources) to train two interactive classifiers (Blum and Mitchell, 1998).",
        "Since we focus on building emotion lexicons using multiple resources (multiple views), those who want to see the advantages of multi-view learning over learning with one view can refer to (Blum and Mitchell, 1998), (Sindetc."
      ]
    },
    {
      "heading": "4. Experiments",
      "text": [
        "We use the method in section 3 to rank for each emotion with a few seed emotion words.",
        "Once we implement the ranking algorithm 1, the main work resides in constructing similarity matrices, which are highly domain-dependent.",
        "Here, we introduce how to construct four similarity matrices used in building emotion lexicons.",
        "Three of them are based on cooccurrence of words; the fourth matrix is from a heuristic rule.",
        "We use ictclas3.0 to perform word segmentation and POS tagging.",
        "In our experiments, the number of words involved in ranking is 93506, so theoretically, the matrices are 93506 x 93506.",
        "If the similarity between any pair of words is considered, the computation becomes impractical in both time and space cost.",
        "So we require that each word has at most 500 nearest neighbors.",
        "Four matrices are constructed as follows:",
        "The unlabeled corpus used is People's Daily(A & 0 Ä1997~2004).",
        "After word segmentation and POS tagging, we chose three POS's (i,a,l).",
        "The nouns were not included to limit the scale of word space.",
        "We set the cooccurrence window to a sentence, and removed the duplicate occurrences of words.",
        "Any pair of words in a sentence will contribute a unit weight to the edge which connects the pair of words.",
        "We used the Chinese synonym dictionary (PP I^^l^^ttfl f&) for this matrix.",
        "In this dictionary, the words in a synonym set are presented in one line and separated by spaces, so there is no need to perform word segmentation and POS tagging.",
        "Any pair of words in one line will contribute a unit weight to the edge which connects the pair of words.",
        "We used The Contemporary Chinese Dictionary (JÄf^ÄiiHilÄ) to construct the third similarity matrix.",
        "Since word segmentation may segment the entries of the dictionary, we extracted all the entries in the dictionary and store them in a file whose words ictclas3.0 was required not to segment.",
        "Furthermore, for an entry in the dictionary, the example sentences or phrases appearing in its gloss may contain many irrelevant words in terms of emotions, so they were removed from the gloss.",
        "After word segmentation and POS tagging, we set the cooccurrence window to one line (an entry and its gloss without example sentences or phrases), and removed the duplicate occurrences of words.",
        "An entry and any word in the modified gloss will contribute a unit weight to the edge which connects the pair of words.",
        "This constructing was a bit different, since we did not consider the similarity between words in modified gloss.",
        "In Chinese, a word is composed of one or several Chinese characters.",
        "A Chinese character is normally by itself an independent semantic unit, so the similarity between two words can be inferred from the character(s) that they share.",
        "For example, the Chinese word jjft (happy) appears in the word /tfcM (readily).",
        "Since /tfcM and jjft share one Chinese character, they are regarded as similar.",
        "Naturally, the larger the proportion that two words share, the more similar they are.",
        "In this way, the fourth weighted matrix was formed.",
        "To avoid incurring noises, we exclude the cases where one Chinese character is shared, with the exception that the Chinese character itself is one of the two Chinese words.",
        "After processing all the lines (or sentences), the weighted matrices are normalized as in algorithm 1, then four similarity matrices are linearly fused with equal weights (1/4 for each matrix).",
        "In our experiments, we chose emotions of happiness, sadness, anger, fear and surprise which are widely accepted as basic emotions.",
        "Empirically, we assigned each emotion with seed words given in Table 1.",
        "We obtained five ranking lists of words using the method in section 3.",
        "Following the workof(Riloff and Shepherd, 1997), we adopted the following evaluation setting.",
        "To evaluate the quality of emotion ranking lists, each list was manually rated by two persons independently.",
        "For each emotion, we selected the top 200 words of each ranking list and presented them to judges.",
        "We presented the words in random order so that the judges had no idea how our system had ranked the words.",
        "The judges were asked to rate each word on a scale from 1 to 5 indicating how strongly it was associated with an emotion, 0 indicating no association.",
        "We allowed the judges to assign 1 to a word if they did not know what it meant.",
        "For the words rated as -1, we manually assigned ratings that we thought were appropriate.",
        "The results of judges are shown in figures 1-5.",
        "In these figures, horizontal axes are the number of reviewed words in ranking lists and vertical axes are number of emotion words found (with 5 different strength).",
        "The curve labeled as > x means that it counts the number of words which are rated",
        "Emotion",
        "Seed words",
        "H (happiness)",
        "tërtfe, m %",
        "M (anger)",
        "mm, » mx, m m, mm, mm, mm, m m, nx, mm, m^x#, xmmM, m%wx",
        "M(sadness)",
        "mfë, m, m^, fëù, m",
        "a, MM, m$t, TâU, M'ù",
        "fë, mm, mm, mmmë,",
        "m(fear)",
        "®m, m te, ôù, fêù^ m, i®, mm, s",
        "i(surprise)",
        "iw, 1 ,mi, i ®, m, '« i, *4, is, n",
        "words reviewed",
        "greater than x by either judge.",
        "Curves (> 0, > 1, > 2) display positive slopes even at the end of the 200 words, which implies that more emotion words would occur if more than 200 words are reviewed.",
        "By comparison, curves (> 3, > 4) tend to be flat when they are close to the right side, which means the cost of identifying high-quality emotion words will increase greatly as one checks along the ranking list in descendent order.",
        "It is observed that words which both judges assign 5 are few.",
        "In surprise emotion, the number is even 0.",
        "Such results may reflect that emotion is harder to identify compared with topical categories in (Riloff and Shepherd, 1997).",
        "From the semantic dictionary, our method found many low-frequency emotion words such as 'W (pleasant, glad), Hi (surprise and happy), fH fB (sad), or those used in Chinese dialects such as (fear), W% (angry).",
        "Such emotion words are necessary for comprehensive emotion lexicons.",
        "Because more POS's than adjectives and verbs are included in our experiments, some emotion words such as the noun Ï1 (unexpected win-ner),and the adverb (to one's surprise) are also spotted, which to some extent implies the generality of our method."
      ]
    },
    {
      "heading": "5. Construct emotion lexicons",
      "text": [
        "The above section introduced a method to rank words with a few seed emotion words.",
        "However, to build emotion lexicons requires that we manually remove the noises incurred by the automatic ranking method.",
        "Accordingly, guidelines for identifying emotions are needed, and also some linguistic consideration in identifying emoting words should be given.",
        ">0",
        "->2",
        ">4",
        "y",
        " – • – ",
        "--",
        "_... >0",
        ">3",
        ">4",
        "___",
        "y--'",
        ">0",
        "->2",
        "^ /......",
        ">4",
        " – ~~",
        "--^",
        "__",
        "--",
        "In our experiments, we observed that noises incurred by similarity matrices are almost unavoidable.",
        "For example, in the unlabeled corpus, S l?tfj (state visits) always co-occurred with M 7n (happy) or fÉlS: (happy), so in happiness emotion, S l^tfj fp| acquired a high ranking position (174th); in terms of the heuristic rule, Ä$4 (expected) shares two Chinese characters with tij f Ä$4 (unexpected, surprised), however they have opposite meaning because tJB f (exceed, beyond) is a negative word.",
        ";©$4 unfavorably ranked high (88th) in surprise emotion; from the semantic dictionary, the gloss of ^iffll (Chinese Spring Festival pictures) contains )0Cifc (happy), thus in happiness emotion, ranked high (158th).",
        "So after each ranking of an emotion, in the descendent order of ranking scores, we manually revised some scores in about top 500.",
        "Several criteria (see 5.2 and 5.3) were given to guide if a word has a specified emotion.",
        "For those words surely bearing the specified emotion, we assigned 1 to them ,and left others unchanged.",
        "Seeing the words newly revised to be 1 as new seed emotion words, we run the ranking algorithm again.",
        "After such feedback was repeated 2~3 times, we collected all the words labeled with 1 to form the final emotion lexicons.",
        "In (Zhou et al.",
        ", 2004), the author also suggested such iterative feedback to extend the query (seed) set and improve the ranking output.",
        "Commonly, the size of an emotion lexicon is small, so we do not have to check too many words.",
        "The human revising procedure is sensitive to annotators' background.",
        "To improve the quality of the emotion lexicons, experts with linguistic or psychology background will help.",
        "Furthermore, the ranking algorithm used in our paper is clearly sensitive to the initial seed words, but since we adopt an iterative feedback framework, the words not appearing in the initial set of seed words will show up in next iteration with high ranking scores.",
        "We also performed experiments which selected emotion seed words based on the Chinese synonym dictionary and the emotion words in (Chen et al.",
        ", 2009), similar results were found.",
        "The same as (Chen et al.",
        ", 2009), we used the definition that emotion is the felt awareness of bodily reactions to something perceived or thought.",
        "Also, we were highly influenced by the structure of the affective lexicon presented by (Ortony et al.",
        ", 1987), and used the Affective states and Affective-Behavioral conditions in the structure to identify emotion words in our paper.",
        "With such guidelines, Ifi j/ (cowardice, relates more to external evaluation) is not an emotional word of fear.",
        "We also intentionally distinguish between emotions and expression of emotions.",
        "For example, (laugh), PPPP (haw-haw) are seen as expression of happiness and KS (tremble) as of fear, but not as emotion words.",
        "In addition, we try to distinguish between an emotion and the cause of an emotion, see 5.3 for an example.",
        "For each emotion, brief description is given as below :",
        "1.",
        "Happiness: the emotional reaction to something that is satisfying.",
        "2.",
        "Anger: do not satisfy the current situation and have a desire to fight or change the situation.",
        "Often there exists a target for this emotion.",
        "3.",
        "Sadness: an emotion characterized by feelings of disadvantage, loss, and helplessness.",
        "Sadness often leads to cry.",
        "4.",
        "Fear: the emotional response to a perceived threat.",
        "Fear almost always relates to future events, such as worsening of a situation, or continuation of a situation that is unacceptable.",
        "5.",
        "Surprise: the emotional reaction to something unexpected.",
        "If a word has multiple senses, we only consider its emotional one(s).",
        "For example, fe^t (as a verb, it means be angry, but means vitality or spirits as a noun) will appear in the emotion lexicon of anger.",
        "If one sense of a word is the combination of emotions, the word will appear in all related emotions.",
        "We mainly consider four POS's, namely nouns, verbs, adjectives and adverb.",
        "If a word has multiple POS's, we normally consider its POS with strongest emotion (Empirically, we think the emotion strength ranks in decedent order as following: adjectives, verbs, adverbs, nouns.).",
        "So we consider the verb of (fear) when it can be used as a noun and a verb in Chinese.",
        "The fe^t example above also applies here.",
        "For each of four POS's, instruction for emotion identification is given as below:",
        "Nouns: For example, SX (rage, anger), Ä^t (joy or jubilation), H (an unexpected winner) are selected as emotion words.",
        "We distinguish between an emotion and the cause of an emotion.",
        "For example, calamity often leads to sadness, but does not directly contain the emotion of sadness.",
        "<4* H appears in the surprise lexicon because we believe it contains surprise by itself.",
        "Adverbs: The adverbs selected into emotion lexicons contain the emotions by themselves.",
        "For example, äI (unexpectedly), /tfc/t^I (cheerily), ^%n?n?",
        "(angrily), ÜI (unexpectedly), fë'LVl (sadly) etc.",
        "Verbs: As in (Ortony et al.",
        ", 1987), Chinese emotion verbs also fall into at least two distinct classes, causatives and noncausatives.",
        "Both classes are included in our emotion lexicons.",
        "For example, zZj JJf X (be angry), ;LV (fear) are noncausative verbs, while #S (enrage), MS (to make someone surprised) are causative ones.",
        "Probably due to the abundant usage of ^A/ih À/fJËÀ (to make someone) etc., causative emotion verbs are few compared to noncausative ones in Chinese.",
        "Adjective : Quite a lot of emotion words fall in this POS, since adjectives are the natural expression of internal states of humans.",
        "For example, M t£ (happy), SW (surprised), MS (angry) etc.",
        "For any word that it is hard to identify at first sight, we used a search tool to retrieve sentences which contain the word, and then identify if the word is emotional or not by its usage in the sentences.",
        "Under the guidelines for manually identifying emotion words, we finally constructed five Chinese emotion lexicons using the iterative feedback.",
        "The newly constructed emotion lexicons were also reported as resources together with our paper.",
        "The emotion lexicon of surprise is shown in Table 2.",
        "In this part, we compare our lexicons with the following counterparts, see Table 3.",
        "Ours1 in the table is the final emotion lexicons, and Ours2 is the abridged version that excludes the words of single Chinese character and Chinese idioms.",
        "Chinese Concept Dictionary (CCD) is a WordNet-like semantic lexicon(Liu et al.",
        ", 2003).",
        "In ff In ÄIn xs&ê, xs/min ta, ig,",
        "I, IIIS, fei, SM, si, fei, Stt, fefê^fê, s",
        "InÜ^SnS^*^NSff N",
        "SI, SS, S^^^n it, S A, StäiftN SX, SÄ, Slil, SÄTJ^K SU,",
        "Table 3: Compare various emotion lexicons We only considered the noun network which is richly developed in CCD, as in other semantic dictionaries.",
        "For each emotion, we chose its synset as well as the synsets of its hypernym and hy-ponym(s).",
        "In fact, most of words in the emotion nouns extracted can be used as verbs or adjectives in Chinese.",
        "However, since CCD is not designed for emotion analysis, words which are expression of emotions such as (cry) or evaluation such as fiB/h (cowardice) were included.",
        "Selecting nouns and verbs, Xu and Tao (2003) offered an emotion taxonomy of 390 emotion words.",
        "The taxonomy contains 24 classes of emotions and excludes Chinese idioms.",
        "By our inspection to the offered emotion words in this taxonomy, the authors tried to exclude expression of emotions, evaluation and cause of emotions from emotions, which is similar with our processing.",
        "Ours2 is intentionally created to compare with this emotion taxonomy.",
        "Based on (Xu and Tao, 2003), Chen et al.",
        "(2009) removed the words of single Chinese character; let two persons to judge if a word is an emotional one and only those agreed by the two persons were seen as emotion words.",
        "It is worth noting that Chen et al.",
        "(2009) merges S (anger) and M (fidget) in (Xu and Tao, 2003) to form the S (anger) lexicon, thus i4\"Pü (dislike) appears in anger lexicon.",
        "However, we believe ÜPÜ (dislike) is different with S (anger), and should be put into another emotion.",
        "Also, we distinguish between Itl (hate) and S (anger).",
        "Xu et al.",
        "(2008) constructed a large-scale affective lexicon ontology.",
        "Given the example words in their paper, we found that the authors did not intentionally exclude the expression of emotions such as MtEl^^ (literally, red face and ear), ^ DfcDfc' (literally, be smiling).",
        "Such criteria of identifying emotion words may partially account for the large size of their emotion resources."
      ]
    },
    {
      "heading": "6. Conclusion and future work",
      "text": [
        "In this paper, aiming to build Chinese emotion lexicons, we adopt a graph-based algorithm and incorporate multiple resources to improve the quality of lexicons and save human labor.",
        "This is an initial attempt to build Chinese emotion lexicons, the quality of constructed emotion lexicons is far from perfect and is supposed to be improved step by step.",
        "The method in this paper can be further extended to subjectivity/polarity classification and other non-sentimental tasks such as word similarity computing, and can be also adapted to other languages.",
        "The more resources we use, the more human cost can be saved and the higher the quality of built emotion lexicons is.",
        "In the future work, we want to construct other emotion lexicons such as M (like, love), M (dislike), ^ (desire) etc.",
        "using the same method.",
        "Acknowledgement This research is supported by National Natural Science Foundation of China",
        "Ä 1=1",
        "S",
        "Ä",
        "I",
        "S",
        "CCD nouns",
        "22",
        "27",
        "38",
        "46",
        "10",
        "(Xu and Tao, 2003)",
        "45",
        "12",
        "28",
        "21",
        "12",
        "(Chen et al.",
        ", 2009)",
        "28",
        "34",
        "28",
        "17",
        "11",
        "(Xu et al.",
        ", 2008)",
        "609",
        "187",
        "362",
        "182",
        "47",
        "Ours1",
        "95",
        "118",
        "97",
        "106",
        "99",
        "Ours2",
        "52",
        "77",
        "72",
        "57",
        "65"
      ]
    }
  ]
}
