{
  "info": {
    "authors": [
      "Mo Shen",
      "Hongxiao Liu",
      "Daisuke Kawahara",
      "Sadao Kurohashi"
    ],
    "book": "ACL",
    "id": "acl-P14-2042",
    "title": "Chinese Morphological Analysis with Character-level POS Tagging",
    "url": "https://aclweb.org/anthology/P14-2042",
    "year": 2014
  },
  "references": [
    "acl-C04-1067",
    "acl-C08-1049",
    "acl-C10-2139",
    "acl-D10-1082",
    "acl-D12-1132",
    "acl-P07-2055",
    "acl-P08-1102",
    "acl-P09-1058",
    "acl-P11-1139",
    "acl-P11-1141",
    "acl-P13-1013",
    "acl-W02-1001",
    "acl-W04-3236"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 253?258, Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational Linguistics Chinese Morphological Analysis with Character-level POS Tagging Mo Shen?, Hongxiao Liu?, Daisuke Kawahara?, and Sadao Kurohashi?",
        "Abstract",
        "The focus of recent studies on Chinese word segmentation, part-of-speech (POS) tagging and parsing has been shifting from words to characters.",
        "However, existing methods have not yet fully utilized the potentials of Chinese characters.",
        "In this paper, we investigate the usefulness of character-level part-of-speech in the task of Chinese morphological analysis.",
        "We propose the first tagset designed for the task of character-level POS tagging.",
        "We propose a method that performs character-level POS tagging jointly with word segmentation and word-level POS tagging.",
        "Through exper-iments, we demonstrate that by introducing character-level POS information, the performance of a baseline morphological analyzer can be significantly improved."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In recent years, the focus of research on Chinese word segmentation, part-of-speech (POS) tagging and parsing has been shifting from words toward characters.",
        "Character-based methods have shown superior performance in these tasks compared to traditional word-based methods (Ng and Low, 2004; Nakagawa, 2004; Zhao et al., 2006; Kruengkrai et al., 2009; Xue, 2003; Sun, 2010).",
        "Studies investigating the morphological-level and character-level internal structures of words, which treat character as the true atom of morphological and syntactic processing, have demonstrated encouraging results (Li, 2011; Li and Zhou, 2012; Zhang et al., 2013).",
        "This line of research has provided great insight in revealing the roles of characters in word formation and syntax of Chinese language.",
        "However, existing methods have not yet fully utilized the potentials of Chinese characters.",
        "While Li (2011) pointed out that some characters Character-level Part-of-Speech Examples of Verb verb + noun ??",
        "(invest : throw + wealth) noun + verb ??",
        "(feel sorry : heart + hurt) verb + adjective ??",
        "(realize : recognize + clear) adjective + verb ??",
        "(hate : pain + hate) verb + verb ??",
        "(inspect : examine + re-view) Table 1.",
        "Character-level POS sequence as a more specified version of word-level POS: an example of verb.",
        "can productively form new words by attaching to existing words, these characters consist only a portion of all Chinese characters and appear in 35% of the words in Chinese Treebank 5.0 (CTB5) (Xue et al., 2005).",
        "Zhang (2013) took one step further by investigating the character-level structures of words; however, the machine learning of inferring these internal structures relies on the character forms, which still suffers from data sparseness.",
        "In our view, since each Chinese character is in fact created as a word in origin with complete and independent meaning, it should be treated as the actual minimal morphological unit in Chinese language, and therefore should carry specific part-of-speech.",
        "For example, the character ???",
        "(beat) is a verb and the character ???",
        "(broken) is an adjective.",
        "A word on the other hand, is either single-character, or a compound formed by single-character words.",
        "For example, the verb ??",
        "??",
        "(break) can be seen as a compound formed by the two single-character words with the construction ?verb + adjective?.",
        "Under this treatment, we observe that words with the same construction in terms of character-level POS tend to also have similar syntactic roles.",
        "For example, the words having the con-253 struction ?verb + adjective?",
        "are typically verbs, and those having the construction ?adjective + noun?",
        "are typically nouns, as shown in the following examples: (a) verb : verb + adjective ????",
        "(break) : ???",
        "(beat) + ???",
        "(broken) ????",
        "(update) : ???",
        "(replace) + ???",
        "(new) ????",
        "(bleach) : ???",
        "(wash) + ???",
        "(white) (b) noun : adjective + noun ????",
        "(theme) : ???",
        "(main) + ???",
        "(topic) ????",
        "(newcomer) : ???",
        "(new) + ???",
        "(person) ????",
        "(express) : ???",
        "(fast) + ???",
        "(car) This suggests that character-level POS can be used as cues in predicting the part-of-speech of unknown words.",
        "Another advantage of character-level POS is that, the sequence of character-level POS in a word can be seen as a more fine-grained version of word-level POS.",
        "An example is shown in Table 1.",
        "The five words in this table are very likely to be tagged with the same word-level POS as verb in any available annotated corpora, while it can be commonly agreed among native speakers of Chinese that the syntactic behaviors of these words are different from each other, due to their distinctions in word constructions.",
        "For example, verbs having the construction ?verb + noun?",
        "(e.g.",
        "??)",
        "or ?verb + verb?",
        "(e.g.",
        "??)",
        "can also be nouns in some context, while others cannot; And verbs having the constructions ?verb + adjective?",
        "(e.g.",
        "??)",
        "require exact one object argument, while others generally do not.",
        "Therefore, compared to word-level POS, the character-level POS can produce information for more expressive features during the learning process of a morphological analyzer.",
        "In this paper, we investigate the usefulness of character-level POS in the task of Chinese morphological analysis.",
        "We propose the first tagset designed for the task of character-level POS tag-ging, based on which we manually annotate the entire CTB5.",
        "We propose a method that performs character-level POS tagging jointly with word segmentation and word-level POS tagging.",
        "Through experiments, we demonstrate that by introducing character-level POS information, the performance of a baseline morphological analyzer can be significantly improved.",
        "Tag Part-of-Speech Example n noun ?",
        "?/NN (bill) v verb ?",
        "?/VV (publish) j adj./adv.",
        "?",
        "?/VA (vast) t numerical ???",
        "?/CD (3.14) m quantifier ?/CD ?/M (a piece of) d date ??",
        "?/NT (1995) k proper noun ?",
        "?/NR (sino-US) b prefix ??",
        "?/NN (vice mayor) e suffix ??",
        "?/NN (construction inductry) r transliteration ???",
        "?/NR (?rp?d) u punctuation ??????",
        "?/NR (Charles Dickens) f foreign chars X?",
        "?/NN (X-ray) o onomatopoeia ?",
        "?/AD (rumble) s surname ??",
        "?/NR (Wang Xinmin) p pronoun ?",
        "?/PN (they) c other functional ?",
        "?/VV (be used for) Table 2.",
        "Tagset for character-level part-of-speech tagging.",
        "The underlined characters in the examples correspond to the tags on the left-most column.",
        "The CTB-style word-level POS are also shown for the examples.",
        "2 Character-level POS Tagset We propose a tagset for the task of character-level POS tagging.",
        "This tagset contains 16 tags, as illustrated in Table 2.",
        "The tagset is designed by treating each Chinese character as a single-character word, and each (multi-character) word as a phrase of single-character words.",
        "Some of these tags are directly derived from the commonly accepted word-level part-of-speech, such as noun, verb, adjective and adverb.",
        "It should be noted that, for single-character words, the difference between adjective and adverb can almost be ignored, because for any of such words that can be used as an adjective, it usually can also be used as an adverb.",
        "Therefore, we have merged these two tags into one.",
        "On the other hand, some other tags are designed specifically for characters, such as trans-literation, surname, prefix and suffix.",
        "Unlike some Asian languages such as Japanese, there is no explicit character set in Chinese that are used exclusively for expressing names of foreign per-sons, places or organizations.",
        "However, some characters are used much more frequently than others in these situations.",
        "For example, in the person's name ??????",
        "(?rp?d), all the four characters can be frequently observed in words 254 Figure 1.",
        "A Word-character hybrid lattice of a Chinese sentence.",
        "Correct path is represented by blue bold lines.",
        "Word Length 1 2 3 4 5 6 7 or more Tags S BE BB2E BB2B3E BB2B3ME BB2B3MME BB2B3M...ME Table 3.",
        "Word representation with a 6-tag tagset: S, B, B2, B3, M, E of transliterations.",
        "Similarly, surnames in Chinese are also drawn from a set of limited number of characters.",
        "We therefore assign specific tags for this kind of character sets.",
        "The tags for prefixes and suffixes are motivated by the previous studies (Li, 2011; Li and Zhou, 2012).",
        "We have annotated character-level POS for all words in CTB5 1 .",
        "Fortunately, character-level POS in most words are independent of context, which means it is sufficient to annotate word forms unless there is an ambiguity.",
        "The annotation was conducted by two persons, where each one of them was responsible for about 70% of the documents in the corpus.",
        "The redundancy was set for the purposes of style unification and quality control, on which we find that the inter-annotator agreement is 96.2%.",
        "Although the annotation also includes the test set, we blind this portion in all the experiments.",
        "1 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?CharPosCN 3 Chinese Morphological Analysis with Character-level POS 3.1 System Description Previous studies have shown that jointly processing word segmentation and POS tagging is preferable to pipeline processing, which can propagate errors (Nakagawa and Uchimoto, 2007; Kruengkrai et al., 2009).",
        "Based on these studies, we propose a word-character hybrid model which can also utilize the character-level POS information.",
        "This hybrid model constructs a lattice that consists of word-level and character-level nodes from a given input sentence.",
        "Word-level nodes correspond to words found in the system's lexicon, which has been compiled from training data.",
        "Character-level nodes have special tags called position-of-character (POC) that indicate the word-internal position (Asahara, 2003; Nakagawa, 2004).",
        "We have adopted the 6-tag tagset, which (Zhao et al., 2006) reported to be optimal.",
        "This tagset is illustrated in Table 3.",
        "Figure 2 shows an example of a lattice for the Chinese sentence: ?????????",
        "(Chen Deming answers to journalists?",
        "questions).",
        "The correct path is marked with blue bold lines.",
        "The 255 Category Template Condition Baseline-unigram ?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "Baseline-bigram ?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "Otherwise Proposed-unigram ?",
        "?",
        "Proposed-bigram ?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "?",
        "Table 4.",
        "Feature templates.",
        "The ?Condition?",
        "column describes when to apply the templates: and denote the previous and the current word-level node; and denote the previous and the current character-level node; and denote the previous and the current node of any types.",
        "Word-level nodes represent known words that can be found in the system's lexicon.",
        "upper part of the lattice (word-level nodes) represents known words, where each node carries information such as character form, character-level POS , and word-level POS.",
        "A word that contains multiple characters is represented by a sub-lattice (the dashed rectangle in the figure), where a path stands for a possible sequence of character-level POS for this word.",
        "For example, the word ????",
        "(journalist) has two possible paths of character-level POS: ?verb + suffix?",
        "and ?noun + suffix?.",
        "Nodes that are inside a sub-lattice cannot be linked to nodes that are outside, except from the boundaries.",
        "The lower part of the lattice (character-level nodes) represents unknown words, where each node carries a position-of-character tag, in addition to other types of information that can also be found on a word-level node.",
        "A sequence of character-level nodes are considered as an unknown word if and only if the sequence of POC tags forms one of the cases listed in Table 3.",
        "This table also illustrates the permitted transitions between adjacent character-level nodes.",
        "We use the standard dynamic programming technique to search for the best path in the lattice.",
        "We use the averaged perceptron (Col- lins, 2002), an efficient online learning algorithm, to train the model.",
        "3.2 Features We show the feature templates of our model in Table 4.",
        "The features consist of two categories: baseline features, which are modified from the templates proposed in (Kruengkrai et al., 2009); and proposed features, which encode character-level POS information.",
        "Baseline features: For word-level nodes that represent known words, we use the symbols , and to denote the word form, POS tag and length of the word, respectively.",
        "The functions and return the first and last character of .",
        "If has only one character, we omit the templates that contain or .",
        "We use the subscript indices 0 and -1 to indicate the current node and the previous node during a Viterbi search, respectively.",
        "For character-level nodes, denotes the surface character, and denotes the combination of POS and POC (position-of-character) tags.",
        "Proposed features: For word-level nodes, the function returns the pair of the character-level POS tags of the first and last characters of , and returns the sequence of character-level POS tags of .",
        "If either the pair or the sequence of character-level POS is ambig-uous, which means there are multiple paths in the sub-lattice of the word-level node, then the values on the current best path (with local context) during the Viterbi search will be returned.",
        "If has only one character, we omit the templates that contain .",
        "For character-level nodes, the function returns its character-level POS.",
        "The subscript indices 0 and -1 as well as 256 other symbols stand for the same meaning as they are in the baseline features.",
        "4 Evaluation 4.1 Settings To evaluate our proposed method, we have conducted two sets of experiments on CTB5: word segmentation, and joint word segmentation and word-level POS tagging.",
        "We have adopted the same data division as in (Jiang et al., 2008a; Jiang et al., 2008b; Kruengkrai et al., 2009; Zhang and Clark, 2010; Sun, 2011): the training set, dev set and test set have 18,089, 350 and 348 sentences, respectively.",
        "The models applied on all test sets are those that result in the best performance on the CTB5 dev set.",
        "We have annotated character-level POS information for all 508,768 word tokens in CTB5.",
        "As mentioned in section 2, we blind the annotation in the test set in all the experiments.",
        "To learn the characteristics of unknown words, we built the system's lexicon using only the words in the training data that appear at least 3 times.",
        "We applied a similar strategy in building the lexicon for character-level POS, where the threshold we choose is 2.",
        "These thresholds were tuned using the development data.",
        "We have used precision, recall and the F-score to measure the performance of the systems.",
        "Precision ( ) is defined as the percentage of output tokens that are consistent with the gold standard test data, and recall ( ) is the percentage of tokens in the gold standard test data that are recognized in the output.",
        "The balanced F-score ( ) is defined as .",
        "4.2 Experimental Results We compare the performance between a baseline model and our proposed approach.",
        "The results of the word segmentation experiment and the joint experiment of segmentation and POS tagging are shown in Table 5(a) and Table 5(b), respectively.",
        "Each row in these tables shows the performance of the corresponding system.",
        "?CharPos?",
        "stands for our proposed model which has been described in section 3.",
        "?Baseline?",
        "stands for the same model except it only enables features from the baseline templates.",
        "The results show that, while the differences between the baseline model and the proposed model in word segmentation accuracies are small, the proposed model achieves significant improvement in the experiment of joint segmentati-(a) Word Segmentation Results System P R F Baseline 97.48 98.44 97.96 CharPOS 97.55 98.51 98.03 (b) Joint Segmentation and POS Tagging Results System P R F Baseline 93.01 93.95 93.48 CharPOS 93.42 94.18 93.80 Table 5.",
        "Experimental results on CTB5.",
        "System Segmentation Joint Baseline 97.96 93.48 CharPOS 98.03 93.80 Jiang2008a 97.85 93.41 Jiang2008b 97.74 93.37 Kruengkrai2009 97.87 93.67 Zhang2010 97.78 93.67 Sun2011 98.17 94.02 Table 6.",
        "Comparison with previous studies on CTB5.",
        "on and POS tagging2.",
        "This suggests that our proposed method is particularly effective in predicting the word-level POS, which is consistent with our observations mentioned in section 1.",
        "In Table 6 we compare our approach with morphological analyzers in previous studies.",
        "The accuracies of the systems in previous work are directly taken from the original paper.",
        "As the results show, despite the fact that the performance of our baseline model is relatively weak in the joint segmentation and POS tagging task, our proposed model achieves the second-best performance in both segmentation and joint tasks.",
        "5 Conclusion We believe that by treating characters as the true atoms of Chinese morphological and syntactic analysis, it is possible to address the out-of-vocabulary problem that word-based methods have been long suffered from.",
        "In our error analy-sis, we believe that by exploring the character-level POS and the internal word structure (Zhang et al., 2013) at the same time, it is possible to further improve the performance of morphological analysis and parsing.",
        "We will address these issues in our future work.",
        "2 in McNemar's test.",
        "257 Reference"
      ]
    }
  ]
}
