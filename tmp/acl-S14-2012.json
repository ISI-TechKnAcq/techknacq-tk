{
  "info": {
    "authors": [
      "Corentin Ribeyre",
      "Eric Villemonte de la Clergerie",
      "Djam√© Seddah"
    ],
    "book": "*SEM",
    "id": "acl-S14-2012",
    "title": "Alpage: Transition-based Semantic Graph Parsing with Syntactic Features",
    "url": "https://aclweb.org/anthology/S14-2012",
    "year": 2014
  },
  "references": [
    "acl-C04-1204",
    "acl-C08-1095",
    "acl-C10-1011",
    "acl-D07-1096",
    "acl-P10-1110",
    "acl-P13-1091",
    "acl-P13-2111"
  ],
  "sections": [
    {
      "text": [
        "Alpage: Transition-based Semantic Graph Parsing with Syntactic Features Corentin Ribeyre ?",
        "?",
        "Eric Villemonte de la Clergerie ?",
        "Djam?",
        "Seddah ?",
        "\u0005 ?",
        "Alpage, INRIA ?",
        "Univ Paris Diderot, Sorbonne Paris Cit?",
        "\u0005 Universit?",
        "Paris Sorbonne firstname.lastname@inria.fr",
        "Abstract",
        "This paper describes the systems deployed by the ALPAGE team to participate to the SemEval-2014 Task on Broad-Coverage Semantic Dependency Parsing.",
        "We developed two transition-based dependency parsers with extended sets of actions to handle non-planar acyclic graphs.",
        "For the open track, we worked over two orthogonal axes ?",
        "lexical and syntactic ?",
        "in order to provide our models with lexical and syntactic features such as word clusters, lemmas and tree fragments of different types."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In recent years, we have seen the emergence of semantic parsing, relying on various techniques ranging from graph grammars (Chiang et al., 2013) to transitions-based dependency parsers (Sagae and Tsujii, 2008).",
        "Assuming that obtaining predicate argument structures is a necessary goal to move from syntax to accurate surface se-mantics, the question of the representation of such structures arises.",
        "Regardless of the annotation scheme that should be used, one of the main issues of semantic representation is the construction of graph structures, that are inherently harder to generate than the classical tree structures.",
        "In that aspect, the shared task's proposal (Oepen et al., 2014), to evaluate different syntactic-semantic schemes (Ivanova et al., 2012; Hajic et al., 2006; Miyao and Tsujii, 2004) could not arrive at a more timely moment when state-of-the-art surface syntactic parsers regularly reach, or cross, a 90% labeled dependency recovery plateau for a ",
        ".",
        "wide range of languages (Nivre et al., 2007a; Seddah et al., 2013).",
        "The two systems we present both extend transition-based parsers in order to be able to generate acyclic dependency graphs.",
        "The first one follows the standard greedy search mechanism of (Nivre et al., 2007b), while the second one follows a slightly more global search strategy (Huang and Sagae, 2010; Goldberg et al., 2013) by relying on dynamic programming techniques.",
        "In addition to building graphs directly, the main originality of our work lies in the use of different kinds of syntactic features, showing that using syntax for pure deep semantic parsing improves global performance by more than two points.",
        "Although not state-of-the-art, our systems perform very honorably compared with other single systems in this shared task and pave quite an interesting way for further work.",
        "In the remainder of this paper, we present the parsers and their extensions for building graphs; we then present our syntactic features and discuss our results.",
        "2 Systems Description Shift-reduce transition-based parsers essentially rely on configurations formed of a stack and a buffer, with stack transitions used to go from a configuration to the next one, until reaching a final configuration.",
        "Following K?bler et al. (2009), we define a configuration by c = (?, ?,A) where ?",
        "denotes a stack of words w i , ?",
        "a buffer of words, and A a set of dependency arcs of the form (w i , r, w j ), with w i the head, w j the dependent, and r a label in some set R. However, despite their overall similarities, transition-based systems may differ on many as-pects, such as the exact definition of the configura-tions, the set of transitions extracted from the con-figurations, the way the search space is explored (at parsing and training time), the set of features, the way the transition weights are learned and ap-97 (?,w i |?,A) ` (?|w i , ?, A) (shift) BOTH (?|w j |w i , ?, A) ` (?|w i , ?, A ?",
        "(w i , r, w j )) (left-reduce) S&T PARSER (?|w j |w i , ?, A) ` (?|w j , ?, A ?",
        "(w j , r, w i )) (right-reduce) S&T PARSER (?|w j |w i , ?, A) ` (?|w j |w i , ?, A ?",
        "(w i , r, w j )) (left-attach) BOTH (?|w j |w i , ?, A) ` (?|w j , w i |?,A ?",
        "(w j , r, w i ) (right-attach) BOTH (?|w i , ?, A) ` (?, ?,A) (pop0) BOTH (?|w j |w i , ?, A) ` (?|w i , ?, A) (pop1) DYALOG-SR (?|w j |w i , ?, A) ` (?|w i |w j , ?, A) (swap) DYALOG-SR Figure 1: An extended set of transitions for building dependency graphs.",
        "plied, etc.",
        "For various reasons, we started our experiments with two rather different transition-based parsers, which have finally converged on several aspects.",
        "In particular, the main convergence concerns the set of transitions needed to parse the three proposed annotation schemes.",
        "To be able to attach zero, one, or more heads to a word, it is necessary to clearly dissociate the addition of a dependency from the reduction of a word (i.e. its removal from the stack).",
        "Following Sagae and Tsujii (2008), as shown in Figure 1, beside the usual shift and reduce transitions of the arc-standard strategy, we introduced the new left and right attach actions for adding new dependencies (while keeping the dependent on the stack) and two reduce pop0 and pop1 actions to remove a word from the stack after attachement of its dependents.",
        "All transitions adding an edge should also satisfy the condition that the new edge does not create a cycle or multiple edges between the same pair of nodes.",
        "It is worth noting that the pop actions may also be used to remove words with no heads.",
        "2.1 Sagae & Tsujii's DAG Parser Our first parsing system is a partial rewrite, with several extensions, of the Sagae and Tsujii (2008) DAG parser (henceforth S&T PARSER).",
        "We modified it to handle dependency graphs, in particular non-governed words using pop0 transitions.",
        "This new transition removes the topmost stack element when all its dependents have been attached (through attach or reduce transitions).",
        "Thus, we can handle partially connected graphs, since a word can be discarded when it has no incoming arc.",
        "We used two different learning algorithms: (i) the averaged perceptron because of its good balance between training time and performance (Daume, 2006), (ii) the logistic regression model (maximum entropy (Ratnaparkhi, 1997)).",
        "For the latter, we used the truncated gradient optimization (Langford et al., 2009), implemented in Clas-sias (Okazaki, 2009), in order to estimate the parameters.",
        "These algorithms have been used interchangeably to test their performance in terms of F-score.",
        "But the difference was negligeable in general.",
        "2.2 DYALOG-SR Our second parsing system is DYALOG-SR (Villemonte De La Clergerie, 2013), which has been developed to participate to the SPMRL?13 shared task.",
        "Coded on top of tabular logic programming system DYALOG, it implements a transition-based parser relying on dynamic programming techniques, beams, and an averaged structured perceptron, following ideas from (Huang and Sagae, 2010; Goldberg et al., 2013).",
        "It was initially designed to follow an arc-standard parsing strategy, relying on shift and left/right reduce transitions.",
        "To deal with dependency graphs and non governed words, we first added the two attach transitions and the pop0 transition.",
        "But because there exist some overlap between the reduce and attach transitions leading to some spurious ambiguities, we finally decided to remove the left/right reduce transitions and to complete with the pop1 transition.",
        "In order to handle some cases of non-projectivty with minimal modifications of the system, we also added a swap transition.",
        "The parsing strategy is now closer to the arc-eager one, with an oracle suggesting to attach as soon as possible.",
        "2.3 Tree Approximations In order to stack several dependency parsers, we needed to transform our graphs into trees.",
        "We report here the algorithms we used.",
        "The first one uses a simple strategy.",
        "For nodes with multiple incoming edges, we keep the longest incoming edge.",
        "Singleton nodes (with no head) are attached with a _void_-labeled edge (by decreasing priority) to the immediately adjacent 98 Word ?",
        "1 Lemma ?",
        "1 POS ?",
        "1 leftPOS ?",
        "1 rightPOS ?",
        "1 leftLabel ?",
        "1 rightLabel ?",
        "1 Word ?",
        "2 Lemma ?",
        "2 POS ?",
        "2 leftPOS ?",
        "2 rightPOS ?",
        "2 leftLabel ?",
        "2 rightLabel ?",
        "2 Word ?",
        "3 POS ?",
        "3 Word ?",
        "1 Lemma ?",
        "1 POS ?",
        "1 Word ?",
        "2 Lemma ?",
        "2 POS ?",
        "2 POS ?",
        "3 a d 12 d ?",
        "11 Table 1: Baseline features for S&T PARSER.",
        "node N , or the virtual root node (token 0).",
        "This strategy already improves over the baseline, provided by the task organisers, on the PCEDT by 5 points.",
        "The second algorithm tries to preserve more edges: when it is possible, the deletion of a re-entrant edge is replaced by reversing its direction and changing its label l into <l.",
        "We do this for nodes with no incoming edges by reversing the longest edge only if this action does not create cycles.",
        "The number of labels increases, but many more edges are kept, leading to better results on DM and PAS corpora.",
        "3 Feature Engineering 3.1 Closed Track For S&T PARSER we define Word ?",
        "i (resp.",
        "Lemma ?",
        "i and POS ?",
        "i ) as the word (resp.",
        "lemma and part-of-speech) at position i in the queue.",
        "The same goes for ?",
        "i , which is the position i in the stack.",
        "Let d i,j be the distance between Word ?",
        "i and Word ?",
        "j .",
        "We also define d ?",
        "i,j , the distance between Word ?",
        "i and Word ?",
        "j .",
        "In addition, we define leftPOS ?",
        "i (resp.",
        "leftLabel ?",
        "i ) the part-of-speech (resp.",
        "the label if any) of the word immediately at the left handside of ?",
        "i , and the same goes for rightPOS ?",
        "i (resp.",
        "rightLabel ?",
        "i ).",
        "Finally, a is the previous predicted action by the parser.",
        "Table 1 reports our baseline features.",
        "For DYALOG-SR we have the following lexical features lex, lemma, cat, and morphosyn-tactic mstag.",
        "They apply to next unread word ( * I, say lemmaI), the three next lookahead words ( * I2 to * I4), and (when present) to the 3 stack elements ( * 0 to * 2), their two leftmost and rightmost children (before b[01] * [012] and after a[01] * [012]).",
        "We have dependency features such as the labels of the two leftmost and rightmost edges ([ab][01]label[012]), the left and right valency (number of depen-dency, [ab]v[012]) and domains (set of dependency labels, [ab]d[012]).",
        "Finally, we have 3 (discretized) distance features between the next word and the stack elements (delta[01]) and between the two topmost stack elements (delta01).",
        "Most feature values are atomic (ei- ther numerical or symbolic), but they can also be (recursively) a list of values, for instance for the mstag and domain features.",
        "For dealing with graphs, features were added about the incoming edges to the 3 topmost stack elements, similar to valency (ngov[012]) and domain (gov[012]).",
        "For the PCEDT scheme, because of the high number of dependency labels, the 30 most unfrequent ones were replaced by a generic label when used as feature value.",
        "Besides, for the PCEDT and DM corpora, static and dynamic guiding features have been tried for DYALOG-SR, provided by MATE (Bohnet, 2010) (trained on versions of these corpora projected to trees, using a 10-fold cross valida-tion).",
        "The two static features mate_label and mate_distance are attached to each token h, indicating the label and the relative distance to its governor d (if any).",
        "At runtime, dynamic features are also added relative to the current configuration: if a semantic dependency (h, l, d) has been predicted by MATE, and the topmost 2 stack elements are either (h, d) or (d, h), a feature suggesting a left or right attachment for l is added.",
        "We did the same for S&T PARSER, except that we used a simple but efficient hack: instead of keeping the labels predicted by our parser, we replaced them by MATE predictions whenever it was possible.",
        "3.2 Open Track For this track, we combined the previously described features (but the MATE-related ones) with various lexical and syntactic features, our intuition being that syntax and semantic are inter-dependent, and that syntactic features should therefore help semantic parsing.",
        "In particular, we have considered the following bits of information.",
        "Unsupervized Brown clusters To reduce lexical sparsity, we extracted 1,000 clusters from the BNC (Leech, 1992) preprocessed following Wagner et al. (2007).",
        "We extended them with capi-talization, digit features and 3 letters suffix signa-tures, leading to a vocabulary size reduced by half.",
        "Constituent tree fragments They were part of the companion data provided by the organizers.",
        "99 They consist of fragments of the syntactic trees and can be used either as enhanced parts of speech or as features.",
        "Spinal elementary trees A full set of parses was reconstructed from the tree fragments.",
        "Then we extracted a spine grammar (Seddah, 2010), using the head percolation table of the Bikel (2002) parser, slightly modified to avoid determiners to be marked as head in some configurations.",
        "Predicted MATE dependencies Also provided in the companion data, they consist in the parses built by the MATE parsers, trained on the Stanford dependency version of the PTB.",
        "We combined the labels with a distance ?",
        "= t ?",
        "h where t is the token number and h the head number.",
        "Constituent head paths Inspired by Bj?rkelund et al. (2013), we used the MATE dependencies to extract the shortest path between a token and its lexical head and included the path length (in terms of traversed nodes) as feature.",
        "Tree frag.",
        "MATE labels+?",
        "Spines trees Head Paths Train 648 1305 637 27,670 Dev 272 742 265 3,320 Test 273 731 268 2,389 Table 2: Syntactic features statistics.",
        "4 Results and Discussion We present here the results on section 21 (test set) 1 for both systems.",
        "We report in Table 3, the different runs we submitted for the final evaluation of the shared task.",
        "We also report improvements between the two tracks.",
        "Both systems show relatively close F-measures, with correct results on every corpus.",
        "If we compare the results more precisely, we observe that in general, DYALOG-SR tends to behave better for the unlabeled metrics.",
        "Its main weakness is on MRS scheme, for both tracks.",
        "2 1 Dev set results are available online at http://goo.gl/w3XcpW.",
        "2 The main and still unexplained problem of DYALOG-SR was that using larger beams has no impact, and often a negative one, when using the attach and pop transitions.",
        "Except for PAS and PCEDT where a beam of size 4 worked best for the open track, all other results were obtained for beams of size 1.",
        "This situation is in total contradiction with the large impact of beam previously observed for the arc standard strategy during the SPMRL?13 shared task and during experiments led on the French TreeBank (Abeill?",
        "et al., 2003) (FTB).",
        "Late experiments on the FTB using the attach and pop actions (but delaying attachments as long as possible) has On the other hand, it is worth noting that syntactic features greatly improve semantic parsing.",
        "In fact, we report in Figure 2(a) the improvement of the five most frequent labels and, in Figure 2(b), the five best improved labels with a frequency over 0.5% in the training set, which represent 95% of the edges in the DM Corpus.",
        "As we can see, syntactic information allow the systems to perform better on coordination structures and to reduce ambiguity between modifiers and verbal arguments (such as the ARG3 label).",
        "We observed the same behaviour on the PAS corpus, which contains also predicate-argument structures.",
        "For PCEDT, the results show that syntactic features give only small improvements, but the corpus is harder because of a large set of labels and is closer to syntactic structures than the two others.",
        "Of course, we only scratched the surface with our experiments and we plan to further investigate the impact of syntactic information during semantic parsing.",
        "We especially plan to explore the deep parsing of French, thanks to the recent release of the Deep Sequoia Treebank (Candito et al., 2014).",
        "5 Conclusion In this paper, we presented our results on the task 8 of the SemEval-2014 Task on Broad-Coverage Semantic Dependency Parsing.",
        "Even though the results do not reach state-of-the-art, they compare favorably with other single systems and show that syntactic features can be efficiently used for semantic parsing.",
        "In future work, we will continue to investigate this idea, by combining with more complex systems and more efficient machine learning tech-niques, we are convinced that we can come closer to state of the art results.",
        "and that syntax is the key for better semantic parsing.",
        "Acknowledgments We warmly thank Kenji Sagae for making his parser's code available and kindly answering our questions.",
        "References"
      ]
    }
  ]
}
