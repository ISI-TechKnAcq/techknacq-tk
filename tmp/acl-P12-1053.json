{
  "info": {
    "authors": [
      "Andreas Maletti",
      "Joost Engelfriet"
    ],
    "book": "ACL",
    "id": "acl-P12-1053",
    "title": "Strong Lexicalization of Tree Adjoining Grammars",
    "url": "https://aclweb.org/anthology/P12-1053",
    "year": 2012
  },
  "references": [
    "acl-C88-2121",
    "acl-J12-3006",
    "acl-J95-4002",
    "acl-N10-1035",
    "acl-P87-1015",
    "acl-W06-1517"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Recently, it was shown (KUHLMANN, SATTA: Tree-adjoining grammars are not closed under strong lexicalization.",
        "Comput.",
        "Linguist., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol.",
        "A more powerful model, the simple context-free tree grammar, admits such a normal form.",
        "It can be effectively constructed and the maximal rank of the non-terminals only increases by 1.",
        "Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975) are a mildly context-sensitive grammar formalism that can handle certain non-local dependencies (Kuhlmann and Mohl, 2006), which occur in several natural languages.",
        "A good overview on TAG, their formal properties, their linguistic motivation, and their applications is presented by Joshi and Schabes (1992) and Joshi and Schabes (1997), in which also strong lexicalization is discussed.",
        "In general, lexicalization is the process of transforming a grammar into an equivalent one (potentially expressed in another formalism) such that each production contains a lexical item (or anchor).",
        "Each production can then be viewed as lexical information on its anchor.",
        "It demonstrates a syntactical construction in which the anchor can occur.",
        "Since a lexical item is a letter of the string ?",
        "Financially supported by the German Research Foundation (DFG) grant MA 4959 / 1-1. alphabet, each production of a lexicalized grammar produces at least one letter of the generated string.",
        "Consequently, lexicalized grammars offer significant parsing benefits (Schabes et al., 1988) as the number of applications of productions (i.e., derivation steps) is clearly bounded by the length of the input string.",
        "In addition, the lexical items in the productions guide the production selection in a derivation, which works especially well in scenarios with large alphabets.",
        "The GREIBACH normal form (Hopcroft et al., 2001; Blum and Koch, 1999) offers those benefits for context-free grammars [CFG], but it changes the parse trees.",
        "Thus, we distinguish between two notions of equivalence: Weak equivalence (Bar-Hillel et al., 1960) only requires that the generated string languages coincide, whereas strong equivalence (Chomsky, 1963) requires that even the generated tree languages coincide.",
        "Correspondingly, we obtain weak and strong lexicalization based on the required equivalence.",
        "The GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990).",
        "It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG (Schabes, 1990),2 and it was claimed and widely believed that they can strongly lexicalize themselves.",
        "Recently, Kuhlmann and Satta (2012) proved that TAG actually cannot strongly lexicalize themselves.",
        "In fact, they prove that TAG cannot even strongly lexicalize the weaker tree insertion grammars (Schabes and Waters, 1995).",
        "However, TAG can weakly lexicalize themselves (Fujiyoshi, 2005).",
        "Simple (i.e., linear and nondeleting) context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970) are a more powerful grammar formalism than TAG (Mo?nnich, 1997).",
        "However, the monadic variant is strongly equivalent to a slightly extended version of TAG, which is called non-strict TAG (Kepser and Rogers, 2011).",
        "A GREIBACH normal form for a superclass of CFTG (viz., second-order abstract cat-egorial grammars) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006).",
        "In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars (Ge?cseg and Steinby, 1984; Ge?cseg and Steinby, 1997).",
        "CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (LCFRS) of Vijay-Shanker et al. (1987) and the well-nested multiple context-free grammars (MCFG) of Seki et al. (1991).3 Thus, CFTG are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (Go?mez-Rodr?",
        "?guez et al., 2010).",
        "In this contribution, we show that CFTG can strongly lexicalize TAG and also themselves, thus answering the second question in the conclusion of Kuhlmann and Satta (2012).",
        "This is achieved by a series of normalization steps (see Section 4) and a final lexicalization step (see Section 5), in which a lexical item is guessed for each production that does not already contain one.",
        "This item is then transported in an additional argument until it is exchanged for the same item in a terminal production.",
        "The lexicalization is effective and increases the maximal rank (number of arguments) of the non-terminals by at most 1.",
        "In contrast to a transformation into GREIBACH normal form, our lexicalization does not radically change the structure of the derivations.",
        "Overall, our result shows that if we consider only lexicalization, then CFTG are a more natural generalization of CFG than TAG."
      ]
    },
    {
      "heading": "2 Notation",
      "text": [
        "We write [k] for the set {i ?",
        "N |1 ?",
        "i ?",
        "k}, where N denotes the set of nonnegative integers.",
        "We use a fixed countably infinite set X = {x1, x2, .",
        ".",
        ". }",
        "3Kuhlmann (2010), Mo?nnich (2010), and Kanazawa (2009) discuss well-nestedness.",
        "of (mutually distinguishable) variables, and we let Xk = {xi |i ?",
        "[k]} be the first k variables from X for every k ?",
        "N. As usual, an alphabet ?",
        "is a finite set of symbols, and a ranked alphabet (?, rk) adds a ranking rk : ?",
        "?",
        "N. We let ?k = {?",
        "|rk(?)",
        "= k} be the set of k-ary symbols.",
        "Moreover, we just write ?",
        "for the ranked alphabet (?, rk).4 We build trees over the ranked alphabet ?",
        "such that the nodes are labeled by elements of ?",
        "and the rank of the node label determines the number of its children.",
        "In addition, elements of X can label leaves.",
        "Formally, the set T?",
        "(X) of ?-trees indexed by X is the smallest set T such that X ?",
        "T and ?",
        "(t1, .",
        ".",
        ".",
        ", tk) ?",
        "T for all k ?",
        "N, ?",
        "?",
        "?k, and t1, .",
        ".",
        ".",
        ", tk ?",
        "T .5 We use positions to address the nodes of a tree.",
        "A position is a sequence of nonnegative integers indicating successively in which subtree the addressed node is.",
        "More precisely, the root is at position ?",
        "and the position ip with i ?",
        "N and p ?",
        "N?",
        "refers to the position p in the ith direct subtree.",
        "Formally, the set pos(t) ?",
        "N?",
        "of positions of a tree t ?",
        "T?",
        "(X) is defined by pos(x) = {?}",
        "for x ?",
        "X and pos(?",
        "(t1, .",
        ".",
        ".",
        ", tk)) = {?}",
        "?",
        "{ip |i ?",
        "[k], p ?",
        "pos(ti)} for all symbols ?",
        "?",
        "?k and t1, .",
        ".",
        ".",
        ", tk ?",
        "T?(X).",
        "The positions are indicated as superscripts of the labels in the tree of Figure 1.",
        "The subtree of t at position p ?",
        "pos(t) is denoted by t|p, and the label of t at position p by t(p).",
        "Moreover, t[u]p denotes the tree obtained from t by replacing the subtree at p by the tree u ?",
        "T?(X).",
        "For every label set S ?",
        "?, we let posS(t) = {p ?",
        "pos(t) |t(p) ?",
        "S} be the S-labeled positions of t. For every ?",
        "?",
        "?, we let pos?",
        "(t) = pos{?}(t).",
        "The set C?",
        "(Xk) contains all trees t of T?",
        "(X), in which every x ?",
        "Xk occurs exactly once and posX\\Xk(t) = ?.",
        "Given",
        "for every i ?",
        "N and t = ?",
        "(t1, .",
        ".",
        ".",
        ", tk) with ?",
        "?",
        "?k and t1, .",
        ".",
        ".",
        ", tk ?",
        "T?(X).",
        "First-order substitution is illustrated in Figure 1.",
        "sitions, where ?",
        "= {?, ?, ?}",
        "with rk(?)",
        "= 2, rk(?)",
        "= 1, and rk(?)",
        "= 0, and an example first-order substitution.",
        "In first-order substitution we replace leaves (elements of X), whereas in second-order substitution we replace an internal node (labeled by a symbol of ?).",
        "Let p ?",
        "pos(t) be such that t(p) ?",
        "?k, and let u ?",
        "C?",
        "(Xk) be a tree in which the variables Xk occur exactly once.",
        "The second-order substitution t[p ?",
        "u] replaces the subtree at position p by the tree u into which the children of p are (first-order) substituted.",
        "In essence, u is ?folded?",
        "into t at position p. Formally, t[p?",
        "u] = t",
        "Given P ?",
        "pos?",
        "(t) with ?",
        "?",
        "?k, we let t[P ?",
        "u] be t[p1 ?",
        "u] ?",
        "?",
        "?",
        "[pn ?",
        "u], where P = {p1, .",
        ".",
        ".",
        ", pn} and p1 > ?",
        "?",
        "?",
        "> pn in the lexicographic order.",
        "Second-order substitution is illustrated in Figure 2.",
        "Ge?cseg and Steinby (1997) present a detailed introduction to trees and tree languages."
      ]
    },
    {
      "heading": "3 Context-free tree grammars",
      "text": [
        "In this section, we recall linear and nondeleting context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970).",
        "The property ?linear and nondeleting?",
        "is often called ?simple?.",
        "The nonterminals of regular tree grammars only occur at the leaves and are replaced using first-order substitution.",
        "In contrast, the nonterminals of a CFTG are ranked symbols, can occur anywhere in a tree, and are replaced using second-order substitution.6 Consequently, the nonterminals N of a CFTG form a ranked alphabet.",
        "In the left-hand sides of productions we write A(x1, .",
        ".",
        ".",
        ", xk) for a nonterminal A ?",
        "Nk to indicate the variables that hold the direct subtrees of a",
        "The components ` and r are called left-and right-hand side of the production ` ?",
        "r in P .",
        "We say that it is an A-production if ` = A(x1, .",
        ".",
        ".",
        ", xk).",
        "The right-hand side is simply a tree using terminal and nonterminal symbols according to their rank.",
        "Moreover, it contains all the variables ofXk exactly once.",
        "Let us illustrate the syntax on an example CFTG.",
        "We use an abstract language for simplicity and clarity.",
        "We use lower-case Greek letters for terminal symbols and upper-case Latin letters for nonterminals.",
        "We recall the (term) rewrite semantics (Baader and Nipkow, 1998) of the CFTG G = (N,?, S, P ).",
        "Since G is simple, the actual rewriting strategy is irrelevant.",
        "The sentential forms of G are simply SF(G) = TN??(X).",
        "This is slightly more general than necessary (for the semantics of G), but the presence of variables in sentential forms will be useful in the next section because it allows us to treat right-hand sides as sentential forms.",
        "In essence in a rewrite step we just select a nonterminal A ?",
        "N and an A-production ?",
        "?",
        "P .",
        "Then we replace an occur",
        "A-labeled position p ?",
        "posA(?)",
        "in ?, we write ?",
        "?",
        "?,pG ?",
        "[p ?",
        "r].",
        "If there exist ?",
        "?",
        "P and p ?",
        "pos(?)",
        "such that ?",
        "?",
        "?,pG ?, then ?",
        "?G ?."
      ]
    },
    {
      "heading": "9 The",
      "text": [
        "semantics JGK of G is {t ?",
        "T?",
        "|S ?",
        "?G t}, where ?",
        "?G is the reflexive, transitive closure of?G.",
        "Two CFTGG1 andG2 are (strongly) equivalent if JG1K = JG2K.",
        "In this contribution we are only concerned with strong equivalence (Chomsky, 1963).",
        "Although we recall the string corresponding to a tree later on (via its yield), we will not investigate weak equivalence (Bar-Hillel et al., 1960).",
        "derivation is in the language JGexK generated byGex.",
        "Finally, let us recall the relation between CFTG and tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975).",
        "Joshi et al. (1975) show that TAG are special footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monadic CFTG, i.e., CFTG whose nonterminals have rank at most 1 (Mo?nnich, 1997; Fujiyoshi and Kasai, 2000).",
        "Kepser and Rogers (2011) show the strong equivalence of those CFTG to non-strict TAG, which are slightly more powerful than traditional TAG.",
        "In general, TAG are a natural formalism to describe the syntax of natural language.10"
      ]
    },
    {
      "heading": "4 Normal forms",
      "text": [
        "In this section, we first recall an existing normal form for CFTG.",
        "Then we introduce the property of finite ambiguity in the spirit of (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012), which allows us to normalize our CFTG even further.",
        "A major tool is a simple production elimination",
        "scheme, which we present in detail.",
        "From now on, let G = (N,?, S, P ) be the considered CFTG.",
        "The CFTG G is start-separated if posS(r) = ?",
        "for every production `?",
        "r ?",
        "P .",
        "In other words, the start nonterminal S is not allowed in the right-hand sides of the productions.",
        "It is clear that each CFTG can be transformed into an equivalent start-separated CFTG.",
        "In such a CFTG we call each production of the form S ?",
        "r initial.",
        "From now on, we assume, without loss of generality, that G is start-separated.",
        "Example 5.",
        "Let Gex = (N,?, S, P ) be the CFTG of Example 2.",
        "An equivalent start-separated CFTG is G?ex = ({S ?",
        "(0)} ?N,?, S?, P ?",
        "{S?",
        "?",
        "S}).",
        "We start with the growing normal form of Stamer and Otto (2007) and Stamer (2009).",
        "It requires that the right-hand side of each non-initial production contains at least two terminal or nonterminal symbols.",
        "In particular, it eliminates projection productions A(x1) ?",
        "x1 and unit productions, in which the right-hand side has the same shape as the left-hand side (potentially with a different root symbol and a different order of the variables).",
        "Definition 6.",
        "A production ` ?",
        "r is growing if |posN??",
        "(r) |?",
        "2.",
        "The CFTG G is growing if all of its non-initial productions are growing.",
        "The next theorem is Proposition 2 of (Stamer and Otto, 2007).",
        "Stamer (2009) provides a full proof.",
        "From now on, we assume thatG is growing.",
        "Next, we recall the notion of finite ambiguity from (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012).11 We distinguish a subset ?",
        "?",
        "?0 of lexical symbols, which are the symbols that are preserved by the yield mapping.",
        "The yield of a tree is 11It should not be confused with the notion of ?finite ambiguity?",
        "of (Goldstine et al., 1992; Klimann et al., 2004).",
        "Roughly speaking, we can say that the set L has finite ?-ambiguity if eachw ?",
        "??",
        "has finitely many parses in L (where t is a parse of w if yd?",
        "(t) = w).",
        "Our example CFTG Gex is such that JGexK has finite {?, ?",
        "}-ambiguity (because ?1 = ?).",
        "In this contribution, we want to (strongly) lexicalize CFTG, which means that for each CFTG G such that JGK has finite ?-ambiguity, we want to construct an equivalent CFTG such that each non-initial production contains at least one lexical symbol.",
        "This is typically called strong lexicalization (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012) because we require strong equivalence.12 Let us formalize our lexicalization property.",
        "Definition 10.",
        "The production ` ?",
        "r is ?-lexical-ized if pos?",
        "(r) 6= ?.",
        "The CFTG G is ?-lexicalized if all its non-initial productions are ?-lexicalized.",
        "Note that the CFTG G?",
        "?ex of Example 8 is not yet {?, ?}-lexicalized.",
        "We will lexicalize it in the next section.",
        "To do this in general, we need some auxiliary normal forms.",
        "First, we define our simple production elimination scheme, which we will use in the following.",
        "Roughly speaking, a non-initial A-production such that A does not occur in its right-hand side can be eliminated fromG by applying it in 12The corresponding notion for weak equivalence is called weak lexicalization (Joshi and Schabes, 1992).",
        "all possible ways to occurrences in right-hand sides of the remaining productions.",
        "Definition 11.",
        "Let ?",
        "= A(x1, .",
        ".",
        ".",
        ", xk) ?",
        "r in P be a non-initial production such that posA(r) = ?.",
        "For every other production ??",
        "= `?",
        "?",
        "r?",
        "in P and",
        "In particular, ???",
        "= ?",
        "?",
        "for every production ?",
        "?, so every production besides the eliminated production ?",
        "is preserved.",
        "We obtained the CFTG G?",
        "?ex of Example 8 as Elim(G?ex, A(x1, x2) ?",
        "?",
        "(x1, x2)) from G?ex of Example 5.",
        "Lemma 12.",
        "The CFTG G and G??",
        "= Elim(G, ?)",
        "are equivalent for every non-initial A-production ?",
        "= `?",
        "r in P such that posA(r) = ?.",
        "Proof.",
        "Clearly, every single derivation step of G??",
        "can be simulated by a derivation of G using potentially several steps.",
        "Conversely, a derivation of G can be simulated directly by G??",
        "except for derivation steps ?",
        "?,pG using the eliminated production ?.",
        "Since S 6= A, we know that the nonterminal at position p was generated by another production ??.",
        "In the given derivation of G we examine which nonterminals in the right-hand side of the instance of ??",
        "were replaced using ?.",
        "Let J be the set of positions corresponding to those nonterminals (thus p ?",
        "J).",
        "Then instead of applying ??",
        "and potentially several times ?, we equivalently apply ?",
        "?J of G ?",
        "?.",
        "In the next normalization step we use our production elimination scheme.",
        "The goal is to make sure that non-initial monic productions (i.e., productions of which the right-hand side contains at most one nonterminal) contain at least one lexical symbol.",
        "We define the relevant property and then present",
        "the construction.",
        "A sentential form ?",
        "?",
        "SF(G) is monic if |posN (?)",
        "|?",
        "1.",
        "The set of all monic sentential forms is denoted by SF?1(G).",
        "A production ` ?",
        "r is monic if r is monic.",
        "The next construction is similar to the simultaneous removal of epsilon-productions A ?",
        "?",
        "and unit productions A ?",
        "B for context-free grammars (Hopcroft et al., 2001).",
        "Instead of computing the closure under those productions, we compute a closure under non-?-lexicalized productions.",
        "Theorem 13.",
        "If JGK has finite ?-ambiguity, then there exists an equivalent CFTG such that all its non-initial monic productions are ?-lexicalized.",
        "Proof.",
        "Without loss of generality, we assume that G is start-separated and growing by Theorem 7.",
        "Moreover, we assume that each nonterminal is useful.",
        "For every A ?",
        "N with A 6= S, we compute all monic sentential forms without a lexical symbol that are reachable from A(x1, .",
        ".",
        ".",
        ", xk), where",
        "where?+G?",
        "is the transitive closure of?G?",
        "and the CFTG G?",
        "= (N,?, S, P ?)",
        "is such that P ?",
        "contains exactly the non-?-lexicalized productions of P .",
        "The set ?A is finite since only finitely many non-?-lexicalized productions can be used due to the finite ?-ambiguity of JGK.",
        "Moreover, no sentential form in ?A contains A for the same reason and the fact that G is growing.",
        "We construct the",
        "Clearly, G and G1 are equivalent.",
        "Next, we eliminate all productions of P1 from G1 using Lemma 12 to obtain an equivalent CFTG G2 with the productions P2.",
        "In the final step, we drop all non-?-lexicalized monic productions of P2 to obtain the CFTG G, in which all monic productions are ?- lexicalized.",
        "It is easy to see that G is growing, start-separated, and equivalent to G2.",
        "The CFTG G?",
        "?ex only has {?, ?",
        "}-lexicalized non-initial monic productions, so we use a new example.",
        "that are not ?-lexicalized (see Example 14).",
        "P contains the productions",
        "This CFTG Gex2 is start-separated and growing.",
        "Moreover, all its productions are monic, and JGex2K is finitely ?-ambiguous for the set ?",
        "= {?}",
        "of lexical symbols.",
        "Then the productions (3) are non-initial and not ?-lexicalized.",
        "So we can run the construction in the proof of Theorem 13.",
        "The relevant derivations using only non-?-lexicalized productions are shown in Figure 5.",
        "We observe that",
        "We now do one more normalization step before we present our lexicalization.",
        "We call a production ` ?",
        "r terminal if r ?",
        "T?",
        "(X); i.e., it does not contain nonterminal symbols.",
        "Next, we show that for each CFTG G such that JGK has finite ?-ambiguity we can require that each non-initial terminal production contains at least two occurrences of ?-symbols.",
        "Theorem 15.",
        "If JGK has finite ?-ambiguity, then there exists an equivalent CFTG (N,?, S, P ?)",
        "such that |pos?",
        "(r) |?",
        "2 for all its non-initial terminal productions `?",
        "r ?",
        "P ?.",
        "Proof.",
        "Without loss of generality, we assume that G is start-separated and growing by Theorem 7.",
        "Moreover, we assume that each nonterminal is useful and that each of its non-initial monic productions is ?-lexicalized by Theorem 13.",
        "We obtain the desired CFTG by simply eliminating each non-initial terminal production ` ?",
        "r ?",
        "P such that |pos?",
        "(r) |= 1.",
        "By Lemma 12 the obtained CFTG",
        "and a corresponding production of P ???",
        "[right] with right-hand side (r?,2)?",
        "(see Theorem 17).",
        "is equivalent to G. The elimination process terminates because a new terminal production can only be constructed from a monic production and a terminal production or several terminal productions, but those combinations already contain two occurrences of ?- symbols since non-initial monic productions are already ?-lexicalized.",
        "Example 16.",
        "Reconsider the CFTG obtained in Example 14.",
        "Recall that ?",
        "= {?}.",
        "Production (4) is the only non-initial terminal production that violates the requirement of Theorem 15.",
        "We eliminate it and obtain the CFTG with the productions"
      ]
    },
    {
      "heading": "5 Lexicalization",
      "text": [
        "In this section, we present the main lexicalization step, which lexicalizes non-monic productions.",
        "We assume that JGK has finite ?-ambiguity and is normalized according to the results of Section 4: no useless nonterminals, start-separated, growing (see Theorem 7), non-initial monic productions are ?- lexicalized (see Theorem 13), and non-initial terminal productions contain at least two occurrences of ?-symbols (see Theorem 15).",
        "The basic idea of the construction is that we guess a lexical symbol for each non-?-lexicalized production.",
        "The guessed symbol is put into a new parameter of a nonterminal.",
        "It will be kept in the parameter until we reach a terminal production, where we exchange the same lexical symbol by the parameter.",
        "This is the reason why we made sure that we have two occurrences of lexical symbols in the terminal productions.",
        "After we exchanged one for a parameter, the resulting terminal production is still ?-lexicalized.",
        "Lexical items that are guessed for distinct (occurrences of) productions are transported to distinct (occurrences of) terminal productions [cf.",
        "Section 3 of (Potthoff and Thomas, 1993) and page 346 of (Hoogeboom and ten Pas, 1997)].",
        "Theorem 17.",
        "For every CFTG G such that JGK has finite ?-ambiguity there exists an equivalent ?-lexicalized CFTG.",
        "Proof.",
        "We can assume that G = (N,?, S, P ) has the properties mentioned before the theorem without loss of generality.",
        "We let N ?",
        "= N ??",
        "be a new set of nonterminals such that rk(?A, ??)",
        "= rk(A) + 1 for every A ?",
        "N and ?",
        "?",
        "?.",
        "Intuitively, ?A, ??",
        "represents the nonterminal A, which has the lexical symbol ?",
        "in its last (new) parameter.",
        "This parameter is handed to the (lexicographically) first nonterminal in the right-hand side until it is resolved in a terminal production.",
        "Formally, for each right-hand side r ?",
        "TN?N ???",
        "(X) such that posN (r) 6= ?",
        "(i.e., it contains an original nonterminal), each k ?",
        "N, and each ?",
        "?",
        "?, let r?,k and r?",
        "be such that",
        "where p is the lexicographically smallest element of posN (r) and r|p = B(r1, .",
        ".",
        ".",
        ", rn) with B ?",
        "N and r1, .",
        ".",
        ".",
        ", rn ?",
        "TN?N ???(X).",
        "For each nonterminal A-production ?",
        "= `?",
        "r in P let ??",
        "= ?A, ??",
        "(x1, .",
        ".",
        ".",
        ", xk+1)?",
        "r?,k , where k = rk(A).",
        "This construction is illustrated in Figure 6.",
        "Roughly speaking, we select the lexicographically smallest occurrence of a nonterminal in the right-hand side and pass the lexical symbol ?",
        "in the extra parameter to it.",
        "The extra parameter is used in terminal productions, so let ?",
        "= `?",
        "r in P",
        "and the production ?",
        "(see Theorem 17).",
        "be a terminal A-production.",
        "Then we define ?",
        "= ?A, r(p)?",
        "(x1, .",
        ".",
        ".",
        ", xk+1)?",
        "r[xk+1]p , where p is the lexicographically smallest element of pos?",
        "(r) and k = rk(A).",
        "This construction is illustrated in Figure 7.",
        "With these productions we obtain the CFTG G?",
        "= (N ?",
        "N ?,?, S, P ), where",
        "It is easy to prove that those new productions manage the desired transport of the extra parameter if it holds the value indicated in the nonterminal.",
        "Finally, we replace each non-initial non-?-lexicalized production in G?",
        "by new productions that guess a lexical symbol and add it to the new parameter of the (lexicographically) first nonterminal of N in the right-hand side.",
        "Formally, we let",
        "of which P ???",
        "is added to the productions.",
        "Note that each production ` ?",
        "r ?",
        "P nil contains at least one occurrence of a nonterminal ofN (because all monic productions of G are ?-lexicalized).",
        "Now all non-initial non-?-lexicalized productions from P can be removed, so we obtain the CFTGG?",
        "?, which is given by (N ?N ?,?, S,R) with R = (P ?",
        "P ???)",
        "\\ P nil.",
        "It can be verified that G??",
        "is ?-lexicalized and equivalent to G (using the provided argumentation).",
        "Instead of taking the lexicographically smallest element of posN (r) or pos?",
        "(r) in the previous proof, we can take any fixed element of that set.",
        "In the definition of P ?",
        "we can change posN (r) 6= ?",
        "to |pos?",
        "(r) |?",
        "1, and simultaneously in the definition of P ??",
        "change posN (r) = ?",
        "to |pos?",
        "(r) |?",
        "2.",
        "With the latter changes the guessed lexical item is only transported until it is resolved in a production with at least two lexical items.",
        "Example 18.",
        "For the last time, we consider the CFTG G?",
        "?ex of Example 8.",
        "We already illustrated the parts of the construction of Theorem 17 in Figures 6 and 7.",
        "The obtained {?, ?",
        "}-lexicalized CFTG has the following 25 productions for all ?, ??",
        "?",
        "{?, ?",
        "}:",
        "?)))",
        ", where A?",
        "= ?A, ??",
        "and S?",
        "= ?S, ??.",
        "If we change the lexicalization construction as indicated before this example, then all the productions S?",
        "(x1) ?",
        "A?(?",
        "?, ?",
        "?, x1) are replaced by the productions S?",
        "(x1) ?",
        "A(x1, ?).",
        "Moreover, the productions (5) can be replaced by the productions A(x1, x2) ?",
        "A(?",
        "(x1, S?(?",
        ")), ?",
        "(x2, S)), and then the nonterminalsA?",
        "and their productions can be removed, which leaves only 15 productions.",
        "Conclusion For k ?",
        "N, let CFTG(k) be the set of those CFTG whose nonterminals have rank at most k. Since the normal form constructions preserve the nonterminal rank, the proof of Theorem 17 shows that CFTG(k) are strongly lexicalized by CFTG(k+1).",
        "Kepser and Rogers (2011) show that non-strict TAG are strongly equivalent to CFTG(1).",
        "Hence, non-strict TAG are strongly lexicalized by CFTG(2).",
        "It follows from Section 6 of Engelfriet et al. (1980) that the classes CFTG(k) with k ?",
        "N induce an infinite hierarchy of string languages, but it remains an open problem whether the rank increase in our lexicalization construction is necessary.",
        "Go?mez-Rodr?",
        "?guez et al. (2010) show that well-nested LCFRS of maximal fanout k can be parsed in time O(n2k+2), where n is the length of the input string w ?",
        "??.",
        "From this result we conclude that CFTG(k) can be parsed in time O(n2k+4), in the sense that we can produce a parse tree t that is generated by the CFTG with yd?",
        "(t) = w. It is not clear yet whether lexicalized CFTG(k) can be parsed more efficiently in practice."
      ]
    }
  ]
}
