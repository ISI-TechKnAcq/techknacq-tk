{
  "info": {
    "authors": [
      "Alexander Dikovsky"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P01-1021",
    "title": "Grammars for Local and Long Dependencies",
    "url": "https://aclweb.org/anthology/P01-1021",
    "year": 2001
  },
  "references": [
    "acl-C92-1061",
    "acl-C96-2122",
    "acl-P97-1043",
    "acl-P98-1026",
    "acl-P98-1106",
    "acl-P98-2130"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "Polarized dependency (PD-) grammars are proposed as a means of efficient treatment of discontinuous constructions.",
        "PD-grammars describe two kinds of dependencies : local, explicitly derived by the rules, and long, implicitly specified by negative and positive valencies of words.",
        "If in a PD-grammar the number of non-saturated valencies in derived structures is bounded by a constant, then it is weakly equivalent to a cf-grammar and has a 0(n3)-time parsing algorithm.",
        "It happens that such bounded PD-grammars are strong enough to express such phenomena as unbounded raising, extraction and ex-traposition."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Syntactic theories based on the concept of dependency have a long tradition.",
        "Tesni`ere (Tesni`ere, 1959) was the first who systematically described the sentence structure in terms of binary relations between words (dependencies), which form a dependency tree (D-tree for short).",
        "D-tree itself does not presume a linear order on words.",
        "However, any its surface realization projects some linear order relation (called also precedence).",
        "Some properties of surface syntactic structure can be expressed only in terms of both dependency (or its transitive closure called dominance) and precedence.",
        "One of such properties, projectivity, requires that any word occurring between a word g and a word d dependent on g be dominated by g. In first dependency grammars (Gaifman, 1961) and in some more recent proposals: link grammars (Sleator and Temperly, 1993), projective dependency grammars (Lombardo and Lesmo, 1996) the projectivity is implied by definition.",
        "In some other theories, e.g. in word grammar (Hudson, 1984), it is used as one of the axioms defining acceptable surface structures.",
        "In presence of this property, D-trees are in a sense equivalent to phrase structures with head selection 1.",
        "It is for this reason that D-trees determined by grammars of Robinson (Robinson, 1970), cate-gorial grammars (Bar-Hillel et al., 1960), classical Lambek calculus (Lambek, 1958), and some other formalisms are projective.",
        "Projectivity affects the complexity of parsing : as a rule, it allows dynamic programming technics which lead to polynomial time algorithms (cf. 0(n3)-time algorithm for link grammars in (Sleator and Tem-perly, 1993)).",
        "Meanwhile, the projectivity is not the norm in natural languages.",
        "For example, in most European languages there are such regular non-projective constructions as WH- or relative clause extraction, topicalization, comparative constructions, and some constructions specific to a language, e.g. French pronominal clitics or left dislocation.",
        "In terms of phrase structure, non-projectivity corresponds to discontinuity.",
        "In this form it is in the center of discussions till 70-ies.",
        "There are various dependency based approaches to this problem.",
        "In the framework of Meaning-Text Theory (Mel’ˇcuk and Pertsov, 1987), dependencies between (some",
        "times non adjacent) words are determined in terms of their local neighborhood, which leads to non-tractable parsing (the NP-hardness argument of (Neuhaus and Br¨oker, 1997) applies to them).",
        "More recent versions of dependency grammars (see e.g.(Kahane et al., 1998; Lombardo and Lesmo, 1998; Br¨oker, 1998)) impose on non-projective D-trees some constraints weaker than projectivity (cf. meta-projectivity (Nasr, 1995) or pseudo-projectivity (Kahane et al., 1998)), sufficient for existence of a polynomial time parsing algorithm.",
        "Still another approach is developed in the context of intuitionistic resource-dependent logics, where D-trees are constructed from derivations (cf. e.g. a method in (Lecomte, 1992) for Lambek calculus).",
        "In this context, non-projective D-trees are determined with the use of hypothetical reasoning and of structural rules such as commutativity and associativity (see e.g. (Moortgat, 1990)).",
        "In this paper, we put forward a novel approach to handling discontinuity in terms of dependency structures.",
        "We propose a notion of a polarized dependency (PD-) grammar combining several ideas from cf-tree grammars, dependency grammars and resource-dependent logics.",
        "As most dependency grammars, the PD-grammars are analyzing.",
        "They reduce continuous groups to their types using local (context-free) reduction rules and simultaneously assign partial dependency structures to reduced groups.",
        "The valencies (positive for governors and negative for subordinates) are used to specify discontinuous (long) dependencies lacking in partial dependency structures.",
        "The mechanism of establishing long dependencies is orthogonal to reduction and is implemented by a universal and simple rule of valencies saturation.",
        "A simplified version of PD-grammars adapted for the theoretical analysis is introduced and explored in (Dikovsky, 2001).",
        "In this paper, we describe a notion of PD-grammar more adapted for practical tasks."
      ]
    },
    {
      "heading": "2 Dependency structures",
      "text": [
        "We fix finite alphabets W of terminals (words), C of nonterminals (syntactic types or classes), and N of dependency names.",
        "Definition 1.",
        "Let x E (W U C)+ be a string.",
        "A set 7 = {dl, ..., dn} of trees (called components of 7r) which cover exactly x, have no nodes in common, and whose arcs are labeled by names in N is a dependency (D-) structure on x if one component dt of 7 is selected as its head 2.",
        "We use the notation x = w (7r) .",
        "7 is a terminal D-structure if x is a string of terminals.",
        "When 7 has only one component, it is a dependency (D-) tree on x.",
        "For example, the D-structure in Fig. 1 has two components.",
        "V (aux) is the root of the non projective head component, the other component",
        "In distinction to (Dikovsky, 2001), the nonterminals (and even dependency names) can be structured.",
        "We follow (Mel’ˇcuk and Pertsov,",
        "The alphabets being finite, the features unification is a means of compacting a grammar.",
        "The D-structures we will use will be polarized in the sense that some words will have valencies specifying long dependencies which must enter or go from them.",
        "A valency is an expression of one of the forms +L : r, +R : r (a positive valency), or – L: r, – R : r (a negative valency), r being a dependency name.",
        "For example, the intuitive sense of a positive valency +R : r of a node n is that a long dependency r might go from n somewhere on the right.",
        "All nonterminals will be signed: we presume that C is decomposed into two classes: of positive (C(+)) and negative (CH) nonterminals respectively.",
        "D-structures with valencies, DV-structures, are defined so that valencies saturation would imply connectivity.",
        "is positive, otherwise it is negative.",
        "A D-structure 7 on a string x of polarized symbols is a DV-structure on x, if the following conditions are satisfied:",
        "(v1) if a terminal node n of 7 is negative, then V (n) contains exactly one negative valency, (v2) if a dependency of 7 enters a node n, then n is positive, (v3) the non-head components of 7 (if any) are all negative.",
        "In Fig. 2 4, both words in 712 have no valencies, all nonterminals in 711 and 71$ are positive (we label only negative nonterminals), 715 is positive because its head component is a positive unit D-tree, 721 and 722 are negative because their roots are negative.",
        "Valencies are saturated by long dependencies.",
        "Definition 3.",
        "Let 7 be a terminal DV-structure.",
        "A triplet l =< nl, n2i r >, where nl, n2 are nodes of 7 and r E N, is a long dependency 4 For the reasons of space, in our examples we are not accurate with morphological features.",
        "E.g., in the place of GrV(gov: upon) we should rather have GrV(gov: upon)<inf 5. with the name r, directed from nl to n2 (nota",
        "We will say that vl saturates v2 by long dependency 1.",
        "The set of valencies in 7 is totally ordered by the order of nodes and the orders in their valency",
        "is a saturation of7 by l and denote it by 7 � 71.",
        "Among all possible saturations of 7r we will select the following particular one: Let vi E V,r(nl) be the first non saturated positive valency in 7, and v2 E V,r(n2) be the closest corresponding 5 non saturated negative valency in 7.",
        "Then the long dependency",
        "We transform the relations �CFA into partial orders closing them by transitivity.",
        "Suppose that in Fig. 3, both occurrences of a in 70 and the first occurrence of a in 71 have V(a) _ { – R : r}, and both occurrences of b in 7ro and the second occurrence of b in 71 have",
        "In (Dikovsky, 2001), we prove that .",
        "If 7r is a terminal DV-structure and 7 --� 71, then either 71 has a cycle, or it is a DV-structure (Lemma 1).",
        "As it follows from Definition 3, each saturation of a terminal DV-structure 7 has the same set of nodes and a strictly narrower set of valencies.",
        "Therefore, any terminal DV-structure has maximal saturations with respect to the order relations �CFA �Very importantly, there is a single maximal FA-saturation of 7r denoted MS' (7r).",
        "E.g., in Fig. 3, MS' (70) = 72 is a D-tree.",
        "In order to keep track of those valencies which are not yet saturated we use the following notion of integral valency.",
        "Definition 4.",
        "Let 7 be a terminal DV-structure.",
        "The integral valency E 7 of 7 is the list",
        "this D-tree saturates 7 and call 7 saturable.",
        "By this definition, E MS' (7) = E 7.",
        "FA FA Saturability is easily expressed in terms of integral valency (Lemma 2 in (Dikovsky, 2001)) : Let 7 be a terminal DV-structure.",
        "Then:",
        "• 7 has at most one saturating D-tree.",
        "The semantics of PD-grammars will be defined in terms of composition of DV-structures which generalizes strings substitution.",
        "Definition 5.",
        "Let 7r1 = {dl, ..., dk} be a DV-structure, A be a nonterminal node of one of its components, and 72 = {di ... d', ..., d'l} be a t DV-structure of the same polarity as A and with the head component d't. Then the result of the composition of 7x2 into 71 in A is the DV-structure 71 [A\\721, in which 72 is substituted for A, the root of d' inherits all dependencies of A in 7r1, t and the head component is that of 7r1 (changed respectively if touched on by composition)6.",
        "It is easy to see that DV-structure 7 in Fig. 4 can be derived by the following series of compo",
        "sitions of the DV-structures in Fig. 2:",
        "The DV-structures composition has natural properties: .",
        "The result of a composition into a DV-structure 7 is a DV-structure of the same polarity as 7 (Lemma 3 in (Dikovsky, 2001)).",
        "• If E 71 = E 72i then E 7ro[A\\MS'(7)]"
      ]
    },
    {
      "heading": "3 Polarized dependency grammars",
      "text": [
        "Polarized dependency grammars determine DV-structures in the bottom-up manner in the course of reduction of phrases to their types, just as the categorial grammars do.",
        "Each reduction step is accompanied by DV-structures composition and by subsequent FA-saturation.",
        "The yield of a successful reduction is a D-tree.",
        "In this paper, we describe a superclass of grammars in (Dikovsky, 2001) which are more realistic from the point of view of real applications and have the same parsing complexity.",
        "Definition 6.",
        "A PD-grammar is a system G – (W, C, N, I, A, R), where W, C, N are as described above, I C_ C(+) is a set of axioms (which are positive nonterminals), A C_ W x C x L is a ternary relation of lexical interpretation, L being",
        "the set of lists ofpairwise different valencies, and R is a set of reduction rules.",
        "For simplicity, we start with the strict reduction rules (the only rules in (Dikovsky, 2001)) of the form 7 – � A, where A E C and 7 is a DV-structure over C of the same polarity as A (below we will extend the strict rules by side effects).",
        "In the special case, where the DV-structures in the rules are D-trees, the PD-grammar is local7.",
        "Intuitively, we can think of A as of the combined information available after the phase of morphological analysis (i.e. dictionary information and tags).",
        "So (w, A, vl) E A means that a type A and a valency list vl can be a priori assigned to the word w. Semantics.",
        "1.",
        "Let r = (w, A, vl) E A and 70 be the unit DV-structure w with V (w) = vl.",
        "Then r is a reduction of the structure 70 to its type A (notation 7ro �-r A) and vl is the integral valency of this reduction denoted by vl = 7ro.",
        "with k nonterminals’ occurrences A,,..., Akin 7, k > 0, and 7r1 H1 A1, ..., Irk �-Pk Ak be some reductions.",
        "Then p = (pl ... pk; r) is a reduction of the structure 70 = MS1(7[A1\\71, ..., Ak\\7rk]) to its type A (notation 70 H A).",
        "PI,•••,Pk as well as p itself are subreductions of p. The integral valency of 70 via p is E70 =",
        "determined by G. L(PDG) denotes the class of languages determined by PD-grammars.",
        "By way of illustration, let us consider the PD-grammar Go with the lexical interpretation A containing triplets:",
        "Then the D-tree d in Fig. 4 is reducible in Go to ClW h and its reduction is depicted in Fig. 5.",
        "As we show in (Dikovsky, 2001), the weak generative capacity of PD-grammars is stronger than that of cf-grammars.",
        "For example, the PD",
        "anbndcn, n > 01.",
        "D-tree 72 in Fig. 3 is determined by G1 on w(2).",
        "Its reduction combined with the diagram of local and long dependencies is presented in Fig. 6.",
        "The local PD-grammars are weakly equivalent to cf-grammars, so they are weaker than general PD-grammars.",
        "Meanwhile, what is really important concerning the dependency grammars, is their strong generative capacity, i.e. the D-trees they derive.",
        "From this point of view, the grammars like Gl above are too strong.",
        "Let us remark that in the reduction in Fig. 6, the first saturation becomes possible only after all positive valencies emerge.",
        "This means that the integral valency of subreductions increases with n. This seems to be never the case in natural languages, where next valencies arise only after the preceding ones are saturated.",
        "This is why we restrict ourself to the class of PD-grammars which have such a property.",
        "Definition 7.",
        "Let G be a PD-grammar.",
        "For a reduction ☛ of a terminal structure, its defect is defined as ✢ (☛) = max { ✑ E 7r'✑✑☛' is a subre✝✣ duction of ☛}.",
        "G has bounded (unbounded) defect if there is some (there is no) constant q which bounds the defect of all its reductions.",
        "The minimal constant q having this property (if any) is the defect of G (denoted ✢(G)).",
        "There is a certain technical problem concerning PD-grammars.",
        "Even if in a reduction to an axiom all valencies are saturated, this does not guarantee that a D-tree is derived: the graph may have cycles.",
        "In (Dikovsky, 2001) we give a sufficient condition for a PD-grammar of never producing cycles while FA-saturation.",
        "We call the grammars satisfying this condition lc- (locally cycle-)free.",
        "For the space reasons, we don’t cite its definition, the more so that the linguistic PD-grammars should certainly be lc-free.",
        "In (Dikovsky, 2001) we prove the following theorem.",
        "Theorem 1.",
        "For any lc-free PD-grammar G of bounded defect there is an equivalent cf-grammar.",
        "Together with this we show an example of a DT-language which cannot be determined by local PD-grammars.",
        "This means that not all structures determined in terms of long dependencies can be determined without them."
      ]
    },
    {
      "heading": "4 Side effect rules and parsing",
      "text": [
        "An important consequence of Theorem 1 is that lc-free bounded defect PD-grammars have a 0(n3) parsing algorithm.",
        "In fact, it is the classical Earley algorithm in charter form (the charters being DV-structures).",
        "To apply this algorithm in practice, we should analyze the asymptotic factor which depends on the size of the grammar.",
        "The idea of theorem 1 is that the integral valency being bounded, it can be compiled into types.",
        "This means that a reduction",
        "types keeping all possible integral valencies not causing cycles.",
        "Theoretically, this might blow up vk(✦+1) times the size of a grammar with defect q, v valencies and the maximal length ✂ of left parts of rules.",
        "So theoretically, the constant factor in the 0(n3) time bound is great.",
        "In practice, it shouldn’t be as awful, because in linguistic grammars q will certainly equal ★, one rule will mostly treat one valency (i.e. ✂ = ★) and the majority of rules will be local.",
        "Practically, the effect may be that some local rules will have variants propagating upwards a certain valency: 7r[✪\\✪[v]] – � A[v].",
        "The actual problem lies elsewhere.",
        "Let us analyze the illustration grammar Go and the reduction in Fig. 5.",
        "This reduction is successful due to the fact that the negative valency – R: prepos – obj is assigned to the preposition upon and the corresponding positive valency +L : prepos – obj is assigned to the verb rely.",
        "What might serve the formal basis for these assignments?",
        "Let us start with rely.",
        "This verb has the strong government over prepositions on, upon.",
        "In the clause in Fig. 4, the group of the preposition is moved, which is of course a sufficient condition for assigning the positive valency to the verb.",
        "But this condition is not available in the dictionary, nor even through morphological analysis (rely may occur at a certain distance from the end of the clause).",
        "So it can only be derived in the course of reduction, but strict PD-grammars have no rules assigning valencies.",
        "Theoretically, there is no problem: we should just introduce into the dictionary both variants of the verb description – with the local dependency prepos – obj to the right and with the positive valency +L : prepos – obj to the left.",
        "Practically, this “solution” is inacceptable because such a lexical ambiguity will lead to a brute force search.",
        "The same argument shows that we shouldn’t assign the negative valency –R:prepos–obj to upon in the dictionary, but rather “calculate” it in the reduction.",
        "If we compare the clause in Fig. 4 with the clauses what theories we may rely upon; what kind of theories we may rely upon; the dependency theories of what kind we may rely upon etc., we see that we can assign a –R valency to wh-words in the dictionary and then raise negative valencies till the FA-saturation.",
        "The problem is that in the strict PD-grammars there are no rules of valency raising.",
        "For these reasons we extend the reduction rules by side effects sufficient for the calculations of both kinds.",
        "r effects: valency raising ([vl](i) v2) and valency assignment ((i) -� – _ v), v, vl, v2 being valency names and i an integer.",
        "A rule of the form",
        "(r2) a local dependency r enters Ai in 7, (r3) for positive vl, v2, 7 –� A is a strict",
        "reduction rule, (r4) if vl, v2 are negative, then AZ, A E CH, and replacing Ai by any positive nonterminal we obtain a DV-structure 8.",
        "A rule of the form",
        "with k nonterminals A,,..., Akin 7 and 1 < i < k is valency assigning if:",
        "(a1) for a positive v, 7 –� A is a strict 8 So this occurrence of Ai in 7 contradicts to the point (v2) of definition 2.",
        "of 7r, then A E CH, Ai E CW is a non head component of 7 9 and replacing Ai by any negative nonterminal we obtain a DV-structure.",
        "Semantics.",
        "We change the reduction semantics as follows.",
        "r .",
        "For a raising rule 7r([vl](i) v2) –� A, the result of the reduction is the DV-structure",
        "Ak\\irk])), where 6(v, 7r') is the DV-structure resultingfrom 7' by deleting v from V(root(7r')), and a (v, 7') is the DV-structure resulting from 7' by adding v to V(root(7')).",
        "▪ For a valency assignment rule 7((i) -�-- v) –� A, the result of the reduction is theDV-structure 70 = MS1(7[A1\\71, ..., Ai\\a(v,7z),..., Ak\\irk]).",
        "A PD-grammar with side effect rules is a PDSE-grammar.",
        "This definition is correct in the sense that the result of a reduction with side effects is always a DV-structure.",
        "We can prove Theorem 2.",
        "For any lc-free PDSE-grammar G of bounded defect there is an equivalent cf-grammar.",
        "Moreover, the bounded defect PDSE-grammars are also parsed in time 0(n3).",
        "In fact, we can drop negative vi in raising rules (it is unique) and indicate the type of root(7) in both side effect rules, because the composition we use makes this information local.",
        "Now, we can revise the grammar Go above, e.g. excluding the dictionary assignment (upon, (Prep) – , [–R: prepos – obj]), and using in its place several valency raising rules such as: prepos d�terrn, ,l (Prep) (Adj, wh) GrNn (Q)"
      ]
    },
    {
      "heading": "prepos",
      "text": [
        "where a = Q](3(GrNn)) f prep -R:prepos-obj)."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "The main ideas underlying our approach to discontinuity are the following:",
        "GrW h (upon) • Continuous (local, even if non projective) dependencies are treated in terms of trees composition (which reminds TAGs).",
        "E.g., the French pronominal clitics can be treated in this way.",
        ".",
        "Discontinuous (long) dependencies are captured in terms of FA-saturation of valencies in the course of bottom-up reduction of dependency groups to their types.",
        "As compared with the SLASH of GPSG or the regular expression lifting control in non projective dependency grammars, these means turn out to be more efficient under the conjecture of bounded defect.",
        "This conjecture seems to be true for natural languages (the contrary would mean the possibility of unlimited extraction from extracted groups).",
        ".",
        "The valency raising and assignment rules offer a way of deriving a proper valency saturation without unwarranted increase of lexical ambiguity.",
        "A theoretical analysis and experiments in English syntax description show that the proposed grammars may serve for practical tasks and can be implemented by an efficient parser."
      ]
    },
    {
      "heading": "6 Acknowledgments",
      "text": [
        "I would like to express my heartfelt gratitude to N. Pertsov for fruitful discussions of this paper.",
        "The idea of valency raising has emerged from our joint work over a project of a PD-grammar for a fragment of English."
      ]
    }
  ]
}
