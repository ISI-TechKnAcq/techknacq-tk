{
  "info": {
    "authors": [
      "Ido Dagan",
      "Zvika Marx",
      "Eli Shamir"
    ],
    "book": "Conference on Computational Natural Language Learning CoNLL",
    "id": "acl-W02-2009",
    "title": "Cross-Dataset Clustering: Revealing Corresponding Themes Across Multiple Corpora",
    "url": "https://aclweb.org/anthology/W02-2009",
    "year": 2002
  },
  "references": [
    "acl-P93-1024"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We present a method for identifying corresponding themes across several corpora that are focused on related, but distinct, domains.",
        "This task is approached through simultaneous clustering of keyword sets extracted from the analyzed corpora.",
        "Our algorithm extends the information-bottleneck soft clustering method for a suitable setting consisting of several datasets.",
        "Experimentation with topical corpora reveals similar aspects of three distinct religions.",
        "The evaluation is by way of comparison to clusters constructed manually by an expert."
      ]
    },
    {
      "heading": "I Introduction",
      "text": [
        "This paper addresses the problem of detecting corresponding subtopics, or themes, within related bodies of text.",
        "Such task is typical to comparative research, whether commercial or scientific: a conceivable application would aim at detecting corresponding characteristics regarding, e.g., companies, markets, legal systems or political organizations.",
        "Clustering has often been perceived as a mean for extracting meaningful components from data (Tishby, Pereira and Bialek, 1999).",
        "Regarding textual data, clusters of words (Pereira, Tishby and Lee, 1993) or documents (Lee and Seung, 1999; Dhillon and Modha, 2001) are often interpreted as capturing topics or themes that play prominent role in the analyzed texts.",
        "Our work extends the \"standard\" clustering paradigm, which pertains to a single dataset.",
        "We address a setting in which several datasets, corresponding to related domains, are given.",
        "We focus on the comparative task of detecting those themes that are expressed across several datasets, rather than discovering internal themes within each individual dataset.",
        "More specifically, we address the task of clustering simultaneously multiple datasets such that each cluster includes elements from several datasets, capturing a common theme, which is shared across the sets.",
        "We term this task cross-dataset (CD) clustering.",
        "In this article we demonstrate CD clustering through detecting corresponding themes across three different religions.",
        "That is: we apply our approach to three sets of religion-related keywords, extracted from three corpora, which include encyclopedic entries and introductory articles regarding Buddhism, Christianity and Islam.",
        "Each one of three representative keyword-sets, which were extracted from the above corpora, presumably encapsulates topics and themes discussed within its source corpus.",
        "Our algorithm succeeds to reveal common themes such as scriptures, rituals and schools through respective keyword clusters consisting of terms such as Sutra, Bible and Quran;"
      ]
    },
    {
      "heading": "Full Moon, Easter and Id al Fitr; Theravada,",
      "text": [
        "Protestant and Shiite (see Table 1 below for a detailed depiction of our results).",
        "The CD clustering algorithm, presented in Section 2.2 below, extends the information bottleneck (113) soft clustering method.",
        "Our modifications to the IB formulation enable the clustering algorithm to capture characteristic patterns that run across different datasets, rather then being \"trapped\" by unique characteristics of individual datasets.",
        "Like other topic discovery tasks that are approached by clustering, the goal of CD clustering is not defined in precise terms.",
        "Yet, it is clear that its focus on detecting themes in a comparative manner, within multiple datasets, distinguishes CD clustering substantially from the standard single-dataset clustering paradigm.",
        "A related problem, of detecting analogies between different information systems has been addressed in the past within cognitive research (e.g. Gentner, 1983; Hofstadter et al., 1995).",
        "Recently, a related computational method for detecting corresponding themes has been introduced (coupled clustering, Marx et al., 2002).",
        "The coupled clustering setting, however, being focused on detecting analogies, is limited to two data sets.",
        "Further, it requires similarity values between pairs of data elements as input: this setting does not seem straightforwardly applicable to the multiple dataset setting.",
        "Our method, in distinction, uses a more direct source of information, namely word co-occurrence statistics within the analyzed corpora.",
        "Another difference is that we take the \"soft\" approach to clustering, producing probabilities of assignments into clusters rather than a deterministic 0/1 assignment values."
      ]
    },
    {
      "heading": "2 Algorithmic Framework",
      "text": []
    },
    {
      "heading": "2.1 Review of the IB Clustering Algorithm",
      "text": [
        "The information bottleneck (IB) iterative clustering method is a recent approach to soft (probabilistic) clustering for a single set, denoted by X, consisting of elements to be clustered (Tishby, Pereira & Bialek, 1999).",
        "Each element xE X is identified by a probabilistic feature vector, with an entry, p(*), for every feature y from a predetermined set of features Y.",
        "The p(ylx) values are estimated from given co-occurrence data:",
        "(hence Y_,,E Yp(ylx) = 1 for every x in X).",
        "The IB algorithm is derived from information theoretic considerations that we do not address here.",
        "It computes, through an iterative EM-like process, probabilistic assignments p(clx) for each element x into each cluster c. Starting with random (or heuristically chosen) p(cI ) values at time t , the 1B algorithm iterates the following steps until convergence: IBl: Calculate for each cluster c its marginal probability:",
        "IB2: Calculate for each feature y and cluster c a conditional probability p(yI c):",
        "(Bayes' rule is used to compute p(xI c)).",
        "IBI Calculate for each element x and each cluster c a value p(cI ), indicating the \"probability of assignment\" of x into c:",
        "with sim,\"(x,c) = exp { /3DKL,[ P(*)I I Pt(yI c) ] } (DK, is the Kullback-Leibler divergence, see Cover & Thomas, 1991).",
        "The parameter /3 controls the sensitivity of the clustering procedure to differences between the p(yI c) values.",
        "The higher /3 is, the more \"determined\" the algorithm becomes in assigning each element into the closest cluster.",
        "As /3 is increased, more clusters that are separable from each other are obtained upon convergence (the target number of clusters is fixed).",
        "We want to ensure, however, that assignments do not follow more than necessary minute details of the given data, as a result of too high /3 (similarly to over generalization in supervised settings).",
        "The IB algorithm is therefore applied repeatedly in a cooling-like process: it starts with a low /3 value, corresponding to low temperature, which is increased every repetition of the whole iterative converging cycle, until the desired number of separate clusters is obtained."
      ]
    },
    {
      "heading": "2.2 The Cross-dataset (CD) Clustering Method",
      "text": [
        "The (soft) CD clustering algorithm receives as input multiple datasets along with their feature vectors.",
        "In the current application, we have three sets extracted from the corresponding Corpora – XBuddhism, XChristianitp and Xlslam – each of –150 keywords to be clustered.",
        "A particular keyword might appear in two or more of the datasets, but the CD setting considers it as a distinct element within each dataset, thus keeping the sets of clustered elements disjoint.",
        "Like the IB clustering algorithm, the CD algorithm produces probabilistic assignments of the data elements.",
        "The feature set Y consists, in the current work, of about 7000 content words, each occurs in at least two of the examined corpora.",
        "The set of features is used commonly for all datasets, thus it underlies a common representation, which enables the clustering process to compare elements of different sets.",
        "Naively approached, the original IB algorithm could be utilized unaltered to the multiple-dataset setting, simply by applying it to the unified set X, consisting of the union of the disjoint X's. The problem of this simplistic approach is that each dataset has its own characteristic features and feature combinations, which correspond to prominent topics discussed uniquely in that corpus.",
        "A standard clustering method, such as the IB algorithm, would have a tendency to cluster together elements that originate in the same dataset, producing clusters populated mostly by elements from a single dataset (cf. Marx et al., 2002).",
        "The goal of CD clustering is to neutralize this tendency and to create clusters containing elements that share common features across different datasets.",
        "To accomplish this goal, we change the criterion by which elements are assigned into clusters.",
        "Recall that the assignment of an element x to a cluster c is determined by the similarity of their characterizing feature distributions, p(ylx) and p(ylc) (step IB3).",
        "The problem lies in using the p(yl c) distribution, which is determined by summing p(ylx) values over all cluster elements, to characterize a cluster without taking into account dataset boundaries.",
        "Thus, for a certain y, p(yl c) might be high despite of being characteristic only for cluster elements originating in a single dataset.",
        "This results in the tendency discussed above to favor clusters consisting of elements of a single dataset.",
        "Therefore, we define a biased probability distribution, p°(y), to be used by the CD clustering algorithm for characterizing a cluster c. It is designed to call attention toy's that are typical for cluster members in all, or most, different datasets.",
        "Consequently, an element x would be assigned to a cluster c (as in step IB3) in accordance to the degree of similarity between its own characteristic features and those characterizing other cluster members from all datasets.",
        "The resulting clusters would thus contain representatives of all datasets.",
        "The definition of p°(y) is based on the joint probability p(y,c,X).",
        "First, compute the geometric mean of p(y,c,X) over all X, weighted by p(X):",
        "(see Appendix below for the details of how p(X) andp(y,c,X) are calculated).",
        "p is not a probability measure, but just a function of y and c into [ 0,1 ].",
        "However, since a geometric mean reflects \"uniformity\" of the averaged values, p captures the degree to which p(y,c,X) values are high across all datasets.",
        "We found empirically that at this stage, it is advantageous to normalize p across all clusters and then to rescale the resulting probabilities (over the c's, for each y) by the original p(y):",
        "Finally, to obtain a probability distribution over y for each cluster c, normalize the obtained p'(y,c) over all y's:",
        "As explained, p°(y) characterizes c (analogously to p(ylc) in IB), while ensuring that the feature-based similarity of c to any element x reflects feature distribution across all data sets.",
        "The CD clustering algorithm, starting at t = 0, iterates, in correspondence to the IB algorithm, the following steps:",
        "CD1: Calculate for each cluster c its marginal probability (same as 1B I): P, (c) = E'.U X. P(X)P,-, (c I X) CD2: Compute p°(y) as described above.",
        "CD3: Compute p(clx) (with p°(y) playing the role played by p(yl c) in IB3):",
        "with SIMrYI'(x,c) = exp { – PDKd p(&)I I P, (Y)] }"
      ]
    },
    {
      "heading": "3 CD Clustering for Religion Comparison",
      "text": [
        "The three corpora that are focused on the compared religions – Buddhism, Christianity and Islam – have been downloaded from the Internet.",
        "Each corpus contains 20,000-40,000 word tokens (5-10 Megabyte).",
        "We have used a text mining tool to extract most religion keywords that form the three sets to which we applied the CD algorithm.",
        "The software we have used – TextAnalyst 2.0 – identifies within the corpora key-phrases, from which we have excluded items that appear in fewer than three",
        "lamentation (.99), grief (.99), animal (.89), pain (.87), death (.86), kill (.84), reincarnation (.81), realm (.76), samsara (.69), rebirth (.61), dukkha (.56), anger (.53), soul (.43), nirvana (.43), birth (.33) punish (.94), hell (.93), violence (.86), fish (.86), sin (.83), earth (.81), soul (.78), death (.77), sinner (.76), sinful (.74), heaven (.73), satan (.72), suffer (.71), flesh (.71), judgment (.67) hell (.97), earth (.88), heaven (.87), death (.85), sin (.85), alcohol (.69), satan (.60), face (.59), day of judgment (.52), deed (.48), angel (.25), being (.24), universe (.16), existence (.13), bearing (.12) korea (.99), china (.99), tibet (.99), theravada (.99), school (.99), asia (.99), founded (.99), west (.99), sri lanka (.99), mahayana (.99), india (.99), history (.99), hindu (.99), japan (.99), study (.99) cardinal (.99), orthodox (.99), protestant (.99), university (.99), vatican (.99), catholic (.99), bishop (.99), rome (.99), pope (.99), monk (.99), tradition (.99), theology (.99), baptist (.98), church (.98), divinity (.93) africa (.99), shiite (.99), sunni (.99), shia (.99), west (.99), christianity (.99), arab (.99), founded (.98), arabia (.97), sufi (.96), history (.96), fiqh (.95), scholar (.91), imam (.90), jew (.89) gautama (.96), king (.95), friend (.68), disciple (.60), birth (.48), hear (.43), ascetic (.41), amida (.40), deva (.33), teach (.19), sacrifice (.15), statue (.14), buddha (.12), bodhisattva (.12), dharma (.09) bethlehem (.98), jordan (.97), mary (.95), lamb (.90), king (.90), second coming (.81), born (.76), israel (.74), child (.73), elijah (.72), baptize (.70), john the baptist (.68), priest (.68), adultery (.65), zion (.61) husband (.99), ismail (.98), father (.97), son (.95), mother (.94), born (.92), wife (.92), child (.89), ali (.88), musa (.71), isa (.70), ibrahim (.67), caliph (.43), tribe (.35), saint (.30) hebrew (.99), translate (.99), gospels (.99), greek (.99), book (.98), new testament (.98), old testament (.96), passage (.96), matthew (.95), write (.94), luke (.93), apostle (.93), bible (.91), paul (.90), john (.90) translatee (.99), bible (.99), write (.98), book (.97), hadith (.96), sunna (.96), quran (.94), word (.93), story (.93), revelation (.88), companion (.80), muhammad (.80), prophet (.73), writing (.71), read quran (.46) tripitaka (.98), sanskrit (.94), translate (.93), sutra (.85), discourse (.79), pali canon (.74), story (.66), book (.64), word (.61), write (.45), buddha (.39), lama (.32), text (.23), dharma (.21), teacher (.17) corpus documents'.",
        "Thus, composite and rare terms as well as phrases that the software has inappropriately segmented were filtered out.",
        "We have added to the automatically extracted terms additional items contributed by a comparative religion expert (about 15% of the sets were thus not extracted automatically, but those terms occur frequently enough to underlie informative co-occurrence vectors).",
        "The common set of features consists of all corpus words that occur in at least three different documents within two or three of the corpora, excluding a list of common function words.",
        "Co-occurrences were counted within a bidirectional five-word window, truncated by sentence ends.",
        "The number of clusters produced – seven – was empirically determined as the maximal number with relatively large proportion (p(c) >.01) for all clusters.",
        "Trying eight clusters or more, we obtain clusters of minute size, which apparently do not reveal additional themes or topics.",
        "Table 1 presents, for each cluster c and each religion, the 15 keywords x with the highest p(clx) values.",
        "The number 15 has no special meaning other than providing rich, balanced and displayable notion of all clusters.",
        "The displayed 3X15 keyword subsets are denoted ĉ, ... ĉ7.",
        "We gave each cluster a title, reflecting our (naive) impression of its content.",
        "As we interpret the clusters, they indeed reveal prominent aspects of religion: rituals (ĉ2), schools (ĉ5), narratives (ĉ6) and scriptures (ĉ7).",
        "More delicate issues, such as cherished qualities (ĉl), spiritual states (ĉ3), suffering and sin (ĉ4) are reflected as well, in spite of the very different position taken by the distinct religions with regard to these issues."
      ]
    },
    {
      "heading": "3.1 Comparison to Expert Data",
      "text": [
        "We have asked an expert of comparative religion studies to simulate roughly the CD clustering task: assigning (freely-chosen) keywords into corresponding subsets, reflecting prominent resembling aspects that cut across the three examined religions.",
        "The expert was not asked to indicate a probability of assignment, but he was allowed to use the same keyword in more than",
        "one cluster.",
        "The expert clusters, with the exclusion of terms that we were not able to locate in our corpora, are displayed in Table 2.",
        "In addition to our tags – e, ... e8 – the expert gave a title to each cluster.",
        "Although the keyword-clustering task is highly subjective, there are notable overlapped regions shared by the expert clusters and ours.",
        "Two expert topics – `Books' (e,) and `Ritual' (e3) – are clearly captured (by ĉ7 and ĉ2 respectively).",
        "`Society and Politics' (e4) and `Establishments' (e5) – are both in some correspondence with our `Schools and Traditions' cluster (ĉ5).",
        "On the other hand, our output fails to capture the `Mysticism' expert cluster (e6).",
        "Further, our output suggests the `spiritual states' theme (ĉ3) and distinguishes cherished qualities (ĉl) from sin and suffering (ĉ4).",
        "Such observations might make sense but are not covered by the expert.",
        "To quantify the overall level of overlap between our output and the expert's, we introduce suitable versions of recall and precision measures.",
        "We want the recall measure to reflect the proportion of expert terms that are captured by our configuration, provided that an optimal correspondence between our clusters to the expert is considered.",
        "Hence, for each expert cluster, ej, we find a particular ĉk with maximal number of overlapping terms (note that two or more expert clusters are allowed to be covered by a single ĉk, to reflect cases where several related subtopics are merged within our results).",
        "Denote this maximal number by M(ej):",
        "Consequently, the recall measure R is defined to be the sum of the above maximal overlap counts over all expert clusters, divided by all 131 expert terms (repetitions in distinct clusters counted):",
        "To estimate how precise our results are, we are interested in the relative part of our clusters, reduced to the expert terms, which has been assigned to the \"right\" expert cluster by the same optimal correspondence.",
        "Note that in this case we do not want to sum up several M values that are associated with a single ĉk: a single cluster covering several expert clusters should be considered as an indication of poor precision.",
        "Furthermore, if we do this, we might recount some of ĉk s terms (specifically, keywords that the expert has included in several clusters; this might result in precision >I 00%).",
        "We need therefore to consider at most one M value per ĉk, namely the largest one.",
        "Define",
        "(Al*ĉk = 0 if the set on the right-hand side is empty, i.e. there is no e; that share M(e;) elements with ĉk).",
        "The global precision measure P is the sum of all M* values, divided by the number of expert terms appearing among the ĉk s (repetitions counted), which are, in the current case, the 94 underlined terms in Table 1:",
        "Our algorithm has achieved the following values: R = / P = / .",
        "This is a notable improvement relatively to the 1B algorithm results: R / and P = / (random assignment of the keywords into seven clusters yield average values R , P = ).",
        "As we have expected, three of the clusters produced by the 1B algorithms are populated, with very high probability, by most keywords of a single religion.",
        "Within these specific religion clusters as well as the other sparsely populated clusters, the ranking inducted by the p(clx) values is not very informative regarding particular subtopics.",
        "Thus, the 1B performs the CD clustering task poorly, even in comparison to random results.",
        "We note that, similarly to our algorithm, the 1B algorithm produces at most 7 clusters of non-negligible size.",
        "This somewhat supports our",
        "meditation', statue', sacrifice''6, sunday', pray', confession 3, pilgrim', charity', ramadan2, gift, stupa' eucharist', christmas', baptism f fasting 2, id al tr', pray', friday', kaaba', mecca'"
      ]
    },
    {
      "heading": "e4: Society and Politics ĉ5 4 9 (of 19)",
      "text": [
        "dalai lama, monk', bodhisattva\", romes, vaticans, churchs, minister', sharia, caliph', imams, shias, lama' priests, cardinals, popes, bishops sunna7, ali6, sufis e5: Establishments ĉ5 4 6 (of 10) monastery', temple', sangha, churchs, cardinals, popes, bishops mosque', imams schools e6: Mysticism ĉn42 (of 11) meditation', nirvana 1A, samadhi3, eucharist', miracle, crucifixion, suffer4, love, saint tantra e7: Learning and Education monastery', monk', sutra', monks, universitys, theologys, meditation' divinitys es: Names and Places ĉ6 4 7 (of 20) gautama6, buddha5,7 jesus christ', john the baptists, muhammad7, ali6, mecca', jordan6, jerusalem', bethlehem6, medina2 maryy, romes, john', paul', luke', matthew', zion6 sufis ĉ5 4 4 (of 8) impression that the limit on number of \"interesting\" clusters reflects intrinsic exhaustion of the information embodied within the given data.",
        "It is yet to be carefully examined whether this observation provides any hint regarding the general issue of the \"right\" number of clusters."
      ]
    },
    {
      "heading": "4 Conclusion",
      "text": [
        "This paper addressed the relatively unexplored problem of detecting corresponding themes across multiple corpora.",
        "We have developed an extended clustering algorithm that is based on the appealing and highly general Information Bottleneck method.",
        "Substantial effort has been devoted to adopting this method for the Cross-Dataset clustering task.",
        "Our approach was demonstrated empirically on the challenging task of fording corresponding themes across different religions.",
        "Subjective examination of the system's output, as well as its comparison to the output of a human expert, demonstrate the potential benefits of applying this approach in the framework of comparative research, and possibly in additional text mining applications.",
        "Given the early stage of this line of research, there is plenty of room for future work.",
        "In particular, further research is needed to provide theoretic grounding for the CD clustering formulations and to specify their properties.",
        "Empirical work is needed to explore the potential of the proposed paradigm for other textual domains as well as for related applications.",
        "Particularly, we have recently presented a similar framework for template induction in information extraction (cross-component clustering, Marx, Dagan, & Shamir, 2002), which should be studied in relation to the CD algorithm presented here."
      ]
    },
    {
      "heading": "Appendix",
      "text": [
        "The value of p(X), which is required for the calculations in Section 3.2, is given directly from the input co-occurrence data as follows:",
        "The values p4cIX), p,(yI c,X) are calculated from values that are available at time step t-1:"
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "We thank Eitan Reich for providing the expert data, as well as for illuminating discussions.",
        "This work has been partially supported by ISRAEL SCIENCE FOUNDATION founded by The Academy of Sciences and Humanities (grants 574/98-1 and 489/00)."
      ]
    }
  ]
}
