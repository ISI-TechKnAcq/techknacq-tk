{
  "info": {
    "authors": [
      "Nancy M. Ide"
    ],
    "book": "SIGLEX Workshop on Standardizing Lexical Resources",
    "id": "acl-W99-0508",
    "title": "Parallel Translations as Sense Discriminators",
    "url": "https://aclweb.org/anthology/W99-0508",
    "year": 1999
  },
  "references": [
    "acl-C92-2070",
    "acl-H93-1051",
    "acl-H93-1052",
    "acl-J94-4003",
    "acl-J96-2004",
    "acl-P91-1017",
    "acl-P98-2228",
    "acl-W97-0207",
    "acl-W97-0213"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This article reports the results of a preliminary analysis of translation equivalents in four languages from different language families, extracted from an on-line parallel corpus of George Orwell's Nineteen Eighty-Four The goal of the study is to determine the degree to which translation equivalents for different meanings of a polysemous word in English are lexicalized differently across a variety of languages, and to detet mine whether this information can be used to stiucture or create a set of sense distinctions useful in natural language processing applications A coherence Index is computed that measures the tendency for different senses of the same English woid to be lexicalized differently, and flout this data a clustering algorithm is used to create sense hierat chies"
      ]
    },
    {
      "heading": "Introduction",
      "text": [
        "It is well known that the most nagging issue for word sense disambiguation (WSD) is the definition of just what a word sense is At its base, the problem is a philosophical and linguistic one that is far from being resolved However, work in automated language processing has led to effotts to find practical means to distinguish word senses, at least to the degree that they are useful for natural language processing tasks such as summarization, document retrieval, and machine translation Several criteria have been suggested and exploited to automatically determine the sense of a word in context (see Ide and \\Term's, 1998), including syntactic behavior, semantic and pragmatic knowledge, and especially in more recent empirical studies, word co-occurrence within syntactic relations (e g 7 Hearst, 1991, Yarowsky, 1993), words co-occurring in global context (e g, Gale et a!, 1993, Yarowsky, 1992 Sch√ºtze, 1992, 1993), etc No clear criteria have emerged, however, and the problem continues to loom large for WSD work The notion that cross-lingual comparison can be useful foi sense disambiguation has served as a basis for some recent work on WSD Foi example, Brown et at (1991) and Gale et at (1992a, 1993) used the parallel, aligned Hansard Corpus of Canadian Parliamentary debates foi WSD, and Dagan et at (1991) and Dagan and Itai (1994) used monolingual corpora of Hebiew and German and a bilingual dictionary These studies rely on the assumption that the mapping between words and word senses varies significantly among languages For example, the word duty in English tianslates into French as depoir in its obligation sense, and imp& in its tax sense By determining the translation",
        "equivalent of duty in a parallel French text, the correct sense of the English word is identified These studies exploit this information in order to gather co-occurrence data for the different senses, which is then used to disambiguate new texts In related work, Dyvik (1998) used patterns of translational relations in an English-Norwegian parallel corpus (ENPC, Oslo University) to define semantic properties such as synonymy, ambiguity, vagueness, and semantic fields and suggested a derivation of semantic representations for signs (e g , lexemes), capturing semantic relationships such as hyponymy etc , fiorn such translational relations Recently, Resnik and Yarowsky (1997) suggested that foi the purposes of WSD, the different senses of a woid could be deteimined by considering only sense distinctions that are lexicalized cross-linguistically In particular, they propose that some set of target languages be identified, and that the sense distinctions to be considered for language processing applications and evaluation be restricted to those that are realized lexically in some minimum subset of those languages This idea would seem to piovide an answer, at least in part, to the problem of determining different senses of a word intuitively, one assumes that if another language lexicalizes a word in two or more ways, there must be a conceptual motivation If we look at enough languages, we would be likely to find the significant lexical differences that delimit different senses of a word However, this suggestion raises several questions Foi instance, it is well known that many ambiguities are preserved acioss languages (for example, the French /titer& and the English interest), especially languages that are relatively closely related Assuming this pioblem can be overcome, should differences found in closely related languages be given lesser (or greater) weight than those found in more distantly related languages') More generally, which languages should be considered for this exercise') All languages?",
        "Closely related languages?",
        "Languages from different language families?",
        "A mixture of the two?",
        "How many languages, and of which types, would be \"enough\" to provide adequate infoimation tot this purpose?",
        "There is also the question of the criteria that would be used to establish that a sense distinction is \"lexicalized cross-linguistically\" How consistent must the distinction be?",
        "Does it mean that two concepts are expressed by mutually non-Intetchangeable lexical Items in some significant number of other languages, or need it only be the case that the option of a different lexicalization exists in a certain percentage of cases') Another consideration is where the cross-lingual information to answer these questions would come from Using bilingual dictionaries would be extremely tedious and error-prone, given the substantial divergence among dictionaries in terms of the kinds and degree of sense distinctions they make Resnik and Yaiowsky (1997) suggest EutoWordNet (Vossen, 1998) as a possible souice of information, but, given that EuroWordNet is piimailly a lexicon and not a corpus, it is subject to many of the same objections as for bilingual dictionaries An alternative would be to gather the information from parallel, aligned corpoi a Unlike bilingual and multilingual dictionaries, translation equivalents in parallel texts ale determined by experienced translatois, who evaluate each instance of a word's use in context rather than as a part of the metalinguistic activity of classifying senses for inclusion in a dictionary However, at present very few parallel aligned corpora exist The vast majority of these are bi-texts, involving only two languages, one of which is very often English Ideally, a serious",
        "evaluation of Resnik and Yarowsky's proposal would include parallel texts in languages from several different language families, and, to maximally ensure that the word in question is used in the exact same sense across languages, it would be preferable that the same text were used over all languages in the study The only currently available parallel corpora for more than two languages are thwell's Nineteen Eighty-Foui (Erjavec and Ide, 1998), Plato's Republic (Erjavec, et al., 1998), the MULTEXT Journal of the Commission corpus (Ide and Veroms, 1994), and the Bible (Resnik, et a!, press) It is likely that these corpora do not provide enough appropriate data to reliably determine sense distinctions Also, it is not clear how the lexicalization of sense distinctions across languages is affected by genre, domain, style, etc This paper attempts to provide some preliminary answers to the questions outlined above, in order to eventually determine the degree to which the use of parallel data is viable to determine sense distinctions, and, if so, the ways in which this information might be used Given the lack of laige parallel texts across multiple languages, the study is necessarily limited, however, close examination of a small sample of parallel data can, as a flist step, provide the basis and direction for more extensive studies"
      ]
    },
    {
      "heading": "1 Methodology",
      "text": [
        "I have conducted a small study using parallel, aligned versions of George Orwell's Nineteen Eighty-Four (Erjavec and Ide, 1998) in five languages English, Slovene, Estonian, Romanian, and Czech ' The study therefoie involves languages from four language families I The Oiwell parallel corpus also includes versions of Nineteen-Eight) Four in Hungarian, Bulgarian, Latvian, Lithuanian, Seiblan, and Russian (Germanic, Slavic, Fmno-Ugrec, and Romance), two languages from the same family (Czech and Slovene), as well as one non-Indo-European language (Estonian) Nineteen Eighty-Four is a text of about 100,000 words, translated directly from the original English in each of the other languages The parallel versions of the text are sentence-aligned to the English and tagged for part of speech Although Nineteen Eighty-Four is a work of fiction, Orwell's prose is not highly stylized and, as such, it provides a reasonable sample of modern, ordinary language that is not tied to a given topic or sub-domain (such as newspapers, technical reports, etc ) Furthermore, the translations of the text seem to be relatively faithful to the original for instance, over 95% of the sentence alignments in the full paiallel corpus of seven languages are one-to-one (Priest-Dorman, et a!, 1997) Nine ambiguous English words were considered hard, head, country, line, promise, slight, seize, scrap, float The first four were chosen because they have been used in other disambiguation studies, the latter five were chosen from among the words used in the Senseval disambiguation exercise (Kilgarnff and Palmer, forthcoming) In all cases, the study was necessarily limited to words that occurred frequently enough in the Orwell text to warrant consideration Five hundred forty-two sentences containing an occurrence or occurrences (including morphological variants) of each of the nine words were extracted from the English text, together with the paiallel sentences in which they occur in the texts of the four comparison languages (Czech, Estonian, Romanian, Slovene) As Wilks and Stevenson (1998) have pointed out, pait-of-speech tagging accomplishes a good portion of the work of disambiguation, theiefore occuirences of woids that appealed in the data in more than",
        "one part of speech were grouped separately 2 The English occurrences were then grouped using the sense distinctions in WordNet, (version I 6) [Miller et a!, 1990, Fellbaum, 19981) The sense categorization was performed by the author and two student assistants, results from the three were compared and a final, mutually agreeable set of sense assignments was established For each of the four comparison languages, the corpus of sense-grouped parallel sentences were sent to a linguist and native speaker of the comparison language The linguists were asked to provide the lexical item in each parallel sentence that corresponds to the ambiguous English word If inflected, they were asked to provide both the inflected form and the root form In addition, the linguists were asked to indicate the type of translation, according to the distinctions given in Table 1 For over 85% of the English word occurrences (corresponding to types I and 2 in Table I), a specific lexical item or items could be identified as the translation equivalent for the corresponding English word For comparison purposes, each translation equivalent was represented by its lemma (or the lemma of the loot form in the case of derivatives) and associated with the WordNet sense to which it corresponds In ordei to determine the degree to which the assigned sense distinctions correspond to translation equivalents, a cohetence index (CI) was computed that measures how often each pair of senses is tianslated using the same woid as well as the consistency with which a given is translated with the same word Note that the 2 The adjective and adverb senses of hard are consideied together because the distinction is not consistent across the translations used in the study Note that the CI is similar to semantic entropy (Melamed, 1997) However, Melamed computes CIs do not determine whether or not a sense distinction can be lexicalized in the target language, but only the degree to which they are lexicalized differently in the translated text However, it can be assumed that the CIs provide a measure of the tendency to lexicalize different WordNet senses differently, which can in tuin be seen as an indication of the degree to which the distinction is valid",
        "where",
        "‚Ä¢ n is the number of comparison languages under consideration, ‚Ä¢ m‚Äû, and m, are the nUmber of occurrences ot sense sq and sense Sr in the English corpus, respectively, including occurrences that have no identifiable translation, ‚Ä¢ ‚Äû(') is the number of times that senses q and r are translated by the same lexical item in language t, i e,",
        "The Cl is a value between 0 and 1, computed by examining clusters of occurrences translated by the same word in the othei languages If sense and sense j are consistently translated with the same woid in each comparison language, then C/(s, si) = 1, if they are translated with a different word in every occurrence, C/(s, s,) = 0 In general, the CI for pails of different senses provides an index of their relatedness, i e , the greater the value of C/(s, s), the more frequently occurrences of-sense t and sense j are translated with the same lexical item When t = j, we entiopy tot woid types, lathe' than woid senses",
        "obtain a measure of the coherence of a given sense",
        "and head that occurred in the data The CI data s 'saw¬∞ hard and head are given in Tables 3 and 4 UOUS Cis measuring the affinity of a sense with itself ‚Äì that is, the tendency for all occurrences of that sense to be translated with the same word--show that all of the six senses of &lid have greatei internal consistency than affinity with other senses, with senses 1 1 (\"difficult\" - CI = 56) and 1 3 (\"not soft\" ‚Äì CI = 63) registering the highest internal consistency 6 The same holds true for three of the four senses of head, while the CI for senses 1 3 (\"intellect\") and 1 1 (\"part of the body\") is higher than the CI for 1 3/1 3",
        "CIs were also computed for each language individually as well as for different language groupings Romanian, Czech, and Estonian (three different language families) Czech and Slovene (same family), Romanian, Czech, Slovene (Indo-European, and Estonian (non-Indo-European) To better visualize the relationship between senses, a hierarchical clustering algorithm was applied to the CI data to generate trees reflecting sense proximity 4 Finally, in order to determine the degree to which the linguistic relation between languages may affect coherence, a correlation was run among CIs for all pairs of the four target languages"
      ]
    },
    {
      "heading": "2 Results",
      "text": [
        "Although the data sample is small, it gives some insight into ways in which a laiger sample might contribute to sense discrimination",
        "Figure 2 shows the sense clusters for !laid generated from the CI data 7 The senses fall into two main clusters, with the two most internally consistent senses (1 1 and 1 3) at the deepest level of each of the respective groups The two adverbial forms8 are placed in separate groups, ieflecting their semantic proximity to the different adjectival meanings of hard The clusters for head (Figure 2) similarly show two distinct groupings, each anchored in the two senses with the highest internal consistency and the lowest mutual CI (\"part of the body\" (1 1) and \"ruler, chief' (1 4)) The hierarchies apparent in the cluster graphs make intuitive sense Structured like dictionary entries, the clusters for hard and head might appeal as in Figure I This is not dissimilar to actual dictionary entries for hard and head, for example, the entries for hard in four differently constructed dictionaries (Collins English (CED), Longman 's (LDOCE), Oxfot d Advanced Learner's (OALD), and COBUILD) all list the \"difficult\" and \"not soft\" senses first and second, which, since most dictionaries list the most common oi frequently used senses first, reflects the gross division apparent in the clusters Beyond this, it is difficult to assess the 7 Fot the purposes of the cluster analysis, CIs of 1 00 resulting from a single occurrrence weie normalized to 5 8 Because loot toms weie used in the analysis, no distinction in tianslation equivalents was made for part of speech correspondence between the senses in the dictionary entries and the clusters The remaining WordNet senses are scattered at various places within the entries or, in some cases, split across various senses The hierarchical relations apparent in the clusters are not reflected in the dictionary entries, since the senses are for the most part presented in flat, linear lists However, It is interesting to note that the first five senses of hard in the COBUILD dictionary, which is the only dictionary in the group constructed on the basis of cotpus examples' and presents senses in older of frequency, correspond to five of the six WordNet senses in this study WordNet's \"metaphorically hard\" is spread over multiple senses in the COB UILD, as it is in the other dictionaries",
        "The results for difteient language groupings show that the tendency to lexicalize senses differently is not affected by language distance (Table 5) In fact, the mean CI foi Estonian, the only non-Indo-European language in the study, is lower than that for any other group, indicating that WordNet sense distinctions are slightly less likely to be lexicalized differently in Estonian",
        "Correlations of CIs for each language pair (Table 5) also show no relationship between the degree to which sense distinctions are lexicalized differently and language distance This is contrary to results obtained by Resnik and Yarowsky (submitted), who, using a metric similar to the one used in this study, found that that non-Indo-European languages tended to lexicalize English sense distinctions more than Indo-European languages, especially at finer-grained levels Howevei, their translation data was generated by native speakers presented with isolated sentences in English, who were asked to provide the translation for a given word in the sentence It is not clear how this data compares to translations generated by trained translators working with full context"
      ]
    },
    {
      "heading": "Conclusion",
      "text": [
        "The small sample in this study suggests that cross-lingual lexicalization can be used to define and structure sense distinctions The cluster graphs above provide information about relations among WordNet senses that could be used, for example, to determine the granularity of sense differences, which in turn could be used in tasks such as machine translation, information retrieval, etc For example, it is likely that as sense distinctions become finer, the degree of error is less severe Resnik and Yarowsky (1997) suggest that confusing finer-grained sense distinctions should be penalized less severely than confusing grosser distinctions when evaluating the peiformance of sense disambiguation systems The clusters also provide insight into the lexicalization of sense distinctions related by various semantic relations (metonymy, meronymy, etc ) across languages, for instance, the \"part of the body\" and \"intellect\" senses of head are lexicalized with the same item a significant portion of the time across all languages, information that could be used in machine translation In addition, clustei data such as that presented here could be used in lexicography, to deteimine a mole detailed hierarchy of relations among senses in dictionary entries It is less clear how cross-lingual information can be used to determine sense distinctions independent of a predefined set, such as the WordNet senses used here In an effort to explore how this might be done, I have used the small sample from this study to cleate word groupings horn \"back translations\" (i e additional translations in the original language of the translations in the target language) and developed a metric that uses this information to determine relatedness between occurrences, which is in turn used to cluster occurrences into sense groups I have also compared sets of back translations for words representing the vanous WordNet senses, which provide word groups similar to WordNet synsets Interestingly, there is virtually no overlap between the WordNet synsets and word groups generated from back translations The results show, however, that sense distinctions useful for natural language processing tasks such as machine translation could potentially be determined, oi at least influenced, by considenng this information The automatically generated synsets themselves may also be useful in the same applications' where WordNet synsets (and ontologies) have been used in the past More work needs to be done on the topic of cross-lingual sense determination, utilizing substantially larger parallel corpora that include a variety of language types as well as texts horn several genres This small study explores a possible methodology to apply when such resources become available"
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "The author would like to gratefully acknowledge the contribution of those who provided the translation infoimation Tomaz Eija‚Äòec (Slovene), Kadri Muischnek (Estonian), Vladimir Petkevic (Czech), and Dan Tuhs (Romanian), as well as Dana Fleui and Daniel Kline, who helped to transcribe and evaluate the data Special thanks to Dan Melamed and Hinrich Sch√ºtze for their helpful comments"
      ]
    }
  ]
}
