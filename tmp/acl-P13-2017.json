{
  "info": {
    "authors": [
      "Ryan McDonald",
      "Joakim Nivre",
      "Yvonne Quirmbach-Brundage",
      "Yoav Goldberg",
      "Dipanjan Das",
      "Kuzman Ganchev",
      "Keith Hall",
      "Slav Petrov",
      "Hao Zhang",
      "Oscar Täckström",
      "Claudia Bedini",
      "Núria Bertomeu Castelló",
      "Jungmee Lee"
    ],
    "book": "ACL",
    "id": "acl-P13-2017",
    "title": "Universal Dependency Annotation for Multilingual Parsing",
    "url": "https://aclweb.org/anthology/P13-2017",
    "year": 2013
  },
  "references": [
    "acl-D07-1096",
    "acl-D09-1086",
    "acl-D11-1006",
    "acl-D12-1125",
    "acl-J93-2004",
    "acl-N06-2015",
    "acl-P03-1054",
    "acl-P04-1061",
    "acl-P07-1122",
    "acl-P09-1042",
    "acl-P11-1061",
    "acl-P11-2033",
    "acl-P13-2103",
    "acl-Q13-1001",
    "acl-W02-1503",
    "acl-W04-2709",
    "acl-W06-2920",
    "acl-W08-1301",
    "acl-W09-2307",
    "acl-W12-1909"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "We present a new collection of treebanks with homogeneous syntactic dependency annotation for six languages: German, English, Swedish, Spanish, French and Korean.",
        "To show the usefulness of such a resource, we present a case study of cross-lingual transfer parsing with more reliable evaluation than has been possible before.",
        "This ?universal?",
        "treebank is made freely available in order to facilitate research on multilingual dependency parsing.1"
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "In recent years, syntactic representations based on head-modifier dependency relations between words have attracted a lot of interest (Ku?bler et al., 2009).",
        "Research in dependency parsing ?",
        "computational methods to predict such representations ?",
        "has increased dramatically, due in large part to the availability of dependency treebanks in a number of languages.",
        "In particular, the CoNLL shared tasks on dependency parsing have provided over twenty data sets in a standardized format (Buch-holz and Marsi, 2006; Nivre et al., 2007).",
        "While these data sets are standardized in terms of their formal representation, they are still heterogeneous treebanks.",
        "That is to say, despite them all being dependency treebanks, which annotate each sentence with a dependency tree, they subscribe to different annotation schemes.",
        "This can include superficial differences, such as the renaming of common relations, as well as true divergences concerning the analysis of linguistic constructions.",
        "Common divergences are found in the",
        "clauses, and multi-word expressions (Nilsson et al., 2007; Ku?bler et al., 2009; Zeman et al., 2012).",
        "These data sets can be sufficient if one's goal is to build monolingual parsers and evaluate their quality without reference to other languages, as in the original CoNLL shared tasks, but there are many cases where heterogenous treebanks are less than adequate.",
        "First, a homogeneous representation is critical for multilingual language technologies that require consistent cross-lingual analysis for downstream components.",
        "Second, consistent syntactic representations are desirable in the evaluation of unsupervised (Klein and Manning, 2004) or cross-lingual syntactic parsers (Hwa et al., 2005).",
        "In the cross-lingual study of McDonald et al. (2011), where delexicalized parsing models from a number of source languages were evaluated on a set of target languages, it was observed that the best target language was frequently not the closest typologically to the source.",
        "In one stunning example, Danish was the worst source language when parsing Swedish, solely due to greatly divergent annotation schemes.",
        "In order to overcome these difficulties, some cross-lingual studies have resorted to heuristics to homogenize treebanks (Hwa et al., 2005; Smith and Eisner, 2009; Ganchev et al., 2009), but we are only aware of a few systematic attempts to create homogenous syntactic dependency annotation in multiple languages.",
        "In terms of automatic construction, Zeman et al. (2012) attempt to harmonize a large number of dependency treebanks by mapping their annotation to a version of the Prague Dependency Treebank scheme (Hajic?",
        "et al, 2001; Bo?hmova?",
        "et al, 2003).",
        "Additionally, there have been efforts to manually or semi-manually construct resources with common syn",
        "tactic analyses across multiple languages using alternate syntactic theories as the basis for the representation (Butt et al., 2002; Helmreich et al., 2004; Hovy et al., 2006; Erjavec, 2012).",
        "In order to facilitate research on multilingual syntactic analysis, we present a collection of data sets with uniformly analyzed sentences for six languages: German, English, French, Korean, Spanish and Swedish.",
        "This resource is freely available and we plan to extend it to include more data and languages.",
        "In the context of part-of-speech tagging, universal representations, such as that of Petrov et al. (2012), have already spurred numerous examples of improved empirical cross-lingual systems (Zhang et al., 2012; Gelling et al., 2012; Ta?ckstro?m et al., 2013).",
        "We aim to do the same for syntactic dependencies and present cross-lingual parsing experiments to highlight some of the benefits of cross-lingually consistent annotation.",
        "First, results largely conform to our expectations of which target languages should be useful for which source languages, unlike in the study of McDonald et al. (2011).",
        "Second, the evaluation scores in general are significantly higher than previous cross-lingual studies, suggesting that most of these studies underestimate true accuracy.",
        "Finally, unlike all previous cross-lingual studies, we can report full labeled accuracies and not just unlabeled structural accuracies."
      ]
    },
    {
      "heading": "2 Towards A Universal Treebank",
      "text": [
        "The Stanford typed dependencies for English (De Marneffe et al., 2006; de Marneffe and Manning, 2008) serve as the point of departure for our ?universal?",
        "dependency representation, together with the tag set of Petrov et al. (2012) as the underlying part-of-speech representation.",
        "The Stanford scheme, partly inspired by the LFG framework, has emerged as a de facto standard for dependency annotation in English and has recently been adapted to several languages representing different (and typologically diverse) language groups, such",
        "widespread use and proven adaptability makes it a natural choice for our endeavor, even though additional modifications will be needed to capture the full variety of grammatical structures in the world's languages.",
        "Alexandre re?side avec sa famille a` Tinqueux ."
      ]
    },
    {
      "heading": "NOUN VERB ADP DET NOUN ADP NOUN P NSUBJ ADPMOD ADPOBJ POSS ADPMOD ADPOBJ P",
      "text": [
        "We use the so-called basic dependencies (with punctuation included), where every dependency structure is a tree spanning all the input tokens, because this is the kind of representation that most available dependency parsers require.",
        "A sample dependency tree from the French data set is shown in Figure 1.",
        "We take two approaches to generating data.",
        "The first is traditional manual annotation, as previously used by Helmreich et al. (2004) for multilingual syntactic treebank construction.",
        "The second, used only for English and Swedish, is to automatically convert existing treebanks, as in Zeman et al. (2012)."
      ]
    },
    {
      "heading": "2.1 Automatic Conversion",
      "text": [
        "Since the Stanford dependencies for English are taken as the starting point for our universal annotation scheme, we begin by describing the data sets produced by automatic conversion.",
        "For English, we used the Stanford parser (v1.6.8) (Klein and Manning, 2003) to convert the Wall Street Journal section of the Penn Treebank (Marcus et al., 1993) to basic dependency trees, including punctuation and with the copula verb as head in copula constructions.",
        "For Swedish, we developed a set of deterministic rules for converting the Tal-banken part of the Swedish Treebank (Nivre and Megyesi, 2007) to a representation as close as possible to the Stanford dependencies for English.",
        "This mainly consisted in relabeling dependency relations and, due to the fine-grained label set used in the Swedish Treebank (Teleman, 1974), this could be done with high precision.",
        "In addition, a small number of constructions required structural conversion, notably coordination, which in the Swedish Treebank is given a Prague style analysis (Nilsson et al., 2007).",
        "For both English and Swedish, we mapped the language-specific part-of-speech tags to universal tags using the mappings of Petrov et al. (2012)."
      ]
    },
    {
      "heading": "2.2 Manual Annotation",
      "text": [
        "For the remaining four languages, annotators were given three resources: 1) the English Stanford",
        "guidelines; 2) a set of English sentences with Stanford dependencies and universal tags (as above); and 3) a large collection of unlabeled sentences randomly drawn from newswire, weblogs and/or consumer reviews, automatically tokenized with a rule-based system.",
        "For German, French and Spanish, contractions were split, except in the case of clitics.",
        "For Korean, tokenization was more coarse and included particles within token units.",
        "Annotators could correct this automatic tokenization.",
        "The annotators were then tasked with producing language-specific annotation guidelines with the expressed goal of keeping the label and construction set as close as possible to the original English set, only adding labels for phenomena that do not exist in English.",
        "Making fine-grained label distinctions was discouraged.",
        "Once these guidelines were fixed, annotators selected roughly an equal amount of sentences to be annotated from each domain in the unlabeled data.",
        "As the sentences were already randomly selected from a larger corpus, annotators were told to view the sentences in order and to discard a sentence only if it was 1) fragmented because of a sentence splitting error; 2) not from the language of interest; 3) incomprehensible to a native speaker; or 4) shorter than three words.",
        "The selected sentences were preprocessed using cross-lingual taggers (Das and Petrov, 2011) and parsers (McDonald et al., 2011).",
        "The annotators modified the pre-parsed trees using the TrEd2 tool.",
        "At the beginning of the annotation process, double-blind annotation, followed by manual arbitration and consensus, was used iteratively for small batches of data until the guidelines were finalized.",
        "Most of the data was annotated using single-annotation and full review: one annotator annotating the data and another reviewing it, making changes in close collaboration with the original annotator.",
        "As a final step, all annotated data was semi-automatically checked for annotation consistency."
      ]
    },
    {
      "heading": "2.3 Harmonization",
      "text": [
        "After producing the two converted and four annotated data sets, we performed a harmonization step, where the goal was to maximize consistency of annotation across languages.",
        "In particular, we wanted to eliminate cases where the same label was used for different linguistic relations in different languages and, conversely, where one and",
        "the same relation was annotated with different labels, both of which could happen accidentally because annotators were allowed to add new labels for the language they were working on.",
        "Moreover, we wanted to avoid, as far as possible, labels that were only used in one or two languages.",
        "In order to satisfy these requirements, a number of language-specific labels were merged into more general labels.",
        "For example, in analogy with the nn label for (element of a) noun-noun compound, the annotators of German added aa for compound adjectives, and the annotators of Korean added vv for compound verbs.",
        "In the harmonization step, these three labels were merged into a single label compmod for modifier in compound.",
        "In addition to harmonizing language-specific labels, we also renamed a small number of relations, where the name would be misleading in the universal context (although quite appropriate for English).",
        "For example, the label prep (for a modifier headed by a preposition) was renamed adpmod, to make clear the relation to other modifier labels and to allow postpositions as well as prepositions.3 We also eliminated a few distinctions in the original Stanford scheme that were not annotated consistently across languages (e.g., merging complm with mark, number with num, and purpcl with advcl).",
        "The final set of labels is listed with explanations in Table 1.",
        "Note that relative to the universal part-of-speech tagset of Petrov et al. (2012) our final label set is quite rich (40 versus 12).",
        "This is due mainly to the fact that the the former is based on deterministic mappings from a large set of annotation schemes and therefore reduced to the granularity of the greatest common denominator.",
        "Such a reduction may ultimately be necessary also in the case of dependency relations, but since most of our data sets were created through manual annotation, we could afford to retain a fine-grained analysis, knowing that it is always possible to map from finer to coarser distinctions, but not vice versa.4"
      ]
    },
    {
      "heading": "2.4 Final Data Sets",
      "text": [
        "version in our case were English, for which the Stanford dependencies were originally defined, and Swedish, where the native annotation happens to have a fine-grained label set.",
        "verted WSJ section of the PTB.",
        "The data release includes scripts to generate this data, not the data itself.",
        "?Automatically converted Talbanken section of the Swedish Treebank.",
        "N=News, B=Blogs, R=Consumer Reviews.",
        "due to the source and tokenization.",
        "For example, Korean has 50% more sentences than Spanish, but ?40k less tokens due to a more coarse-grained tokenization.",
        "In addition to the data itself, annotation guidelines and harmonization rules are included so that the data can be regenerated."
      ]
    },
    {
      "heading": "3 Experiments",
      "text": [
        "One of the motivating factors in creating such a data set was improved cross-lingual transfer evaluation.",
        "To test this, we use a cross-lingual transfer parser similar to that of McDonald et al. (2011).",
        "In particular, it is a perceptron-trained shift-reduce parser with a beam of size 8.",
        "We use the features of Zhang and Nivre (2011), except that all lexical identities are dropped from the templates during training and testing, hence inducing a ?delexicalized?",
        "model that employs only ?universal?",
        "properties from source-side treebanks, such as part-of-speech tags, labels, head-modifier distance, etc.",
        "We ran a number of experiments, which can be seen in Table 3.",
        "For these experiments we randomly split each data set into training, development and testing sets.",
        "The one exception is English, where we used the standard splits.",
        "Each row in Table 3 represents a source training language and each column a target evaluation language.",
        "We report both unlabeled attachment score (UAS) and labeled attachment score (LAS) (Buch-holz and Marsi, 2006).",
        "This is likely the first reliable cross-lingual parsing evaluation.",
        "In particular, previous studies could not even report LAS due to differences in treebank annotations.",
        "We can make several interesting observations.",
        "Most notably, for the Germanic and Romance target languages, the best source language is from the same language group.",
        "This is in stark contrast to the results of McDonald et al. (2011), who observe that this is rarely the case with the heterogenous CoNLL treebanks.",
        "Among the Germanic languages, it is interesting to note that Swedish is the best source language for both German and English, which makes sense from a typological point of view, because Swedish is intermediate between German and English in terms of word order properties.",
        "For Romance languages, the cross-lingual parser is approaching the accuracy of the supervised setting, confirming that for these languages much of the divergence is lexical and not structural, which is not true for the Germanic languages.",
        "Finally, Korean emerges as a very clear outlier (both as a source and as a target language), which again is supported by typological considerations as well as by the difference in tokenization.",
        "With respect to evaluation, it is interesting to compare the absolute numbers to those reported",
        "mon to both studies (DE, EN, SV and ES).",
        "In that study, UAS was in the 38?68% range, as compared to 55?75% here.",
        "For Swedish, we can even measure the difference exactly, because the test sets are the same, and we see an increase from 58.3% to 70.6%.",
        "This suggests that most cross-lingual parsing studies have underestimated accuracies."
      ]
    },
    {
      "heading": "4 Conclusion",
      "text": [
        "We have released data sets for six languages with consistent dependency annotation.",
        "After the initial release, we will continue to annotate data in more languages as well as investigate further automatic treebank conversions.",
        "This may also lead to modifications of the annotation scheme, which should be regarded as preliminary at this point.",
        "Specifically, with more typologically and morphologically diverse languages being added to the collection, it may be advisable to consistently enforce the principle that content words take function words as dependents, which is currently violated in the analysis of adpositional and copula constructions.",
        "This will ensure a consistent analysis of functional elements that in some languages are not realized as free words or are not obligatory, such as adpositions which are often absent due to case inflections in languages like Finnish.",
        "It will also allow the inclusion of language-specific functional or morphological markers (case markers, topic markers, classifiers, etc.)",
        "at the leaves of the tree, where they can easily be ignored in applications that require a uniform cross-lingual representation.",
        "Finally, this data is available on an open source repository in the hope that the community will commit new data and make corrections to existing annotations."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "Many people played critical roles in the process of creating the resource.",
        "At Google, Fernando Pereira, Alfred Spector, Kannan Pashupathy, Michael Riley and Corinna Cortes supported the project and made sure it had the required resources.",
        "Jennifer Bahk and Dave Orr helped coordinate the necessary contracts.",
        "Andrea Held, Supreet Chinnan, Elizabeth Hewitt, Tu Tsao and Leigha Weinberg made the release process smooth.",
        "Michael Ringgaard, Andy Golding, Terry Koo, Alexander Rush and many others provided technical advice.",
        "Hans Uszkoreit gave us permission to use a subsample of sentences from the Tiger Treebank (Brants et al., 2002), the source of the news domain for our German data set.",
        "Annotations were additionally provided by Sulki Kim,"
      ]
    }
  ]
}
