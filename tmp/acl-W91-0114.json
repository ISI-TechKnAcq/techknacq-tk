{
  "info": {
    "authors": [
      "James Barnett",
      "Inderjeet Mani"
    ],
    "book": "Workshop on Reversible Grammar in Natural Language Processing",
    "id": "acl-W91-0114",
    "title": "Shared Preferences",
    "url": "https://aclweb.org/anthology/W91-0114",
    "year": 1991
  },
  "references": [
    "acl-A88-1003",
    "acl-A88-1021",
    "acl-E89-1032",
    "acl-J81-1002",
    "acl-J87-1005",
    "acl-P89-1002",
    "acl-P90-1013"
  ],
  "sections": [
    {
      "text": [
        "Abstract 2 Preferences in Understanding and Generation This paper attempts to develop a theory of heuristics or preferences that can be shared between understanding and generation systems.",
        "We first develop a formal analysis of preferences and consider the relation between their uses in generation and understanding.",
        "We then present a bidirectional algorithm for applying them and examine typical heuristics for lexical choice, scope and anaphora in, more detail."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Understanding and generation systems must both deal with ambiguity.",
        "In understanding, there are often a number of possible meanings for a string, while there are usually a number of different ways of expressing a given meaning in generation.",
        "To control the explosion of possibilities, researchers have developed a variety of heuristics or preferences - for example, a preference for low attachment of modifiers in understanding or for concision in generation.",
        "This paper investigates the possibility of sharing such preferences between understanding and generation as part of a bidirectional NL system.",
        "In Section 2 we formalize the concept of a preference, and Section 3 presents an algorithm for applying such preferences uniformly in understanding and generation.",
        "In Section 4 we consider specific heuristics for lexical choice, scope, and anaphora.",
        "These heuristics have special properties that permit a more efficient implementation than the general algorithm from Section 3.",
        "Section 5 discusses some of the shortcomings of the theory developed here and suggests directions for future research.",
        "Natural language understanding is a mapping from utterances to meanings, while generation goes in the opposite direction.",
        "Given a set String of input strings (of a given language) and a set bit of interpretations or meanings, we can represent understanding as a relation U C String x Int, and generation as G C IntxString.",
        "U and G are relations, rather than functions, since they allow for ambiguity: multiple meanings for an utterance and multiple ways of expressing a meaningl.",
        "A minimal requirement for a reversible system is that U and G be inverses of each other.",
        "For all s E String and i E ml:",
        "Intuitively, preferences are ways of controlling the ambiguity of U and G by ranking some interpretations (for U) or strings (for G) more highly than others.",
        "Formally, then, we can view preferences as total orders on the objects in question (we will capitalize the term when using it in this technical sense).2 Thus, for any $ E String an understanding Preference Pint will order the pairs 1(s,2)1(s, E 11), while a generation Preference The definitions of U and G allow for strings with no interpretations and meanings with no strings.",
        "Since any meaning can presumably be expressed in any language, we may want to further restrict G so that everything is expressible: VIE Int (3.5 E String Rs, E CJ).",
        "2 We use total orders rather than partial orders to avoid having to deal with incommensurate structures.",
        "The requirement of commensurability is not burdensome in practice, even though many heuristics apparently don't apply to certain structures.",
        "For example, a heuristic favoring low attachment of post-modifiers doesn't clearly tell us how to rank a sentence without post-modifiers, but we can insert such sentences into a total order by observing that they have all modifiers attached as low as possible.",
        "Pat,- will rank {(i, s)ki, E Gr.",
        "Thus we can view the task of understanding as enumerating the interpretations of a string in the order given by Pint.",
        "Similarly, generation will produce strings in the order given by Pit, Using Up,.. and Gp., to denote the result of combining U and G with these preferences, we have, for all s E String and",
        "where U(s) = • • • in) and",
        "where G(4 = {si, , sm) and Li < kl 8;) sk))] Alternatively, we note that any Preference P induces an equivalence relation which groups together the objects that are equal under P.4 We can therefore view the task of Generation and Understanding as being the enumeration of P's equivalence classes in order, without worrying about order within classes (note that Formulae 2 and 3 specify the order only of pairs where one member is less than the other under P.) The question now arises of what the relation between understanding Preferences and generation Preferences should be.",
        "Understanding heuristics are intended to find the meaning that the speaker is most likely to have intended for an utterance, and generation heuristics should select the string that is most likely to communicate a given meaning to the hearer.",
        "We would expect these Preferences to be inverses of each other: if s is the best way to express meaning i, then i should be the most likely interpretation of s. If we don't accept this condition, we will generate sentences that we expect the listener to misinterpret.",
        "Therefore we define class(Preference,pair) to be the equivalence class that pair is assigned to under Preference's ordering,5 and link the the first 3 Note that this definition allows Preferences to work 'across derivations.'",
        "For example, it allows Pmt to rank pairs (s, I), i') where a 8 a'.",
        "It permits a Preference to say that i is a better interpretation for a than i' is for s'.",
        "It is not clear if this sort of power is necessary, and the algorithms below require only that Preferences be able to rank different interpretations (strings) for a given string (interpretation)."
      ]
    },
    {
      "heading": "4 Any order P on a set of objects D partitions D into a set of equivalence classes by assigning each x D to the set {YIY <P r SEr <P",
      "text": [
        "5ciass(Preference, pair) is defined as the number of classes containing items that rank more highly than pair under Preference.",
        "(most highly ranked) classes under Pint and Pnr as follows:",
        "It is also reasonable to require that opposing sets of preferences in understanding be reflected in generation.",
        "If string Si has two interpretations and i2, with i being preferred to i2, and string s2 has the same two interpretations with the preferences reversed, then si should be a better way of expressing i1 than i2, and vice-versa for s2:",
        "Formula 4 provides a tight coupling of heuristics for understanding and generating the most preferred structures, but it doesn't provide any way to share Preferences for secondary readings.",
        "Formula 5 offers a way to share heuristics for secondary interpretations, but it is quite weak and would be highly inefficient to use.",
        "To employ it during generation to choose between si and s2 as ways of expressing i1, we would have to run the understanding system on both si and s2 to see if we could find another interpretation i2 that both strings share but with opposite rankings relative to i1.",
        "If we want to share Preferences for secondary readings, we will need to make stronger assumptions.",
        "The question of ranking secondary interpretations brings us onto treacherous ground since most common heuristics (e.g., preferring low attachment) specify only the best reading and don't help choose between secondary and tertiary readings.",
        "Furthermore, native speakers don't seem to have clear intuitions about the relative ranking of lesser readings.",
        "Finally, there is some question about why we should care about non-primary readings, since the best interpretation or string is normally what we want.",
        "However, it is important to deal with secondary preferences, in part for systematic completeness, but mostly because secondary readings are vital in any attempt to deal with figurative language - humor, irony, and metaphor - which depends on the interplay between primary and secondary readings.",
        "To begin to develop a theory of secondary Preferences, we will simply stipulate that the heuristics in question are shared 'across the board' between understanding and generation.",
        "; The simplest way to do this is to extend Formula 4 into a biconditional, and require it to hold of all classes (we will reconsider this stipulation in Section 5).",
        "For all s E String and iE Int, we have:",
        "Since Preferences now work in either direction, we can simplify our notation and represent them as total orderings of a set T of trees, where each node of each tree is annotated with syntactic and semantic information, and, for any t E T, str(0 returns the string in String that t dominates (i.e., spans), and sern(t) returns the interpretation in Int for the root node of t. For a preference P on T and trees 11, 12, we stipulate:",
        "We close this section by noting a property of Preferences that will be important in Section 4: an ordered list of Preferences can be combined into a new Preference by using each item in the list to refine the 'ordering specified by the previous ones.",
        "That is, the second Preference orders pairs that are equal under the first Preference, and the third Preference applies to those that are still equal under the second Preference, etc.",
        "If"
      ]
    },
    {
      "heading": "3 An Algorithm for Sharing Preferences",
      "text": [
        "If we consider ways of sharing Preferences between understanding and generation, the simplest one is to simply Produce all possible interpreta-tions(strings), and then sort them using the Preference.",
        "This is, of course, inefficient in cases where we are interested in only the more highly ranked possibilities.",
        "We can do better if we are willing to make few assumptions about the structure of Preferences and the understanding and generation routines.",
        "The crucial requirement on Preferences is that they be 'upwardly monotonic' in the following sense: if ti is preferred to 12, then it is also preferred to any tree containing t2 as a subtree.",
        "Using subtree(ti,t2) to mean that ti is a subtree of t2, we stipulate",
        "Without such a requirement, there is no way to cut off unpromising paths, since we can't predict the ranking of a complete structure from that of its constituents.",
        "Finally, we assume that both understanding and generation are agenda-driven procedures that work by creating, combining, and elaborating trees.6 Under these assumptions, the following high-level algorithm can be wrapped around the underlying parsing and generation routines to cause the output to be enumerated in the order given by a Preference P. In the pseudo-code below, mode specifies the direction of processing and input is a string (if mode is understanding) or a semantic representation (if mode is generation).",
        "ezecute_item removes an item from the agenda and executes it, returning 0 or more new trees.",
        "generate_items takes a newly formed tree, a set of previously existing trees, and the mode, and adds a set of new actions to the agenda.",
        "(The underlying understanding or generation algorithm is hidden inside generate_items.)",
        "The variable active holds the set of trees that are currently being used to generate new items, while frozen holds those that won't be used until later.",
        "complete_tree is a termination test that returns True if a tree is complete for the mode in question (i.e., if it has a full semantic interpretation for understanding, or dominates a complete string for generation).",
        "The global variable classes holds a list of equivalence classes used by eguiv_class (defined below), while level holds the number of the equivalence class currently being enumerated.",
        "Thaw&restart is called each time level is incremented to generate new agenda items for trees that may belong to that class."
      ]
    },
    {
      "heading": "ALGORITHM 1",
      "text": [
        "6A wide variety of NLP algorithms can be implemented in this manner, particularly such recent reversible generation algorithms as [Shieber, van Noord, Moore, and Pereira, 1989] and [Calder, fteape, and Zeevat, 1989].",
        "classes := Nil; solutions := Nil; new-trees := Nil; agenda := Nil; level := 1; frozen := initialize_agenda(input, mode); {end of global declarations} while frozen do begin solutions := get_completeArees (frozen, level, mode); agenda := thawStrestart (frozen, level, agenda, mode); while agenda do begin new_trees := execute_item(agenda); while newArees do begin newAree := pop(newArees); if equiv_class (P, newAree) , > level then push(new_tree, frozen); else if completeAree (newAree,mode) then push(newAree, solutions); else generate_items (newAree, active, agenda, mode); end; end; {agenda exhausted for this level} {solutions may need partitioning} while solutions do begin completeAree := pop(solutions); if equiv_class(P, completeAree) > level then push(completeAree, frozen); else output(completeAree, level) end {increment level to output next class} level := level + 1; end; The function equiv_class keeps track of the equivalence classes induced by the Preferences.",
        "Given an input tree, it returns the number of the equivalence class that the tree belongs to.",
        "Since it must construct the equivalence classes as it goes ,along, it may return different values on different calls with the same argument (for example, it will always return 1 the first time it is called, even though the tree in question may end up in a lower class.)",
        "However, successive calls to equiv_class will always return a non-decreasing series of values, so that a given tree is guaranteed to be ranked no more highly than the value returned (it is this property of equiv_class that forces the extra pass over the completed trees in the algorithm above: a tree that was assigned to class n when it was added to solutions may have been demoted to a lower class in the interim as more trees were examined).",
        "Less_than and equal take a Preference and a pair of trees and return True if the first tree is less than (equal to) the second under the Preference.",
        "Ctvate_class takes a tree and creates a new class whose only member is that tree, while insert adds a class to classes in the indicated position (shifting other classes down, if necessary), and select_member returns an arbitrary member of a class.",
        "function equiv_class (P: Preference, T: Tree) begin",
        "for class in classes do begin if lessAhan (P, T, select_member(class)) then begin insert(new_class(T), classes, class_num); return(class_num); end; else if equal (P, T, select_member(class)) then begin add_rnember(T, class); return(class_num);",
        "end; else class_num := class_num + 1; end ;",
        "IT < all classes} insert(new_class(T), classes, class_num); return(class_num); end {equiv_class} To see that the algorithm enumerates trees in the order given by <p, note that the first iteration outputs trees which are minimal under <p. Now consider any tree tn which is output on a subseqent itertion N. For all other tn, output on that iteration, tn =p toll.",
        "Furthermore, in contains a subtree taut, which was frozen for all levels up to N. Using T(J) to denote the set of trees output on iteration J, we have: V 1 < I < N [V ti E T(/) ti <p tub]], whence, by stipulation 10, tn <p i.",
        "Thus tn is greater than or equal to",
        "all trees which were enumerated before it.",
        "To calculate the time complexity of the algorithm, note that it calls equiv_class once for each tree created by the underlying understanding or generation algorithm (and once for each complete interpretation).",
        "Equiv_class, in turn, must potentially compare its argument with each existing equivalence class.",
        "Assuming that the comparison takes constant time, the ',complexity of the algorithm depends on the number k of equivalence classes <p induces: if the underlying algorithm is 0(1(n)), the overall complexity is 0(1(n)) x k. Depending on the Preference, k could be a small constant, or itself proportional to f(n), in which case the complexity would be 0(1(n)2)."
      ]
    },
    {
      "heading": "4 Optimization of Preferences",
      "text": [
        "As we make more restrictive assumptions about Preferences, more efficient algorithms become possible.",
        "Initially, we assumed only that Preferences specified total orders on trees, i.e., that would take two trees as input and determine if one was less than, greater than, or equal to the other'.",
        "Given such an unrestricted view of Preferences, we can do no better than producing all interpretations(strings) and then sorting them.",
        "This simple approach is fine if we want all possibilities, especially if we assume that there won't, be a large number of them, so that standard n2 or n log n sorting algorithms (see [Aho, Hoperoft, and Ullman, 1983]) won't be much of an additional burden.",
        "However, this approach is inefficient if we are interested in only some of the possibilities.",
        "Adding the monotonicity restriction 10 permits Algorithm 1, which is more efficient in that it postpones the creation of (successors of) lower ranked trees.",
        "However, we are still operating with a very general view of what Preferences are, and further improvements are possible when we look at individual Preferences in detail.",
        "In this section, we will consider heuristics for lexical selection, scope, and anaphor resolution.",
        "We do not make any claims for the usefullness of these heuristics as such, but take them as concrete 'examples that show the importance of considering the computational properties of Preferences.",
        "Note that Algorithm 1 is stated in terms of a single Preference.",
        "It is possible to combine multiple Preferences into a single one using Formula 9,",
        "and we are currently investigating other methods of combination.",
        "Since the algorithms below are highly specialized, they cannot be combined with other Preferences using Formula 9.",
        "The ultimate goal of this research, however, is to integrate such specialized algorithms with a more sophisticated version of Algorithm 1."
      ]
    },
    {
      "heading": "4.1 Lexical Choice",
      "text": [
        "One simple preferencing scheme involves assigning integer weights to lexical items and syntactic rules.",
        "Items or rules with higher weights are less common and are considered only if lower ranked items fail.",
        "When combined with restriction 10, this weighting scheme yields a Preference <wt that ranks trees according to their lexical and rule weights.",
        "Using max_wt(T) to denote the most heavily weighted lexical item or rule used in the construction of T, we have: it <wt t2 4-4'de j max_evt(ti) < max_wt(t2)",
        "The significant property here is that the equivalence classes under <,„‘ can be computed without directly comparing trees.",
        "Given a lexical item with weight n, we know that any tree containing it must be in class n or lower.",
        "Noting that our algorithm works by generate-and-test (trees are created and then ranked by equiv_class), we can achieve a modest improvement in efficiency by not creating trees with level n lexical items or rules until it is time to enumerate that equivalence clas.s.",
        "We can implement this change for both generation and understanding by adding level as a parameter to both initialize_agenda and gener-ate_items, and changing the functions they call to consider only rules and lexical items at or below level.",
        "How much of an improvement this yields will depend on how many classes we want to enumerate and how many lexical items and rules there are below the last class enumerated."
      ]
    },
    {
      "heading": "4.2 Scope",
      "text": [
        "Scope is another place where we can improve on the basic algorithm.",
        "We start by considering scoping during Understanding.",
        "Given a sentence s with operators (quantifiers) oi ... on, assigning a scope amounts to determining a total order on oi ons.",
        "If a scope Preference can do 8 Note that this ordering is not a Preference.",
        "A Preference will be a total ordering of trees, each of which contains such a scope ordering, i.e., a scope Preference will be an ordering of orderings of operators.",
        "no more than compare and rank pairs of scopings, then the simple generate-and-test algorithm will require 0(n!)",
        "steps to find the best scoping since it will potentially have to examine every possible ordering.",
        "However, the standard heuristics for assigning scope (e.g., give \"strong\" quantifiers wide scope, respect left-to-right order in the sentence) can be used to directly assign the preferred ordering of oi ...ON.",
        "If we assume that secondary readings are ranked by how closely they match the preferred scoping, we have a Preference <„ can be defined.",
        "In the following (0i, 01) E Sc(s) means that oi preceeds oi in scoping Sc of sentence s, and Scbe,t(s) is the preferred ordering of the operators in s given by the heuristics:",
        "Given such a Preference, we can generate the scopings of a sentence more efficiently by first producing the preferred reading (the first equivalence class), then all scopes that have one pair of operators switched (the second class), then all those with two pairs out of order, etc.",
        "In the following algorithm, ops is the set of operators in the sentence, and sort is any sorting routine.",
        "switched?",
        "is a predicate returning True if its two arguments have already been switched (i.e., if its first arg was to the right of its second in Scbe„(s)), while switch(oi, 02, ord) is a function that returns new ordering which is the same as ord except that 02 precedes 01 in it.",
        "{the best scoping}",
        "{loop will execute n!",
        " – 1 times } while old_set do begin for ordering in old_set do begin for op in ordering do begin {consider adjacent pairs of operators} next := right_neighbor(op, ordering); {switch any pair that hasn't already been} • if next and not(switched?",
        "(op, next)) then do begin new._scope := switch(op, next, ordering); additem(new.scope, new_set); output(new_scope, level) end",
        "While the Algorithm 1 would require 0(n!)",
        "steps to generate the first scoping, this algorithm will output the best scoping in the n2 or n log n steps that it takes to do the sort (cf [Aho, Hoperoft, and Ullman, 1983]), while each additional scoping is produced in constant time.",
        "The algorithm is profligate in that it generates all possible orderings of quantifiers, many of which do not correspond to legal scopings (see [Hobbs and Shieber, 1987]).",
        "It can be tightened up by adding a legality test before scope is output.",
        "When we move from Understanding to Generation, following Formula 6, we see that the task is to take an input semantics with scoping Sc and enumerate first all strings that have Sc as their best scoping, then all those with Sc as the second best scoping, etc.",
        "Equivalently, we enumerate first strings whose scopings exactly match Sc, then those that match Sc except for one pair of operators, then those matching except for two pairs, etc.",
        "We can use the Algorithm 1 to implement this efficiently if we replace each of the two conditional calls to equiv_class.",
        "Instead of first computing the equivalence class and then testing whether it is less than level, we call the following function class_less_than: {True if candidate ranked at level or below} {Target is the desired scoping}",
        "function test_order(cand, larg_rest, targ) begin if null(cand) return True; else",
        "end end return true; end {simple_test}",
        "To estimate the complexity of class_less_than, note that if no switches are encountered, test_order will make one pass through targ_rest (= targ) in 0(n) steps, where n is the length of targ.",
        "Each switch encountered results in a call to sim-ple_test, 0(n) steps, plus a call to test_arg on the full list iarg for another 0(n) steps.",
        "The overall complexity is thus 0((j +1) x n), where level = j is the number switches permitted.",
        "Note that class_less_than tests a candidate string's scoping only against the target scope, without having to inspect other possible strings or other possible scopings for the string.",
        "We therefore do not need to consider all strings that can have Sc as a scoping in order to find the most highly ranked ones that do.",
        "Furthermore, class_less_than will work on partial constituents (it doesn't require that cand have the same number of operators as targ), so unpromising paths can be pruned early."
      ]
    },
    {
      "heading": "4.3 Anaphoi.a.",
      "text": [
        "Next we consider the problem of anaphoric reference.",
        "From the standpoint of Understanding, resolving an anaphoric reference can be viewed as a matter of finding a Preference ordering of all the possible antecedents of the pronoun.",
        "Algorithm 1 would have to produce a separate interpretation for each object that had been mentioned in the discourse and then rank them all.",
        "This would clearly be extremely inefficient in any discourse more than a couple of sentences long.",
        "Instead, we will take the anaphora resolution algorithm from [Rich and Luperfoy, 1988], [Luperfoy and Rich, 1991] and show how it can be viewed as an implementation of a Complex Preference, allowing for a more efficient implementation.",
        "Under this algorithm, anaphora resolution is entrusted to Experts of three kinds: a Proposer finds likely candidate antecendents, Filters provide a quick way of rejecting many candidates, and Rankers perform more expensive tests to choose among the rest.",
        "Recency is a good example of a Proposer; antecedents are often found in the last couple of sentences, so we should start with the most recent sentences and work back.",
        "Gender is a typical Filter; given a use of \"he\", we can remove from consideration all non-male objects that the Proposers have offered.",
        "Semantic plausibility or Syntactic parallelism are Rankers; they are more expensive than the Filters and assign a rational-valued score to each candidate rather than giving a yes/no answer.",
        "When we translate these experts into our framework, we see that Proposers are Preferences that can efficiently generate their equivalence classes in rank order, rather than having to sort a preexisting set of candidates.",
        "This is where our gain in efficiency will come: we can work back through the Proposer's candidates in order, confident that any candidates we haven't seen must be ranked lower than those we have seen.",
        "Filters represent a special class of Preference that partition candidates into only two classes: those that pass and those that are rejected.",
        "Furthermore, we are interested only in candidates that all filters assign to the first class.",
        "If we simply combine n Filters into a Complex Preference using Formula 9, the result is not a Filter since it partitions the input into r classes.",
        "We therefore define a new simple Filter F(fI ...f. ) that assigns its input to class 1 if F1 ...Fn all do.",
        "Finally, Rankers are Preferences of the kind we've been discussing so far.",
        "When we observe that the effect of running a Proposer and then removing all candidates that the Filters reject is equivalent to first running the Filter and then using the Proposer to refine its first",
        "classl°, we see that the algorithm above, when run with Proposer Pr, Filters F1 ...Fn and Rankers ... R1, implements the Complex Preference defined in accordance with Formula 9.",
        "We thus have the following algorithm, where next_class takes a Proposer and a pronoun as input and returns its next equivalence class of candidate antecedents for the pronoun."
      ]
    },
    {
      "heading": "Moving to Generation, we use this Preference",
      "text": [
        "1° In both cases, the result is: p1 n h , • • • Pn, nh , where pi ... pn are the equivalence classes induced by the Proposer, and h is the Filter's first equivalence class.",
        "to decide when to use a pronoun.",
        "Following Formula 6, we want to use a pronoun to refer to object x at level n if that pronoun would be interpreted as referring to z in class n during Understanding.",
        "First we need a test occurs?",
        "(Proposer, z) that will return True if Proposer will eventually output r in some equivalence class.",
        "For example, a Recency Proposer will never suggest a candidate that hasn't occurred in the antecedent discourse, so there is no point in considering a pronoun to refer to such an object.",
        "Next, we note that the candidates that the Proposer returns are really pairs consisting of a pronoun and an antecedent, and that Filters work by comparing the features of the pronoun (gender, number, etc.)",
        "with those of the antecedent.",
        "We can implement Filters to work by unifying the (syntactic) features of the pronoun with the (syntactic and semantic) features of the antecedent, returning either a more fully-specified set of features for the pronoun, or I if unification fails.",
        "We can now take a syntactically underspecified pronoun and x and use the Filter to choose the appropriate set of features.",
        "We are now assured that the Proposer will suggest x at some point, and that x will pass all the filters.",
        "Having established that x is a reasonable candidate for pronominal reference, we need to determine what class x will be assigned to as an antecedent.",
        "Rankers such as Syntactic Parallelism must look at the full syntactic structurell , so we must generate complete sentences before doing the final ranking.",
        "Given a sentence s contaning pronoun p with antecedent x, we can determine the equivalence class of (p, x) by running the Proposer until it (p, x) appears, then running the Filters on all other candidates, and passing all the survivors and (p, x) to refine&outpui, and then seeing what class (p, x) is returned in.",
        "Alternatively, if we only want to check whether (p, x) is in a certain class n or not, we can run the resolution algorithm given above until n classes have been enumerated, quitting if (p, x) is not in it.",
        "(See the next section for a discussion of this algorithm's obvious weaknesses.)",
        "11 The definitions we've given so far do not specify how Preferences should rank \"unfinished\" structures, i.e., those that don't contain all the information the Preference requires.",
        "One obvious solution is to assign incomplete structures to the first equivalence class; as the structures become complete, they can be moved down into lower classes if necessary.",
        "Under such a strategy, Preferences such as Syntactic Parallelism will return high scores on the incomplete constituents, but these scores will be meaningless, since many of the resulting complete structures will be placed into lower classes."
      ]
    },
    {
      "heading": "5 Discussion",
      "text": [
        "Related Work: There is an enormous amount of work on preferences for understanding, e.g., [Whittemore, Ferrara, and Brunner, 1990], [Jensen and Binot, 1988], [Grosz, Appelt, Martin, and Pereira, 1987] for a few recent examples.",
        "In work on generation preferences (in the sense of rankings of structures) are less clearly identifiable since such rankings tend to be contained implicitly in strategies for the larger problem of deciding what to say (but see [Mann and Moore, 1981] and [Reiter, 1990].)",
        "Algorithm 1 is similar in spirit to the \"all possibilities plus constraints\" strategy that is common in principle-based approaches (see [Epstein, 1988]),, but it differs from them in that it imposes a preference ordering on interpretations, rather than restricting the set of legal interpretations to begin with.",
        "Strzalkowski [Strzalkowski, 1990] contrasts two strategies for reversibility: those with a single grammar and two intepreters versus those with a single interpreter and two grammars.",
        "Although the top-level algorithm presented here works for both understanding and generation, the underlying generation and understanding algorithms can belong to either of Strzalkowski's categories.",
        "However, the more specific algorithms discussed in Section 4 belong to the former category.",
        "There is also a clear \"directionality\" in both the scope and the anaphora Preferences; both are basically understanding heuristics that have been reformulated to work Iii-directionally.",
        "For this reason, they are both considerably weaker as generation heuristics.",
        "In particular, the anaphora Preference is clearly insufficient as a method of choosing when to use a pronoun.",
        "At best, it can serve to validate the choices made by a more substantial planning component.",
        "The Two Directions: In general, it is not clear what the relatiOn between understanding and generation heuristics should be.",
        "Formulae 4 and 5 are reasonable requirements, but they are too weak to provide the close linkage between understanding and generation that we would like to have in a bidirectional system.",
        "On the other hand, Formula 6 is probably too strong since it requires the equivalence classes to be the same across the board.",
        "In particular, it entails the converse of Formula, 4, and this has counter-intuitive results.",
        "For example, consider any highly convoluted, but grammatical, sentence: it has a best interpretation, and by Formula 6 it is therefore one of the best ways of expressing that meaning.",
        "But if it is sufficently opaque, it is not a good way of saying anything.",
        "Similarly, a speaker may suddenly use a pronoun to refer to an object in a distant part of the discourse.",
        "If the anaphora Preference is sophisticated enough, it may resolve the pronoun correctly, but we would not want the generation system to conclude that it should use a pronoun in that situation.",
        "One way to tackle this problem is to observe that understanding systems tend to be too loose (they accept a lot of things that you don't want to generate), while generation systems are too strict (they cover only a subset of the language.)",
        "We can therefore view generation Preferences as restrictions of understanding Preferences.",
        "On this view, one may construct a generation Preference from one for understanding by adding extra clauses, with the result that its ordering is a refinement of that induced by the understanding Preference.",
        "Internal Structure: Further research is necessary into the internal structure of Preferences.",
        "We chose a very general definition of Preferences to start with, and found that further restrictions allowed for improvements in efficiency.",
        "Preferences that partition input into a fixed set of equivalence classes that can be determined in advance (e.g., the Preference for lexical choice discussed in Section 4) are particularly desireable since they allow structures to be categorized in isolation, without comparing them to other alternatives.",
        "Other Preferences, such as the scope heuristic, allow us to create the desired structures directly, again without need for comparison with other trees.",
        "On the other hand, the anaphora Preference is based on an algorithm that assigns rational-valued scores to candidate antecedents.",
        "Thus there can be arbitrarily many equivalence classes, and we can't determine which one a given candidate belongs to without looking at all higher-ranked candidates.",
        "This is not a problem during understanding, since the Proposer can provide those candidates efficiently, but the algorithm for generation is quite awkward, amounting to little more than \"make a guess, then run understanding and see what happens.\" The focus of our future research will be a formal analysis of various Preferences to determine the characteristic properties of good understanding and generation heuristics and to investigate methods other than Formula 9 of combining multiple Preferences.",
        "Given such an analysis, Algorithm 1 will be modified to handle multiple Preferences and to treat the different types of Preferences differently, thus reducing the need for",
        "the kind of heuristic-specific algorithms seen in Section 4.",
        "We also plan an implementation of these Preferences as part of the KBNL system [Barnett, Mani, Knight, and Rich, 1990]."
      ]
    }
  ]
}
