{
  "info": {
    "authors": [
      "Alessandro Moschitti"
    ],
    "book": "COLING – Tutorial Notes",
    "id": "acl-C10-5001",
    "title": "Kernel Engineering for Fast and Easy Design of Natural Language Applications",
    "url": "https://aclweb.org/anthology/C10-5001",
    "year": 2010
  },
  "references": [
    "acl-D07-1076",
    "acl-H05-1018",
    "acl-H05-1091",
    "acl-I08-2119",
    "acl-P02-1034",
    "acl-P03-1004",
    "acl-P05-1024",
    "acl-P06-1104",
    "acl-W03-1012",
    "acl-W04-2403",
    "acl-W04-3222",
    "acl-W05-0601"
  ],
  "sections": [
    {
      "heading": null,
      "text": []
    },
    {
      "heading": "Alessandro Moschitti",
      "text": [
        "The 23rd International Conference on Computational Linguistics August 22, 2010 Beijing, China"
      ]
    },
    {
      "heading": "Schedule",
      "text": [
        "Coling 2008: Kernel Engineering for Fast and Easy Design of Natural Language Applications-Tutorial notes, pages 1-91,",
        "■ Motivation",
        "■ Kernel-Based Machines",
        "■ Perceptron",
        "■ Support Vector Machines",
        "■ Kernel Definition",
        "■ Kernel Trick",
        "■ Mercer's conditions",
        "■ Kernel operators",
        "■ Basic Kernels",
        "■ Linear Kernel",
        "■ Polynomial Kernel",
        "■ Lexical Kernel",
        "Outline (2)",
        "■ Structural Kernels",
        "■ String and Word Sequence Kernels",
        "■ Tree Kernels",
        "• Subtree, Syntactic, Partial Tree Kernels",
        "■ Applied Examples of Structural Kernels",
        "■ Semantic Role Labeling (SRL)",
        "■ Question Classification (QC)",
        "■ SVM-Light-TK",
        "■ Experiments in classroom with SRL and QC",
        "■ Inspection of the input, output, and model files"
      ]
    },
    {
      "heading": "Motivation (1)",
      "text": [
        "■ Feature design most difficult aspect in designing a learning system",
        "■ complex and difficult phase, e.g., structural feature representation:",
        "■ deep knowledge and intuitions are required",
        "■ design problems when the phenomenon is described by many features",
        "Outline (3)",
        "■ Kernel Engineering",
        "■ Structure Transformation",
        "■ Syntactic Semantic Tree kernels",
        "■ Kernel Combinations",
        "■ Kernels on Object Pairs",
        "■ Kernels for re-ranking",
        "■ Practical Question and Answer Classifier based on SVM-Light-TK ■ Combining Kernels",
        "■ Conclusion and Future Work"
      ]
    },
    {
      "heading": "Motivation (2)",
      "text": [
        "■ Kernel methods alleviate such problems",
        "■ Structures represented in terms of substructures",
        "■ High dimensional feature spaces",
        "■ Implicit and abstract feature spaces",
        "■ Generate high number of features",
        "■ Support Vector Machines \"select\" the relevant features",
        "■ Automatic Feature engineering side-effect"
      ]
    },
    {
      "heading": "Part I: Kernel Methods Theory",
      "text": []
    },
    {
      "heading": "A simple classification problem: Text Categorization _",
      "text": []
    },
    {
      "heading": "Text Classification Problem",
      "text": [
        "■ Features are dimensions of a Vector Space.",
        "■ Documents and Categories are vectors of feature weights.",
        "■ d is assigned to C if d • Cl > th",
        "Berlusconi acquires Inzaghi before elections",
        "1"
      ]
    },
    {
      "heading": "More in detail",
      "text": [
        "■ In Text Categorization documents are word vectors",
        "■ The dot product x-z counts the number of features in common",
        "This provides a sort of similarity"
      ]
    },
    {
      "heading": "Linear Classifier",
      "text": [
        "The equation of a hyperplane is",
        "f(x) = x-w + b = 0, x,wŒmn,bŒm x is the vector representing the classifying example w is the gradient of the hyperplane",
        "The classification function is"
      ]
    },
    {
      "heading": "The main idea of Kernel Functions",
      "text": [
        "■ Mapping vectors in a space where they are linearly separable x – > 0(x)"
      ]
    },
    {
      "heading": "A mapping example",
      "text": []
    },
    {
      "heading": "Given two masses m } and m 2 , one is constrained",
      "text": []
    },
    {
      "heading": "Apply a force f a to the mass w 7",
      "text": []
    },
    {
      "heading": "Experiments",
      "text": [
        "We want to learn a classifier that tells when a mass w7 will get far away from m2"
      ]
    },
    {
      "heading": "If we consider the Gravitational Newton Law",
      "text": []
    },
    {
      "heading": "A mapping example (2)",
      "text": [
        "■ The gravitational law is not linear so we need to change space (fomum2,r) -> (k,x,y, z) = (ln/a,ln muln w2,lnr)",
        "A kernel-based Machine Perceptron training",
        "w0 < – 0;b0 < – 0;k < – 0;R < – maxls;sl II x;.",
        "II",
        "do",
        "for i = 1 to £",
        "if y.",
        "(wk ■ xt + bk)<0 then",
        "= h + WiR",
        "k = k + l",
        "endif",
        "endfor",
        "while an error is found",
        "return k,(wk,bk)"
      ]
    },
    {
      "heading": "Novikoff's Theorem",
      "text": []
    },
    {
      "heading": "Let S be a non-trivial training-set and let",
      "text": [
        "R = max 11 xt \\\\.",
        "with y > 0.",
        "Then the maximum number of errors of the perceptron",
        "X2",
        "*",
        "*",
        "* t= 1",
        "* .'",
        "* 0 t = -1",
        "f",
        "!",
        "/ /",
        "; / //°o o",
        "/",
        "t",
        "X1",
        "0",
        "0"
      ]
    },
    {
      "heading": "Dual Representation for Classification",
      "text": [
        "■ In each step of perceptron only training data is added with a certain weight",
        "■ Note that data only appears in the scalar product"
      ]
    },
    {
      "heading": "Dual Representation for Learning",
      "text": [
        "■ as well as the updating function",
        "■ The learning rate n only affects the rescaling of the hyperplane, it does not affect the algorithm, so we can fix »7 = 1.",
        "■ So the classification function"
      ]
    },
    {
      "heading": "Dual Perceptron algorithm and Kernel functions",
      "text": []
    },
    {
      "heading": "■ We can rewrite the classification function as",
      "text": []
    },
    {
      "heading": "As well as the updating function",
      "text": [
        "Support Vector Machines",
        "■ Hard-margin SVMs",
        "m Soft-margin SVMs",
        "Which hyperplane do we choose?",
        "\\ \\ • K \\ \\ • o",
        "\\\\ \\ ° \\ \\ V",
        "° ° \\ \\ \\",
        "o o ° \\ \\ \\",
        "o \\ *♦.",
        "\\",
        "° *• \\ \\",
        "^^^^",
        "Classifier with a Maximum Margin",
        "Varj",
        "\\v .",
        "i IDEM: Select the",
        "\\ \\ hyperplane with",
        "''*••.._ \\ \\ maximum margin",
        "o o A X'\"'' Marg'n",
        "Margin"
      ]
    },
    {
      "heading": "Support Vectors",
      "text": [
        "Support Vector Machines",
        "Varj",
        "\\ \\k\\",
        "» \\ \\ The margin is equal to -jpj",
        "\\ V« • •",
        "\\ \\ * *",
        "_» ...V.......\\ \\ w • x + b = k",
        "............ \\ \\ \\",
        "w-x + b = k Jç \\ k Var2",
        "w ■ x + b = 0",
        "Support Vector Machines",
        "Var,",
        "\\ Y • •",
        "\\ * \\ ° °",
        "2|£|",
        "The margin is equal to -jpy We need to solve",
        "2\\k\\",
        "max",
        "II w II",
        "_» .....V.......\\ \\ w ■ x + b = k",
        "M WW",
        "w- x + b> +k, if x is positive",
        "w • x + b < -k, if x is negative",
        "w • x + 6 = -£ ^ \\ k Var2",
        "w • x + b = 0",
        "Support Vector Machines",
        "Var,",
        "\\ V« • •",
        "\\ * \\ ° °",
        "° ° I \" \\",
        "There is a scale for which k=1.",
        "The problem transforms in:",
        "2",
        "_» .....V.......\\ \\ w • x + 6 = 1",
        "II w II",
        "w-x + b>+\\, if xis positive w-x + è<-l, if xis negative",
        "w-x + b = -\\ ^*^\\ I Var2",
        "w ■ x + b = 0",
        "Ulli"
      ]
    },
    {
      "heading": "Final Formulation",
      "text": []
    },
    {
      "heading": "Il w II",
      "text": []
    },
    {
      "heading": "II w II 2",
      "text": []
    },
    {
      "heading": "Optimization Problem",
      "text": [
        "Optimal Hyperplane:",
        "The dual problem is simpler"
      ]
    },
    {
      "heading": "Lagrangian Definition",
      "text": [
        "Def.",
        "2.24 Let f(w), hi(w) and gi(w) be the objective function, the equality constraints and the inequality constraints (i.e. >) of an optimization problem and let L(w, a, fi) be its Lagrangian, defined as follows:"
      ]
    },
    {
      "heading": "Dual Optimization Problem",
      "text": [
        "The Lagrangian dual problem of the above primed problem is maximize 6(a,ß)"
      ]
    },
    {
      "heading": "Dual Transformation",
      "text": [
        "■ Given the Lagrangian associated with our problem",
        "■ To solve the dual problem we need to evaluate:",
        "6(a,ß) = infweW L(w,a,ß) m Let us impose the derivatives to 0, with respect to w"
      ]
    },
    {
      "heading": "Dual Transformation (cont'd)",
      "text": [
        "and wrt b■ Then we substituted them in the obiective function"
      ]
    },
    {
      "heading": "Khun-Tucker Theorem",
      "text": [
        "■ Necessary and sufficient conditions to optimality",
        "The Final Dual Optimization Problem",
        "m j m",
        "maximize a?",
        " – - yiVjOtiOtjXi • Xj i=l ij=l",
        "subject to at > 0. i = 1,... m",
        "m",
        "i=l"
      ]
    },
    {
      "heading": "Soft Margin SVMs",
      "text": [
        "Properties coming from constraints",
        "■ Lagrange constraints: ^aiyi = 0, w = ^aiyixi",
        "m Karush-Kuhn-Tucker constraints",
        "ai '!>/(*/-w + b)-l] = 0, i = l,...,l",
        "m Support Vectors have at not null",
        "■ To evaluate b, we can apply the following equation",
        "_ <r- ■ x+ + w* ■ x-2",
        "^^^^",
        "Soft Margin SVMs",
        "Var,",
        "\\ \\",
        "X,, •",
        "Vi • •",
        "The new constraints are",
        "j;.",
        "(vv-x;.+ è)>l-|;Vx;.",
        "where > 0",
        "' ' \\ i i \\",
        "i",
        "W ................\\",
        "\\ V''",
        "......\\ \\ w ■ x + b = 1",
        "The objective function penalizes the incorrect classified examples",
        "min|llwll+c2.i;",
        "C is the trade-off between margin and tha^ error",
        "w-x + b = -1",
        "J \\ 1 Var2",
        "w ■ x + b = 0",
        "^^^^",
        "Dual formulation",
        "( min ±\\\\w\\\\ +CY,T=i^f } yi(w-Xi + b) > 1 Vi [ & > 0, i = 1, ..,m",
        "= 1, ..,m",
        "1 C mL(üJ, £ a) = w ■ w + – ^2 S ~",
        "m",
        "-^2ai[Vi(w -Xi + b) - 1 +",
        "i=l",
        "■ By deriving wrt w, £ and b",
        "OST!"
      ]
    },
    {
      "heading": "Partial Derivatives",
      "text": []
    },
    {
      "heading": "Substitution in the objective function",
      "text": []
    },
    {
      "heading": "2 S yiVjOiiOLjXi • Xj - – a ■ a =",
      "text": [
        "ô„ of Kronecker"
      ]
    },
    {
      "heading": "Final dual optimization problem",
      "text": []
    },
    {
      "heading": "Soft Margin Support Vector Machines",
      "text": []
    },
    {
      "heading": "The algorithm tries to keep ^ low and maximize the margin",
      "text": [
        "NB: The number of error is not directly minimized (NP-complete problem); the distances from the hyperplane are minimized If C – ><*>, the solution tends to the one of the hard-margin algorithm Attention !!!",
        ": if C = 0 we get 11^11=0, since V, b > 1 - Vx ■ If C increases the number of error decreases.",
        "When C tends to infinite the number of errors must be 0, i.e. the hard-margin formulation"
      ]
    },
    {
      "heading": "Kernels in Support Vector Machines",
      "text": [
        "■ In Soft Margin SVMs we maximize:",
        "■ By using kernel functions we rewrite the problem as:",
        "Robusteness of Soft vs. Hard Margin SVMs",
        "Varj",
        "• •",
        "•",
        "•",
        "Var2",
        "w ■ x + b = 0",
        "w ■ X",
        "Var2",
        "+ 0 = 0",
        "Soft Margin SVM",
        "Hard Margin SVM",
        "^^^^"
      ]
    },
    {
      "heading": "Kernel Function Definition",
      "text": [
        "Def.",
        "2.26 A kernel is a function k, such that^J x,z 6 X",
        "k{x,z) – 4>(x) ■ 4>(z) where (p is a mapping from X to an (inner product) feature space.",
        "m Kernels are the product of mapping functions such as"
      ]
    },
    {
      "heading": "The Kernel Gram Matrix",
      "text": [
        "With KM-based learning, the sole information used from the training data set is the Kernel Gram Matrix"
      ]
    },
    {
      "heading": "training",
      "text": [
        "If the kernel is valid, K is symmetric definite-positive"
      ]
    },
    {
      "heading": "Valid Kernels",
      "text": []
    },
    {
      "heading": "Def. B.ll Eigen Values",
      "text": [
        "Given a matrix A G R'\" x R\", an egei)ivalue A and an egeinvector x G R\" - {0} are such that"
      ]
    },
    {
      "heading": "Def. B.12 Symmetric Matrix",
      "text": [
        "A square matrix A G R\" xR\" is symmetric iffA,j = Aß for i ^ j i = 1,... m and j = 1.... n, i.e. iff A = A'."
      ]
    },
    {
      "heading": "Def. B.13 Positive (Semi-) definite Matrix",
      "text": [
        "A square matrix A G R\" x R\" is said to be positive (semi-) definite if its eigenvalues are all positive (non-negative)."
      ]
    },
    {
      "heading": "Valid Kernels cont'd",
      "text": [
        "Proposition 2.27 (Mercer's conditions)",
        "Let X be a finite input space with K(x.z) a symmetric function on X.",
        "Then K(x, z) is a kernel function if and only if the matrix is positive semi-definite (has non-negative eigenvalues).",
        "m If the matrix is positive semi-definite then we can find a mapping (j> implementing the kernel function"
      ]
    },
    {
      "heading": "Mercer's Theorem (finite space)",
      "text": [
        "m K symmetric => 3 V: K = VAV for Takagi factorization of a complex-symmetric matrix, where:"
      ]
    },
    {
      "heading": "■ a is the diagonal matrix of the eigenvalues X t of k",
      "text": [
        "■ Let us assume lambda values non-negative"
      ]
    },
    {
      "heading": "Mercer's Theorem",
      "text": []
    },
    {
      "heading": "(sufficient conditions) _",
      "text": [
        "■ Therefore"
      ]
    },
    {
      "heading": "m which implies that K is a kernel function",
      "text": []
    },
    {
      "heading": "Is it a valid kernel?",
      "text": [
        "■ It may not be a kernel so we can use M -M",
        "Proposition B.14 Let A be a symmetric matrix.",
        "Then A is positive (semi-) definite iff for any vector x ^ 0",
        "x'Ax > 0 (> 0).",
        "From the previous proposition it follows that: If we find a decomposition A in M'M, then A is semi-definite positive matrix as",
        "x'Ax = x'M'Mx = {Mx)'(Mx) = Mx-Mx = \\ \\Mx\\\\ > 0.",
        "Mercer's Theorem (necessary conditions)",
        "■ Suppose we have negative eigenvalues As and eigenvectors vs the following point",
        "i= 1 i= 1",
        "■ has the following norm:",
        "p|| = ï ■ ï = VÄv'vsVXv'vs = v; vVÄVÄv'vs =",
        "v;^vs= v;^,v, = ^||vj|<0",
        "this contradicts the geometry of the space.",
        "^^^^",
        "■ Linear Kernel",
        "■ Polynomial Kernel"
      ]
    },
    {
      "heading": "Basic Kernels for unstructured data",
      "text": [
        "■ Lexical kernel",
        "■ String Kernel",
        "Valid Kernel operations",
        "■ k(x,z) = kA{x,z)+k2{x,z)",
        "m k(x,z) = k^(x,z)*k2(x,z)",
        "m k(x,z) = a k-i(x,z)",
        ".",
        "k(x,z) = f(x)f(z)",
        ".",
        "k(x,z) = krfrtxMz))",
        "m k(x,z) = x'Bz",
        "■ In Text Categorization documents are word vectors",
        "■ The dot product x-z counts the number of features in common",
        "This provides a sort of similarity"
      ]
    },
    {
      "heading": "Linear Kernel",
      "text": []
    },
    {
      "heading": "Feature Conjunction (polynomial Kernel)",
      "text": [
        "■ The initial vectors are mapped in a higher space",
        "■ More expressive, as (X*2) encodes",
        "Stock+Market VS. Downtown+Market features■ We can smartly compute the scalar product as"
      ]
    },
    {
      "heading": "Lexical Semantic Kernel [CoNLL 2005]",
      "text": [
        "■ The document similarity is the SK function:",
        "■ where s is any similarity function between words, e.g. WordNet [Basili et al.,2005] similarity or LSA [Cristianini et al., 2002]",
        "■ Good results when training data is small",
        "Document Similarity",
        "Doc 1",
        "Doc 2",
        "telephone ><C ~~--- – ",
        ". – ",
        "p o",
        "market"
      ]
    },
    {
      "heading": "Using character sequences",
      "text": [
        "x • z counts the number of common substrings"
      ]
    },
    {
      "heading": "String Kernel",
      "text": [
        "■ Given two strings, the number of matches between their substrings is evaluated",
        "■ B, a, n, k, Ba, Ban, Bank, Bk, an, ank, nk,..",
        "■ R, a , n , k, Ra, Ran, Rank, Rk, an, ank, nk,..",
        "■ String kernel over sentences and texts",
        "■ Huge space but there are efficient algorithms"
      ]
    },
    {
      "heading": "Formal Definition",
      "text": []
    },
    {
      "heading": "Kernel between Bank and Rank",
      "text": [
        "B. a. n. k. Ba.",
        "Ban.",
        "Bank.",
        "an.",
        "ank.",
        "nk.",
        "Bn.",
        "Bnk.",
        "Bk and ak are the substrings of Bank.",
        "R. a. n. k. Ra.",
        "Ran.",
        "Rank.",
        "an.",
        "ank.",
        "nk.",
        "Rn.",
        "Rnk.",
        "Rk and ak are the substrings of Rank."
      ]
    },
    {
      "heading": "An example of string kernel computation _",
      "text": [
        "Efficient Evaluation",
        "■ Dynamic Programming technique",
        "■ Evaluate the spectrum string kernels",
        "■ Substrings of size p",
        "m Sum the contribution of the different spectra",
        "■ Store this in the table",
        "Efficient Evaluation",
        "Given two sequences s ige and we define:",
        "I'll 1*21",
        "DP(\\81\\, M) = EE XM-i+M~r x SKP-",
        "i – l r=l",
        "i(si[l:i],s2[l:r]),",
        "si[l : i] and S2[l : r] are their subsequences from 1 to i and 1 to r.",
        "( A x Dp(|si|, |s2SKp{s\\a, S2&) = <",
        ") if a – b; otherwise.",
        "Dp satisfies the recursive relation:",
        "JDp(fc,0 = ^-i(si[l:A;],S2[l:;])H",
        "- XDp(k,l- 1) +",
        "+AJDp(/e- 1,0 - XDp(k",
        "-1,2-1)",
        "g",
        "a",
        "t",
        "t",
        "a",
        "c",
        "Ü",
        "0",
        "0",
        "0",
        "0",
        "a",
        "0",
        "X",
        "0",
        "0",
        "A",
        "t",
        "0",
        "0",
        "A",
        "A",
        "0",
        "a",
        "0",
        "A",
        "0",
        "0",
        "A"
      ]
    },
    {
      "heading": "Evaluating DP2",
      "text": [
        "■ Evaluate the weight of the string of size p in case a character will be matched",
        "■ This is done by multiplying the double summation by the number of substrings of size p-1",
        "Evaluating the Predictive DP on strings of size 2 (second row)_",
        "Let's consider substrings of size 2 and suppose that:",
        "■ we have matched the first \"a\"",
        "■ we will match the next character that we will add to the two strings We compute the weights of matches above at different string positions with some not-yet known character \"?\"",
        "If the match occurs immediately after \"a\" the weight will be A,1+1x = A and we store just A in the DP entry in [\"a\",\"a\"]",
        "DP2",
        "g a",
        "t",
        "t",
        "c",
        "0 0 0 0",
        "a",
        "0 X",
        "X",
        "X",
        "t",
        "0 Xs",
        "X + X",
        "Ab + A + A\""
      ]
    },
    {
      "heading": "Evaluating the DP wrt different positions (second row) _",
      "text": [
        "■ If the match for \"gatta\" occurs after \"t\" the weight will be XU2(x A = A) since the substring for it will be with \"aD?\"",
        "■ We write such prediction in the entry [\"a\",\"t\"]",
        "■ Same rationale for a match after the second \"t\": we have the substring \"aDD?\"",
        "(matching with \"a?\"",
        "from \"catta\") for a weight of À3+1 (x A)"
      ]
    },
    {
      "heading": "Evaluating the DP wrt different positions (third row) _",
      "text": [
        "If the match occurs after \"t\" of \"cata\", the weight will be A2+* (x A = A) since it will be with the string \"aD?",
        "\", with a weight of A",
        "If the match occurs after T of both \"gatta\" and \"cata\", there are two ways to compose substring of size two: \"aD?\"",
        "with",
        "DP2",
        "g",
        "a",
        "t",
        "t",
        "c",
        "0 0 I) 0",
        "a",
        "0",
        "A",
        "A",
        "A",
        "t",
        "0",
        "A",
        "A + A",
        "* Ab + A + A",
        "DP2",
        "g a",
        "t",
        "t",
        "c",
        "0 0",
        "0",
        "0",
        "a",
        "0 A\"",
        "A",
        "A",
        "t",
        "0 A",
        "A + A",
        "A* + Aa + \\z"
      ]
    },
    {
      "heading": "Evaluating the DP wrt different positions (third row) _",
      "text": [
        "The final case is a match after the last \"t\" of both \"cat\" and \"gatta\"",
        "There are three possible substrings of \"gatta\":",
        "■ \"aD □?",
        "\", \"tD?",
        "\", \"t?\"",
        "for \"gatta\" with weight A , A or A, respectively.",
        "There are two possible substrings of \"cata\" \"aD?",
        "\", \"t?\"",
        "with weight A and A"
      ]
    },
    {
      "heading": "Evaluating SK of size 2 using DP2",
      "text": [
        "XxDp{\\Sll\\s2\\)iîa = b; 0 otherwise.",
        "The number (weight) of substrings of size 2 between \"gat\" and \"cat\" isA=A([\"a'V'a\"] entry of DP) x X(cost of one character), where a = Tand b = T. Between \"gatta\" and \"cata\" is À7+ A + k, i.e the matches of \"aDDa\", \"tDa\", \"ta\" with \"aDa\" and \"ta\".",
        "DP,",
        "g a",
        "t",
        "t",
        "c",
        "o o o o",
        "a",
        "() A",
        "X",
        "A",
        "t",
        "() Xs",
        "A + \\",
        "AbH",
        "1)1'-",
        "gat t",
        "c",
        "0 0 0 0",
        "a",
        "0 A Aa A",
        "t",
        "0 Xs A + A\" A\" • A' • A\"",
        "SKp=2",
        "gat t a",
        "c",
        "0 0 0 0 0",
        "a",
        "0 0 0 0 0",
        "t",
        "0 0 A A 0",
        "a",
        "0 0 0 0 Ä + Aö + A"
      ]
    },
    {
      "heading": "Tree kernels",
      "text": [
        "■ Subtree, Subset Tree, Partial Tree kernels",
        "■ Efficient computation"
      ]
    },
    {
      "heading": "Example of a parse tree",
      "text": [
        "\"John delivers a talk in Rome\"",
        "VP^ VNPPP"
      ]
    },
    {
      "heading": "The Syntactic Tree Kernel (STK)",
      "text": []
    },
    {
      "heading": "The overall fragment set",
      "text": [
        "II I I V NP D N",
        "III I delivers delivers D N"
      ]
    },
    {
      "heading": "The overall fragment set",
      "text": []
    },
    {
      "heading": "Children are not divided",
      "text": [
        "delivers delivers D"
      ]
    },
    {
      "heading": "Explicit kernel space",
      "text": [
        "delivers Ç) N a talk delivers",
        "x - z counts the number of common substructures",
        ".VP",
        "1",
        "VP / 1",
        "VP / 1",
        "1",
        "NP",
        "/ 1",
        "V NP",
        "/ 1",
        "V NP",
        "1",
        "/ \\",
        "/ \\",
        "N",
        "D 1ST",
        "D 1ST 1 1",
        "1",
        "talk",
        "1 1",
        "a talk"
      ]
    },
    {
      "heading": "Efficient evaluation of the scalar product",
      "text": [
        "[Collins and Duffy, ACL 2002] evaluate A in 0(n): A(nx,nz) = 0, if the productions are different else",
        "pre - terminals else"
      ]
    },
    {
      "heading": "Other Adjustments",
      "text": [
        "■ Decay factor",
        "■ Normalization"
      ]
    },
    {
      "heading": "SubTree (ST) Kernel [Vishwanathan and Smola, 2002]",
      "text": []
    },
    {
      "heading": "Evaluation",
      "text": [
        "■ Given the equation for the SST kernel",
        "A(nx,nz) = 0, if the productions are different else A(nx,nz) = 1, if pre - terminals else"
      ]
    },
    {
      "heading": "Fast Evaluation of STK [Moscnitti, eacl 2006]",
      "text": [
        "(nx,nz)ENP",
        "where P(nx) and P(nz) are the production rules used at nodes nx and nz",
        "function Evah.iate_Pair_Set(Tree Ts, T_) returns node_pair_set; LIST Ii,L2; NODE_PA.IR._SET Np; begin"
      ]
    },
    {
      "heading": "ii = Ts .orderedTist;",
      "text": []
    },
    {
      "heading": "while (prodnctiotl_of(rii ) == production_of(n2))",
      "text": [
        "n 2=get_next_elem(T'2 ); /*get the head element and move the pointer to the next element*/ end"
      ]
    },
    {
      "heading": "reset(T_); /*set the pointer at the first element*/ end",
      "text": []
    },
    {
      "heading": "return N v ; end",
      "text": []
    },
    {
      "heading": "Observations",
      "text": [
        "■ We order the production rules used in Tx and Tz, at loading time",
        "■ At learning time we may evaluate NP in",
        "ITx\\ +1 Tz I running time rule=>0(|_TJx|7;| ).■ If Tx and Tz are generated by only one production",
        "..",
        "■ If Tx and Tz are generated by only one production rule => 0(|T;|x|7; I )...",
        "Very Unlikely!!!",
        "!"
      ]
    },
    {
      "heading": "a talk",
      "text": []
    },
    {
      "heading": "Labeled Ordered Tree Kernel",
      "text": [
        "■ SST satisfies the constraint \"remove 0 or all children at a time\".",
        "■ If we relax such constraint we get more general substructures [Kashima and Koyanagi, 2002]"
      ]
    },
    {
      "heading": "gives",
      "text": []
    },
    {
      "heading": "DNDNDNDD N •",
      "text": []
    },
    {
      "heading": "Weighting Problems",
      "text": [
        "Both matched pairs give the same contribution.",
        "Gap based weighting is needed.",
        "A novel efficient evaluation has to be defined",
        "VP",
        "' 1",
        "VP y 1",
        "1",
        "NP / l\\",
        "V 1",
        "1",
        "NP / lN",
        "/ 1 \\ D JJ N 1 1 1",
        "gives",
        "/ 1 D JJ 1 1",
        "\\ N 1",
        "1 1 1 a good talk",
        "1 1 a bad",
        "1",
        "talk"
      ]
    },
    {
      "heading": "Partial Tree Kernel",
      "text": [
        "- if the node labels of rt\\ and n<i are different then A(m,n2) = 0;",
        "■ By adding two decay factors we obtain:",
        "Partial Trees, [Moschitti, EC ML 2006]",
        "■ SST + String Kernel with weighted gaps on Nodes' children",
        "VP VP VP VP VP VP VP VP",
        "y i y i i i i i i i",
        "/I /I 1 1 1 1 1",
        "V NP ._k V NP NP NP NPNPNPNP",
        "1 / \\ ■=> / \\ / \\ 1 \\ 1 1 \\ brought DN DNDNDNDD N • • • II 1 1 1 1 1 1 NP NP NP a cat a cat a cat a a / \\ \\ /",
        "D N N D",
        "^^^^"
      ]
    },
    {
      "heading": "Efficient Evaluation (1)",
      "text": [
        "In [Taylor and Cristianini, 2004 book], sequence kernels with weighted gaps are factorized with respect to different subsequence sizes.",
        "We treat children as sequences and apply the same theory",
        "Given the two child sequences S\\a = cni and S2b = cn2(a and b are the last children), Ap(sia, 82b) – -q"
      ]
    },
    {
      "heading": "Efficient Evaluation (2)",
      "text": [
        "[ 0 otherwise."
      ]
    },
    {
      "heading": "Note that Dp satisfies the recursive relation:",
      "text": [
        "Dp(k,l) = A/( ,(.s,;i : k],s2[l : l\\) + \\Dp(k,l - 1) +AL»P(A: - 1, Z) + AL»P(A; - 1,1 - 1).",
        "■ The complexity of finding the subsequences is 0(p\\si\\\\s2\\)"
      ]
    },
    {
      "heading": "m Therefore the overall complexity is 0(pp 2 \\N Tl \\\\N T2 \\)",
      "text": [
        "where p is the maximum branching factor (p = p)"
      ]
    },
    {
      "heading": "SVM-Iight-TK Software",
      "text": [
        "■ Encodes ST, SST and combination kernels in SVM-Iight [Joachims, 1999]",
        "■ Available at http://dit.unitn.it/~moschitt/",
        "■ Tree forests, vector sets",
        "■ The new SVM-Light-TK toolkit will be released asap"
      ]
    },
    {
      "heading": "Data Format",
      "text": []
    },
    {
      "heading": ". \"What does Html stand for?\"",
      "text": [
        "Basic Commands",
        "■ Training and classification",
        "■ ./svmjearn t 5 C T train.dat model",
        "■ ./svm_classify test.dat model",
        "■ Learning with a vector sequence",
        "■ ./svmjearn t 5 C V train.dat model",
        "■ Learning with the sum of vector and kernel",
        "sequences",
        "■ ./svmjearn t 5 C + train.dat model"
      ]
    },
    {
      "heading": "Part II: Kernel Methods for Practical Applications",
      "text": []
    },
    {
      "heading": "Kernel Engineering approaches",
      "text": [
        "■ Basic Combinations",
        "■ Canonical Mappings, e.g. object transformations",
        "■ Merging of Kernels"
      ]
    },
    {
      "heading": "Kernel Combinations an example",
      "text": [
        "K polynomial kernel of flat features KTree Tree kernel",
        "Kernel Combinations:"
      ]
    },
    {
      "heading": "Object Transformation [Moschitti et ai, eu 2008]",
      "text": [
        "■ Canonical Mapping,",
        "■ object transformation,",
        "■ e. g. a syntactic parse tree into a verb subcategorization frame tree.",
        "■ Feature Extraction, 0E()",
        "■ maps the canonical structure in all its fragments",
        "■ different fragment spaces, e. g. ST, SST and PT.",
        "- + -",
        "Kfree"
      ]
    },
    {
      "heading": "Predicate Argument Classification",
      "text": [
        "■ target words describe relation among different entities",
        "■ the participants are often seen as predicate's arguments.",
        "■ Example:",
        "Paul gives a talk in Rome"
      ]
    },
    {
      "heading": "Predicate-Argument Feature Representation",
      "text": [
        "Given a sentence, a predicate p:"
      ]
    },
    {
      "heading": "1. Derive the sentence parse tree",
      "text": []
    },
    {
      "heading": "2. For each node pair <N p ,N x >",
      "text": [
        "a.",
        "Extract a feature representation set F",
        "b.",
        "If Nx exactly covers the Arg-/, F is one of its positive examples",
        "c. F is a negative example otherwise",
        "Predicate"
      ]
    },
    {
      "heading": "Vector Representation for the linear kernel",
      "text": []
    },
    {
      "heading": "I Given the sentence:",
      "text": [
        "[ Arg0 Paul] [ predicate delivers] [ Arg1 a talk] [ ArgM in formal Style]",
        "b) s.",
        "formal style formal style Arg.M ( formal style^",
        "These are Semantic Structures"
      ]
    },
    {
      "heading": "Sub-Categorization Kernel (SCF) [Moschitti, ACL 2004]",
      "text": [
        "In other words we consider...",
        "s",
        "^ ^A \\",
        "N VP \\",
        "Paul \\ V NP \"/^pp",
        "y 1 / \\\\ / \\",
        "delivers D N \\ IN NP",
        "\"ji a talk \\ in Ü N Arg.",
        "1",
        "formal style",
        "^^^^"
      ]
    },
    {
      "heading": "Experiments on Gold Standard Trees",
      "text": [
        "■ PropBank and PennTree bank",
        "■ Sections from 2 to 21 train., 23 test., 1 and 22 dev.",
        "■ FrameNet and Collins' automatic trees",
        "■ 18 roles (same names are mapped together)",
        "■ Only verbs"
      ]
    },
    {
      "heading": "PropBank Results",
      "text": [
        "Args",
        "P3",
        "PAT",
        "PAT+P",
        "PATxP",
        "SCF+P",
        "SCFxP",
        "ArgO",
        "90.8",
        "88.3",
        "92.6",
        "90.5",
        "94.6",
        "94.7",
        "Argl",
        "91.1",
        "87.4",
        "91.9",
        "91.2",
        "92.9",
        "94.1",
        "Arg2",
        "80.0",
        "68.5",
        "77.5",
        "74.7",
        "77.4",
        "82.0",
        "Arg3",
        "57.9",
        "56.5",
        "55.6",
        "49.7",
        "56.2",
        "56.4",
        "Arg4",
        "70.5",
        "68.7",
        "71.2",
        "62.7",
        "69.6",
        "71.1",
        "ArgM",
        "95.4",
        "94.1",
        "96.2",
        "96.2",
        "96.1",
        "96.3",
        "Global",
        "Accuracy",
        "90.5",
        "88.7",
        "91.3",
        "90.4",
        "92.4",
        "93.2",
        "Argument Classification on PAT using different Tree Fragment Extractor",
        "o.ss",
        "O.S5 O.S3",
        "o.so",
        "O.TS",
        " – o ST – = – SST",
        "_£2,_ I inirar _^_ l=>T",
        "(",
        "D 10 20 30 AO 50 SO TO SO SO 1C \"A, Training Data"
      ]
    },
    {
      "heading": "FrameNet Results",
      "text": [
        "■ ProbBank arguments vs. Semantic Roles"
      ]
    },
    {
      "heading": "Kernel Engineering: Node marking",
      "text": [
        "Roles",
        "P3",
        "PAF",
        "PAF+P",
        "PAFxP",
        "SCF+P",
        "SCFxP",
        "agent",
        "92.0",
        "88.5",
        "91.7",
        "91.3",
        "93.1",
        "93.9",
        "cause",
        "59.7",
        "16.1",
        "41.6",
        "27.7",
        "42.6",
        "57.3",
        "degree",
        "74.9",
        "68.6",
        "71.4",
        "57.8",
        "68.5",
        "60.9",
        "depictive",
        "52.6",
        "29.7",
        "51.0",
        "28.6",
        "46.8",
        "37.6",
        "duration",
        "45.8",
        "52.1",
        "40.9",
        "29.0",
        "31.8",
        "41.8",
        "goal",
        "85.9",
        "78.6",
        "85.3",
        "82.8",
        "84.0",
        "85.3",
        "instrument",
        "67.9",
        "46.8",
        "62.8",
        "55.8",
        "59.6",
        "64.1",
        "manner",
        "81.0",
        "81.9",
        "81.2",
        "78.6",
        "77.8",
        "77.8",
        "Global Acc.",
        "(18 roles)",
        "85.2",
        "79.5",
        "84.6",
        "81.6",
        "83.8",
        "84.2"
      ]
    },
    {
      "heading": "delivers",
      "text": []
    },
    {
      "heading": "Marking Boundary nodes",
      "text": []
    },
    {
      "heading": "mpaf-",
      "text": []
    },
    {
      "heading": "Node Marking Effect",
      "text": [
        "common PAF features NP delivers talk",
        "D) V common M PAF features I",
        "Different tailoring and marking",
        "Experiments",
        "■ PropBank and PennTree bank",
        "■ about 53,700 sentences",
        "■ Charniak trees from CoNLL 2005",
        "■ Boundary detection:",
        "■ Section 2 training",
        "■ Section 24 testing",
        "■ PAF and M PAF"
      ]
    },
    {
      "heading": "Number of examples/nodes of Section 2",
      "text": [
        "Predicate Argument Feature (PAF) vs."
      ]
    },
    {
      "heading": "Marked PAF (MPAF) [Moschitti et al., ACL-ws-2005]",
      "text": [
        "Section 2",
        "Section 24",
        "Nodes",
        "pos",
        "neg",
        "tOT",
        "pos",
        "neg",
        "tOT",
        "Internal",
        "11.847",
        "71.126",
        "82.973",
        "7.525",
        "50.123",
        "57.648",
        "Pre-temiinal",
        "894",
        "114.052",
        "114.946",
        "709",
        "80.366",
        "81,075",
        "Both",
        "12.741",
        "185.178",
        "197.919",
        "8.234",
        "130.489",
        "138.723",
        "Tagams strategy",
        "CPUtime",
        "Fl",
        "PAF",
        "5.179.18",
        "75.24",
        "MPAF",
        "3.131.56",
        "82.07"
      ]
    },
    {
      "heading": "Merging of Kernels [Bioehdom & Moscmtti, ecir",
      "text": [
        "Definition 4 (Tree Fragment Similarity Kernel).",
        "For two tree fragments fuh ^ J~ ■ we 'h'fine the Tree Fragment Similarity Kernel as:",
        "Merging of Kernels [ECIR2007]: Question/Answer Classification",
        "■ Syntactic/Semantic Tree Kernel",
        "■ Kernel Combinations",
        "■ Experiments",
        "^^^^"
      ]
    },
    {
      "heading": "Delta Evaluation is very simple",
      "text": [
        "0. if »i and ri2 are pre-terminals and label(n\\) = labelfa) then Zi(?u^2) =",
        "1. if the productions at and n2 are different then A{ni,n2) = 0:",
        "Merging of Kernels",
        "V NP",
        "/ l\\",
        "V NP",
        "/ l\\",
        "/ 1 \\ glV6S Î 1 T",
        "/ 1 \\",
        "glves Î1 T",
        "a good talk",
        "a solid talk",
        "ht{TuT2)= ^ ^2 A(nun2)",
        "where A(ni,n2) = XZi=î Sjji",
        "7i(ni)/,(n2)«^(/t,/i)-",
        "^^^^"
      ]
    },
    {
      "heading": "Question Classifier based on Tree Kernels",
      "text": [
        "■ Distributed on 6 categories: Abbreviations, Descriptions, Entity, Human, Location, and Numeric.",
        "■ Fixed split 5500 training and 500 test questions",
        "■ Cross-validation (10-folds)",
        "■ Using the whole question parse trees",
        "■ Constituent parsing",
        "■ Example",
        "\"What is an offer of direct stock purchase plan ?\"",
        "Question Classification",
        "■",
        "Definition: What does HTML stand for?",
        "■",
        "Description: What's the final line in the Edgar Allan Poe",
        "poem \"The Raven\"?",
        "■",
        "Entity: What foods can cause allergic reaction in people?",
        "■",
        "Human: Who won the Nobel Peace Prize in 1992?",
        "■",
        "Location: Where is the Statue of Liberty?",
        "■",
        "Manner: How did Bob Marley die?",
        "■",
        "Numeric: When was Martin Luther King Jr. born?",
        "■",
        "Organization: What company makes Bentley cars?",
        "^^^^"
      ]
    },
    {
      "heading": "ROOT I",
      "text": []
    },
    {
      "heading": "JJ nn nn nn",
      "text": [
        "direct stock purchase plan",
        "Kernels",
        "■ BOW, POS are obtained with a simple tree, e.g.",
        "^^^^",
        "* * * * *",
        "■ PT (parse tree)",
        "■ PAS (predicate argument structure)",
        "i"
      ]
    },
    {
      "heading": "Question classification",
      "text": []
    },
    {
      "heading": "Similarity based on WordNet",
      "text": [
        "Inverted Path Length:",
        "Wu fe Palmer:",
        "simipL(ci,c2)",
        "Features",
        "Accuracy fJJIUC)",
        "Accuracy (c.v.)",
        "PT",
        "90.4",
        "S4.S • 1.4",
        "BOW",
        "90.6",
        "N I.7 : 1.4",
        "PAS",
        "34.2",
        "43.0±2.2",
        "POS",
        "26.4",
        "32.4±2.5",
        "PT+BOW",
        "91.8",
        "86.1±1.3",
        "PT+BOW+POS",
        "91.8",
        "84.7±1.7",
        "PAS+BOW",
        "90.0",
        "82.1Ü.5",
        "PAS+BOW+POS",
        "88.8",
        "81.0Ü.7"
      ]
    },
    {
      "heading": "Question Classification with S/STK",
      "text": [
        "Accuracy",
        "À parameter",
        "0.4",
        "0.05",
        "0.01",
        "0.005",
        "0.001",
        "linear (bow)",
        "0.905",
        "string matching",
        "0.890",
        "0.910",
        "0.914",
        "0.914",
        "0.912",
        "full",
        "0.904",
        "0.924",
        "0.918",
        "0.922",
        "0.920",
        "full-ic",
        "0.908",
        "0.922",
        "0.916",
        "0.918",
        "0.918",
        "path-1",
        "0.906",
        "0.918",
        "0.912",
        "0.918",
        "0.916",
        "path-2",
        "0.896",
        "0.914",
        "0.914",
        "0.916",
        "0.916",
        "lin",
        "0.908",
        "0.924",
        "0.918",
        "0.922",
        "0.922",
        "wup",
        "0.908",
        "0.926",
        "0.918",
        "0.922",
        "0.922"
      ]
    },
    {
      "heading": "TASK: Question/Answer Classification [Moschitti, cikm 2008] _",
      "text": [
        "■ The classifier detects if a pair (question and answer) is correct or not",
        "■ A representation for the pair is needed",
        "■ The classifier can be used to re-rank the output of a basic QA system"
      ]
    },
    {
      "heading": "Dataset 2: TREC data",
      "text": [
        "■ 138 TREC 2001 test questions labeled as \"description\"",
        "■ 2,256 sentences, extracted from the best ranked paragraphs (using a basic QA system based on Lucene search engine on TREC dataset)",
        "■ 216 of which labeled as correct by one annotator"
      ]
    },
    {
      "heading": "Dataset 2: TREC data",
      "text": [
        "138 TREC 2001 test questions labeled as \"description\"",
        "A question is linked to many answers: all its derived )airs cannot be shared by training and test sets 216 of which labeled as correct by one annotator"
      ]
    },
    {
      "heading": "Bags of words (BOW) and POS-tags (POS)",
      "text": [
        "To save time, apply STK to these trees:"
      ]
    },
    {
      "heading": "Word and POS Sequences",
      "text": []
    },
    {
      "heading": "What_is_offer What_is",
      "text": [
        ".",
        "WHNP VBZ DT NN IN...(POS sequence, possk)"
      ]
    },
    {
      "heading": "WHNP VBZ NN",
      "text": []
    },
    {
      "heading": "WHNP NN IN",
      "text": [
        "Syntactic Parse Trees (PT)",
        "RO",
        "SB-",
        "WHNP S 1",
        "WP \\",
        "OT LRQ",
        "P ?",
        "What",
        "\\\"BZ",
        "NP",
        "is",
        "NP PP",
        "DT 1",
        "an",
        "NN",
        "offer IN NP",
        "Jj\"\" NN NN NN 1 1 1 1 direct stock purchase plan",
        "Predicate Argument Structure for Partial Tree Kernel (PASPTK)",
        "[ARG1 Antigens] were [AM-TMP originally] [rel defined] [ARG2 as non-self molecules].",
        "[ARGO Researchers] [rel describe] [ARG1 antigens][ARG2 as foreign molecules] [ARGM-LOC in the body]",
        "pas...............................",
        "define antigens as non-self molecules originally describe researchers antigens as foreign molecules in the body"
      ]
    },
    {
      "heading": "Kernels and Combinations",
      "text": [
        "Exploiting the property: k(x,z) = k1(x,z)+k2(x,z) BOW, POS, WSK, POSSK, PT, PASPTK> BOW+POS, BOW+PT, PT+POS, ...",
        "Results on TREC Data (5 folds cross validation)",
        "tu",
        "38 -36 -",
        "a, ~ 3 32 -to",
        "S 30 E 28 H 26 -",
        "1 – 1",
        "Ml",
        " – ",
        "n",
        " – ",
        "r",
        " – ",
        "24 -22 -",
        "-",
        "n",
        "n",
        "^ 9",
        "&",
        "?",
        "?^ V* Kernel Type",
        "*°V ^>>^",
        "Results on TREC Data (5 folds cross validation)",
        "tu",
        "38 -36 -",
        "a, ~ = 32 -to",
        "S 30 E 28 H 26 -",
        "24 -22 -",
        "-",
        "-",
        " – ",
        "1 I",
        " – ",
        "^u n r",
        "of ^",
        "9^ d& ^",
        "Kernel Type ç,?",
        "^rjbs",
        "Results on TREC Data (5 folds cross validation)",
        "tu",
        "38 -36 -",
        "a, ~ 3 32 -to",
        "S 30 E 28 H 26 -",
        "1 – 1",
        "n",
        " – ",
        "r",
        "24 -22 -",
        "T",
        "n",
        "^ 9",
        "&",
        "-# ?^ V*",
        "Kernel Type",
        "Results on TREC Data (5 folds cross validation)",
        "tu",
        "38 -36 -",
        "a, ~ = 32 -to",
        "S 30 E 28 H 26 -",
        "-",
        "n",
        " – ",
        "n",
        " – ",
        "r",
        "24 -22 -",
        "-\\",
        " – ",
        "-s^ ^ jj& ^ ^ ^ ^ Kernel Type ç,y ^rjbs",
        "Results on TREC Data (5 folds cross validation)",
        "tu",
        "38 -36 -",
        "a, ~ 3 32 -to",
        "S 30 E 28 H 26 -",
        "1 – 1",
        "1",
        "n",
        ":",
        "24 -22 -",
        "-",
        "n",
        "9",
        "cp'",
        "?",
        "?^ V*",
        "Kernel Type",
        "^^^^",
        "Results on TREC Data (5 folds cross validation)",
        "tu",
        "38 -36 -",
        "a, ~ = 32 -to",
        "S 30 E 28 H 26 -",
        "24 -22 -",
        "-",
        "n",
        " – ",
        "-",
        "-\\ – \\-",
        "-",
        " – ",
        " – -",
        "^u n I",
        "9",
        "-s^ 9^ j?cp ^",
        "■ 9^^ 9P Kernel Type ç,y ^rjbs"
      ]
    },
    {
      "heading": "Results on TREC Data (5 folds cross validation)",
      "text": [
        "Kernel Type",
        "mprovement"
      ]
    },
    {
      "heading": "Kernels for Re-ranking",
      "text": []
    },
    {
      "heading": "Re-ranking Framework",
      "text": [
        "■ Local classifier generates the most likely set of hypotheses.",
        "■ These are used to build annotation pairs,(hl, hj■ positive instances if h' more correct than hi,",
        "■ A binary classifier decides if h' is more accurate than hi.",
        "m Each candidate annotation h' is described by a structural representation"
      ]
    },
    {
      "heading": "Re-ranking framework",
      "text": []
    },
    {
      "heading": "Hypotheses Puiis Hypotheses",
      "text": [
        "HI",
        "H1.H2",
        "H4",
        "H2 H3",
        "H1.H3",
        "H3",
        "H4",
        "Local Model",
        "...",
        "Re-ranker",
        "W",
        "w",
        "W",
        "Hn.Hl",
        "HI",
        "Hit",
        "Hn.H2",
        "Hu"
      ]
    },
    {
      "heading": "Syntactic Parsing Re-ranking",
      "text": []
    },
    {
      "heading": "Re-ranking concept labeling",
      "text": [
        "■ I have a problem with my monitor",
        "h': I Null have Null a Null problem Problem-B with Null my Null monitor HW-B hi.",
        "I Null have Null a Null problem HW-B with Null my Null monitor"
      ]
    },
    {
      "heading": "Multilevel Tree",
      "text": [
        "Ho EROHLEM-B PROBLEM!",
        "HW-B HW-I un problema col monitor",
        "Flat tree representation (cross-lanquaqe structure)",
        "ROOT",
        "NULL PROBLEM-B PROBLEM-I HW-B",
        "II II",
        "HW-I",
        "1",
        "ii ii Ho un problema col",
        "1",
        "monitor"
      ]
    },
    {
      "heading": "Enriched Multilevel Tree",
      "text": []
    },
    {
      "heading": "Re-ranking for Named-Entity",
      "text": [
        "ORG.Type",
        "NULL",
        "NULL",
        "NULL NULL ORG.Type",
        "NULL ORG.Type",
        "NULL",
        "\\ \"\\ \"\\ \\ \"\\ \\",
        "ORG",
        "ORG ORG ORG",
        "r >\\ \"\\ '\\ \\ ORG \\",
        "ORG",
        "\\ ^\\ \\^ \\^ \\^ \\ \\ \\ \\",
        "South",
        "Africa",
        "Breweries Ltd",
        "bought stakes in the",
        "Lech and",
        "Tychy",
        "brewers",
        "■ Basic Combinations"
      ]
    },
    {
      "heading": "Re-ranking Predicate Argument Structures",
      "text": []
    },
    {
      "heading": "Conclusions",
      "text": [
        "■ Kernel methods and SVMs are useful tools to design language applications",
        "■ Kernel design still requires some level of expertise",
        "■ Engineering approaches to tree kernels",
        "■ Canonical Mappings, e.g.",
        "• Node Marking",
        "■ Merging of kernels in more complex kernels",
        "■ Easy modeling produces state-of-the-art accuracy in many tasks, RTE, SRL, QC, NER, RE",
        "■ SVM-Light-TK efficient tool to use them",
        "NNP",
        "NP",
        "plunged NP"
      ]
    },
    {
      "heading": "Future (on going work)",
      "text": [
        "■ Once we have found the right kernel, are we satisfied?",
        "■ What about knowing the most relevant features?",
        "■ Can we speed up learning/classification at real-application scenario level?",
        "■ The answer is reverse kernel engineering:",
        "■ Mine the most relevant fragments according to SVMs gradient",
        "■ Use the linear space",
        "■ Software for reverse kernel engineering available in the next months",
        "Thank you"
      ]
    }
  ]
}
