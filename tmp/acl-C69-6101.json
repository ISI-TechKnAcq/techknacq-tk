{
  "info": {
    "authors": [
      "DÃ¡niel Varga"
    ],
    "book": "International Conference on Computational Linguistics",
    "id": "acl-C69-6101",
    "title": "Problem of Improving the Efficiency of Parsing Systems",
    "url": "https://aclweb.org/anthology/C69-6101",
    "year": 1969
  },
  "references": [],
  "sections": [
    {
      "text": [
        "1. The number of all the possible structures as a function of the length of the sentence As soon as practical applications are considered the efficiency of the parsing method is of fundamental importance whether natural or programming languages are to be processed.",
        "The problem of efficiency arises because the relationship between the length of a string of symbols and the number of structures that may in theory be assigned to the string is far from linear, the growing number of symbols entails a much more rapidly growing number of possible structures.",
        "For CF grammars it is comparatively easy to determine how the number of structures depends on the length of the string.",
        "Considering binary branchinga only and excluding the possibilities that arise from having different labels attached to one node a linear string of n elements [1].",
        "This means that for a 10 element string the number of different trees is slightly less than 5000, for a 20 element string this number becomes more than 1.75 milliard.",
        "To include non-binary branchings as well I suggest the following recursive formula where n is the number of elements in the string.",
        "Accordingly, more than 100 000 different structures can be assigned to a 10 element string, and 1.6 x 1012 different structures to a 20 element string.",
        "Let us stress again that what we have calculated here is the number of the essentially different derivations, i.e. the number of those yielding different results.",
        "The number of possible derivational paths for 10 elements is 18 times larger than the number of the different results, for 20 elements the number of paths is 750 times larger than that of the different structures (201 1.2 x 1018) ."
      ]
    },
    {
      "heading": "2. Syntactic ambiguities",
      "text": [
        "Natural languages utilize but a small fraction of these possibilities.",
        "As to the number of possible structures of concrete sentences, the syntactic restrictions are very strong yet far from sufficient to yield information for unambiguous assignement.",
        "The number of structures allowed by the formal syntactic rules is in most cases definitely larger than the number of structures a human being becomes aware of in the course of speech.",
        "A well-known point is that unambiguity cannot always be ensured by grammatical means even for artificial languages whose structure is immensely less complicated [2].",
        "It is worth mentioning that the authors of ALGOL-68 decided to let some ambiguities remain in the language as it could have been eliminated but by making the grammar a lot more complicated [3].",
        "Where does the majority of syntactic ambiguities in natural languages come from?",
        "1.",
        "There is a number of words with varying 'mopes and vice versa: some words may fall within the scope of several different words and it cannot be determined by formal syntactic means - nor yet",
        "by semantic ones at times - whose scope they really fall within.",
        "These two things often combine, especially in complex genitive constructions.",
        "A fine Russian specimen of which is as follows:",
        "2.",
        "Another source of syntactic ambiguities is that not even the string of symbols /categories/ can always be unambiguously assigned to the sentence, i.e. homonymy may often appear on the morphological level.",
        "Homonymy arises either because formal differentiation between parts of speech is absent /e.g.",
        "in English/ or because the correspondence of the functions of words and the morphological means of expressing them is ambiguous, the morphological functions are not unambiguously expressed/e.g.",
        "in Russian/.",
        "Completely independent words with or without affloomtoo can of course agree in form.",
        "Still one seldom comes across a sentence that could be assigned several entirely different structures.",
        "Sentences of this type are usually puns or grammatical examples /cf.",
        "\"Time flies like an arrow\"/.",
        "It is the.",
        "so-called local syntactic ambiguity that normally troubles us, i.e. a part of the sentence that can be assigned several different part-structures without influencing the remainder of the sentence-structure.",
        "Now if there are several locally ambiguous parts in the sentence and they are independent from each other, the number of ambiguities for the whole sentence will considerably increase: it will be the arithmetic product of the numbers of independent local ambiguities.",
        "3.",
        "Questions of tactics",
        "The above numeric data clearly show how hopeless it is to simple proceed by checking on all the theoretically possible structures.",
        "But it is also apparent that syntax-directed parsing systems will fail in a considerable number of cases just because the sentence structure is syntactically undetermined [4].",
        "The development of an effective analyzer is at least as much a mathematical as a linguistic problem.",
        "The most important demands a parsing algorithm should meet are as follows: /i/ It should be able to determine all the conceivable parsings that a given sentence is assigned by a particular grammar.",
        "/ii/ It should be consistent in the sense that one parsing could not be arrived at but in one single way.",
        "/It should be a 'one-to-one algorithm'./ /iii/ In some way or other it should counterbalance the immense growth of the number of possible structures.",
        "The purpose to be strived for is a linear relationship between the steps to be taken and the 'length of the sentence.",
        "The efficiency of the algorithm depends considerably on factors that are independent of the particular method one has chosen to apply.",
        "These problems arise with any algorithm even if in different forms.",
        "The most important 'tactical' questions of this type are as follows: /i/ Assuming a large set of rules how does the algorithm select the rules that are /possibly/ to be applied?",
        "/ii/ How does it check for the conditions of applying them?",
        "/iii/ How does it recognize 'blind alleys' i.e. illegal paths /if any/?",
        "/iv/ How does it return from the illegal path to the legal one /or to the one that has not proved to be illegal as yet/?",
        "Some of the well-known methods for solving /i/ are as follows: /a/ Each rule is explicitly assigned the set of rules by which it could be continued.",
        "Hut choosing this method for a complicated grammar with a large number of possibilities one might face troubles.",
        "/b/ The rules are divided into several groups on the basis of different characteristics such as the number or the character of the symbols within the rule etc.",
        "Searching is then carried out within a comparatively small set of rules.",
        "/c/ Each symbol is assigned a set of all the rules this particular symbol appears in.",
        "Assignment can be done according to the position numbers within the rules.",
        "The so called initial symbols, i.e. symbols in first position, play then a distinguished role in the rule selection.",
        "Whatever method one applies one may choose one of the several possible ways of practical realization.",
        "In case of /c/ the choice made will be of immense importance /e.g.",
        "rules arranged in matrix form, chainlike representation etc./.",
        "Problems /i/ and /ii/ are strongly interconnected.",
        "How are we to decide whether the conditions of applying a rule are met?",
        "In the case of CF grammars checking could be carried out quite easily.",
        "For top-to-bottom analysis all we have to do is the identification of the left-hand side.symbol of the rule.Forbottom-to-top analysis based on normal form CF rules /i.e.",
        "binary branchings/ only, once again it is not too difficult to check a twodimensional table for the possibilities of connecting a pair of symbols.",
        "If general form CF or CS grammars are applied, the problem is not trivial at all, it turns out to be that of identifying strings of symbols.",
        "It could of course be solved in a trivial way but this would require an awful lot of work to do.",
        "B. Ddm8lki has developed a moat",
        "elegant method that would examine a whole series of rules at once*.",
        "The checking is performed on Boolean vectors, and the point Ddmtilki has made an excellent use of is that computers carry out logical operations on all the bits of a machine word at the same time [5].",
        "Two subproblems connected with checking rules should be discussed: /a/ When should it start at all?",
        "Suppose that the symbol string is processed in sequential order /left-to-right or right-to-left/ and a possibly applicable rule or a given context should be checked for.",
        "Then we could either go back to symbols that have already been examined /and check them repeatedly when checking for the applicability of various rules/ or have already begun and completed certain examinations so that we finished checking by the time its result is needed.",
        "/The second solution could of course be applied only if an appropriate mechanism automatically provides the checking for the conceivable conditions and the /gradual/ cancelling of the non-realizable possibilities./ /b/ Is some kind of an additional examination necessary before the checking is completed?",
        "Namely it might turn out that the whole checking was superfluous because its result cannot be used later on or it will not lead to a correct result.",
        "We have come very near to /iii/, i.e. to how the occasional impasses /blind alleys/ could be recognized in the course of the analysis?",
        "This is a cardinal problem concerning the efficiency of automatic analysis.",
        "The growing length of the sentence /symbol string/ entails not only a growing number of possible structures but the number of inappropriate part-structures growing as well.",
        "These 'torsoes, correspond to certain parts of the sentence but are incompatible with the remainder of it.",
        "What is more, the longer a sentence the more levels it may have i.e. the deeper its structure can be.",
        "This holds for the blind alleys as well: the longer the sentence the deeper the blind alley can be, the more branches and the more valid elements it may contain.",
        "Sentences that are monosemantic though syntactically ambiguous could be thought of as bottomless blind alleys not yet explored whose exploration needs either a wider context or the use of interrelationships not contained in the text.",
        "The problem once again becomes twofold:",
        "a/ What is the criterium of having got into a blind alley?",
        "b/ How could we prevent getting into a blind alley at least in some cases?",
        "The answer to these questions may be different, of course, for each algorithm and plays a subordinate though extremely important role regarding the \"strategy\" applied.",
        "Just to give an example I would like to mention a moat elegant method of defining and \"calculating\" the criterium of blind alleys using an algorithm built up in terms of logical vectors.",
        "DOmtilki [5] -- who condenses the information related to the hypothetically accepted part structure and to the given symbol string under processing into a state vector defined recursively -- applies the following criteria to determine the impossibility of continuing the analysis along the given line",
        "Accordingly the new symbol ita to be processed may neither continue the paths the previous vector of state contained that have proved possible so far, i.e. T(Qt)A H [xt+1] = 0, nor begin a new rule, i.e. BAH Ezt+1] = 0.",
        "The only handicap of D6mblkits method is that impasses can be recognized only after the algorithm has got into them -- the algorithm cannot pick out the paths that will lead into an impasse later on.",
        "So we have modified the algorithm and instead of using DdmOlkils vector B - that wouleactivate)the first position of each of the rules we let only those of the rules become active that provide /direct or indirect/ continuation of the paths that have already proved to be legal [6].",
        "Experience so far shows three practical methods of at least partial avoidance of impasses: ii/ taking into consideration the context; /ii/ making use of the transitive connectivity of the rules; /iii/ checking ahead the number of symbols not yet processed.",
        "Taking into consideration the context means making use - if possible -- of only one direction of the context to avoid the repetition of the tests performed.",
        "Today such analyzing grammars play an important role in the analysis of artificial languages [7].",
        "In my opinion making use of the transitive joining of rules has yet many important possibilities to offer.",
        "P. Z. Ingerman's analysis is a good example_of experiments in this direction [8].",
        "Taking into consideration the number of symbols not yet processed, saves the analysis many unnecessary tests.",
        "There have been attempts at doing a preliminary global analysis of the complete symbol string on this basis to assess in advance the possibilities of each path of the analysis [9].",
        "Finally let us mention the question as the last of the questions of tactics: /iv/ How to find the way from an'illegal path back to a legal one?",
        "This is the task that must somehow be solved by the parsing algorithm.",
        "So it is not enough to give a sign or \"flag\" at the points where the decision may perhaps be a failure.",
        "/1/ It must be ensured that the state prior to committing the error is reconstructed.",
        "/ii/ It would be advantageous to return to the state immediately prior to committing the error thus avoiding unnecessary delays.",
        "(Nevertheless, there exist fine algorithms with no assurance that every error could be corrected.",
        "One of them is the well-known 'compiler compiler' that would never reinterpret a part of the symbol string if the part has once been accepted, consequently it is unable to recognize certain structures.)",
        "One of the possible solutions to the problem in question is to have the \"current state\" of the analysis stored whilst proceeding so that it could be accessed later on.",
        "What we have termed \"current state\" here may include all the half-finished and abandoned rule applications that could be continued only after other rules have been applied.",
        "Whenever reaching back for a previous \"current state\" the possibilities that have ceased to exist in the meantime can always be cancelled.",
        "/The techniques followed for practical realization may vary depending on the amount of information to be stored, on the memory area available for the working fields, etc.",
        "(In most cases some kind of a push down store is applied.)",
        "4.",
        "The strategy of analysis I.",
        "The problems mentioned so far are common in varying degrees for all parsing systems, the ways they are solved have no decisive influence ou the whole flow of analysis /though they are of decisive importance as far as efficiency is concerned/.",
        "T.V.",
        "Griffiths and S.R.",
        "Petrick base the determination of the types of parsing systems on two considerations [4 /whilst stressing that 'some procedures are described in these terms only with difficulty' and 'others seem to allow no such classification'/: /1/ In what direction does the parsing proceed is it a top-to-bottom or a bottom-to-top analysis?",
        "/The third type mentioned - 'direct substitution algorithms' - is a subclass of the bottom-to-top algorithms./ /ii/ Does the algorithm apply any means of a preventive reduction of the number of blind alleys, i.e. for increasing the 'selectivity' of the algorithm?",
        "Their most important findings concerning the efficiency of the different types of algorithms are as follows: /a/ Algorithms proceeding from top to bottom especially those of the direct substitution type - are the more efficient ones.",
        "/b/ Methods of increasing selectivity are of no special importance in the case of top-to-bottom",
        "analyses but they do considerably increase the efficiency in the case of bottom-to-top analyses.",
        "/di Efficiency is demonstratably influenced by the asymmetry/left-branching or right-branching/ of the structure to be analyzed.",
        "In the case of analysis proceeding from top to bottom it is influenced in the reverse direction if compared with the analysis proceeding from the bottom upwards.",
        "/We assume that the analysis proceeds either from right to left in both cases or from left to right in both cases./ They considered the parsing time of the following sentence types: anb anon ahn abncd left right embedding compound.",
        "branching branching /left-branching /'regressive' /'progressive' with respect to in Yngve's term/ in Yngve's term/ recursivity/+ Parsing time as a function of sentence length increases - according to Griffiths' and Patrick's date as follows: +The grammar given would have allowed right recuraivity as well /abnce/ but in the measurements only the above restrictions of grammar are dealt with.",
        "According to Griffiths's and Patrick's data it is the bottom-to-top selective parser alone that is able to analyze sentences of the last, comparatively simple type grammar with a better than exponential efficiency.",
        "What are the underlying reasons for the results obtained by Griffiths and Petrick?",
        "/i/ Bottom-to-top algorithms are characterized by the fact that they take their start from what actually exists instead of looking for what \"could be\" [11].",
        "In the case of exceedingly extensive grammars the top-to-bottom analysis must work with a huge number of potential possibilities and the elements of the symbol string to be analyzed will but slowly filter out the possibilities that may not be realized.",
        "/ii/ Selectivity, in the sense Griffiths and Petrick use the term, does not influence all this to any degree as the :filtering on the basis of a precedence-matrix extends only to testing the first element.",
        "It will be shown later on that selectivity can be considerably increased and, going even further, it could be made the basis of the strategy of the analysis.",
        "/iii/ In the case of bottom-to-top analysis the situation is entirely different.",
        "Here the seemingly identical apparatus works with a much greater efficiency.",
        "But /a/ the \"look ahead\" condition suggested by Bastian [12]",
        "/i.e.",
        "the possibility of the resultant symbol aohieving its aim checks the compatibility/ one level higher up and the distance from the top is so muoh less.",
        "/b/ Here only such rules are to be realised in which all the components oan be found, the others are omitted in the oourse of the rule controls.",
        "It is out of the question therefor to regard this seleotivity as analogous with the top-to-bottom selectivity that is based on the first symbol of the lowest level.",
        "/iv/ Griffiths's and Patrick's measurements of the effect of the asymmetry of sentences on the efficiency of the analysis are a practical justification of an observation I made in 1964.",
        "In an article about Yngve'a hypothesis [13] I developed the idea that for languages that have mostly \"progressive\" /right-branching/ structures it is the right-to-left analysis that is more effective in the case of analysis from bottom to top.",
        "/The right-to-left analysis is equivalent of course with a left-to-right analysis in a system that is a mirror image of the original./ In case of pure structures the explanation of the phenomenon is simple: In a right-branching structure the number of erroneous linkings is started at the end of a sentence.",
        "Let us take the example from the above mentioned article of mine: Bu snaeve =WV reopen[ o npegexax.",
        "Its processing from right to left is very simple: By esavre more tempos o npeyesax If, however, the analysis is started from the beginning of the sentence we get erroneous /or incomplete/ linkages again and again: By anaeTe ansere inforo /ammo Teopen In the case of complex structures the situation is more complicated.",
        "In this case the effectivity greatly depends on the method used for eliminating the impasses.",
        "/On the disadvantages of vertical analysis see the next paragraph./"
      ]
    },
    {
      "heading": "5. TheatrateFLV of analysis II.",
      "text": [
        "When determining the type of analysis apart from its starting point it is also very important to know along what paths the analysis proceeds towards its goal, or in other words in what sequence the tests are carried out together with the inseparable question of in what form or structure the part-results are stored.",
        "On the basis of these considerations there are two basic types of parsers.In theory this classification is independent of the fact whether the analysis proceeds from the bottom upwards or from the top downwards.",
        "/i/ Those parsers that proceed with \"maximum width\" from level to level working on the full symbol string, first produce all the reductions that may be achieved by applying a single rule, than those that may be obtained by applying two rules and so on until the part-structures thus obtained are gradually linked.",
        "/In the analysis that proceeds from top downwards, these correspond to the derivations produced by applying two, there, ... rules, followed by the comparison of the terminal symbols thus obtained with the symbol string being analysed./ /ii/ The parsers that proceed with a \"minimum width\" and the \"steepest slope\", while gradually extending the 20 elements of the symbol string take the first opportunity to apply a rule and will not extend the analysis to a new symbol until there are new rules that could be built on the rules applied so far.",
        "We could mention as an example for the first method the Sakai-Nagao algorithm [14]M the Cocke algorithm [16] or its application by Kuno to context sensitive languages [17] /the same strategy is applied by Vauquois in his analysis of Russian/.",
        "The algorithms by Woods [18] by Boracsev [19] and the Diimdlki-Varga algorithms [5] [6] are examples of the second method.",
        "Both methods have their advantages and disadvantages; perhaps it may be useful to draw the attention to them.",
        "The great advantage of the analysis that proceeds from level to level is the ease with which in case of appropriate storage the part-analyses that could be continued along the same line, are contracted /see Griffiths-Petrick: \"Merging similar sections of different TM [Turing Machine] paths\"/.",
        "Its disadvantage is the fact that a/ relatively large number of independent part structures has to be stored, b/ it needs relatively lengthy tests to detemine whether the individual part structures are compatible.",
        "The strategy of \"maximal hierarchization\" is more advantageous beyond doubt as far as economy in storage is concerned because in this case a single push down store will suffice to store the results and all the paths that have proved incorrect may be removed once and for all from the push down store together with all the derivations.",
        "This principle may be formalized as follows.",
        "Let us denote according to inverse Polish notation the result of the rule applied to the elements ak ak+1... akfr with the result Bm as r .",
        "In other words let the ak ak+r Bm elements of the symbol string that we applied the rule remain in the symbol string and let us simply add to the end of the string the symbol obtained as the result of the rule application.",
        "Accordingly the resulting symbol string will be min al...ai Bi1 r14 after applying the first applicable rule.",
        "Let us suppose that there are at most m-1 more applicable rules following the first one while no new symbol is read /m4:0/ The symbol string will become , rm max min al...ai 811... Bm .",
        "m i ri",
        "While continuing the application of this principle the symbol string will be increased by new terminal and non-terminal symbols:",
        "max min max min a,... a. B.1 ...B a.",
        ".a B i 1 mm 1+1\" j m+1 Bn nj m If the analysis gets into an impasse and cannot continue, then we have to return to the symbol B88 last applied, remove it and continue the analysis applying the above principle.",
        "/First an attempt is made at applying another permissible rule in the same place and only if this fails shall we take a new at symbol and continue the analysis./ The return from an impasse always means the deletion of the last non-terminal symbol and the reconstruction of the symbol string following it.",
        "/We would like to mention that this principle of analysis may be quite easily adopted to analyse context sensitive languages as well/.",
        "This undoubtedly elegant principle of application produces the first possible analysis relatively rapidly, in its canonic form.",
        "The increased selectivity of the analysis gives us a procedure that could be very well used in practical applications.",
        "Going further, having obtained the first",
        "analysis if the analysis is continued on the same principles /just as if the first correct analysis were in an impasse/ all the other analysis may be likewise produced.",
        "The disadvantages of the applied strategy of analysis are as follows: /a/ If right at the beginning of the analysis we have taken an incorrect path, then the correction of this error may only be done after all the following and in part independent applications of the rules have been deleted.",
        "This means that the correct, or perhaps the only possible part-results are lost: after putting the error right they have to be regenerated.",
        "/b/ The position is somewhat similar as far as the erroneous part-results are concerned: the analysis may get into a \"local\" impasse several times.",
        "/c/ A new, different system of storage and searching must be provided if we wish to ensure a newer generation of the identical continuations -- supposing that previously some kind of a change took place in the determined structure."
      ]
    },
    {
      "heading": "6. A new strategy suggested for analyzing_CF languages",
      "text": [
        "The exponential increase in the time of analysis in various systems or analysis is obviously due to the increase in the number and depth of impasses, to their various branches -- in short to their dangerousness increasing with the length of the symbol string.",
        "This is the dangerous point I tried to dodge by elaborating a parsing system that applies selectivity not as an additional device for increasing the efficiency of some method but as an independent method itself.",
        "The linearity of the increase in the process of analysis may be best achieved if the symbol string to be analyzed can be segmented in accordance with the highest level rules applicable and these parts could be analyzed separatedly.",
        "If several parsinga can be assigned to any of these segments /cf.",
        "what we have said about homonymy on p.5/ the structures corresponding to the whole sentence can be produced from the local part-results by combinatorical means.",
        "Segmentation requires the following apparatus: /i/ the transitive initial matrix of the rules /B/a,n// /ii/ the transitive continuation matrix of the rules /c/a,n//",
        "/iii/ the transitive end matrix of the rules /N/a,n// /ivi/ the transitive initial matrix of the ith rule component /Bi/a,n// /v/ the transitive continuation matrix of the ith component /Ci/a,n// /vii/ the transitive end matrix of the ith component /Ei/a,n// /vii/ the matrix of the number of rule components /V/i,n// The structure of the transitive initial matrix of the rules is almost the same as that of the so called precedence /or complete connectivity/ matrix.",
        "The differences show up in two footopnamely a/ the lines correspond to the terminal elements only and not to all the elements of the vocabulary V; b/ the columns are assigned to rules of the grammar and not to the symbols.",
        "Thus it is a Boolean matrix B/a,n/; its element B/a,n/ is a truth function whose value is t if and only if the grammar allows the terminal symbol a to be the first element of the terminal rewriting of the nth rule.",
        "The transitive continuation matrix of the rules 2/a,n/ is a Boolean matrix whose element C/a,n/ is t if and only if the terminal symbol a is whichever but not the first element of the terminal strings of the nth rule.",
        "The value of an element E/a,n/ of the transitive end 26 matrix of the rules is t if and only if the terminal symbol a can be the last element of the terminal strings of the nth rule.",
        "It follows from the definition that B/apon/ = E/ap,n/ and C/aq,n/ = E/aq,n/ may occur but B/ap,n/ = E/ap,n/ = C/ap,n/ may not.",
        "The initial, continuation and end matrices of the rule components can be defined in a similar way, so it will be sufficient to give the definition of the 'initial th i matrix of the rule component: The value of an element B.",
        "/a n/ of the initial",
        "matrix of the ith rule component Bi /a,n/ is t if and only if the non-terminal symbol a may be first element of the terminal strings of the ith direct component of the nth rule.",
        "The line of thought of the algorithm is as follows: Tests are carried out on two levels: on the level of inter-rule linkages /from top downwards/ and on the level of inter-terminal-symbol linkages /from left to right/.",
        "In each successive step of the test the individual components of the rules are made to correspond in the sequence of the components to a certain series of the terminal symbols of which the given component may be built up.",
        "By continuing this process finally either we arrive at the terminal ending in case of all components or the given segmentation is found",
        "to be incorrect.",
        "In case of incorrect segmentation first the permissible branches of the latest segmentation are tested by the algorithm.",
        "In our experience the selectivity of the system is considerable.",
        "Therefore even the storage of relatively small quantity of information allows a rapid examination of all the possibilities.",
        "During segmentation we apply a \"principle of segmentation\" that is analogous to the principle discussed in connection with the \"maximum hierarchization\": the shortest component that is nearest to the beginning of the segment or to the end of the previous component, is taken and used until it becomes evident that for some reason the given segmentation is not applicable.",
        "In this case an attempt is made at solving the situation by shifting the last border of segmentation to the right: only if this leads to no result, is the previous border of segmentation changed.",
        "The outstanding effectivity of the method applied is due to a/ making best use of the bottleneck for the reduction in analyzing time; b/ the fact that the tests for the possibilities of various part-segmentations can be quickly performed; c/ the possibility of testing each segment in complete separation from all the other segments; d/ the fact that the twosided approach leads to much fewer unnecessary part results than either Cock's or the well-known top-to-bottom algorithms."
      ]
    },
    {
      "heading": "Bibliography",
      "text": []
    }
  ]
}
