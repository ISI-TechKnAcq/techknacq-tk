{
  "info": {
    "authors": [
      "James Paul White"
    ],
    "book": "SemEval",
    "id": "acl-S12-1044",
    "title": "UWashington: Negation Resolution using Machine Learning Methods",
    "url": "https://aclweb.org/anthology/S12-1044",
    "year": 2012
  },
  "references": [
    "acl-S12-1035",
    "acl-W09-1105",
    "acl-W10-3002",
    "acl-W10-3014"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper reports on a simple system for resolving the scope of negation in the closed track of the *SEM 2012 Shared Task.",
        "Cue detection is performed using regular expression rules extracted from the training data.",
        "Both scope tokens and negated event tokens are resolved using a Conditional Random Field (CRF) sequence tagger ?",
        "namely the SimpleTagger library in the MALLET machine learning toolkit.",
        "The full negation F1 score obtained for the task evaluation is 48.09% (P=74.02%, R=35.61%) which ranks this system fourth among the six submitted for the closed track."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Resolving the scope of negation is an interesting area of research for Natural Language Processing (NLP) systems because many such systems have used methods that are insensitive to polarity.",
        "As a result it is fairly common to have a system that treats ?X does Y?",
        "and ?X does not Y?",
        "as having the same, or very nearly the same, meaning1.",
        "A few application areas that have been addressing this issue recently are in sentiment analysis, bio?",
        "medical NLP, and recognition of textual entail?",
        "ment.",
        "Sentiment analysis systems are frequently used in corporate and product marketing, call cen?",
        "ter quality control, and within ?recommender?",
        "sys?",
        "tems which are all contexts where it is important to recognize that ?X does like Y?",
        "is contrary to ?X does not like Y?.",
        "Similarly in biomedical text such 1A one token difference between the strings surely indicating at least an inexact match.",
        "as research papers and abstracts, diagnostic proce?",
        "dure reports, and medical records it is important to differentiate between statements about what is the case and what is not the case.",
        "The *SEM 2012 Shared Task is actually two re?",
        "lated tasks run in parallel.",
        "The one this system was developed for is the identification of three features of negation: the cue, the scope, and the factual negated event (if any).",
        "The other task is concerned with the focus of negation.",
        "Detailed description of both subtasks, including definition of the relevant concepts and terminology (negation, cue, scope, event, and focus) appears in this volume (Morante and Blanco, 2012).",
        "Roser Morante and Eduardo Blanco describe the corpora provided to partici?",
        "pants with numbers and examples, methods used used to process the data, and briefly describes each participant and analyzes the overall results.",
        "Annotation of the corpus was undertaken at the University of Antwerp and was performed on sev?",
        "eral Sherlock Holmes works of fiction written by Sir Arthur Conan Doyle.",
        "The corpus includes all sentences from the original text, not just those em?",
        "ploying negation.",
        "Roser Morante and Walter Daelemans provide a thorough explanation of those gold annotations of negation cue, scope, and negated event (if any) (Morante and Daelemans, 2012).",
        "Their paper explains the motivations for the particular annotation decisions and describes in de?",
        "tail the guidelines, including many examples."
      ]
    },
    {
      "heading": "2 Related Work",
      "text": [
        "Recognition of phrases containing negation, partic?",
        "ularly in the medical domain, using regular expres?",
        "sions has been described using several different ap?",
        "proaches.",
        "Systems such as Negfinder (Mutalik et",
        "al, 2001) and NegEx (Chapman et al., 2001) use manually constructed rules to extract phrases from text and classify them as to whether they contain an expression of negation.",
        "Rokach et alevaluate several methods and show their highest level of performance (an F1 of 95.9 ?",
        "1.9%) by using cas?",
        "caded decision trees of regular expressions learned from labelled narrative medical reports (Rokach et al., 2008).",
        "Those systems perform a different function than that required for this task though.",
        "They classify phrases extracted from plain text as to whether they contain negation or not, while the requirement of this shared task for negation cue detection is to identify the particular token(s) or part of a token that signals the presence of negation.",
        "Furthermore, those systems only identify the scope of negation at the level of phrasal constituents, which is differ?",
        "ent than what is required for this task in which the scopes are not necessarily contiguous.",
        "Conditional Random Field (CRF) sequence tag?",
        "gers have been successfully applied to many scope resolution problems, including those of negation.",
        "The NegScope system (Agarwal and Yu, 2010) trains a CRF sequence tagger on labelled data to identify both the cue and scope of negation.",
        "How?",
        "ever, that system only recognizes a whole word as a cue and does not recognize nor generalize nega?",
        "tion cues which are affixes.",
        "There are also systems that use CRF sequence taggers for detection of hedge scopes (Tang et al. 2010, Zhao et al. 2010).",
        "Morante and Daelemans describe a method for im?",
        "proving resolution of the scope of negation by combining IGTREE, CRF, and Support Vector Ma?",
        "chines (SVM) (Morante and Daelemans, 2009)."
      ]
    },
    {
      "heading": "3 System Description",
      "text": [
        "This system is implemented as a three stage cas?",
        "cade with the output from each of the first two stages included as input to the subsequent stage.",
        "The stages are ordered as cue detection, scope de?",
        "tection, and finally negated event detection.",
        "The format of the inputs and outputs for each stage use the shared task's CoNLL?style file format.",
        "That simplifies the use of the supplied gold?standard data for training of each stage separately.",
        "Because this system was designed for the closed track of the shared task, it makes minimal language?specific assumptions and learns (nearly) all language?specific rules from the gold?labelled training data (which includes the development set for the final system).",
        "The CRF sequence tagger used by the system is that implemented in the SimpleTagger class of the MALLET toolkit, which is a Java library distrib?",
        "uted under the Common Public License2.",
        "The system is implemented in the Groovy pro?",
        "gramming language, an agile and dynamic lan?",
        "guage for the Java Virtual Machine3.",
        "The source code is available under the GNU Public License on GitHub4."
      ]
    },
    {
      "heading": "3.1 Cue Detection",
      "text": [
        "Cues are recognized by four different regular ex?",
        "pression rule patterns: affixes (partial token), single (whole) token, contiguous multiple token, and gappy (discontiguous) multiple token.",
        "The rules are learned by a two pass process.",
        "In the first pass, for each positive example of a negation cue in the training data, a rule that matches that example is added to the prospective rule set.",
        "Then, in the sec?",
        "ond pass, the rules are applied to the training data and the counts of correct and incorrect matches are accumulated.",
        "Rules that are wrong more often than they are right are removed from the set used by the system.",
        "A further filtering of the prospective rules is done in which gappy multiple token rules that match the same word type more than once are re?",
        "moved.",
        "Those prospective rules are created to match cases in the supplied training data where the a repetition has occurred and then encoded by the annotators as a single cue (and thus scope) of nega?",
        "tion5.",
        "The single token and multiple token rules match both the word string feature (ignoring case) and the part?of?speech (POS) feature of each token.",
        "And because a single token rule might also match a cue that belongs to a multiple token rule, multiple to?",
        "ken rules are checked first.",
        "Affix rules are of two types: prefix cues and non?prefix cues.",
        "The distinction is that while pre?",
        "fix cues must match starting at the beginning of the word string, the non?prefix cues may have a suffix following them in the word string that is not part of the cue.",
        "Affix rules only match against the word",
        "string feature of the tokens and are insensitive to the POS feature.",
        "In order to generalize the affix rules, sets are ac?",
        "cumulated of both base word strings (the substring following a prefix cue or substring preceding a non?prefix cue) and suffixes (the substring follow?",
        "ing non?prefix cues, if any).",
        "In addition, all other word strings and lemma strings in the training cor?",
        "pus that are at least four characters long are added to the set of possible base word strings6.",
        "A set of negative word strings is also accumulated in the second pass of the rule training to condition against false positive matches for each affix rule.",
        "A prefix cue rule will match a token with a word string that starts with the cue string and is followed by any of the strings in the base word set.",
        "Similarly a suffix cue rule will match a token whose word string contains the cue string preceded by a string in the base word set and is either at the end of the string or is followed by one of the strings in the suffix string set.",
        "Affix rules, unlike the other cue?matching rules, also output the string for matched base word as the value of the scope for the matched token.",
        "In any case, if the token's word string is in the negative word string set for the rule then it will not be matched.",
        "Following submission of the system outputs for the shared tasked I discovered that a hand written regular expression rule that filters out the (poten?",
        "tial) cues detected for ?",
        "(be|have) no doubt?",
        "and ?none the (worse|less)?",
        "was inadvertently included in the system.",
        "Although those rules could be learned automatically from the training data (and such was my intention), the system as reported here does not currently do so."
      ]
    },
    {
      "heading": "3.2 Negation Scope Resolution",
      "text": [
        "For each cue detected, scope resolution is per?",
        "formed as a ternary classification of each token in the sentence as to whether it is part of a cue, part of a scope, or neither.",
        "The classifier is the CRF se?",
        "quence tagger implemented in the SimpleTagger class of the MALLET toolkit (McCallum, 2002).",
        "Training is performed using the gold?standard data including the gold cues.",
        "The output of the tagger is not used to determine the scope value of a token in 6This ?longer than four character?",
        "rule was manually created to correct for over?generalization observed in the training data.",
        "If the affix rule learner selected this value using the correct/in?",
        "correct counts as it does with the other rule parameters then this bit of language?specific tweaking would be unnecessary.",
        "those cases where an affix rule in the cue detector has matched a token and therefore has supplied the matched base word string as the value of the scope for the token.",
        "For features that are computed in terms of the cue token, the first (lowest numbered) token marked as a cue is used when there is more than one cue token for the scope.",
        "Features used by the scope CRF sequence tag?",
        "ger are: ?",
        "Of the per?token data: word string in low?",
        "ercase, lemma string in lowercase, part?of?",
        "speech (POS) tag, binary flag indicating whether the token is a cue, a binary flag in?",
        "dicating whether the token is at the edge of its parent non'terminal node or an internal sibling, a binary flag indicating whether the token is a cue token, and relative posi?",
        "tion to the cue token in number of tokens.",
        "?",
        "Of the cue token data: word string in low?",
        "ercase, lemma string in lowercase, and POS tag.",
        "?",
        "Of the path through the syntax tree from the cue token: an ordered list of the non?",
        "terminal labels of each node up the tree to the lowest common parent, an ordered list of the non'terminal labels of each node down the tree from that lowest common parent, a path relation value consisting of the label of the lowest common parent node concatenated with an indication of the relative position of the paths to the cue and token in terms of sibling order."
      ]
    },
    {
      "heading": "3.3 Negated Event Resolution",
      "text": [
        "Detection of the negated event or property is per?",
        "formed using the same CRF sequence tagger and features used for scope detection.",
        "The only differ?",
        "ence is that the token classification is in terms of whether each token in the sentence is part of a fac?",
        "tual negated event for each negation cue."
      ]
    },
    {
      "heading": "3.4 Feature Set Selection",
      "text": [
        "A comparison of the end?to?end performance of this system using several different sets of per token feature choices for the scope and negated event classifiers is shown in Table 1.",
        "In each case the training data is the entire training data and the dev data is the entire dev data supplied by the organiz?",
        "ers for this shared task.",
        "The scores are computed",
        "by the evaluation program also supplied by the or?",
        "ganizers.",
        "The baseline features are those provided in the data, with the exception of the syntactic tree fragment: word string in lowercase, lemma in low?",
        "ercase, and POS tag.",
        "The ?set 1?",
        "features are the remainder of the features described in section 3.2, with the exception of those of the path through the syntax tree from the cue token.",
        "The ?set 2?",
        "fea?",
        "tures are the three baseline features plus the three features of the path through the syntax tree from the cue token: list of non'terminal labels from cue up to the lowest common parent, lowest common parent label concatenated with the relative distance in nodes between the siblings, list of non'terminals from the lowest common parent down to the token.",
        "The ?system?",
        "feature set is the union of set 1 and set 2, and is the one used by the submitted system.",
        "The baseline score is an F1 of 31.5% (P=79.1%, R=19.7%) on the dev data.",
        "Using either feature set 1 or 2 results in substantially better performance.",
        "They achieve nearly the same score on the dev set with an F1 of 50?0.5% (P=87?0.2%, R=35?0.3%) in which the difference is that between one case of true positive vs. false negative out of 173.",
        "The combination of those feature sets is better still though with an F1 of 54.4% (P=88.3%, R=39.3%)."
      ]
    },
    {
      "heading": "4 Results",
      "text": [
        "Table 2 presents the scores computed for the sys?",
        "tem output on the held?out evaluation data.",
        "The F1 for full negation is 48.1% (P=74%, R=35.6%), which is noticeably lower than that seen for the dev data (54.4%).",
        "That reduction is to be expected because the dev data was used for system tuning.",
        "There was also evidence of significant over?fitting to the training data because the F1 for that was 76.5% (P=92%, R=65.5%).",
        "The largest compo?",
        "nent of the fall off in performance is in the recall.",
        "The worst performing component of the system is the negated event detection which has an F1 of 54.3% (P=58%, R=51%) on the evaluation data.",
        "One contributor to low precision for the negated event detector is that the root word of an affix cue is always output as a negated event, bypassing the negated event CRF sequence classifier.",
        "In the combined training and dev data there is a total of 1157 gold cues (and scopes) of which 738 (63.8%) are annotated as having a negated event.",
        "Of the 1198 cues the system outputs for that data, 188 (15.7%) are affix cues, each of which will also be output as a negated event.",
        "Therefore it would be reasonable to expect that approximately 16 (27.7%) of the false positives for the negated event in the evaluation (60) are due to that behavior."
      ]
    },
    {
      "heading": "5 Conclusion",
      "text": [
        "This paper describes the system I implemented for the closed track of the *SEM 2012 Shared Task for negation cue, scope, and event resolution.",
        "The sys?",
        "tem's performance on the held?out evaluation data, an F1 of 48.09% (P=74.02%, R=35.61%) for the full negation, relative to the other entries for the task is fourth among the six teams that partici?",
        "pated.",
        "The strongest part of this system is the scope re?",
        "solver which performs at a level near that of the best?performing systems in this shared task.",
        "I think it is likely that the performance on scope res?",
        "olution would be equivalent to them with a better negation cue detector.",
        "That is supported by the ?no cue match?",
        "version of the scope resolution evalua?",
        "tion for which this system has the highest F1 (72.4%).",
        "Clearly the weakest link is the negated event detector.",
        "Since one obvious source of error is that the root word extracted when an affix cue is de?",
        "tected is always output as a negated event, a promising approach for improvement would be to instead utilize that as a feature for the negated event's CRF sequence tagger so that they have a chance to be filtered out in non?factual contexts."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "I want to thank Roser Morante and Eduardo Blanco for organizing this task, the reviewers for their thorough and very helpful suggestions, and Emily Bender for her guidance."
      ]
    }
  ]
}
