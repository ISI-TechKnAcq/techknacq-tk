{
  "info": {
    "authors": [
      "Ben Hutchinson"
    ],
    "book": "Annual Meeting of the Association for Computational Linguistics",
    "id": "acl-P04-1087",
    "title": "Acquiring the Meaning of Discourse Markers",
    "url": "https://aclweb.org/anthology/P04-1087",
    "year": 2004
  },
  "references": [
    "acl-A00-2018",
    "acl-E99-1007",
    "acl-J03-4002",
    "acl-N04-1020",
    "acl-P00-1010",
    "acl-P02-1047",
    "acl-P03-1059",
    "acl-P97-1011",
    "acl-W02-0908",
    "acl-W98-1414"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper applies machine learning techniques to acquiring aspects of the meaning of discourse markers.",
        "Three subtasks of acquiring the meaning of a discourse marker are considered: learning its polarity, veridicality, and type (i.e. causal, temporal or additive).",
        "Accuracy of over 90% is achieved for all three tasks, well above the baselines."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "This paper is concerned with automatically acquiring the meaning of discourse markers.",
        "By considering the distributions of individual tokens of discourse markers, we classify discourse markers along three dimensions upon which there is substantial agreement in the literature: polarity, veridical-ity and type.",
        "This approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of Baldwin and Bond (2003) and Stevenson and Merlo (1999).",
        "Discourse markers signal relations between discourse units.",
        "As such, discourse markers play an important role in the parsing of natural language discourse (Forbes et al., 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002).",
        "In addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (Moser and Moore, 1995; Grote and Stede, 1998).",
        "It follows that a detailed account of the semantics and pragmatics of discourse markers would be a useful resource for natural language processing.",
        "Rather than looking at the finer subtleties in meaning of particular discourse markers (e.g. Best-gen et al.",
        "(2003)), this paper aims at a broad scale classification of a subclass of discourse markers: structural connectives.",
        "This breadth of coverage is of particular importance for discourse parsing, where a wide range of linguistic realisations must be catered for.",
        "This work can be seen as orthogonal to that of Di Eugenio et al.",
        "(1997), which addresses the problem of learning if and where discourse markers should be generated.",
        "Unfortunately, the manual classification of large numbers of discourse markers has proven to be a difficult task, and no complete classification yet exists.",
        "For example, Knott (1996) presents a list of around 350 discourse markers, but his taxonomic classification, perhaps the largest classification in the literature, accounts for only around 150 of these.",
        "A general method of automatically classifying discourse markers would therefore be of great utility, both for English and for languages with fewer manually created resources.",
        "This paper constitutes a step in that direction.",
        "It attempts to classify discourse markers whose classes are already known, and this allows the classifier to be evaluated empirically.",
        "The proposed task of learning automatically the meaning of discourse markers raises several questions which we hope to answer: Q1.",
        "Difficulty How hard is it to acquire the meaning of discourse markers?",
        "Are some aspects of meaning harder to acquire than others?",
        "Q2.",
        "Choice of features What features are useful for acquiring the meaning of discourse markers?",
        "Does the optimal choice of features depend on the aspect of meaning being learnt?",
        "Q3.",
        "Classifiers Which machine learning algorithms work best for this task?",
        "Can the right choice of empirical features make the classification problems linearly separable?",
        "Q4.",
        "Evidence Can corpus evidence be found for the existing classifications of discourse markers?",
        "Is there empirical evidence for a separate class of TEMPORAL markers?",
        "We proceed by first introducing the classes of discourse markers that we use in our experiments.",
        "Section 3 discusses the database of discourse markers used as our corpus.",
        "In Section 4 we describe our experiments, including choice of features.",
        "The results are presented in Section 5.",
        "Finally, we conclude and discuss future work in Section 6."
      ]
    },
    {
      "heading": "2 Discourse markers",
      "text": [
        "Discourse markers are lexical items (possibly multi-word) that signal relations between propositions, events or speech acts.",
        "Examples of discourse markers are given in Tables 1, 2 and 3.",
        "In this paper we will focus on a subclass of discourse markers known as structural connectives.",
        "These markers, even though they may be multiword expressions, function syntactically as if they were coordinating or subordinating conjunctions (Webber et al., 2003).",
        "The literature contains many different classifications of discourse markers, drawing upon a wide range of evidence including textual cohesion (Halliday and Hasan, 1976), hypotactic conjunctions (Martin, 1992), cognitive plausibility (Sanders et al., 1992), substitutability (Knott, 1996), and psycholinguistic experiments (Louw-erse, 2001).",
        "Nevertheless there is also considerable agreement.",
        "Three dimensions of classification that recur, albeit under a variety of names, are polarity, veridicality and type.",
        "We now discuss each of these in turn."
      ]
    },
    {
      "heading": "2.1 Polarity",
      "text": [
        "Many discourse markers signal a concession, a contrast or the denial of an expectation.",
        "These markers have been described as having the feature polar-ity=NEG-POL.",
        "An example is given in (1).",
        "(1) Suzy’s part-time, but she does more work than the rest of us put together.",
        "(Taken from Knott (1996, p. 185))",
        "This sentence is true if and only if Suzy both is part-time and does more work than the rest of them put together.",
        "In addition, it has the additional effect of signalling that the fact Suzy does more work is surprising – it denies an expectation.",
        "A similar effect can be obtained by using the connective and and adding more context, as in (2)",
        "(2) Suzy’s efficiency is astounding.",
        "She’s part-time, and she does more work than the rest of us put together.",
        "The difference is that although it is possible for and to co-occur with a negative polarity discourse relation, it need not.",
        "Discourse markers like and are said to have the feature polarity=POS-POL.",
        "1 On",
        "the other hand, a NEG-POL discourse marker like but always co-occurs with a negative polarity discourse relation.",
        "The gold standard classes of POS-POL and NEG-POL discourse markers used in the learning experiments are shown in Table 1.",
        "The gold standards for all three experiments were compiled by consulting a range of previous classifications (Knott, 1996; Knott and Dale, 1994; Louwerse, 2001).",
        "2 POS-POL NEG-POL after, and, as, as soon as, although, because, before, considering but, even if, that, ever since, for, given that, even though, if, in case, in order that, in that, even when, insofar as, now, now that, on only if, only the grounds that, once, seeing when, or, or as, since, so, so that, the in else, though, stant, the moment, then, to the unless, until, extent that, when, whenever whereas, yet"
      ]
    },
    {
      "heading": "2.2 Veridicality",
      "text": [
        "A discourse relation is veridical if it implies the truth of both its arguments (Asher and Lascarides, 2003), otherwise it is not.",
        "For example, in (3) it is not necessarily true either that David can stay up or that he promises, or will promise, to be quiet.",
        "For this reason we will say if has the feature veridical-ity=NON-VERIDICAL.",
        "(3) David can stay up if he promises to be quiet.",
        "The disjunctive discourse marker or is also NON-VERIDICAL, because it does not imply that both of its arguments are true.",
        "On the other hand, and does imply this, and so has the feature veridical-ity=VERIDICAL.",
        "The VERIDICAL and NON-VERIDICAL discourse markers used in the learning experiments are shown in Table 2.",
        "Note that the polarity and veridicality are independent, for example even if is both NEG-POL and NON-VERIDICAL."
      ]
    },
    {
      "heading": "2.3 Type",
      "text": [
        "Discourse markers like because signal a CAUSAL relation, for example in (4).",
        "account, discourse markers have positive polarity only if they can never be paraphrased using a discourse marker with negative polarity.",
        "Interpreted in these terms, our experiment aims to distinguish negative polarity discourse markers from all others.",
        "2A n effort was made to exclude discourse markers whose classification could be contentious, as well as ones which showed ambiguity across classes.",
        "Some level ofjudgement was therefore exercised by the author.",
        "VERIDICAL NON-VERIDICAL after, although, and, as, as soon assuming as, because, but, considering that, even if, that, even though, even when, if, if ever, if ever since, for, given that, in or only, in case, der that, in that, insofar as, now, on condition now that, on the grounds that, that, on the once, only when, seeing as, assumption since, so, so that, the instant, that, only if, the moment, then, though, to or, or else, the extent that, until, when, supposing whenever, whereas, while, yet that, unless",
        "Table 2: Discourse markers used in the veridicality experiment (4) The tension in the boardroom rose sharply because the chairman arrived.",
        "As a result, because has the feature type=CAUSAL.",
        "Other discourse markers that express a temporal relation, such as after, have the feature type=TEMPORAL.",
        "Just as a POS-POL discourse marker can occur with a negative polarity discourse relation, the context can also supply a causal relation even when a TEMPORAL discourse marker is used, as in (5).",
        "(5) The tension in the boardroom rose sharply after the chairman arrived.",
        "If the relation a discourse marker signals is neither CAUSAL or TEMPORAL it has the feature type=ADDITIVE.",
        "The need for a distinct class of TEMPORAL discourse relations is disputed in the literature.",
        "On the one hand, it has been suggested that TEMPORAL relations are a subclass of ADDITIVE ones on the grounds that the temporal reference inherent in the marking of tense and aspect “more or less” fixes the temporal ordering of events (Sanders et al., 1992).",
        "This contrasts with arguments that resolving discourse relations and temporal order occur as distinct but interrelated processes (Lascarides and Asher, 1993).",
        "On the other hand, several of the discourse markers we count as TEMPORAL, such as as soon as, might be described as CAUSAL (Oberlan-der and Knott, 1995).",
        "One of the results of the experiments described below is that corpus evidence suggests ADDITIVE, TEMPORAL and CAUSAL discourse markers have distinct distributions.",
        "The ADDITIVE, TEMPORAL and CAUSAL discourse markers used in the learning experiments are shown in Table 3.",
        "These features are independent of the previous ones, for example even though is CAUSAL, VERIDICAL and NEG-POL.",
        "ADDITIVE TEMPORAL CAUSAL and, but, after, as although, because, whereas soon as, even though, for, given before, that, if, if ever, in case, ever on condition that, on since, the assumption that, now, now on the grounds that, that, once, provided that, provid-until, ing that, so, so that, when, supposing that, though, whenever unless"
      ]
    },
    {
      "heading": "3 Corpus",
      "text": [
        "The data for the experiments comes from a database of sentences collected automatically from the British National Corpus and the world wide web (Hutchinson, 2004).",
        "The database contains example sentences for each of 140 discourse structural connectives.",
        "Many discourse markers have surface forms with other usages, e.g. before in the phrase before noon.",
        "The following procedure was therefore used to select sentences for inclusion in the database.",
        "First, sentences containing a string matching the surface form of a structural connective were extracted.",
        "These sentences were then parsed using a statistical parser (Charniak, 2000).",
        "Potential structural connectives were then classified on the basis of their syntactic context, in particular their proximity to S nodes.",
        "Figure 1 shows example syntactic contexts which were used to identify discourse markers.",
        "It is because structural connectives are easy to identify in this manner that the experiments use only this subclass of discourse markers.",
        "Due to both parser errors, and the fact that the syntactic heuristics are not foolproof, the database contains noise.",
        "Manual analysis of a sample of 500 sentences revealed about 12% of sentences do not contain the discourse marker they are supposed to.",
        "Of the discourse markers used in the experiments, their frequencies in the database ranged from 270 for the instant to 331,701 for and.",
        "The mean number of instances was 32,770, while the median was 4,948."
      ]
    },
    {
      "heading": "4 Experiments",
      "text": [
        "This section presents three machine learning experiments into automatically classifying discourse markers according to their polarity, veridicality and type.",
        "We begin in Section 4.1 by describing the features we extract for each discourse marker token.",
        "Then in Section 4.2 we describe the different classifiers we use.",
        "The results are presented in Section 4.3."
      ]
    },
    {
      "heading": "4.1 Features used",
      "text": [
        "We only used structural connectives in the experiments.",
        "This meant that the clauses linked syntactically were also related at the discourse level (Webber et al., 2003).",
        "Two types of features were extracted from the conjoined clauses.",
        "Firstly, we used lexical co-occurrences with words of various parts of speech.",
        "Secondly, we used a range of linguistically motivated syntactic, semantic, and discourse features.",
        "Lexical co-occurrences have previously been shown to be useful for discourse level learning tasks (La-pata and Lascarides, 2004; Marcu and Echihabi, 2002).",
        "For each discourse marker, the words occurring in their superordinate (main) and subordinate clauses were recorded,3 along with their parts of speech.",
        "We manually clustered the Penn Treebank parts of speech together to obtain coarser grained syntactic categories, as shown in Table 4.",
        "We then lemmatised each word and excluded all lemmas with a frequency of less than 1000 per million in the BNC.",
        "Finally, words were attached a prefix of either SUB_ or SUPER_ according to whether they occurred in the sub or superordinate clause linked by the marker.",
        "This distinguished, for example, between occurrences of then in the antecedent (subordinate) and consequent (main) clauses linked by if.",
        "We also recorded the presence of other discourse markers in the two clauses, as these had previously",
        "been found to be useful on a related classification task (Hutchinson, 2003).",
        "The discourse markers used for this are based on the list of 350 markers given by Knott (1996), and include multiword expressions.",
        "Due to the sparser nature of discourse markers, compared to verbs for example, no frequency cutoffs were used."
      ]
    },
    {
      "heading": "4.1.2 Linguistically motivated features",
      "text": [
        "These included a range of one and two dimensional features representing more abstract linguistic information, and were extracted through automatic analysis of the parse trees.",
        "One dimensional features Two one dimensional features recorded the location of discourse markers.",
        "POSITION indicated whether a discourse marker occurred between the clauses it linked, or before both of them.",
        "It thus relates to information structuring.",
        "EMBEDDING indicated the level of embedding, in number of clauses, of the discourse marker beneath the sentence’s highest level clause.",
        "We were interested to see if some types of discourse relations are more often deeply embedded.",
        "The remaining features recorded the presence of linguistic features that are localised to a particular clause.",
        "Like the lexical co-occurrence features, these were indexed by the clause they occurred in: either SUPER or SUB.",
        "We expected negation to correlate with negative polarity discourse markers, and approximated negation using four features.",
        "NEG-SUBJ and NEG-VERB indicated the presence of subject negation (e.g. nothing) or verbal negation (e.g. n’t).",
        "We also recorded the occurrence of a set of negative polarity items (NPI), such as any and ever.",
        "The features NPI-AND-NEG and NPI-WO-NEG indicated whether an NPI occurred in a clause with or without verbal or subject negation.",
        "Eventualities can be placed or ordered in time using not just discourse markers but also temporal expressions.",
        "The feature TEMPEX recorded the number of temporal expressions in each clause, as returned by a temporal expression tagger (Mani and Wilson, 2000).",
        "If the main verb was an inflection of to be or to do we recorded this using the features BE and DO.",
        "Our motivation was to capture any correlation of these verbs with states and events respectively.",
        "If the final verb was a modal auxiliary, this ellipsis was evidence of strong cohesion in the text (Halliday and Hasan, 1976).",
        "We recorded this with the feature VP-ELLIPSIS.",
        "Pronouns also indicate cohesion, and have been shown to correlate with subjectivity (Bestgen et al., 2003).",
        "A class of features PRONOUNSX represented pronouns, with X denoting either 1 st person, 2nd person, or 3rd person animate, inanimate or plural.",
        "The syntactic structure of each clause was captured using two features, one finer grained and one coarser grained.",
        "STRUCTURAL-SKELETON identified the major constituents under the S or VP nodes, e.g. a simple double object construction gives “NP VB NP NP”.",
        "ARGS identified whether the clause contained an (overt) object, an (overt) subject, or both, or neither.",
        "The overall size of a clause was represented using four features.",
        "WORDS, NPS and PPS recorded the numbers of words, NPs and PPs in a clause (not counting embedded clauses).",
        "The feature CLAUSES counted the number of clauses embedded beneath a clause.",
        "Two dimensional features These features all recorded combinations of linguistic features across the two clauses linked by the discourse marker.",
        "For example the MOOD feature would take the value <DECL,IMP> for the sentence John is coming, but don’t tell anyone!",
        "These features were all determined automatically by analysing the auxiliary verbs and the main verbs’ POS tags.",
        "The features and the possible values for each clause were as follows: MODALITY: one of FUTURE, ABILITY or NULL; MOOD: one of DECL, IMP or INTERR; PERFECT: either YES or NO; PROGRESSIVE: either YES or NO; TENSE: either PAST or PRESENT."
      ]
    },
    {
      "heading": "4.2 Classifier architectures",
      "text": [
        "Two different classifiers, based on local and global methods of comparison, were used in the experiments.",
        "The first, 1 Nearest Neighbour (1NN), is an instance based classifier which assigns each marker to the same class as that of the marker nearest to it.",
        "For this, three different distance metrics were explored.",
        "The first metric was the Euclidean distance function L2, shown in (6), applied to probability distributions.",
        "The second, KLa, is a smoothed variant of the information theoretic Kullback-Leibner divergence (Lee, 2001, with a = 0.95).",
        "Its definition",
        "The third metric, Jacct, is a t-test weighted adaption of the Jaccard coefficient (Curran and Moens, 2002).",
        "In it basic form, the Jaccard coefficient is essentially a measure of how much two distributions overlap.",
        "The t-test variant weights co-occurrences by the strength of their collocation, using the following function:",
        "This is then used define the weighted version of the Jaccard coefficient, as shown in (8).",
        "The words associated with distributions p and q are indicated by wp and wq, respectively.",
        "KLa and Jacct had previously been found to be the best metrics for other tasks involving lexical similarity.",
        "L2 is included to indicate what can be achieved using a somewhat naive metric.",
        "The second classifier used, Naive Bayes, takes the overall distribution of each class into account.",
        "It essentially defines a decision boundary in the form of a curved hyperplane.",
        "The Weka implementation (Witten and Frank, 2000) was used for the experiments, with 10-fold cross-validation."
      ]
    },
    {
      "heading": "4.3 Results",
      "text": [
        "We began by comparing the performance of the 1NN classifier using the various lexical co-occurrence features against the gold standards.",
        "The results using all lexical co-occurrences are shown",
        "in Table 5.",
        "The baseline was obtained by assigning discourse markers to the largest class, i.e. with the most types.",
        "The best results obtained using just a single POS class are also shown.",
        "The results across the different metrics suggest that adverbs and verbs are the best single predictors of polarity and veridicality, respectively.",
        "We next applied the 1NN classifier to co-occurrences with discourse markers.",
        "The results are shown in Table 7.",
        "The results show that for each task 1NN with the weighted Jaccard coefficient performs at least as well as the other three classifiers.",
        "We also compared using the following combinations of different parts of speech: vb + aux, vb + in, vb + rb, nn + prp, vb + nn + prp, vb + aux + rb, vb + aux + in, vb + aux + nn + prp, nn + prp + in, DMs + rb, DMs + vb and DMs + rb + vb.",
        "The best results obtained using all combinations tried are shown in the last column of Table 5.",
        "For DMs + rb, DMs + vb and DMs + rb + vb we also tried weighting the co-occurrences so that the sums of the co-occurrences with each of verbs, adverbs and discourse markers were equal.",
        "However this did not lead to any better results.",
        "One property that distinguishes Jacct from the other metrics is that it weights features the strength of their collocation.",
        "We were therefore interested to see which co-occurrences were most informative.",
        "Using Weka’s feature selection utility, we ranked discourse marker co-occurrences by their information gain when predicting polarity, veridicality and type.",
        "The most informative co-occurrences are listed in Table 6.",
        "For example, if also occurs in the subordinate clause then the discourse marker is more likely to be ADDITIVE.",
        "The 1NN and Naive Bayes classifiers were then applied to co-occurrences with just the DMs that were most informative for each task.",
        "The results, shown in Table 8, indicate that the performance of",
        "Weka’s feature selection utility was also applied to all the linguistically motivated features described in Section 4.1.2.",
        "The most informative features are shown in Table 9.",
        "Naive Bayes was then applied using both all the linguistically motivated features, and just the most informative ones.",
        "The results are shown in Table 10."
      ]
    },
    {
      "heading": "5 Discussion",
      "text": [
        "The results demonstrate that discourse markers can be classified along three different dimensions with an accuracy of over 90%.",
        "The best classifiers used a global algorithm (Naive Bayes), with co-occurrences with a subset of discourse markers as features.",
        "The success of Naive Bayes shows that with the right choice of features the classification task is highly separable.",
        "The high degree of accuracy attained on the type task suggests that there is empirical evidence for a distinct class of TEMPORAL markers.",
        "The results also provide empirical evidence for the correlation between certain linguistic features and types of discourse relation.",
        "Here we restrict ourselves to making just five observations.",
        "Firstly, verbs and adverbs are the most informative parts of speech when classifying discourse markers.",
        "This is presumably because of their close relation to the main predicate of the clause.",
        "Secondly, Table 6 shows that the discourse marker DM in the structure X, but/though/although Y DMZ is more likely to be signalling a positive polarity discourse relation between Y and Z than a negative polarity one.",
        "This suggests that a negative polarity discourse relation is less likely to be embedded directly beneath another negative polarity discourse relation.",
        "Thirdly, negation correlates with the main clause of NEG-POL discourse markers, and it also correlates with subordinate clause of CAUSAL ones.",
        "Fourthly, NON-VERIDICAL correlates with second person pronouns, suggesting that a writer/speaker is less likely to make assertions about the reader/listener than about other entities.",
        "Lastly, the best results with knowledge poor features, i.e. lexical co-occurrences, were better than those with linguistically sophisticated ones.",
        "It may be that the sophisticated features are predictive of only certain subclasses of the classes we used, e.g. hypotheticals, or signallers of contrast."
      ]
    },
    {
      "heading": "6 Conclusions and future work",
      "text": [
        "We have proposed corpus-based techniques for classifying discourse markers along three dimensions: polarity, veridicality and type.",
        "For these tasks we were able to classify with accuracy rates of 90.7%, 91.8% and 93.5% respectively.",
        "These equate to error reduction rates of 71.5%, 69.1% and 84.5% from the baseline error rates.",
        "In addition, we determined which features were most informative for the different classification tasks.",
        "In future work we aim to extend our work in two directions.",
        "Firstly, we will consider finer-grained classification tasks, such as learning whether a causal discourse marker introduces a cause or a consequence, e.g. distinguishing because from so.",
        "Secondly, we would like to see how far our results can be extended to include adverbial discourse markers, such as instead or for example, by using just features of the clauses they occur in."
      ]
    },
    {
      "heading": "Acknowledgements",
      "text": [
        "I would like to thank Mirella Lapata, Alex Lascarides, Bonnie Webber, and the three anonymous reviewers for their comments on drafts of this paper.",
        "This research was supported by EPSRC Grant GR/R40036/01 and a University of Sydney Travelling Scholarship."
      ]
    }
  ]
}
