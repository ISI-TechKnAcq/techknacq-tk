{
  "info": {
    "authors": [
      "Peilu Wang",
      "Zhongye Jia",
      "Hai Zhao"
    ],
    "book": "CoNLL",
    "id": "acl-W14-1710",
    "title": "Grammatical Error Detection and Correction using a Single Maximum Entropy Model",
    "url": "https://aclweb.org/anthology/W14-1710",
    "year": 2014
  },
  "references": [
    "acl-C08-1109",
    "acl-D09-1004",
    "acl-D13-1082",
    "acl-E09-1100",
    "acl-J96-1002",
    "acl-N12-1067",
    "acl-P09-1007",
    "acl-W13-3602",
    "acl-W13-3603",
    "acl-W13-3604",
    "acl-W13-3605",
    "acl-W13-3610",
    "acl-W13-3616",
    "acl-W14-1701"
  ],
  "sections": [
    {
      "text": [
        "Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, pages 74?82, Baltimore, Maryland, 26-27 July 2014. c ?2014 Association for Computational Linguistics Grammatical Error Detection and Correction using a Single Maximum Entropy Model ?",
        "Peilu Wang, Zhongye Jia and Hai Zhao ?",
        "Abstract",
        "This paper describes the system of Shanghai Jiao Tong Unvierity team in the CoNLL-2014 shared task.",
        "Error correction operations are encoded as a group of predefined labels and therefore the task is formulized as a multi-label classification task.",
        "For training, labels are obtained through a strict rule-based approach.",
        "For decoding, errors are detected and corrected according to the classification results.",
        "A single maximum entropy model is used for the classification implementation incorporated with an improved feature selection algorithm.",
        "Our system achieved precision of 29.83, recall of 5.16 and F 0.5 of 15.24 in the official evaluation."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "The task of CoNLL-2014 is grammatical error correction which consists of detecting and correcting the grammatical errors in English essays written by non-native speakers (Ng et al., 2014).",
        "The research of grammatical error correction can potentially help millions of people in the world who are learning English as foreign language.",
        "Although there have been many works on grammatical error correction, the current approaches mainly focus on very limited error types and the result is far from satisfactory.",
        "The CoNLL-2014 shared task, compared with the previous Help Our Own (HOO) tasks (Dale et al., 2012) considering only determiner and preposition errors and the CoNLL-2013 shared task fo-?",
        "This work was partially supported by the National Natural Science Foundation of China (Grant No.60903119, Grant No.61170114, and Grant No.61272248), the National Basic Research Program of China (Grant No.2013CB329401), the Science and Technology Commission of Shanghai Municipality (Grant No.13511500200), and the European Union Seventh Framework Program (Grant No.247619).",
        "?",
        "Corresponding author cusing on five major types of errors, requires to correct all 28 types of errors (Ng et al., 2014).",
        "One traditional strategy is designing a system combined of a set of sub-models, where each sub-model is specialized for a specific subtask, for ex-ample, correcting one type of errors.",
        "This strategy is computationally efficient and can adopt different favorable features for each subtask.",
        "Top ranked systems in CoNLL-2013 (Rozovskaya et al., 2013; Kao et al., 2013; Xing et al., 2013; Yoshimoto et al., 2013; Xiang et al., 2013) are based on this strategy.",
        "However, the division of the model relies on prior-knowledges and the designing of different features for each sub-model requires a large amount of manual works.",
        "This shortage is especially notable in CoNLL-2014 shared task, since the number of error types is much larger and the composition of errors is more complicated than before.",
        "In contrast, we follow the work in (Jia et al., 2013a; Zhao et al., 2009a), integrating everything into one model.",
        "This integrated system holds a merit that a one-way feature selection benefits the whole system and no additional process is needed to deal with the conflict or error propagation of every sub-models.",
        "Here is a glance of this method: A set of more detailed error types are generated automatically from the original 28 types of errors.",
        "The detailed error type can be regarded as the label of a word, thus the task of grammatical error detection is transformed to a multi-label classification task using maximum entropy model (Berger et al., 1996; Zhao et al., 2013).",
        "A feature selection approach is introduced to get effective features from large amounts of feature candidates.",
        "Once errors are detected through word label classification, a rule-based method is used to make corrections according to their labels.",
        "The rest of the paper is organized as follows.",
        "Section 2 describes the system architecture.",
        "Section 3 introduces the feature selection approach 74 and the features we used.",
        "Experiments and results are presented in section 5, followed by conclusion.",
        "2 System Architecture In our approach, the grammatical error detection is regarded as a multi-label classification task.",
        "At first, each token in training corpus is assigned a label according to the golden annotation.",
        "The construction of labels is rule based using an extended version of Levenshtein edit distance algorithm which will be discussed in the following subsection.",
        "Each label maps an edit operation to do the correction, thus the generated labels are much more detailed than the originial 28 error types.",
        "Then, a maximum entropy (ME) model is adopted as the classifier.",
        "With the labeled data, the process of grammatical error correction is just applying the edit operation mapped by each label, which is basically the reverse of the labeling phase.",
        "2.1 Data Labeling In CoNLL-2014 shared task, there are 28 error types but they can not be used directly as class la-bels, since these types are too general that they can hardly be corrected by applying one rule-based edit.",
        "For example, the correction of Vform (ver- b form) error type includes all verb form inflections such as converting a verb to its infinitive for-m, gerund form, past form and past participle and so on.",
        "Previous works (Dahlmeier et al., 2012; Rozovskaya et al., 2012; Kochmar et al., 2012) manually decompose each error types to more detailed subtypes.",
        "For example, in (Dahlmeier et al., 2012), the determinater errors are decomposed in-to: ?",
        "replacement determiner (RD): { a ?",
        "the } ?",
        "missing determiner (MD): { ?",
        "?",
        "a } ?",
        "unwanted determiner (UD): { a ?",
        "? }",
        "For a task with a few error types such as merely determinative and preposition error in HOO 2012, manually decomposition may be sufficient.",
        "How-ever, for CoNLL-2014, all 28 error types are required to be corrected and some of these types such as Rloc-(Local redundancy) and Um (Un- clear meaning) are quite complex that the manual decomposition is time consuming and requires lots of grammatical knowledges.",
        "Therefore, an au-tomatica decomposition method is proposed.",
        "It is extended from the Levenshtein edit distance algorithm and can divide error types into more detailed subtypes that each subtype can be corrected by applying one simple rule.",
        "How to calculate the extended Levenshtein edit distance is described in Algorithm 1.",
        "Algorithm 1 Extended Levenshtein Edit Distance INPUT: toks src , toks dst OUTPUT: E,P l src , l dst ?",
        "len(toks src ), len(toks dst ) D[0 .",
        ".",
        ".",
        "l src ][0 .",
        ".",
        ".",
        "l dst ]?",
        "0 B[0 .",
        ".",
        ".",
        "l src ][0 .",
        ".",
        ".",
        "l dst ]?",
        "(0, 0) E[0 .",
        ".",
        ".",
        "l src ][0 .",
        ".",
        ".",
        "l dst ]?",
        "?",
        "for i?",
        "1 .",
        ".",
        ".",
        "l src do D[i][0]?",
        "i B[i][0]?",
        "(i-1, 0) E[i][0]?",
        "D end for for j ?",
        "1 .",
        ".",
        ".",
        "l dst do D[0][j]?",
        "j B[0][j]?",
        "(0, j-1) E[0][j]?",
        "A end for for i?",
        "1 .",
        ".",
        ".",
        "l src ; do for j ?",
        "1 .",
        ".",
        ".",
        "l dst do if toks src [i-1] = toks dst [j-1] then D[i][j]?",
        "D[i-1][j-1] B[i][j]?",
        "(i-1, j-1) E[i][j]?",
        "U else m = min(D[i-1][j-1], D[i-1][j], D[i][j-1]) if m = D[i-1][j-1] then D[i][j]?",
        "D[i-1][j-1] + 1 B[i][j]?",
        "(i-1, j-1) if lemma(toks src [i-1]) = lemma(toks dst [j-1]) then E[i][j]?",
        "S else E[i][j]?",
        "I end if else if m = D[i-1][j] then D[i][j]?",
        "D[i-1][j] + 1 B[i][j]?",
        "(i-1, j) E[i][j]?",
        "D else if m = D[i][j-1] then D[i][j]?",
        "D[i][j-1] + 1 B[i][j]?",
        "(i, j-1) E[i][j]?",
        "A end if end if end for end for i, j ?",
        "l src , l dst while i > 0 ?",
        "j > 0 do insert E[i][j] into head of E insert toks dst [j ?",
        "1] into head of P (i, j)?",
        "B[i][j] end while return (E,P) In this algorithm, toks src represents the tokens that are annotated with one grammatical error and toks dst represents the corrected tokens of toks src .",
        "At first, three two dimensional matrixes D, B and 75 E are initialized.",
        "For all i and j, D[i][j] holds the Levenshtein distance between the first i tokens of toks src and first j tokens of toks dst .",
        "B stores the path of the Levenshtein distance and E stores the edit operations in this path.",
        "The original Levenshtein edit distance has 4 edit operations: unchange (U ), addition (A), deletion (D) and substitution (S).",
        "We extend the ?substitution?",
        "edit into two types of edits: inflection (I) and the original substitution (S).",
        "If two different words have the same lemma, the substitution operation is I, else is S. lemma(x) returns the lemma of token x.",
        "This algorithm returns the edit operations E and the parameters of these operations P. Here is a simple sample illustrating this algorithm.",
        "For the golden edit {a red apple is ?",
        "red apples are}, toks src is a red apple is, toks dst is red apples are, the output edits E will be {D,U , I,S}, and the parameters P will be {-, red, apples, are}.",
        "Then with the output of this extended Levenshtein distance algorithm, labels can be generated by transforming these edit operations into readable symbols.",
        "For those tokens without errors, we directly assign a special label ???",
        "to them.",
        "A tricky part of the labeling process is the problem of the edit ?addition?,A.",
        "A new token can only be added before or after an existing token.",
        "Thus for edit operation with addition, we must find an existing token that the label can be assigned to, and this sort of token is defined as pivot.",
        "A pivot can be a token that is not changed in an edit operation, such as the ?apple?",
        "in edit {apple ?",
        "an apple}, or some other types of edit such as the inflection of ?look?",
        "to ?looking?",
        "in edit {look ?",
        "have been looking at}.",
        "The names of these labels are based on BNF syntax which is defined in Figure 1.",
        "The non-terminal ?word?",
        "can be substituted by all words in the vocabulary.",
        "The non-terminal ?inflection- rules?",
        "can be substituted by terminals of inflection rules that are used for correcting the error types of noun number, verb form, and subject-verb agreement errors.",
        "All the inflection rules are listed in Table 1.",
        "With the output of extended Levenshtein edits distance algorithm, Algorithm 2 gives the process to generate labels whose names are based on the syntax defined in Figure 1.",
        "It takes the output E, P of Algorithm 1 as inputs and returns the generated set of labels L. Each label in L corresponds to one token in toks src in order.",
        "For our previous example of edit {a red apple is ?",
        "red apples are}, ?label?",
        "::= ?simple-label?",
        "| ?compound-label?",
        "?simple-label?",
        "::= ?pivot?",
        "| ?add-before?",
        "| ?add-after?",
        "?compound-label?",
        "::= ?add-before?",
        "?pivot?",
        "| ?pivot?",
        "?add-after?",
        "| ?add-before?",
        "?pivot?",
        "?add-after?",
        "?pivot?",
        "::= ?unchange?",
        "| ?substitution?",
        "| ?inflection?",
        "| ?deletion?",
        "?add-before?",
        "::= ?word??",
        "| ?word???add-before?",
        "?add-after?",
        "::= ??word?",
        "| ??word??add-after?",
        "?substitution?",
        "::= ?word?",
        "?inflection?",
        "::= ?inflection-rules?",
        "?unchange?",
        "::= ?",
        "?deletion?",
        "::= ?",
        "Figure 1: BNF syntax of label Rules Description LEMMA change word to its lemma NPLURAL change noun to its plural form VSINGULAR change verb to its singular form GERUND change verb to its gerund form PAST change verb to its past form PART change verb to its past participle Table 1: Inflection rules the L returned by Algorithm 2 is {?, ?, NPLU-RAL, ARE} corresponding to the tokens {a, red, apple, is} in toks src .",
        "Some other examples of the generated labels are presented in Table 2.",
        "These labels are elaborately designed that each of them can be interpreted easily as a series of edit operations.",
        "Once the labels are determined by classifier, the correction of the grammatical errors is conducted by applying the edit operations interpreted from these labels.",
        "76 Algorithm 2 Labeling Algorithm 1: INPUT: E,P 2: OUTPUT: L 3: pivot?",
        "number of edits in E that are not A 4: L?",
        "?",
        "5: L?",
        "??",
        "6: while i < length(E) do 7: if E[i] = A then 8: L?",
        "L+ label of edit E[i] with P[i] 9: i?",
        "i + 1 10: else 11: l?",
        "L+ label of edit E[i] with P[i] 12: pivot?",
        "pivot?",
        "1 13: if pivot = 0 then 14: i?",
        "i + 1 15: while i < length of E do 16: l?",
        "l +?+ P[i] 17: i?",
        "i + 1 18: end while 19: end if 20: push l into L 21: L?",
        "??",
        "22: end if 23: end while 24: L?",
        "upper case of L 25: return L Tokens Edit Label to {to reveal?revealing} ?",
        "reveal GERUND a {a woman?women} ?",
        "woman NPLURAL developing {developing world THE?",
        "wold ?the developing world} ?",
        "a {a?",
        "?}",
        "?",
        "in {in?on} ON apple {apple?an apple} AN?",
        "Table 2: Examples of labeling 2.2 Label Classification Using the approach described above, the training corpus is converted to a sequence of words with labels.",
        "Maximum entropy model is used as the classifier.",
        "It allows a very rich set of features to be used in a model and has shown good performance in similiar tasks (Zhao et al., 2013).",
        "The features we used are discussed in the next section.",
        "3 Feature Selection and Generation One key factor affecting the performance of maximum entropy classifier is the features it used.",
        "A good feature that contains useful information to guide classification will significantly improve the performance of the classifier.",
        "One direct way to involve more good features is involving more features.",
        "In our approach, large amounts of candidate features are collected at first.",
        "We carefully examine the factors involved in a wide range of features that have been or can be used to the word label classification task.",
        "Many features that are considered effective in various of previous works (Dahlmeier et al., 2012; Rozovskaya et al., 2012; Han et al., 2006; Rozovskaya et al., 2011; Tetreault, Joel R and Chodorow, Martin, 2008) are included.",
        "Besides, features that are used in the similar spell checking tasks (Jia et al., 2013b; Yang et al., 2012) and some novel features showing effectiveness in other NLP tasks (Wang et al., 2013; Zhang and Zhao, 2013; Xu and Zhao, 2012; Ma and Zhao, 2012; Zhao, 2009; Zhao et al., 2009b) are also included.",
        "However, using too many features is time consuming.",
        "Besides, it increases the probability of overfitting and may lead to a poor solution of the maximum-likelihood parameter estimate in the ME training.",
        "Algorithm 3 Greedy Feature Selection 1: INPUT: all feature candidates F 2: OUTPUT: selected features S 3: S = {f 0 , f 1 , .",
        ".",
        ".",
        ", f k }, a random subset of F 4: while do 5: C = RECRUITMORE(S) 6: if C = {} then 7: return S 8: end if 9: S ?",
        "= SHAKEOFF(S+C) 10: if scr(M(S)) ?",
        "scr(M(S ? ))",
        "then 11: return S 12: end if 13: S = S ?",
        "14: end while 15: function RECRUITMORE(S) 16: C = {}, and p = scr(M(S)) 17: for each f ?",
        "F ?",
        "S do 18: if p < scr(M(S + {f})) then 19: C = C + {f} 20: end if 21: end for 22: end function 23: function SHAKEOFF(S) 24: while do 25: S ?",
        "= S 0 = S 26: for each f ?",
        "S do 27: if scr(M(S ? ))",
        "< scr(M(S ?",
        "?",
        "{f})) then 28: S ?",
        "= S ?",
        "?",
        "{f} 29: end if 30: end for 31: S = S ?",
        "32: if S ?",
        "= S 0 then 33: return S ?",
        "34: end if 35: end while 36: end function Therefore a feature selection algorithm is introduced to filter out ?bad?",
        "features at first and the remaining features will be used to generate new features.",
        "The feature selection algorithm has shown 77 effectiveness in (Zhao et al., 2013) and is presented in Algorithm 3.",
        "In this algorithm, M(S) represents the model using feature set S and scr(M) represents the evaluation score of model M on a development data set.",
        "It repeats two main steps until no further performance gain is achievable: 1.",
        "Include any features from the rest of F into the current set of candidate features if the inclusion would lead to a performance gain.",
        "2.",
        "Exclude any features from the current set of candidate templates if the exclusion would lead to no deterioration in performance.",
        "By repeatedly adding the useful and removing the useless features, the algorithm aims to return a better and smaller set of features for next round.",
        "Only 55 of the 109 candidate features remain after using this algorithm and they are presented in Table 4.",
        "Table 3 gives an interpretation of the abbreviations used in Table 4.",
        "Each feature of a word is set to that listed in feature column if the word satisfies the condition listed in current word col-umn, else the feature is set to ?NULL?.",
        "For ex-ample, if the current word satisfies the condition in the first row of Table 4 which is the first word in the left of a NC, feature 1 of this word is set to all words in the NC, otherwise, feature 1 is set to ?NULL?.",
        "4 Experiment 4.1 Data Sets The CoNLL-2014 training data is a corpus of learner English provided by (Dahlmeier et al., 2013).",
        "This corpus consists of 1,397 articles, 12K sentences and 116K tokens.",
        "The official blind test data consists of 50 articles, 245 sentences and 30K tokens.",
        "More detailed information about this data is described in (Ng et al., 2014; Dahlmeier et al., 2013).",
        "In development phase, the entire training corpus is splited by sentence.",
        "80% sentences are picked up randomly and used for training and the rest 20% are used as the developing corpus.",
        "For the final submission, the entire corpus is used for training.",
        "Abbreviation Description NP Noun Phrase NC Noun Compound and is active if second to last word in NP is tagged as noun VP Verb Phrase cw Current Word pos part-of-speech of the current word X.l i the ith word in the left of X X.r i the ith word in the right of X NP[0] the first word of NP NP.head the head word of NP NP.",
        "(DT or IN or TO) word in NP whose pos is DT or IN or TO VP.verb word in VPwhose pos is verb VP.NP NP in VP dp the dependency relation generated by standford dependency parser dp.dep the dependent in the dependency relation dp.head the head in the dependency relation dp.rel the type of the dependency relation Table 3: The interpretation of the abbrevations in Table 4 4.2 Data Labeling The labeling algorithm described in section 2.1 is firstly applied to the training corpus.",
        "Total 7047 labels are generated and those whose count is larger than 15 is presented in Table 5.",
        "Directly applying these 7047 labels for correction receives an M 2 score of precision=90.2%, recall=87.0% and F 0.5=89.5%.",
        "However, the number of labels is too large that the training process is time consuming and those labels appears only few times will hurt the generalization of the trained model.",
        "Therefore, labels with low frequency which appear less than 30 times are cut out and 109 labels remain.",
        "The M 2 score of the system using this refined labels is precision=83.9%, recall=64.0% and F 0.5=79.0%.",
        "Note that even applying all labels, the F 0.5 is not 100%.",
        "It is because some annotations in the training corpus are not consistency.",
        "78 current word feature NC.l 1 NC NP.l 1 NP NP[0] NP.l 1 .pos NC.l 1 NC NC.l 1 NC.l 1 .pos NC.l 1 and pos=DT NC NC.l 1 and pos=VB NC NP.l 1 and pos=VB NP pos=VB cw pos=DT cw the cw.r 1 a cw.r 1 an cw.r 1 NP[0] cw NP[0] NP.l 1 NP[0] NP.l 2 NP[0] NP.l 3 NP[0] NP.l 1 .pos NP[0] NP.l 2 .pos NP[0] NP.l 3 .pos NP.l 1 NP.head NP.l 1 NP.head.pos NP.head NP.",
        "head NP.head NP.",
        "head.bag NP.head NP.",
        "head.pos NP.head NP.",
        "head.pos.bag NP.head NP.",
        "(JJ or CC) NP.",
        "(DT or IN or TO) NP NP.",
        "(DT or IN or TO) NP.head NP.",
        "(DT or IN or TO) NP.head.pos dp.dep dp.head dp.head dp.dep dp.dep dp.head.pos dp.head dp.dep.pos dp.dep dp.rel dp.head dp.rel VP.verb VP.NP VP.verb VP.NP.head VP.NP.head VP.verb VP.verb VP.NP.head.pos VP.NP.head VP.verb.pos cw cw.l i , i ?",
        "{0, 1, 2, 3} cw cw.r i , i ?",
        "{1, 2, 3} cw cw.l i .pos, i ?",
        "{0, 1, 2, 3} cw cw.r i .pos, i ?",
        "{1, 2, 3} Table 4: Remained features after the feature selection.",
        "Count Label 1091911 ?",
        "31507 ?",
        "3637 NPLURAL 2822 THE?",
        "2600 LEMMA 948 ,?",
        "300?900 A?",
        "PAST THE IN TO .",
        "IS OF ARE FOR GERUND , 50?100 AND ON AN?",
        "A VSINGULAR WAS THEIR 20?50 ELDERLY IT OF?",
        "THEY WITH TO?",
        "WERE THIS ; ITS .?",
        "THAT ?S?",
        "AND?",
        "THAT?",
        "HAVE?",
        "CAN AS HAVE?PART FROM BE WOULD BY 15?20 HAVE HAS?WILL HAS AT AN THESE ?, THEM IN?",
        "INTO #?",
        "ARE?",
        "WHICH PEOPLE HAS?PART ECONOMIC IS?",
        "BE?",
        "SO COULD TO?LEMMA MANY PART MAY LESS IT?",
        "FOR?",
        "BEING?",
        "15?20 NOT ABOUT WILL?LEMMA SHOULD HIS BECAUSE AGED SUCH ALSO WHICH?",
        "HAVE?PAST WILL?",
        "WHO WHEN MUCH 15?20 ON?",
        "?",
        "THROUGH BE?PAST MORE IF HELP THE?ELDERLY ?S ONE AS?",
        "THERE THEIR?",
        "WITH?",
        "HAVE??",
        "ECONOMY DEVELOPMENT CONCERNED PEOPLE?",
        "PROBLEMS BUT MEANS THEREFORE HOWEVER BEING : UP PROBLEM ??",
        "THE?LEMMA IN?ADDITION HOWEVER?,?",
        "AMONG ;?",
        "WHERE THUS ONLY HEALTH HAS?PAST FUNDING EXTENT ALSO?",
        "TECHNOLOGICAL ?",
        "OR HAD WOULD?",
        "VERY .",
        "?THIS ITS?",
        "IMPORTANT DEVELOPED ?BEEN AGE ABOUT?WHO?",
        "USE THEY?",
        "THAN NUMBER HOWEVER?, GOVERNMENT FURTHERMORE DURING BUT?",
        "YOUNGER RIGHT POPULATION PERSON?",
        "FEWER ENVIRONMENTALLY WOULD?LEMMA OTHER MAY?",
        "LIMITED HE COULD?HAVE BEEN STILL SPENDING SAFETY OVER ONE?",
        "?S MAKE MADE LIFE HUMAN HAD?",
        "FUNDS CARE ARGUED ALL ??",
        "WHEN?",
        "TIME THOSE SOCIETY RESEARCH PROVIDE OLD NEEDS INCREASING DEVELOPING BECOME BE??",
        "ADDITION Table 5: Labels whose count is larger than 15. current word feature NC.l 1 NC, cw, cw.l 1 , cw.l 1 .pos, cw.r 1 , cw.r 1 .pos NP[0] NP.head, NP.l 1 , NP.l 2 , cw, cw.l 1 , cw.l 1 .pos, NP.head NP[0], NP.l 1 , NP.l 2 , cw, cw.l 1 , cw.l 1 .pos, dp.head cw, cw.l 1 , cw.l 2 dp.dep, dp.dep.pos, dp.rel Table 6: Examples of the new generated features.",
        "79 4.3 Data Refinement The training corpus is refined before used that sentences which do not contain errors are filtered out.",
        "Only 38% of the total sentences remain.",
        "With less training corpus, it takes less time to train the ME model.",
        "Table 7 presents the performance of systems using the unrefined training corpus and refined corpus.",
        "System Presicion Recall F 0.5 unrefined 26.99% 1.67% 6.71% refined 11.17% 3.1% 7.34% Table 7: Comparison of systems with different training corpus.",
        "All sets of these systems are kept the same except the training corpus they use.",
        "It can be seen that the refinement also improves the performance of the system.",
        "4.4 Feature Selection Figure 2 shows the results of systems with different feature sets.",
        "sys 10 is the system with Figure 2: Performance of systems with different features.",
        "10 randomly chosen features which are used as the initial set of features in Algorithm 3, sys 55 is the system with the refined 55 features.",
        "With these refined features, various of new features are generated by combining different features.",
        "This combination is conducted empirically that features which are considered having relations are combined to generate new features.",
        "Using this method, 165 new features are generated and total 220 features are used in sys 220.",
        "Table 6 gives a few of examples showing the combined features.",
        "The performance is evaluated by the precision, recall and F 0.5 score of the M 2 scorer according to (Dahlmeier and Ng, 2012).",
        "It can be seen that sys 220 with the most number of features achieves the best performance.",
        "4.5 Evaluation Result The final system we use is sys 220 with refined training data, the performance of our system on the developing corpus and the blind official test data is presented in Table 8.",
        "The score is calculated using M 2 scorer.",
        "Data Set Precision Recall F 0.5 DEV 13.52% 6.41% 11.07% OFFICIAL 29.83% 5.16% 15.24% Table 8: Evaluation Results 5 Conclusion In this paper, we describe the system of Shanghai Jiao Tong Univerity team in the CoNLL-2014 shared task.",
        "The grammatical error detection is regarded as a multi-label classification task and the correction is conducted by applying a rule-based approach based on these labels.",
        "A single maximum entropy classifier is introduced to do the multi-label classification.",
        "Various features are involved and a feature selection algorithm is used to refine these features.",
        "Finally, large amounts of feature templates that are generated by the combination of the refined features are used.",
        "This system achieved precision of 29.83%, recall of 5.16% and F 0.5 of 15.24% in the official evaluation.",
        "References"
      ]
    }
  ]
}
