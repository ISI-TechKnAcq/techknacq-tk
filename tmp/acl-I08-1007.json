{
  "info": {
    "authors": [
      "Eiji Aramaki",
      "Takeshi Imai",
      "Kengo Miyo",
      "Kazuhiko Ohe"
    ],
    "book": "Proceedings of the Third International Joint Conference on Natural Language Processing",
    "id": "acl-I08-1007",
    "title": "Orthographic Disambiguation Incorporating Transliterated Probability",
    "url": "https://aclweb.org/anthology/I08-1007",
    "year": 2008
  },
  "references": [
    "acl-C02-1099",
    "acl-C04-1086",
    "acl-C04-1119",
    "acl-C04-1176",
    "acl-J98-4003",
    "acl-P04-1021",
    "acl-P07-1016",
    "acl-P07-1082",
    "acl-P07-1083",
    "acl-W98-1005"
  ],
  "sections": [
    {
      "text": [
        "Eiji ARAMAKI Takeshi IMAI Kengo Miyo Kazuhiko Ohe",
        "Orthographic variance is a fundamental problem for many natural language processing applications.",
        "The Japanese language, in particular, contains many orthographic variants for two main reasons: (1) transliterated words allow many possible spelling variations, and (2) many characters in Japanese nouns can be omitted or substituted.",
        "Previous studies have mainly focused on the former problem; in contrast, this study has addressed both problems using the same framework.",
        "First, we automatically collected both positive examples (sets of equivalent term pairs) and negative examples (sets of inequivalent term pairs).",
        "Then, by using both sets of examples, a support vector machine based classifier determined whether two terms (t\\ and t2) were equivalent.",
        "To boost accuracy, we added a transliterated probability P(t\\\\s)Pwhich is the probability that both terms (t\\ and t2) were transliterated from the same source term (s), to the machine learning features.",
        "Experimental results yielded high levels of accuracy, demonstrating the feasibility of the proposed approach."
      ]
    },
    {
      "heading": "1. Introduction",
      "text": [
        "Spelling variations, such as \"center\" and \"centre\", which have different spellings but identical meanings, are problematic for many NLP applications including information extraction (IE), question answering (QA), and machine transliteration (MT).",
        "In",
        "* {} indicates a pronunciation.",
        "() indicates a translation.",
        "this paper, these variations can be termed orthographic variants.",
        "The Japanese language, in particular, contains many orthographic variants, for two main reasons:",
        "1.",
        "It imports many words from other languages using transliteration, resulting in many possible spelling variations.",
        "For example, Masuyama et al.",
        "(2004) found at least six different spellings for \" spaghetti\" in newspaper articles (Table 1",
        "Left).",
        "2.",
        "Many characters in Japanese nouns can be omitted or substituted, leading to tons of insertion variations (Daille et al., 1996) (Table 1 Right).",
        "To address these problems, this study developed a support vector machine (SVM) based classifier that can determine whether two terms are equivalent.",
        "Because a SVM-based approach requires positive and negative examples, we also developed a method to automatically generate both examples.",
        "spaghetti",
        "Thompson operation",
        "{ supagettji )",
        "(Thompson's operation method)",
        "( supagettjii )",
        "(Thompson's operation)",
        "{ supagetji )",
        "(Thompson operation)",
        "{ supagetjn )",
        "{ supagetji )",
        "Our proposed method differs from previously developed methods in two ways.",
        "1.",
        "Previous studies have focused solely on the former problem (transliteration); our target scope is wider.",
        "We addressed both transliteration and character omissions/substitutions using the same framework.",
        "2.",
        "Most previous studies have focused on backtransliteration (Knight and Graehl, 1998; Goto et al., 2004), which has the goal of generating a source word (s) for a Japanese term (i).",
        "In contrast, we employed a discriminative approach, which has the goal of determining whether two terms (t1 and t2) are equivalent.",
        "These two goals are related.",
        "For example, if two terms (t1and t2) were transliterated from the same word (s), they should be orthographic variants.",
        "To incorporate this information, we incorporated a transliterated-probability (P(s\\t1) x P(s\\i2)) into the SVM features.",
        "Although we investigated performance using medical terms, our proposed method does not depend on a target domain."
      ]
    },
    {
      "heading": "2. Orthographic Variance in Dictionary Entries",
      "text": [
        "Before developing our methodology, we examined problems related to orthographic variance.",
        "First, we investigated the amount of orthographic variance between two dictionaries' entries (DIC1 (Ito et al., 2003), totaling 69,604 entries, and DIC2 (Nanzando, 2001), totaling 27,971 entries).",
        "Exact matches between entries only occurred for 10,577 terms (15.1% of DIC1, and 37.8% of DIC2).",
        "From other entries, we extracted orthographic variance as follows.",
        "STEP 1: Extracting Term Pairs with Similar Spelling",
        "We extracted term pairs with similar spelling (t1 and i2) using edit distance-based similarity (defined by Table 2).",
        "We extracted term pairs with SIMed > 0.8, and found 5,064 term pairs with similar spelling.",
        "STEP 2: Judging Orthographic Variance",
        "We then manually judged whether each term pair was composed of orthographic variants (whether or not they had the same meaning).",
        "Our results indicated that 1,889 (37.3%) of the terms were orthographic variants.",
        "Figure 1 presents the relation between the orthographic variation ratio and similarity threshold (0.81.0).",
        "As shown in the figure, a higher similarity threshold (SIM=0.96-97) does not always indicate that terms are orthographic variants.",
        "The following term pair is a typical example:",
        "(mutated hepatitis type B virus), (mutated hepatitis type C virus).",
        "They have only one character difference (\"B\" and \"C\"), resulting in high levels of spelling similarity, but the meanings are not equivalent.",
        "This type of limitation, intrinsic to measurements of spelling similarity, motivated us to develop an SVM-based classifier."
      ]
    },
    {
      "heading": "3. Method",
      "text": [
        "We developed an SVM-based classifier that determines whether two terms are equivalent.",
        "Section 3.1 will describe the method we used to build training data, and Section 3.2 will introduce the classifier.",
        "Our method uses a straight forward approach to extract positive examples.",
        "The basic idea is that orthographic variants should have (1) similar spelling, and (2) the same English translation.",
        "The method consists of the following two steps:",
        "STEP 1: First, using two or more translation dictionaries, extract a set of Japanese terms with the same English translation.",
        "STEP 2: Then, for each extracted set, generate two possible term pairs (t1 and t2) and calculate the spelling similarity between them.",
        "Spelling similarity is measured by edit distance-based similarity (see Section 2).",
        "Any term pair with more than a threshold (SIMed(t1,t2) > 0.8) similarity is considered a positive example.",
        "Negative Examples",
        "We based our method of extracting negative examples using the dictionary-based method.",
        "As with positive examples, we collected term pairs with similar spellings (SIMed(t\\,t2) > 0.8), but differing English translations.",
        "However, the above heuristic is not sufficient to extract negative examples; different English terms might have the same meaning, which could cause unsuitable negative examples.",
        "For example, t\\ \"W;® (stomach cancer)\" and l2 \"t^frfv (stomach carcinoma)\": although these words have differing English translations, unfortunately they are not a negative example (\"cancer\" and \"carcinoma\" are synonymous).",
        "To address this problem, we employed a corpus-based approach, hypothesizing that if two terms are orthographic variants, they should rarely both appear in the same document.",
        "Conversely, if both terms appear together in many documents, they are unlikely to be orthographic variants (negative examples).",
        "Based on this assumption, we defined the following scoring method:",
        "where HIT(t) is the number of Google hits for a query t. We only used negative examples with the highest K score, and discarded the others.",
        "The next problem was how to convert training-data into machine learning features.",
        "We used two types of features.",
        "Character-Based Features",
        "We expressed different characters between two terms and their context (window size ±1) as features, shown in Table 3.",
        "Thus, to represent an omission, \"0 (null)\" is considered a character.",
        "Two examples are provided in Figures 2.",
        "Note that if terms contain two or more differing parts, all the differing parts are converted into features.",
        "Similarity-based Features",
        "Another type of feature is the similarity between two terms (t1 and t2).",
        "We employed two similarities:",
        "1.",
        "Edit distance-based similarity SIMed(t1,t2) (see Section 2).",
        "2.",
        "Transliterated similarity, which is the probability that two terms (t1 and t2) were transliterated",
        "The edit distance-based similarity (SIMed) between two terms (t1} t2) is defined as follows:",
        ".",
        "EditDistance(ti,t2) x 2 where len(t1) is the number of characters of t1, len(t2) is the number of characters of t2, Edit Distance(ti, t2) is the minimum number of point mutations required to change t1 into t2, where a point mutation is one of: (1) a change in a character, (2) the insertion of a character, and (3) the deletion of a character.",
        "For details, see (Levenshtein, 1965).",
        "pre dIff p°st \\",
        "pre diff post I i I",
        "from the same source word (t) (defined in Table4).",
        "Note that the latter, transliterated similarity, is applicable to a situation in which the input pair is transliterated."
      ]
    },
    {
      "heading": "4. Experiments",
      "text": [
        "To evaluate the performance of our system, we used judged term pairs, as discussed in Section 2 (ALLSET).",
        "We also extracted a subset of these pairs in order to focus on a transliteration problem (TRANSSET).",
        "1.",
        "ALL-SET: This set consisted of all examples (1,889 orthographic variants of 5,064 pairs)",
        "2.",
        "TRANS-SET: This set contained only examples of transliteration (543 orthographic variants or 1,111 pairs).",
        "Using the proposed method set out in Section 3, we automatically constructed a training-set from two translation dictionaries (Japan Medical Terminology English-Japanese(Nanzando, 2001) and 25-Thousand-Term Medical Dictionary(MEID, 2005)).",
        "LEX-DIFF",
        "Differing characters between two terms, consisting of a pair of n : m characters (n > 0 and m > 0).",
        "For example, we regard \"^(t)^ (/>\" as LEX-DIFF in Figure 2 TOP.",
        "LEX-PRE",
        "Previous character of DIFF.",
        "We regard \"^(ge)\" as LEX-PRE in Figure 2 TOP.",
        "LEX-POST",
        "Subsequent character of DIFF.",
        "We regard \"-r(te)\" as LEX-",
        "POST in Figure 2 TOP.",
        "TYPE-DIFF",
        "A script type of differing characters between two terms, classified into four categories: (1) HIRAGANA-script, (2) KATAKANA-script, (3) Chinese-character script or (4) others (symbols, numerous expressions etc.))",
        "We regard \"KATAKANA^ <p\" as TYPE-DIFF in Figure 2 TOP.",
        "TYPE-PRE",
        "A type previous character of DIFF.",
        "We regard \"KATAKANA\"",
        "as TYPE-PRE in Figure 2 TOP.",
        "TYPE-POST",
        "A type subsequent character of DIFF.",
        "We regard \"KATAKANA\" as TYPE-POST in Figure 2 TOP.",
        "LEN-DIFF",
        "A length (the number of characters) of differing parts.",
        "The resulting training-set consisted of 82,240 examples (41,120 positive examples and 41,120 negative examples).",
        "We compared the following methods:",
        "1.",
        "SIM-ED: An edit distance-based method, which regards an input with a similarity SIMed(t1} t2) > TH as an orthographic variant.",
        "2.",
        "SIM-TR: A transliterated based method, which regards an input with a spelling similarity SIMtr(t1,t2) > TH as an orthographic variant (TRANS-SET only).",
        "3.",
        "PROPOSED: Our proposed method without SIMtr features."
      ]
    },
    {
      "heading": "4.. PROPOSED+TR: Our proposed method with",
      "text": [
        "SIMtr features.",
        "(TRANS-SET only).",
        "For SVM learning, we used TinySVM with polynomial kernel (d=2).",
        "We used the three following measures to evaluate our method:",
        "Precision # of pairs found and correct total # of pairs found ' # of pairs found and correct total # of pairs correct",
        "Recall + Precision",
        "Table 5 presents the performance of all methods.",
        "The accuracy of similarity-based methods (SIM-ED and SIM-TR) varied depending on the threshold (TH).",
        "Figure 3 is a precision-recall graph of all",
        "methods in TRANS-SET.",
        "In ALL-SET, PROPOSED outperformed a similarity-based method (SIM-ED) in Fp=1, demonstrating the feasibility of the proposed discriminative approach.",
        "Precision(%)",
        "Figure 3: SIM and orthographic variants ratio.",
        "In TRANS-SET, PROPOSED also outperformed two similarity-based methods (SIM-ED and SIM-TR).",
        "In addition, PROPOSED+TR yielded higher levels of accuracy than PROPOSED.",
        "Based on this result, we can conclude that adding transliterated-probability improved accuracy.",
        "It was difficult to compare accuracy between the results of our study and previous studies.",
        "Previous studies used different corpora, and also focused on (back-) transliteration.",
        "However, our accuracy levels were at least as good as those in previous studies (64% by (Knight and Graehl, 1998) and 87.7% by (Goto et al., 2004)).",
        "We investigated errors from PROPOSED and PRO-POSED+TR, and found two main types."
      ]
    },
    {
      "heading": "1.. Different Script Types",
      "text": [
        "The Japanese language can be expressed using three types of script: KANJI (Chinese characters), KATAKANA, and HIRAGANA.",
        "Although each of these scripts can be converted to another, (such as \"JH$H\" {\"epilepsia\" in KANJI script) and \"Xfafchj\" {\"epilepsia\" in HIRAGANA script), our method cannot deal with this phenomenon.",
        "Future research will need to add steps to solve this problem."
      ]
    },
    {
      "heading": "2.. Transliteration from Non-English Lan-",
      "text": [
        "* The performance in SIM-ED and SIM-TR showed the highest Fp=1 values.",
        "While our experimental set consisted of medical terms, including a few transliterations from Latin or German, transliteration-probability was trained using transliterations from the English language (using a general dictionary).",
        "Therefore, PROPOSED+TR results are inferior when inputs are from non-English languages.",
        "In a general domain, SIM-TR and",
        "PROPOSED+TR would probably yield higher",
        "accuracy.",
        "5 Related Works",
        "As noted in Section 1, transliteration is the most relevant field to our work, because it results in many orthographic variations.",
        "Most previous transliteration studies have focused on finding the most suitable back-transliteration of a term.",
        "For example, Knight (1998) proposed a probabilistic model for transliteration.",
        "Goto et al.",
        "(2004) proposed a similar method, utilizing surrounding characters.",
        "Their method is not only applicable to Japanese; it has already been used for Korean(Oh and Choi,",
        "Arabic(Stalls and Knight, 1998; Sherif and Konsian(Karimi et al., 2007).",
        "Our method uses a different kind of task-setting, compared to previous methods.",
        "It is based on determining whether two terms within the same language are equivalent.",
        "It provides high levels of accuracy, which should be practical for many applications.",
        "Another issue is that of how to represent transliteration phenomena.",
        "Methods can be classified into three main types: grapheme-based (Li et al., 2004); phoneme-based (Knight and Graehl, 1998); and combinations of both these meth-ods( hybrid-model(Bilac and Tanaka, 2004) and correspondence-based model(Oh and Choi, 2002; Oh and Choi, 2005)).",
        "Our proposed method employed a grapheme-based approach.",
        "We selected this kind of approach because it allows us to handle not only transliteration but also character omissions/substitutions, which we would not be able to address using a phoneme-based approach (and a combination approach).",
        "Yoon et al.",
        "(2007) also proposed a discriminative transliteration method, but their system was based on determining whether a target term was transliterated from a source term.",
        "Bergsma and Kondrak (2007) and Aramaki et al.",
        "(2007) proposed on a discriminative method for similar spelling terms.",
        "However, they did not deal with a transliterated probability.",
        "Japanese transliteration variants (positive examples) from a large corpus.",
        "In contrast, we collected both positive and negative examples in order to train the classifier."
      ]
    },
    {
      "heading": "6. Conclusion",
      "text": [
        "We developed an SVM-based orthographic disambiguation classifier, incorporating transliteration probability.",
        "We also developed a method for collecting both positive and negative examples.",
        "Experimental results yielded high levels of accuracy, demonstrating the feasibility of the proposed approach.",
        "Our proposed classifier could become a fundamental technology for many NLP applications."
      ]
    },
    {
      "heading": "Acknowledgments",
      "text": [
        "Part of this research is supported by Grant-in-Aid for Scientific Research of Japan Society for the Promotion of Science (Project Number:16200039, F.Y.2004-2007 and 18700133, F.Y.2006-2007) and the Research Collaboration Project (#047100001247) with Japan Anatomy Laboratory Co.Ltd.",
        "ALL-SET",
        "TRANS-SET",
        "Precision",
        "Recall",
        "Fß=i",
        "Precision",
        "Recall",
        "Fß=\\",
        "SIM-ED",
        "65.2%",
        "64.6%",
        "0.65",
        "91.2%",
        "36.3%",
        "0.51",
        "SIM-TR",
        "-",
        "-",
        "-",
        "92.6%",
        "43.9%",
        "0.59",
        "PROPOSED",
        "78.2%",
        "70.2%",
        "0.73",
        "81.9%",
        "75.6%",
        "0.78",
        "PROPOSED+TR",
        "-",
        "-",
        "-",
        "81.7%",
        "82.7%",
        "0.82"
      ]
    }
  ]
}
