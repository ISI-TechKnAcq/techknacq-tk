{
  "info": {
    "authors": [
      "Marius Pa≈üca"
    ],
    "book": "EMNLP",
    "id": "acl-D13-1039",
    "title": "Open-Domain Fine-Grained Class Extraction from Web Search Queries",
    "url": "https://aclweb.org/anthology/D13-1039",
    "year": 2013
  },
  "references": [
    "acl-A00-1031",
    "acl-C02-1144",
    "acl-C10-1058",
    "acl-C10-1112",
    "acl-C10-2110",
    "acl-C92-2082",
    "acl-D08-1061",
    "acl-D09-1025",
    "acl-D09-1089",
    "acl-D09-1098",
    "acl-D10-1108",
    "acl-D11-1049",
    "acl-D11-1142",
    "acl-D12-1082",
    "acl-P06-1015",
    "acl-P06-1101",
    "acl-P08-1119",
    "acl-P09-1050",
    "acl-P09-1116",
    "acl-P10-1136",
    "acl-P10-1149",
    "acl-P12-1059"
  ],
  "sections": [
    {
      "heading": "Abstract",
      "text": [
        "This paper introduces a method for extracting fine-grained class labels (?countries with double taxation agreements with india?)",
        "from Web search queries.",
        "The class labels are more numerous and more diverse than those produced by current extraction methods.",
        "Also extracted are representative sets of instances (singapore, united kingdom) for the class labels."
      ]
    },
    {
      "heading": "1 Introduction",
      "text": [
        "Motivation: As more semantic constraints are added, concepts like companies become more specific, e.g., companies that are in the software business, and have been started in a garage.",
        "The sets of instances associated with the classes become smaller; the class labels used to concisely describe the meaning of more specific concepts tend to become longer.",
        "In fact, fine-grained class labels such as ?software companies started in a garage?",
        "are often complex noun phrases, since they must somehow summarize multiple semantic constraints.",
        "Although Web users are interested in both coarse (e.g., ?companies?)",
        "and fine-grained (e.g., ?software companies started in a garage?)",
        "class labels, virtually all class labels acquired from text by previous extraction methods (Etzioni et al., 2005; Van Durme and Pas?ca, 2008; Kozareva and Hovy, 2010; Snow et al., 2006) exhibit little syntactic diversity.",
        "Indeed, instances and class labels that are relatively complex nouns are known to be difficult to detect and pick out precisely from surrounding text (Downey et al., 2007).",
        "This and other challenges associated with large-scale extraction from Web text (Etzioni et al., 2011) cause the extracted class labels to usually follow a rigid modifiers-plus-nouns format.",
        "The format covers nouns (?companies?)",
        "possibly preceded by one or many modifiers (?software companies?, ?computer security software companies?).",
        "Examples of actual extractions include ?european cities?",
        "(Etzioni et al., 2005), ?strong acids?",
        "(Pan-tel and Pennacchiotti, 2006), ?prestigious private schools?",
        "(Van Durme and Pas?ca, 2008), ?aquatic birds?",
        "(Kozareva and Hovy, 2010).",
        "As an alternative to extracting class labels from text, some methods simply import them from human-curated resources, for example from the set of categories encoded in Wikipedia (Remy, 2002).",
        "As a result, class labels potentially exhibit higher syntactic diversity.",
        "The modifiers-plus-nouns format (?computer security software companies?)",
        "is usually still the norm.",
        "But other formats are possible: ?software companies based in london?, ?software companies of the united kingdom?.",
        "Vocabulary coverage gaps remain a problem, with many relevant class labels (?software companies of texas?",
        "?software companies started in a garage?, ?software companies that give sap training?)",
        "still missing.",
        "There is a need for methods that more aggressively identify fine-grained class labels, beyond those extracted by previous methods or encoded in existing, manually-created resources.",
        "Such class labels increase coverage, for example in scenarios that enrich Web search results with instances available for the class labels specified in the queries.",
        "Contributions: The contributions of this paper are twofold.",
        "First, it proposes a weakly-supervised",
        "method to assemble a large vocabulary of class labels from queries.",
        "The class labels include fine-grained class labels (?countries with double taxation agreements with india?, ?no front license plate states?)",
        "that are difficult to extract from text by previous methods for open-domain information extraction.",
        "Second, the method acquires representative instances (singapore, united kingdom; arizona, new mexico) that belong to fine-grained class labels (?countries with double taxation agreements with india?, ?no front license plate states?).",
        "Both class labels and their instances are extracted from Web search queries."
      ]
    },
    {
      "heading": "2 Extraction from Queries",
      "text": []
    },
    {
      "heading": "2.1 Extraction of Class Labels",
      "text": [
        "Overview: Given a set of arbitrary Web search queries as input, our method produces a vocabulary of fine-grained class labels.",
        "For this purpose, it: a) selects an initial vocabulary of class labels, as a subset of input queries that are likely to correspond to search requests for classes; b) expands the vocabulary, by generating a large, noisy set of other possible class labels, through replacements of ngrams within initial class labels with their similar phrases; c) restricts the generated class labels to those that match the syntactic structure of class labels within the initial vocabulary; and d) further restricts the generated class labels to those that appear within the larger set of arbitrary Web search queries.",
        "Initial Vocabulary of Class Labels: Out of a set of arbitrary search queries available as input, the queries in the format ?list of ..?",
        "are selected as the initial vocabulary of class labels.",
        "The prefix ?list of?",
        "is discarded from each query.",
        "Thus, the query ?list of software companies that use linux?",
        "gives the class label ?software companies that use linux?.",
        "Generation via Phrase Similarities: As a prerequisite to generating class labels, distributionally similar phrases (Lin and Pantel, 2002; Lin and Wu, 2009; Pantel et al., 2009) and their scores are collected in advance.",
        "A phrase is represented as a vector of its contextual features.",
        "A feature is a word, collected from windows of three words centered around the occurrences of the phrase in sentences across Web documents (Lin and Wu, 2009).",
        "In the contextual vector of a phrase, the weight of a feature is the pointwise-mutual information (Lin and Wu, 2009) between the phrase P and the feature F .",
        "The distributional similarity score between two phrases is the cosine similarity between the contextual vectors of the two phrases.",
        "The lists of most distribution-ally similar phrases of a phrase P are thus compiled offline, by ranking the similar phrases of P in decreasing order of their similarity score relative to P .",
        "Each class label from the initial vocabulary is expanded into a set of generated, candidate class labels.",
        "To this effect, every ngram P within a given class label is replaced with each of the distribution-ally similar phrases, if any, available for the ngram.",
        "As shown later in the experimental section, the expansion can increase the vocabulary by a factor of 100.",
        "Approximate Syntactic Filtering: The set of generated class labels is noisy.",
        "The set is filtered, by retaining only class labels whose syntactic structure matches the syntactic structure of some class label(s) from the initial vocabulary.",
        "The syntactic structure is loosely approximated at surface rather than syntactic level.",
        "A generated class label is retained, if its sequence of part of speech tags matches the sequence of part of speech tags of one of the class labels from the initial vocabulary.",
        "As an additional constraint, the sequence must contain one tag corresponding to a common noun in plural form, i.e., NNS.",
        "Otherwise, the class label is discarded.",
        "Query Filtering: Generated class labels that pass previous filters are further restricted.",
        "They are intersected with the set of arbitrary Web search queries available as input.",
        "Generated class labels that are not full queries are discarded."
      ]
    },
    {
      "heading": "2.2 Extraction of Instances",
      "text": [
        "Overview: Our method mines instances of fine-grained class labels from queries.",
        "In a nutshell, it identifies queries containing two types of information simultaneously.",
        "First, the queries contain an instance (marvin gaye) of the more general class labels (?musicians?)",
        "from which the fine-grained class labels (?musicians who have been shot?)",
        "can be obtained.",
        "Second, the queries contain the constraints added by the fine-grained class labels (?...",
        "shot?)",
        "on top of the more general class labels.",
        "Instances of General Class Labels: Following (Ponzetto and Strube, 2007), the Wikipedia category network is refined into a hierarchy that discards",
        "non-IsA (thematic) edges, and retains only IsA (sub-sumption) edges from the network (Ponzetto and Strube, 2007).",
        "Instances, i.e., titles of Wikipedia articles, are propagated upwards to all their ancestor categories.",
        "The class label ?musicians?",
        "would be mapped into madonna, marvin gaye, jon bon jovi etc.",
        "The mappings from each ancestor category, to all its descendant instances in the Wikipedia hierarchy, represent our mappings from more general class labels to instances.",
        "Decomposition of Fine-Grained Class Labels: A fine-grained class label (e.g., ?musicians who have been shot?)",
        "is effectively decomposed into pairs of two pieces of information.",
        "The first piece is a more general class label (?musicians?",
        "), if any occurs in it.",
        "The second piece is a bag of words, collected from the remainder of the fine-grained class label after discarding stop words.",
        "Note that the standard set of stop words is augmented with auxiliary verbs (e.g., does, has, is, would), determiners, conjunctions, prepositions, and question wh-words (Radev et al., 2005) (e.g., where, how).",
        "In the first piece of each pair, the general class label is then replaced with each of its instances.",
        "This produces multiple pairs of a candidate instance and a bag of words, for each fine-grained class label.",
        "As an illustration, the class labels ?musicians who have been shot?",
        "and ?automobiles with remote start?",
        "are decomposed into pairs like <madonna, {shot}>, <marvin gaye, {shot}>; and <buick lacrosse, {remote, start}>, <nissan versa, {remote, start}>, respectively.",
        "Matching of Candidate Instances: A decomposed class label is retained, if there are matching queries that contain the candidate instance, the bag of words, and optionally stop words.",
        "Otherwise, the decomposed class label is discarded.",
        "The word matching is performed after word stemming (Porter, 1980).",
        "The aggregated frequency of the matching queries is assigned as the score of the candidate instance for the fine-grained class label:",
        "For example, the score of the candidate instance marvin gaye for the class label ?musicians who have been shot?, is the sum of the frequencies of the matching queries ?marvin gaye is shot?, ?when was marvin gaye shot?, ?why marvin gaye was shot?",
        "etc.",
        "Similarly, the score of buick lacrosse for ?automobiles with remote start?",
        "is given by the aggregated frequencies of the queries ?buick lacrosse remote start?, ?how to remote start buick lacrosse?, ?remote start for buick lacrosse?.",
        "Candidate instances of a class label are ranked in decreasing order of their scores."
      ]
    },
    {
      "heading": "3 Experimental Setting",
      "text": [
        "Web Textual Data: The experiments rely on a sample of 1 billion queries in English submitted by users of a Web search engine.",
        "Each query is accompanied by its frequency of occurrence.",
        "Also available is a sample of around 200 million Web documents in English.",
        "Phrase Similarities: Web documents are used in the experiments only to construct a phrase similarity repository following (Lin and Wu, 2009; Pantel et al., 2009).",
        "The repository contains ranked lists of the top 1000 phrases, computed to be the most distributionally similar to each of around 16 million phrases.",
        "Text Pre-Processing: The TnT tagger (Brants, 2000) assigns part of speech tags to words in class labels.",
        "Instances: To collect mappings from Wikipedia categories (as more general class labels) to titles of descendant Wikipedia articles (as instances), a snapshot of Wikipedia articles was intersected with the Wikipedia category hierarchy from (Ponzetto and Strube, 2007).",
        "The mappings connect a total of 1,535,083 instances to a total of 108,756 class labels."
      ]
    },
    {
      "heading": "4 Evaluation of Class Labels",
      "text": []
    },
    {
      "heading": "4.1 Evaluation Procedure",
      "text": [
        "Experimental Runs: Human-compiled information available within Wikipedia serves as the source of data for two baseline runs.",
        "The set of all categories, listed in Wikipedia for any of its articles, corresponds to the set of class labels ?acquired?",
        "in run Rwc.",
        "Categories used for internal Wikipedia bookkeeping (Ponzetto and Strube, 2007) are discarded.",
        "Their names contain one of the words article(s), cat-egory(ies), indices, pages, redirects, stubs, or templates.",
        "Similarly, the titles of Wikipedia articles with the prefix ?List of ..?",
        "(e.g., ?List of automobile manufacturers of Germany?)",
        "form the set of class labels",
        "?acquired?",
        "in run Rwl.",
        "The prefix ?List of?",
        "is discarded.",
        "For completeness, a third baseline run, Rdc, corresponds to class labels extracted from Web documents.",
        "The class labels are noun phrases C that fill extraction patterns equivalent to ?C such as I?.",
        "The patterns are matched to document sentences.",
        "The boundaries of the class labels C are approximated from part of speech tags of sentence words (Van Durme and Pas?ca, 2008).",
        "The patterns were proposed in (Hearst, 1992).",
        "They were employed widely in subsequent methods (Etzioni et al., 2005; Kozareva et al., 2008; Wu et al., 2012), which extract class labels precisely from the set of class labels C produced by the extraction patterns.",
        "Even methods using queries as a textual data source still extract class labels from documents using the same extraction patterns (Pas?ca, 2010).",
        "Therefore, from the point of view of evaluating class labels, run Rdc is a valid representative of previous extraction methods, including (Etzioni et al., 2005; Kozareva et al., 2008; Van Durme and Pas?ca, 2008; Pas?ca, 2010; Wu et al., 2012).",
        "Besides the baseline runs, three experimental runs are considered.",
        "In run Rql, the queries starting with the prefix ?list of?",
        "form the set of class labels.",
        "The prefix ?list of?",
        "is discarded from each query.",
        "In run Rqg, the class labels are generated via phrase similarities, starting from Rql as an initial set of class labels.",
        "Run Rqa represents an ablation experiment.",
        "It is created from Rqg, by limiting the expansion of a given class label via distributional similarities to only one, rather than multiple, phrases within the class label.",
        "Note that, by design, none of the class labels that appear in Rql also appear in runs Rqa or Rqg.",
        "Therefore, the intersection between Rql, on one hand, and Rqa and Rqg, on the other hand, is the empty set.",
        "All data, including the class labels extracted in all experimental runs, is converted to lower case."
      ]
    },
    {
      "heading": "4.2 Relative Coverage of Class Labels",
      "text": [
        "Coverage Over Entire Sets: Table 1 illustrates the overall coverage of the various experimental runs.",
        "The table takes all class labels into account, relative to the Wikipedia-based runs as reference sets: Rwc (Wikipedia categories), in the upper part of the table;",
        "experimental runs, relative to class labels available in Wikipedia before and after intersecting them with a large set of arbitrary queries (A = reference set, relative to which coverage is computed; B = measured set, for which coverage is computed relative to the reference set; |A |= size of set A; Q = set of input queries) part of the table.",
        "Note that the number of class labels extracted by the individual run shown in the second column (B) is shown in the fourth column (|B|).",
        "In particular, there are around 1.6 million unique ?list of ..?",
        "queries, from which class labels are collected in run Rql.",
        "During the computation of coverage, the reference set, and the set for which coverage is being computed, are intersected.",
        "Intersection relies on strict string matching.",
        "All words, including punctuation, must match exactly in order for a class label to be part of the intersection.",
        "The reference sets are intersected with the set of all Web search queries Q used in the experiments.",
        "Coverage is computed both before and after intersection.",
        "Less than half (126,318 of 295,587) of the class labels, for",
        "the reference set Rwc; and about a third (47,442 of 134,840) for Rwl; appear in the set Q of all queries.",
        "Three conclusions can be drawn from the results.",
        "First, query-based runs vastly outperform Wikipedia-based runs in terms of absolute coverage.",
        "Run Rql contains around 5 and 12 times more class labels, than Rwc and Rwl respectively.",
        "On top of that, generating class labels via phrase similarities further increases the class label count by about 20 times for Rqa, and 80 times for Rqg.",
        "Second, query-based runs Rqa and Rqg surpass the document-based run Rdc.",
        "Third, higher class label counts translate into higher relative coverage.",
        "In the upper part of the table, run Rwl contains 3.9% (relative to Rwc) and 7.1% (relative to Rwc?Q) of the reference set.",
        "But the relative coverage doubles for Rql at 7.4% (relative to Rwc) and 17.3% (relative to Rwc?Q).",
        "Coverage again doubles for Rqg at 14.8% (relative to Rwc) and 34.7% (relative to Rwc?Q).",
        "The union of query-based initial and generated class labels is Rql?Rqg.",
        "The union contains about a quarter (i.e., 22.2%) or half (52.1%) of the reference set Rwc, depending on whether the reference set is intersected with the set of all queries or not.",
        "In the lower part of the table, more than 90% of the queries in the reference set Rwl that are also queries are found among the class labels collectively extracted in the query-based runs.",
        "Note that, since Rql is disjoint from Rqa and Rqg, none of the class labels already in Rql can be ?re-discovered?",
        "(generated) again in Rqa or Rqg.",
        "Therefore, by experimental design, relative coverage scores of Rql may be relatively difficult to surpass by Rqa or Rqg taken individually.",
        "Diversity: Class labels restricted to those that have the format ?..",
        "that/which/who ..?",
        "are relatively more specific, e.g., ?grocery stores that double coupons in omaha?, ?airlines which fly from santa barbara?, ?writers who were doctors?.",
        "The most frequent head phrases of such restricted class labels offer an idea about how diverse the class labels are.",
        "The counts of class labels for the most frequent head phrases are in the order of 10's in the case of Rwl vs. 10,000's for Rqg.",
        "In comparison, none of the class labels of run Rdc have this format.",
        "The lack of such class labels in run Rdc, and their smaller proportion in run Rwl vs. Rqg, suggest that class labels extracted by the proposed method exhibit higher lexical and syntactic diversity than previous methods do.",
        "Tag (Value): Examples of Class Labels correct (1.0): angioplasty specialists in kolkata, good things pancho villa did, eating disorders inpatient units in the uk nhs specialist services questionable (0.5): picture framers adelaide cbd, side effects bicalutamide, different eating disorders, private hospitals treat kidney stones uk incorrect (0.0): al hirschfield theatre hours, value of berkshire hathaway shares, remove spaces in cobol, dogs with loss of appetite, 1999 majorca open",
        "bels containing one of the (underlined) target phrases, extracted by various runs"
      ]
    },
    {
      "heading": "4.3 Precision of Class Labels",
      "text": [
        "Evaluation Metric: Class labels being evaluated are manually assigned a correctness tag.",
        "A class label is deemed correct, if it is grammatically well-formed and describes a relevant concept that embodies some (unspecified) set of instances that share similar properties; questionable, if it is relevant but not well-formed; or incorrect.",
        "A questionable class label is not well-formed because it lacks necessary linking particles (e.g., the prepositions of or for in ?side effects bicalutamide?",
        "), or contains undesirable modifiers (?different eating disorders?).",
        "Examples of correct and incorrect class labels are ?angioplasty specialists in kolkata?",
        "and ?al hirschfield theatre hours?",
        "respectively.",
        "To compute the precision score, the correctness tags are converted to numeric values, as shown in Table 2: correct to 1; questionable to 0.5; and incorrect to 0.",
        "Precision over a list of class labels is measured as the sum of the correctness values of the class labels in the list, divided by the size of the list.",
        "Precision Relative to Target Phrases: The precision of the class labels in each run is determined similarly to how relative coverage was computed earlier.",
        "More precisely, the precision is computed over the class labels whose names contain each phrase from the set of 75 target phrases from (Alfonseca et al., 2010).",
        "For each phrase, and for each run, a random sample of at most 50 of the class labels that match the phrase is selected for evaluation.",
        "The samples taken for each run, corresponding to the same phrase, are combined into a merged list.",
        "This produces one merged list for each phrase, for a total of 75 merged lists.",
        "The precision score over a target",
        "phrase is the precision score over its sample of class labels.",
        "The last two columns of Table 3 capture the precision scores for the class labels.",
        "The scores are computed in two ways: averaged over the (variable) subsets of target phrases for which some matching class label(s) exist, in the last but one column, e.g., over 19 of the 75 target phrases for Rwc; and averaged over the entire set of 75 target phrases, in the last column.",
        "The former does not penalize a run for not being able to extract any class labels containing a particular target phrase, whereas the latter does penalize.",
        "Naturally, precision scores over the entire set of target phrases decrease when coverage is lower, for runs Rwc, Rwl and, to a lesser extent, Rdc and Rql.",
        "But even after ignoring target phrases with no matching class labels, precision scores in the last but one column in Table 3 reveal important properties of the experimental runs.",
        "First, between the two Wikipedia-based runs, Rwl has perfect class labels, whereas as many as 1 in 4 class labels of run Rwc are marked as incorrect during the evaluation.",
        "Second, the class labels collected from ?list of ..?",
        "queries in run Rql correspond to relevant, well-formed concepts in 80% of the cases.",
        "Third, the generation of class labels via phrase similarities (Rqg) greatly increases coverage as shown earlier.",
        "The increase comes at the expense of lowering precision from 80% to 72%.",
        "However, the phrases from initial queries that are expanded via distributional similarities can be limited from multiple to only one, by switching from Rqg to Rqa.",
        "This gives higher precision for Rqa than for Rqg.",
        "As a complement to Table 3, the graphs in Figure 1 offer a more detailed view into the precision of class labels.",
        "The figure covers a Wikipedia-based run (Rwc) and two query-based runs (Rql, Rqg).",
        "The graphs show the precision scores, over each of the 75 target phrases.",
        "Among target phrases for which some matching class labels exist in the respective run, the target phrases with the lowest precision scores are robotics (score of 0.15) and karlsruhe (0.33), for Rwc; carotid arteries and kidney stones, both with a score of 0.00 because their matching class labels are all incorrect, for Rdc; african population and chester arthur, both with a score of 0.00 because their matching class labels are all incorrect, for Rql; and arlene martel (0.00) and right to vote",
        "names contain) each target phrase, computed as an average over (variable) subsets of target phrases for which some matching class label(s) exist, and as an average over the entire set of 75 target phrases",
        "Rqg , over class labels that match (i.e., contain) each of the 75 target phrases (0.25), for Rqg.",
        "Precision over Samples of Class Labels: The precision is separately computed over a random sample of 400 class labels per experimental run.",
        "The samples are selected from the set of all class labels extracted by the respective run.",
        "The precision scores are: 0.759 for Rwc; 1.000 for Rwl; 0.806 for Rdc; 0.811 for Rql; 0.856 for Rqa; and 0.711 for Rqg.",
        "The scores are in line with scores computed earlier over the target phrases, in the fourth column of Table 3.",
        "Discussion: As noted in (Ponzetto and Strube, 2007), Wikipedia organizes its articles and categories into a category network that mixes IsA (sub-sumption) edges with non-IsA (thematic) edges.",
        "Whenever an edge in Wikipedia is not IsA, the par"
      ]
    },
    {
      "heading": "Longest Class Labels",
      "text": [
        "Rwl: [japanese army and navy members in military or politic services in proper japan korea manchuria occupied china and nearest areas in previous times and pacific war epoch(1930-40s), mental disorders as defined by the diagnostic and statistical manual of mental disorders and the international statistical classification of diseases and related health problems,..] Rqg: [differences between transformational leadership and transactional leadership, things to do in llanfairpwllgwyngyllgogerychwyrndrobwllllantysilio-gogogoch, philosophical differences between thomas jefferson and alexander hamilton, musculoskeletal manifestations of human immunodeficiency virus infection,..]"
      ]
    },
    {
      "heading": "Rqg",
      "text": [
        "ent category may not be a relevant concept that describes some set of instances that share similar properties.",
        "Such categories are not good class labels, and therefore are marked as incorrect.",
        "Examples include the class labels ?austrian contemporary art?, ?1999 majorca open?",
        "and ?u.s.",
        "route 30?, listed in Wikipedia as categories of the instances vienna bien-nale, 1999 majorca open and squirrel hill tunnel respectively.",
        "This affects the precision scores for Rwc in Table 3.",
        "It also affects the coverage values relative to Rwc in Table 1.",
        "Ideally, high-precision experimental runs would not extract any incorrect class labels that happen to appear in Rwc, for example ?austrian contemporary art?.",
        "But the coverage relative to Rwc would artificially penalize such runs, for not extracting the incorrect class labels from Rwc.",
        "As a proxy for estimating class label complexity, Table 4 shows the longest class labels derived from Wikipedia (Rwl) vs. generated from queries (Rqg).",
        "Class labels derived from Web search queries may be semantically overlapping.",
        "Examples are ?writers who killed themselves?",
        "vs. ?writers who committed suicide?.",
        "The overlap is desirable, since different Web users may request the same information via different queries.",
        "The same phenomenon has been observed in other information extraction tasks.",
        "It also affects manually-created resources like Wikipedia.",
        "The continuous manual refinements to Wikipedia content still cannot prevent the occurrence of duplicate class labels among Wikipedia List-Of categories.",
        "The duplicates are present in run Rwl.",
        "Exam"
      ]
    },
    {
      "heading": "Target Class Labels",
      "text": [
        "007 movie actors, .308 weapons, actors with obsessive compulsive disorder, antibiotics for multiple sclerosis, astronauts in space station, automobiles with remote start, beatles songs of love, beetles that bite, companies with sustainable competitive advantage, countries with double taxation agreements with india, criminals who have been executed, daft punk live albums, dal-las medical companies, direct democracy states, electronic companies in electronic city bangalore, expensive brands of shoes, eye diseases in cats, f1 car companies, fwd sports cars, garden landscaping magazines, heliskiing resorts, hell in a cell wrestlers, holidays celebrated in sydney, ibf weight classes, ibiza 2011 djs, immunology scientists, jewelry manufacturing companies, kanye west songs on youtube, kingston upon thames supermarkets, latin military ranks, lud-hiana newspapers, maastricht treaty countries, musicians who have been shot, no front license plate states, non-profit organizations in nashville tennessee, organic chocolate companies, plants which are used in homeopathy, programming languages for server side programming, qatar chemical companies, qld private schools, real estate companies in virginia beach virginia, respiratory infection antibiotics, serial killers with antisocial personality disorder, singers with curly hair, telecommunications companies in the philip-pines, trains from la to san diego, visual basic database management systems, warmblood colors, washington university basketball players, world heritage sites in northern ireland",
        "ples are ?formula one drivers that never qualified for a race?",
        "vs. ?formula one drivers who never qualified for a race?",
        "; or ?goaltenders who have scored a goal in a nhl game?",
        "vs. ?goaltenders who have scored a goal in an nhl game?.",
        "Some of the lexical differences among class labels are due to undesirable misspellings.",
        "Again, similar problems occasionally affect existing Wikipedia categories: ?no-bel laureates who endorse barack obama?",
        "vs. ?no-bel laureates who endorse barrack obama?."
      ]
    },
    {
      "heading": "5 Evaluation of Instances",
      "text": []
    },
    {
      "heading": "5.1 Evaluation Procedure Target Set of Class Labels: The target set for evalu",
      "text": [
        "ation is shown in Table 5.",
        "Initially, a random sample of 100 class labels is selected from all class labels in",
        "Tag (Value): Examples of Instances correct (1.0): countries with double taxation agreements with india: thailand; hell in a cell wrestlers: brock lesnar; ibiza 2011 djs: dimitri from paris; he-liskiing resorts: valle nevado questionable (0.5): 007 movie actors: david niven; kanye west songs on youtube: the good life; holidays celebrated in sydney: waitangi day incorrect (0.0): electronic companies in electronic city bangalore: bank of baroda; garden landscaping magazines: marquis; immunology scientists: rosalind",
        "extracted from queries for various class labels run Rqg.",
        "Class labels deemed incorrect, as well as class labels for which no instances are extracted, are manually removed from the sample.",
        "Out of the remaining class labels, a smaller random sample of 50 of the remaining class labels is retained, for the purpose of evaluating the quality of instances extracted for various class labels.",
        "Evaluation Metric: The evaluation computes the precision of the ranked list of instances extracted for each target class label.",
        "To remove any undesirable bias towards higher-ranked instances, the ranked list is sorted alphabetically, then each instance is assigned one of the correctness tags from Table 6.",
        "Instances are deemed questionable, if they would be correct for a rather obscure interpretation of the class label.",
        "For example, david niven is an actor in one of the spoofs rather than main releases of the 007 movie.",
        "Instances that would be correct if a few words were dropped or added are also deemed questionable: the good life is not one of the ?kanye west songs on youtube?",
        "but good life is.",
        "To compute the precision score over a ranked list of instances, the correctness tags are converted to numeric values.",
        "Precision at some rank N in the list is measured as the sum of the correctness values of the instances extracted up to rank N, divided by the number of instances extracted up to rank N."
      ]
    },
    {
      "heading": "5.2 Precision of Instances",
      "text": [
        "Precision: Precision scores in Table 7 vary across target class labels.",
        "For some class labels, the extracted instances are noisy enough that scores are below 0.50 at ranks 10 and higher.",
        "This is the case for ?electronic companies in electronic city banga",
        "instances extracted from queries, for various target class labels and as an average over the entire set of 50 target class labels lore?",
        "and ?daft punk live albums?, and especially for ?garden landscaping magazines?",
        "which has the worst precision.",
        "On the other hand, instances extracted for ?companies with sustainable competitive advantage?",
        "or ?criminals who have been executed?",
        "have high precision across all ranks.",
        "As an average over all target class labels, precision is 0.76 at rank 10, and 0.71 at rank 50.",
        "Although there is room for improvement, we find these accuracy levels to be encouragingly good, especially at rank 50.",
        "As a reminder, instances are extracted from noisy queries, and for class labels as fine-grained as those acquired and used in our experiments.",
        "Some of the extracted ranked lists of instances are shown in Table 8.",
        "[singapore, malaysia, mauritius, kenya, australia, united kingdom, cyprus, turkey, thailand, germany,..] direct democracy states [california, oregon, nevada, wis-consin, louisiana, arizona, vermont, alaska, illinois, michigan,..] fwd sports cars [scion tc, ford probe, honda prelude, nissan 200sx, lotus elan, mitsubishi fto, dodge srt-4, mitsubishi gto, volvo c30, toyota celica,..] garden landscaping magazines [front, contemporary, gallery, edge, view, chelsea, wallpaper, expo, wizard, sunset,..] holidays celebrated in sydney [halloween, australia day, anzac day, independence day, waitangi day, melbourne cup, hogmanay, rotuma day, solstice, yule,..]",
        "of class labels In additional experiments, the same evaluation procedure is applied to output from two previous extraction methods.",
        "The first method starts by internally generating a small set of seed instances for a class label given as input (Wang and Cohen, 2009).",
        "A set expansion module then expands the seed set into a longer, ranked list of instances.",
        "The instances are extracted from unstructured and semi-structured text within Web documents.",
        "The documents are accessed via the search interface of a general-purpose Web search engine (cf. (Wang and Cohen, 2009) for more details).",
        "The second method extracts instances of class labels using the extraction patterns proposed in (Hearst, 1992).",
        "As such, it is similar to (Kozareva et al., 2008; Van Durme and Pas?ca, 2008; Wu et al., 2012).",
        "The method corresponds to the run Rdc described earlier, where the relative ranking of instances and class labels uses the co-occurrence of instances and class labels within queries (Pas?ca, 2010).",
        "For the purpose of the evaluation, when no instances are available for a target class label, the class label is generalized into iteratively shorter phrases containing fewer modifiers, until some instances are available for the shorter phrase.",
        "For example, target class labels like actors with obsessive compulsive disorder, beatles songs of love, garden landscaping magazines do not have any instances extracted by the second method.",
        "Therefore, the instances evaluated for the second method for these target class labels are collected from the instances of the more general actors, beatles songs, landscaping magazines.",
        "Without the generalization, the target class label would receive no credit during the evaluation, and the two previous methods would have lower precision scores.",
        "Over the 50 target class labels, the precision of the two methods is 0.11 and 0.27 at rank 5; 0.06 and 0.25 at rank 10; 0.05 and 0.22 at rank 20; and 0.05 and 0.20 at rank 50.",
        "The results confirm that, as explained earlier, previous methods for open-domain information extraction have limited ability to extract instances of fine-grained class labels.",
        "Discussion: Earlier errors in the acquisition of the class label affect the usefulness of any instances that may be subsequently extracted for them.",
        "The experiments require candidate instances to appear in Wikipedia.",
        "This may improve precision, at the expense of not extracting instances that are not yet in Wikipedia (Lin et al., 2012)."
      ]
    },
    {
      "heading": "6 Related Work",
      "text": [
        "Previous methods for extracting classes of instances from text acquire sets of instances that are each either unlabeled (Pennacchiotti and Pantel, 2009; Jain and Pennacchiotti, 2010; Shi et al., 2010), or associated with a class label (Banko et al., 2007; Wang and Cohen, 2009).",
        "The sets of instances and/or class labels may be organized as flat sets or hierarchically, relative to inferred hierarchies (Kozareva and Hovy, 2010) or existing hierarchies such as WordNet (Snow et al., 2006; Davidov and Rappoport, 2009) or the category network within Wikipedia (Wu and Weld, 2008; Ponzetto and Navigli, 2009).",
        "Semi-structured text from Web documents is a complementary resource to unstructured text, for the purpose of extracting relations in general (Cafarella et al., 2008), and classes and instances in particular (Talukdar et al., 2008; Dalvi et al., 2012).",
        "With previous methods, the vocabulary of class labels potentially produced for any instance is confined to a closed set provided manually as input (Wang and Cohen, 2009; Carlson et al., 2010).",
        "The closed set is often derived from resources like Wikipedia (Talukdar and Pereira, 2010; Lin et al.,",
        "2012; Hoffart et al., 2013) or Freebase (Pantel et al., 2012).",
        "Alternatively, the vocabulary is not a closed set, but instead is acquired along with the instances (Pantel and Pennacchiotti, 2006; Snow et al., 2006; Banko et al., 2007; Van Durme and Pas?ca, 2008; Kozareva and Hovy, 2010).",
        "In the latter case, the extracted class labels take the form of head nouns preceded by modifiers.",
        "Examples are ?cities?, ?european cities?",
        "(Etzioni et al., 2005); ?artists?, ?strong acids?",
        "(Pantel and Pennacchiotti, 2006); ?outdoor activities?, ?prestigious private schools?",
        "(Van Durme and Pas?ca, 2008); ?methate-rians?, ?aquatic birds?",
        "(Kozareva and Hovy, 2010).",
        "In contrast, the class labels extracted in our method exhibit greater syntactic diversity and are finer-grained.",
        "In addition, they are not constrained to a particular set of categories available in resources like Wikipedia.",
        "Fine-grained class labels roughly correspond to queries submitted in typed search (Demartini et al., 2009) or entity search (Balog et al., 2010) or list-seeking questions (?name the circuit judges in the cayman islands that are british?).",
        "But our focus is on generating, rather than answering such queries or, more generally, attempting to deeply understand their semantics (Li, 2010).",
        "Phrase similarities can be derived with any methods, using documents (Lin and Wu, 2009) or search queries (Jain and Pennacchiotti, 2010).",
        "Whether Web search queries are a useful textual data source for open-domain information extraction has been investigated in several tasks.",
        "Examples are collecting unlabeled sets of similar instances (Jain and Pennacchiotti, 2010), ranking of class labels already extracted from text (Pas?ca, 2010), extracting attributes of instances (Alfonseca et al., 2010) and identifying the occurrences in queries of instances of several types, where the types are defined in a manually-created resource (Pantel et al., 2012).",
        "Comparatively, we show that queries are useful in identifying possible class labels, not only re-ranking them; and even in populating the class labels with relevant, albeit small, sets of corresponding instances.",
        "As automatically-extracted class labels become finer-grained, they more clearly illustrate a phenomenon that received little attention.",
        "Namely, class labels of an instance, on one hand, and relations linking the instance with other instances and classes, on the other hand, are not mutually exclusive pieces of knowledge.",
        "Their extraction does not necessarily require different, dedicated techniques.",
        "Quite the opposite, class labels serve in text as nothing more than convenient lexical representations, or lexical shorthands, of relations linking instances with other instances.",
        "The class labels ?no front license plate states?",
        "and ?states with no front license plate requirement?",
        "are applicable to arizona.",
        "If so, it is because arizona is a state, and states require the installation of license plates on vehicles, and the requirement does not apply to the front of vehicles in the case of arizona.",
        "The connection between class labels and relations has been judiciously exploited in (Nastase and Strube, 2008).",
        "In that study, relations encoded implicitly within Wikipedia categories are transformed into explicit relations.",
        "As an example, the explicit relation that deconstruct-ing harry is directed by woody allen is obtained from the fact that deconstructing harry is listed under ?movies directed by woody allen?",
        "in Wikipedia.",
        "Ours is the first approach to examine the potential for extracting relations from search queries, where relations are compactly and loosely folded into the respective class labels.",
        "A variety of methods address the more general task of acquisition of open-domain relations from documents, e.g., (Zhu et al., 2009; Carlson et al., 2010; Fader et al., 2011; Lao et al., 2011)."
      ]
    },
    {
      "heading": "7 Conclusion",
      "text": [
        "The approach introduced in this paper exploits knowledge loosely encoded within Web search queries.",
        "It acquires a vocabulary of class labels that are finer grained than in previous literature.",
        "The class labels have precision comparable to that of class labels derived from human-created knowledge repositories.",
        "Furthermore, representative instances are extracted from queries for the fine-grained class labels, at encouraging levels of accuracy.",
        "Current work explores the use of noisy syntactic features to increase the accuracy of extracted class labels; the extraction of instances from evidence in multiple, rather than single queries; the expansion of extracted instances into larger sets; and the conversion of fine-grained class labels into relations among classes."
      ]
    }
  ]
}
